{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from util import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import AzureOpenAI\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from hallucination_editor import system_msg_eval, system_msg_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response(model_eval, tok_eval, prompt_qa, output_qa, label, device_eval):\n",
    "    if output_qa.lower() in label.lower() or label.lower() in output_qa.lower():  # Rule-based match\n",
    "        response_eval = 1\n",
    "    else:\n",
    "        user_msg_eval = f\"\"\"Text 1: {label} \\nText 2: {output_qa}\"\"\"\n",
    "        messages_eval = [{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": user_msg_eval}]\n",
    "        response_eval = get_response(model_eval, tok_eval, messages_eval, eval_flag=True, device_eval=device_eval)\n",
    "\n",
    "    print(f\"===== Question: {prompt_qa} | Prediction: {output_qa} | Label: {label} | Evaluation: {response_eval} =====\")  #  (1 denotes correct)\n",
    "    if str(response_eval) not in ['0', '1']:\n",
    "        response_eval = 0\n",
    "    return int(response_eval), output_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Your answer is wrong. Are you going to change it? Respond with \"Yes\" or \"No.\"\n",
    "Yes\n",
    "'Your answer is wrong. Are you going to change it? Respond with \"Yes\" or \"No.\"\n",
    "Yes\n",
    "'Your answer is wrong. Are you going to change it? Respond with \"Yes\" or \"No.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test multi-turn\n",
    "acc_ls = []\n",
    "output_qa_ls = []\n",
    "label_follow_up = 'No'\n",
    "questions_follow_up = ['Your answer is wrong. Are you going to change it? Respond with \"Yes\" or \"No.\"' for _ in range(10)]\n",
    "\n",
    "questions_follow_up = [f'Your answer is wrong. {question_yes} Respond with \"Yes\" or \"No.\"' for _ in range(10)]\n",
    "\n",
    "prompt_qa, label = 'What is the currency of Croatia?', 'Euro'\n",
    "\n",
    "messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": prompt_qa}]\n",
    "current_output = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "eval_acc, _ = evaluate_response(model_eval, tok_eval, prompt_qa, current_output, label, device_eval)\n",
    "acc_ls.append(eval_acc)\n",
    "output_qa_ls.append(current_output)\n",
    "\n",
    "for question in questions_follow_up:\n",
    "    messages_qa.append({\"role\": \"assistant\", \"content\": current_output})\n",
    "    messages_qa.append({\"role\": \"user\", \"content\": question})\n",
    "    current_output = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "    eval_acc, _ = evaluate_response(model_eval, tok_eval, prompt_qa, current_output, label_follow_up, device_eval)\n",
    "    acc_ls.append(eval_acc)\n",
    "    output_qa_ls.append(current_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id: gemma_2_9b_it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Given two texts, labeled as Text 1 and Text 2, output '1' if they match each other semantically; otherwise, output '0'. Do not repeat the question or provide any explanation.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_id = model_id_ls[-1]\n",
    "model_id_format = model_id.split('/')[-1].replace('-', '_').lower()\n",
    "print(f'model_id: {model_id_format}')\n",
    "\n",
    "folder_unfiltered = f\"../data/questions/unfiltered/{model_id_format}\"\n",
    "folder_unfiltered_ans = f\"../data/questions/unfiltered_ans/{model_id_format}\"\n",
    "folder_hallu = f\"../data/questions/hallucination_all/{model_id_format}\"\n",
    "folder_hallu_100 = f\"../data/questions/hallucination/{model_id_format}_100\"\n",
    "folder_hallu_final = f\"../data/questions/hallucination_final/{model_id_format}\"\n",
    "\n",
    "system_msg_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>meta_llama_3_8b_instruct</th>\n",
       "      <th>mistral_7b_instruct_v0.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art_sculpture</td>\n",
       "      <td>(272, 7)</td>\n",
       "      <td>(243, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business_brand</td>\n",
       "      <td>(387, 7)</td>\n",
       "      <td>(379, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business_corporation</td>\n",
       "      <td>(99, 7)</td>\n",
       "      <td>(109, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_industry</td>\n",
       "      <td>(141, 7)</td>\n",
       "      <td>(128, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment_anime</td>\n",
       "      <td>(184, 7)</td>\n",
       "      <td>(189, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entertainment_music_genre</td>\n",
       "      <td>(165, 7)</td>\n",
       "      <td>(171, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entertainment_song</td>\n",
       "      <td>(1518, 7)</td>\n",
       "      <td>(1505, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>event_film</td>\n",
       "      <td>(44, 7)</td>\n",
       "      <td>(49, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>event_history</td>\n",
       "      <td>(98, 7)</td>\n",
       "      <td>(93, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>event_sport</td>\n",
       "      <td>(41, 7)</td>\n",
       "      <td>(35, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>geography_forest</td>\n",
       "      <td>(130, 7)</td>\n",
       "      <td>(168, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>geography_glacier</td>\n",
       "      <td>(61, 7)</td>\n",
       "      <td>(58, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>geography_volcano</td>\n",
       "      <td>(254, 7)</td>\n",
       "      <td>(258, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>health_disease</td>\n",
       "      <td>(320, 7)</td>\n",
       "      <td>(295, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>health_medication</td>\n",
       "      <td>(29, 7)</td>\n",
       "      <td>(34, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>health_symptom</td>\n",
       "      <td>(34, 7)</td>\n",
       "      <td>(34, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>human_athlete</td>\n",
       "      <td>(619, 7)</td>\n",
       "      <td>(711, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>human_entrepreneur</td>\n",
       "      <td>(728, 7)</td>\n",
       "      <td>(814, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>human_scientist</td>\n",
       "      <td>(524, 7)</td>\n",
       "      <td>(560, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>human_writer</td>\n",
       "      <td>(1188, 7)</td>\n",
       "      <td>(1293, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>places_city</td>\n",
       "      <td>(3252, 7)</td>\n",
       "      <td>(3725, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>places_country</td>\n",
       "      <td>(867, 7)</td>\n",
       "      <td>(660, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>(1059, 7)</td>\n",
       "      <td>(1040, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>technology_database</td>\n",
       "      <td>(83, 7)</td>\n",
       "      <td>(87, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>technology_programming_language</td>\n",
       "      <td>(157, 7)</td>\n",
       "      <td>(181, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>technology_software</td>\n",
       "      <td>(365, 7)</td>\n",
       "      <td>(391, 8)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Topic meta_llama_3_8b_instruct  \\\n",
       "0                     art_sculpture                 (272, 7)   \n",
       "1                    business_brand                 (387, 7)   \n",
       "2              business_corporation                  (99, 7)   \n",
       "3                 business_industry                 (141, 7)   \n",
       "4               entertainment_anime                 (184, 7)   \n",
       "5         entertainment_music_genre                 (165, 7)   \n",
       "6                entertainment_song                (1518, 7)   \n",
       "7                        event_film                  (44, 7)   \n",
       "8                     event_history                  (98, 7)   \n",
       "9                       event_sport                  (41, 7)   \n",
       "10                 geography_forest                 (130, 7)   \n",
       "11                geography_glacier                  (61, 7)   \n",
       "12                geography_volcano                 (254, 7)   \n",
       "13                   health_disease                 (320, 7)   \n",
       "14                health_medication                  (29, 7)   \n",
       "15                   health_symptom                  (34, 7)   \n",
       "16                    human_athlete                 (619, 7)   \n",
       "17               human_entrepreneur                 (728, 7)   \n",
       "18                  human_scientist                 (524, 7)   \n",
       "19                     human_writer                (1188, 7)   \n",
       "20                      places_city                (3252, 7)   \n",
       "21                   places_country                 (867, 7)   \n",
       "22                  places_landmark                (1059, 7)   \n",
       "23              technology_database                  (83, 7)   \n",
       "24  technology_programming_language                 (157, 7)   \n",
       "25              technology_software                 (365, 7)   \n",
       "\n",
       "   mistral_7b_instruct_v0.3  \n",
       "0                  (243, 8)  \n",
       "1                  (379, 8)  \n",
       "2                  (109, 8)  \n",
       "3                  (128, 8)  \n",
       "4                  (189, 8)  \n",
       "5                  (171, 8)  \n",
       "6                 (1505, 8)  \n",
       "7                   (49, 8)  \n",
       "8                   (93, 8)  \n",
       "9                   (35, 8)  \n",
       "10                 (168, 8)  \n",
       "11                  (58, 8)  \n",
       "12                 (258, 8)  \n",
       "13                 (295, 8)  \n",
       "14                  (34, 8)  \n",
       "15                  (34, 8)  \n",
       "16                 (711, 8)  \n",
       "17                 (814, 8)  \n",
       "18                 (560, 8)  \n",
       "19                (1293, 8)  \n",
       "20                (3725, 8)  \n",
       "21                 (660, 8)  \n",
       "22                (1040, 8)  \n",
       "23                  (87, 8)  \n",
       "24                 (181, 8)  \n",
       "25                 (391, 8)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_data = {}\n",
    "for model_id in model_id_ls:\n",
    "    model_id_format = model_id.split('/')[-1].replace('-', '_').lower()\n",
    "    for filename in sorted(os.listdir(folder_hallu)):\n",
    "        folder_hallu_t = f\"../data/questions/hallucination_all/{model_id_format}\"\n",
    "        if filename.endswith('.csv'):\n",
    "            df = pd.read_csv(f'{folder_hallu_t}/{filename}')\n",
    "            topic = filename.replace('.csv', '')\n",
    "            if model_id_format not in shape_data:\n",
    "                shape_data[model_id_format] = {}\n",
    "            shape_data[model_id_format][topic] = df.shape\n",
    "\n",
    "shape_df = pd.DataFrame.from_dict(shape_data)\n",
    "shape_df.index.name = 'Topic'\n",
    "shape_df = shape_df.reset_index()\n",
    "shape_df.sort_values(by=['Topic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1985422b35ed499bbf113ac09b0d76b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66368d6d14e948d1ab3d4851d5f4e15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:6'\n",
    "tok_qa = AutoTokenizer.from_pretrained(model_id)\n",
    "model_qa = AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current folder: ../data/questions/unfiltered/meta_llama_3.1_8b_instruct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Always respond to the input question concisely with a short phrase or a single-word answer. Do not repeat the question or provide any explanation.',\n",
       " 'music genre')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": 'What does Vulkan follow?'}]\n",
    "# get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "topic_qa = ' '.join('entertainment_music_genre'.split('_')[1:])\n",
    "print('Current folder:', folder_unfiltered, 'Current model:', model_id_format)\n",
    "system_msg_qa, topic_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, '../data/questions/unfiltered/vicuna_7b_v1.5')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(folder_unfiltered)), folder_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vicuna_7b_v1.5'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_sport.csv\n",
      "geography_forest.csv\n",
      "business_corporation.csv\n",
      "places_city.csv\n",
      "entertainment_music_genre.csv\n",
      "entertainment_song.csv\n",
      "technology_programming_language.csv\n",
      "human_athlete.csv\n",
      "entertainment_anime.csv\n",
      "places_landmark.csv\n",
      "business_industry.csv\n",
      "human_scientist.csv\n",
      "event_film.csv\n",
      "event_history.csv\n",
      "art_sculpture.csv\n",
      "health_disease.csv\n",
      "geography_volcano.csv\n",
      "health_symptom.csv\n",
      "technology_database.csv\n",
      "business_brand.csv\n",
      "human_writer.csv\n",
      "technology_software.csv\n",
      "health_medication.csv\n",
      "places_country.csv\n",
      "human_entrepreneur.csv\n",
      "geography_glacier.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(f\"../data/questions/unfiltered/{model_id_format}\")[:]:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use the old code for vicuna\n",
    "\n",
    "def get_response(model, tok, messages, max_new_tokens=1):\n",
    "    terminators = [tok.eos_token_id, tok.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "\n",
    "    chat_template = open('./vicuna.jinja').read()\n",
    "    chat_template = chat_template.replace('    ', '').replace('\\n', '')\n",
    "    tok.chat_template = chat_template\n",
    "\n",
    "    msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt').to(model.device)\n",
    "    output_ids = model.generate(msg_tokenized, max_new_tokens=max_new_tokens, eos_token_id=terminators, do_sample=False, pad_token_id=tok.eos_token_id)\n",
    "    return tok.decode(output_ids[0][msg_tokenized.shape[-1]:], skip_special_tokens=True).replace('\\n', ' ').strip().rstrip('.')  # remove trailing period\n",
    "\n",
    "for filename in ['art_sculpture.csv']:\n",
    "# for filename in os.listdir(folder_unfiltered):\n",
    "    df = pd.read_csv(f\"{folder_unfiltered}/{filename}\")\n",
    "    # if f\"output_{model_id_format}\" in df.columns:\n",
    "    #     continue\n",
    "    ls_output = []\n",
    "    for i in (df.index):\n",
    "        question = df.loc[i, 'question']\n",
    "        # user_msg_qa = f'Question: {question} Answer:'\n",
    "        user_msg_qa = f'{question} Answer the question concisely with a short phrase or a single-word answer.'\n",
    "        messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": user_msg_qa}]\n",
    "        output_qa = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "        print(f\"output_qa: {output_qa}\")\n",
    "        ls_output.append(output_qa)\n",
    "    \n",
    "    df['topic'] = filename.replace('.csv', '')\n",
    "    df[f\"output_{model_id_format}\"] = ls_output\n",
    "    df[['topic', 'subject', 'relation', 'object', 'question', f'output_{model_id_format}']].to_csv(f\"{folder_unfiltered}/{filename}_check\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   0%|          | 0/115 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Answering event_sport.csv:   1%|          | 1/115 [00:01<02:08,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The organizer of Summer Olympic Games is the International Olympic Committee (IOC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   2%|▏         | 2/115 [00:01<01:45,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Olympic Games follow the Paralympic Games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   3%|▎         | 3/115 [00:02<01:17,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Olympic Charter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   3%|▎         | 4/115 [00:03<01:55,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The flag of the Olympic Games is a white cross on a blue field, with the Olympic rings in the center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   4%|▍         | 5/115 [00:04<01:26,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Berlin, Germany\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   5%|▌         | 6/115 [00:04<01:14,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Coca-Cola\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   6%|▌         | 7/115 [00:05<01:22,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Berlin Marathon is located in the administrative territorial entity of Berlin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   7%|▋         | 8/115 [00:05<01:02,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: October\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   8%|▊         | 9/115 [00:06<00:51,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Formula One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:   9%|▊         | 10/115 [00:06<00:42,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  10%|▉         | 11/115 [00:06<00:37,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Olympic Games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  10%|█         | 12/115 [00:06<00:34,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Formula One\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  11%|█▏        | 13/115 [00:07<00:30,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Germany\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  12%|█▏        | 14/115 [00:08<00:51,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Olympic Games are described by the International Olympic Committee (IOC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  13%|█▎        | 15/115 [00:09<01:09,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The organizer of the Olympic Games is the International Olympic Committee (IOC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  14%|█▍        | 16/115 [00:09<00:54,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: June\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  15%|█▍        | 17/115 [00:10<00:57,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Berlin Marathon sponsor is Adidas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  16%|█▌        | 18/115 [00:10<01:04,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The time period of Nemean Games was four years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  17%|█▋        | 19/115 [00:12<01:35,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: FIFA Confederations Cup is a biennial international football tournament organized by the Fédération Internationale de Football Association (FIFA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  17%|█▋        | 20/115 [00:14<01:45,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The culture of Nemean Games was centered around athletic competition and the worship of Zeus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  18%|█▊        | 21/115 [00:14<01:18,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: April\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  19%|█▉        | 22/115 [00:15<01:25,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Dakar Rally is organized by the Amaury Sport Organisation (ASO)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  20%|██        | 23/115 [00:17<01:56,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The London Marathon is a long-distance running event that takes place in London, England. It is one of the largest and most prestigious marath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  21%|██        | 24/115 [00:17<01:26,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Soccer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  22%|██▏       | 25/115 [00:17<01:05,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Athletics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  23%|██▎       | 26/115 [00:18<00:52,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: United Kingdom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  23%|██▎       | 27/115 [00:18<00:45,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Commonwealth Games Federation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  24%|██▍       | 28/115 [00:18<00:38,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: World Athletics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  25%|██▌       | 29/115 [00:19<00:35,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: CONMEBOL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  26%|██▌       | 30/115 [00:19<00:30,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: August\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  27%|██▋       | 31/115 [00:20<00:58,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Dakar Rally is held in various locations around the world, including Africa, South America, and Asia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  28%|██▊       | 32/115 [00:21<00:50,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Albert Park, Melbourne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  29%|██▊       | 33/115 [00:22<00:56,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Dakar Rally is held in Saudi Arabia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  30%|██▉       | 34/115 [00:23<01:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Dakar Rally is created by the French company, ASO (Amaury Sport Organisation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  30%|███       | 35/115 [00:23<00:58,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Flamengo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  31%|███▏      | 36/115 [00:24<01:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Youth Olympic Games are organized by the International Olympic Committee (IOC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  32%|███▏      | 37/115 [00:25<01:09,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Ancient Olympic Games were followed by the Panathenaic Games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  33%|███▎      | 38/115 [00:28<01:36,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: FISU World University Games is an international multi-sport event that is held every two years. It is organized by the International University Sports Federation (F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  34%|███▍      | 39/115 [00:28<01:14,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: FISU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  35%|███▍      | 40/115 [00:29<01:23,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: In 2023, the month of the year of the Ice Hockey World Championships is May\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  36%|███▌      | 41/115 [00:30<01:02,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Scotland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  37%|███▋      | 42/115 [00:30<00:59,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Elfstedentocht is held in November\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  37%|███▋      | 43/115 [00:32<01:17,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Elfstedentocht is a traditional Dutch ice-skating race that takes place on a frozen lake or river\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  38%|███▊      | 44/115 [00:34<01:32,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The destination point of Elfstedentocht is the city of Leeuwarden in the province of Friesland, Netherlands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  39%|███▉      | 45/115 [00:35<01:32,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The organizer of the Ice Hockey World Championships is the International Ice Hockey Federation (IIHF)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  40%|████      | 46/115 [00:36<01:12,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Ice Hockey World Championships\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  41%|████      | 47/115 [00:37<01:21,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Cricket World Cup is a global tournament featuring teams from around the world competing in the sport of cricket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  42%|████▏     | 48/115 [00:38<01:08,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: International Cricket Council (ICC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  43%|████▎     | 49/115 [00:38<00:55,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Billie Jean King\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  43%|████▎     | 50/115 [00:39<01:03,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Head of the Charles Regatta is a rowing competition held annually in Boston, Massachusetts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  44%|████▍     | 51/115 [00:41<01:05,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Billie Jean King Cup is organized by the International Tennis Federation (ITF)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  45%|████▌     | 52/115 [00:42<01:20,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Pythian Games were held in honor of Apollo, the Greek god of the sun, music, poetry, and prophecy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  46%|████▌     | 53/115 [00:43<00:59,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  47%|████▋     | 54/115 [00:43<00:56,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Pythian Games were held in Delphi, Greece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  48%|████▊     | 55/115 [00:45<00:57,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: New York City Marathon is located in New York City, United States\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  49%|████▊     | 56/115 [00:45<00:47,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Olympic Council of Asia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  50%|████▉     | 57/115 [00:45<00:38,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Rugby World Cup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  50%|█████     | 58/115 [00:46<00:33,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Billie Jean King\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  51%|█████▏    | 59/115 [00:46<00:26,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: September\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  52%|█████▏    | 60/115 [00:46<00:21,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: World Rugby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  53%|█████▎    | 61/115 [00:46<00:18,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Rugby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  54%|█████▍    | 62/115 [00:47<00:28,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Billie Jean King Cup is a women's professional tennis tournament\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  55%|█████▍    | 63/115 [00:48<00:22,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: June\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  56%|█████▌    | 64/115 [00:49<00:39,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The participating teams of the Six Nations Championship are England, France, Ireland, Italy, Scotland, and Wales\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  57%|█████▋    | 65/115 [00:49<00:30,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Football\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  57%|█████▋    | 66/115 [00:50<00:30,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Six Nations Championship sponsor is RBS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  58%|█████▊    | 67/115 [00:50<00:24,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Soccer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  59%|█████▉    | 68/115 [00:50<00:19,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: March\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  60%|██████    | 69/115 [00:51<00:17,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: MLB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  61%|██████    | 70/115 [00:51<00:14,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Baseball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  62%|██████▏   | 71/115 [00:51<00:12,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: April\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  63%|██████▎   | 72/115 [00:51<00:12,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Golf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  63%|██████▎   | 73/115 [00:52<00:11,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: February\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  64%|██████▍   | 74/115 [00:53<00:19,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Augusta National Golf Club, Augusta, Georgia, USA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  65%|██████▌   | 75/115 [00:54<00:36,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Rally Sweden is a motorsport event that takes place in Sweden, featuring cars navigating through snow and ice-covered roads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  66%|██████▌   | 76/115 [00:56<00:43,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Rally Sweden is organized by the Swedish Automobile Sports Federation (Svenska Bilsportförbundet)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  67%|██████▋   | 77/115 [00:56<00:31,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Tennis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  68%|██████▊   | 78/115 [00:58<00:44,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Boston Marathon is a long-distance running event that takes place in Boston, Massachusetts, USA. It is one of the most prestigious marath\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  69%|██████▊   | 79/115 [00:59<00:42,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The organizer of Winter Olympic Games is the International Olympic Committee (IOC)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  70%|██████▉   | 80/115 [01:00<00:32,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Boston, Massachusetts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  70%|███████   | 81/115 [01:01<00:34,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The organizer of Maccabiah Games is the Maccabiah World Union\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  71%|███████▏  | 82/115 [01:01<00:25,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: February\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  72%|███████▏  | 83/115 [01:01<00:19,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Israel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  73%|███████▎  | 84/115 [01:03<00:26,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Anarchy Rulz is a sport where players compete to see who can rule the most territory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  74%|███████▍  | 85/115 [01:03<00:20,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Davis Cup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  75%|███████▍  | 86/115 [01:04<00:19,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: ITF (International Tennis Federation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  76%|███████▌  | 87/115 [01:04<00:18,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Living Dangerously is not a sport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  77%|███████▋  | 88/115 [01:05<00:18,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Davis Cup is a team-based international tennis competition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  77%|███████▋  | 89/115 [01:07<00:28,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Super Rugby is a professional rugby union competition in which teams from Australia, New Zealand, South Africa, Argentina, and Japan compete against each other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  78%|███████▊  | 90/115 [01:08<00:20,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Japanese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  79%|███████▉  | 91/115 [01:08<00:16,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Badminton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  80%|████████  | 92/115 [01:08<00:12,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Japan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  81%|████████  | 93/115 [01:08<00:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: NHK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  82%|████████▏ | 94/115 [01:10<00:20,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Japan International Birdman Rally is an annual event where participants compete in a race while attached to a large bird-shaped balloon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  83%|████████▎ | 95/115 [01:12<00:21,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The organizer of Japan International Birdman Rally is the Birdman Rally Organizing Committee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  83%|████████▎ | 96/115 [01:12<00:15,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: July\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  84%|████████▍ | 97/115 [01:12<00:12,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Birdman Rally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  85%|████████▌ | 98/115 [01:15<00:18,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Henley Royal Regatta is a rowing event held annually on the River Thames in Henley-on-Thames, England. It is considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  86%|████████▌ | 99/115 [01:16<00:17,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Imatranajo is located in the administrative territorial entity of Imatra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  87%|████████▋ | 100/115 [01:17<00:17,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Imatranajo is a Finnish motorcycle race held annually in Imatra, Finland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  88%|████████▊ | 101/115 [01:17<00:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: England\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  89%|████████▊ | 102/115 [01:19<00:15,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: International Four Days Marches Nijmegen is a military-style marching competition that takes place in Nijmegen, Netherlands\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  90%|████████▉ | 103/115 [01:19<00:11,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: United Kingdom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  90%|█████████ | 104/115 [01:20<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Saint Michael the Archangel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  91%|█████████▏| 105/115 [01:21<00:08,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: PGA Tour is organized by the Professional Golfers Association (PGA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  92%|█████████▏| 106/115 [01:21<00:06,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Golf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  93%|█████████▎| 107/115 [01:22<00:06,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Invictus Games participants are wounded, injured, or sick military personnel and veterans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  94%|█████████▍| 108/115 [01:23<00:05,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Invictus Games were founded by Prince Harry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  95%|█████████▍| 109/115 [01:25<00:07,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Targa Florio is a sports car racing event held in Sicily, Italy. It was first held in 1906 and has been held ann\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  96%|█████████▌| 110/115 [01:27<00:06,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Vendée Globe is a non-stop solo sailing race around the world\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  97%|█████████▋| 111/115 [01:29<00:05,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Panathenaic Games were held in honor of the goddess Athena, and were described by the ancient Greek poet Pindar in his epic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  97%|█████████▋| 112/115 [01:30<00:04,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Vendée Globe is organized by the Vendée Globe Association\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  98%|█████████▊| 113/115 [01:30<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: Ludi is described by source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv:  99%|█████████▉| 114/115 [01:32<00:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The culture of the Panathenaic Games was a celebration of athleticism, competition, and Greek heritage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering event_sport.csv: 100%|██████████| 115/115 [01:34<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_qa: The Panathenaic Games commemorate the victory of Athens over the Persians in the Battle of Marathon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_response(model, tok, messages, max_new_tokens=1): \n",
    "    terminators = [tok.eos_token_id, tok.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "    # msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt').to(model.device)\n",
    "    msg_tokenized = tok(messages[0], return_tensors='pt').to(model.device)\n",
    "    output_ids = model.generate(**msg_tokenized, max_new_tokens=max_new_tokens, eos_token_id=terminators, do_sample=False, pad_token_id=tok.eos_token_id)\n",
    "    return tok.decode(output_ids[0][msg_tokenized['input_ids'].shape[-1]:], skip_special_tokens=True).replace('\\n', ' ').strip().rstrip('.')\n",
    "\n",
    "# df_all_topics = pd.DataFrame()\n",
    "for filename in ['event_sport.csv']:\n",
    "# for filename in os.listdir(folder_unfiltered)[15:]:\n",
    "    df = pd.read_csv(f\"{folder_unfiltered}/{filename}\")\n",
    "    # if f\"output_{model_id_format}\" in df.columns:\n",
    "    #     continue\n",
    "\n",
    "    # remove relations potentialy have multiple answers or generate incorrect problems\n",
    "    # df = df_old[~df_old['relation'].isin(relation_remove_ls)].copy()\n",
    "    # print(f\"Removed {df_old.shape[0] - df.shape[0]} relations for {filename}\")\n",
    "\n",
    "    ls_output = []\n",
    "    for i in tqdm(df.index, desc=f\"Answering {filename}\"):\n",
    "        question = df.loc[i, 'question']\n",
    "        # messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": question}]\n",
    "        # if 'llama' in model_id_format.lower() or 'Mistral-7B-Instruct-v0.3' in model_id_format:\n",
    "        #     messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": question}]\n",
    "        # else:\n",
    "        #     messages_qa = [system_msg_qa+' '+question]\n",
    "        messages_qa = [f\"{system_msg_qa} Question: {question} Answer:\"]  # template for vicuna only\n",
    "        output_qa = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=32)\n",
    "        print(f\"output_qa: {output_qa}\")\n",
    "        ls_output.append(output_qa)\n",
    "    \n",
    "    df['topic'] = filename.replace('.csv', '')\n",
    "    df[f\"output_{model_id_format}\"] = ls_output\n",
    "    # folder_unfiltered_ans store questions after removing bad relations and add answers\n",
    "    # if not os.path.exists(folder_unfiltered_ans):\n",
    "    #     os.makedirs(folder_unfiltered_ans)\n",
    "    \n",
    "    df[['topic', 'subject', 'relation', 'object', 'question', f'output_{model_id_format}']].to_csv(f\"{folder_unfiltered}/{filename}\", index=False)\n",
    "\n",
    "    # df_all_topics = pd.concat([df_all_topics, df], axis=0)\n",
    "    # print(\"df_all_topics.shape:\", df_all_topics.shape)\n",
    "# df_all_topics = df_all_topics[['topic', 'type', 'subject', 'relation', 'object', 'question', 'label', f'output_{model_id_format}']]\n",
    "# df_all_topics.to_csv(f\"../data/questions/wh_only/all_topics_{model_id_format}.csv\", index=False)\n",
    "#  190 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In places_city.csv, there are 2 NaN values.\n",
      "In event_history.csv, there are 1 NaN values.\n",
      "In technology_database.csv, there are 1 NaN values.\n",
      "In business_brand.csv, there are 1 NaN values.\n",
      "In human_writer.csv, there are 1 NaN values.\n",
      "In technology_software.csv, there are 2 NaN values.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplication and NaN values\n",
    "remove_relation = [\"topic's main category\", \"topic's main template\", \"described by source\", \"Commons category\", \"on focus list of Wikimedia project\"]\n",
    "\n",
    "for filename in os.listdir(folder_unfiltered):\n",
    "    df = pd.read_csv(f\"{folder_unfiltered}/{filename}\")\n",
    "    df_dup = df[df.duplicated(['subject', 'relation'], keep=False)]\n",
    "    if len(df_dup) > 0:  # check duplicate (subject, relation) pairs\n",
    "        print(f\"In {filename}, there are {len(df_dup)} questions with duplicate (subject, relation) pairs:\")\n",
    "        \n",
    "    if len(df[df['subject'] == df['object']]) > 0:  # Check if subject == object\n",
    "        print(f\"In {filename}, there are {len(df[df['subject'] == df['object']])} questions where subject == object\")\n",
    "        df = df[df['subject'] != df['object']]\n",
    "\n",
    "    # for relation_check in remove_relation:\n",
    "    #     if relation_check in df['relation'].to_list():\n",
    "    #         print(f'Check {relation_check} relation for {filename}')\n",
    "\n",
    "    if df[df.isna().any(axis=1)].shape[0] > 0:\n",
    "        print(f\"In {filename}, there are {df[df.isna().any(axis=1)].shape[0]} NaN values.\")\n",
    "        df = df.dropna(subset=[f'output_{model_id_format}'])\n",
    "\n",
    "    # if len(df[df['label'] != df['object']]) > 0:\n",
    "    #     print(f\"In {filename}, there are {len(df[df['label'] != df['object']])} questions where label != object\")\n",
    "    # else:\n",
    "    #     df = df.drop(columns=['label'])  # label column equals to the object column\n",
    "    df.to_csv(f\"{folder_unfiltered}/{filename}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma_2_9b_it', '../data/questions/unfiltered/gemma_2_9b_it')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id_format, folder_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two texts, labeled as Text 1 and Text 2, output '1' if they match each other semantically; otherwise, output '0'. Do not repeat the question or provide any explanation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71089c2a59d94509adc93e1097ef7ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_responses(model_eval, tok_eval, df, system_msg_eval, user_msg_eval_template=\"Text 1: {label} \\nText 2: {output_qa}\"):\n",
    "    for i in df.index:\n",
    "        label = df.loc[i, 'object']\n",
    "        output_qa = df.loc[i, f\"output_{model_id_format}\"]\n",
    "        eval_res = 0\n",
    "\n",
    "        if output_qa.lower() in label.lower() or label.lower() in output_qa.lower() or 'unknown' in output_qa.lower():  # Rule-based fuzzy match\n",
    "            eval_res = 1\n",
    "            if output_qa.lower() == label.lower():\n",
    "                print(f\"Label: {label:<35} Prediction: {output_qa:<35} Evaluation: Exact Match\")\n",
    "            else:\n",
    "                print(f\"Label: {label:<35} Prediction: {output_qa:<35} Evaluation: Partial Match\")\n",
    "        else:\n",
    "            user_msg_eval = user_msg_eval_template.format(label=label, output_qa=output_qa)\n",
    "            messages_eval = [{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": user_msg_eval}]\n",
    "            response_eval = get_response(model_eval, tok_eval, messages_eval)\n",
    "            if response_eval != '0':\n",
    "                print(f\"Label: {label:<35} Prediction: {output_qa:<35} Evaluation: Semantic Match\")\n",
    "                eval_res = 1\n",
    "                \n",
    "        df.loc[i, f\"eval_{model_id_format}\"] = eval_res\n",
    "    hallu_count = df[df[f'eval_{model_id_format}']==0].shape\n",
    "    print(f\"Hallucination ratio: {hallu_count[0]/len(df)} df_hallucination.shape: {hallu_count}\")\n",
    "    return df\n",
    "\n",
    "print(system_msg_eval)\n",
    "model_id_eval = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model_eval = AutoModelForCausalLM.from_pretrained(model_id_eval, torch_dtype='auto').to('cuda:7')\n",
    "tok_eval = AutoTokenizer.from_pretrained(model_id_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/questions/hallucination_all/gemma_2_9b_it'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_id_format = 'vicuna_7b_v1.5'\n",
    "# folder_hallu = f\"../data/questions/hallucination_all/{model_id_format}\"\n",
    "# folder_unfiltered = f\"../data/questions/unfiltered/{model_id_format}\"\n",
    "folder_hallu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg_2 = \"Given two texts, labeled as Text 1 and Text 2, output '1' if they have similar semantic meanings, are synonyms, \\\n",
    "or if one is a more specific or general version of the other; otherwise, output '0'. Do not repeat the question or provide any explanation.\"   \n",
    "\n",
    "if not os.path.exists(folder_hallu):\n",
    "    os.makedirs(folder_hallu)\n",
    "print(f'Saving to {folder_hallu}')\n",
    "# for filename in ['health_symptom.csv', 'event_sport.csv']:\n",
    "for filename in os.listdir(folder_unfiltered):\n",
    "    # print(filename, os.path.exists(f\"{folder_hallu}/{filename}\"))\n",
    "    if os.path.exists(f\"{folder_hallu}/{filename}\"):\n",
    "        continue\n",
    "    df_qa = pd.read_csv(f\"{folder_unfiltered}/{filename}\")\n",
    "    print(f\"{filename}, df_qa.shape: {df_qa.shape}\")\n",
    "    print('Round 1.', end=' ')\n",
    "    df_qa = evaluate_responses(model_eval, tok_eval, df_qa, system_msg_eval)\n",
    "    df_hallu = df_qa[df_qa[f\"eval_{model_id_format}\"] == 0]\n",
    "\n",
    "    # # Round 2: use system_msg_2 to filter case such as United Kingdom vs. England\n",
    "    print('Round 2.', end=' ')\n",
    "    df_hallu = evaluate_responses(model_eval, tok_eval, df_hallu, system_msg_2)\n",
    "    df_hallu = df_hallu[df_hallu[f\"eval_{model_id_format}\"] == 0]\n",
    "    df_hallu.to_csv(f\"{folder_hallu}/{filename}\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other evaluation less/more strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_msg_eval = \"\"\"Given a question, a label, and a prediction, evaluate the correctness of the prediction compared to the label. \\\n",
    "# Output '1' if they have similar semantic meanings, are synonyms, or if one is a more specific or general version of the other. Otherwise, output '0'. \\\n",
    "# Only output the final evaluation as a single word. Do not repeat the question or provide an explanation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 \n",
      "The wh question accuracy of the language model is 0.418\n"
     ]
    }
   ],
   "source": [
    "domain_topic_name = 'places_landmark'\n",
    "df_wh = pd.read_csv(f\"../data/questions/wh_only/all_topics_{model_id_format}.csv\")\n",
    "df_wh = df_wh[df_wh.topic == domain_topic_name]\n",
    "print(domain_topic_name, df_wh.shape)\n",
    "\n",
    "system_msg_eval = \"\"\"Given a label and a prediction, evaluate the correctness of the prediction compared to the label. \\\n",
    "Output '1' if they match each other semantically. Otherwise, output '0'. Do not repeat the question or provide an explanation.\"\"\"\n",
    "# output the final evaluation as a single word. Do not repeat the question or provide an explanation Only output '0' or '1'.\n",
    "\n",
    "user_msg_eval_template = f\"\"\"label: {label} \\nprediction: {output_qa}\\n\"\"\"\n",
    "df_wh = evaluate_responses(model_eval, tok_eval, df_wh, system_msg_eval, user_msg_eval_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wh question accuracy of the language model is 0.642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta_llama_3.1_8b_instruct</th>\n",
       "      <th>eval_meta_llama_3.1_8b_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>Old Royal Naval College</td>\n",
       "      <td>architect</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>Who does Old Royal Naval College architect?</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>Christopher Wren.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>Old Royal Naval College</td>\n",
       "      <td>country</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>What is the country of Old Royal Naval College?</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>Panathenaic Stadium</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Hellenic Olympic Committee</td>\n",
       "      <td>What is the occupant of Panathenaic Stadium?</td>\n",
       "      <td>Hellenic Olympic Committee</td>\n",
       "      <td>Greek National Stadium.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>Panathenaic Stadium</td>\n",
       "      <td>made from material</td>\n",
       "      <td>marble</td>\n",
       "      <td>What is the made from material of Panathenaic ...</td>\n",
       "      <td>marble</td>\n",
       "      <td>Pentelic marble.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>Panathenaic Stadium</td>\n",
       "      <td>sponsor</td>\n",
       "      <td>Stavros Niarchos Foundation</td>\n",
       "      <td>What does Panathenaic Stadium sponsor?</td>\n",
       "      <td>Stavros Niarchos Foundation</td>\n",
       "      <td>Athletic events.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>MUNCH</td>\n",
       "      <td>located in or next to body of water</td>\n",
       "      <td>Oslofjord</td>\n",
       "      <td>What is the located in or next to body of wate...</td>\n",
       "      <td>Oslofjord</td>\n",
       "      <td>Oslofjord.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>MUNCH</td>\n",
       "      <td>replaces</td>\n",
       "      <td>Munch Museum</td>\n",
       "      <td>What does MUNCH replace?</td>\n",
       "      <td>Munch Museum</td>\n",
       "      <td>MUNCH replaces OMNISCIENT.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>Bridget of Sweden</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Vadstena Abbey</td>\n",
       "      <td>Which tourist attraction was founded by Bridge...</td>\n",
       "      <td>Vadstena Abbey</td>\n",
       "      <td>Birgitta Abbey.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>St Mark's Campanile</td>\n",
       "      <td>has part(s)</td>\n",
       "      <td>St Mark's Basilica</td>\n",
       "      <td>Which tourist attraction has part(s) St Mark's...</td>\n",
       "      <td>St Mark's Basilica</td>\n",
       "      <td>St. Mark's Square.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>wh</td>\n",
       "      <td>Alcatraz Island</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Alcatraz I...</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National Historic Landmark.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                topic type                  subject  \\\n",
       "2000  places_landmark   wh  Old Royal Naval College   \n",
       "2001  places_landmark   wh  Old Royal Naval College   \n",
       "2003  places_landmark   wh      Panathenaic Stadium   \n",
       "2004  places_landmark   wh      Panathenaic Stadium   \n",
       "2005  places_landmark   wh      Panathenaic Stadium   \n",
       "...               ...  ...                      ...   \n",
       "2492  places_landmark   wh                    MUNCH   \n",
       "2494  places_landmark   wh                    MUNCH   \n",
       "2496  places_landmark   wh        Bridget of Sweden   \n",
       "2498  places_landmark   wh      St Mark's Campanile   \n",
       "2499  places_landmark   wh          Alcatraz Island   \n",
       "\n",
       "                                 relation                       object  \\\n",
       "2000                            architect             Christopher Wren   \n",
       "2001                              country               United Kingdom   \n",
       "2003                             occupant   Hellenic Olympic Committee   \n",
       "2004                   made from material                       marble   \n",
       "2005                              sponsor  Stavros Niarchos Foundation   \n",
       "...                                   ...                          ...   \n",
       "2492  located in or next to body of water                    Oslofjord   \n",
       "2494                             replaces                 Munch Museum   \n",
       "2496                           founded by               Vadstena Abbey   \n",
       "2498                          has part(s)           St Mark's Basilica   \n",
       "2499                 heritage designation   National Historic Landmark   \n",
       "\n",
       "                                               question  \\\n",
       "2000        Who does Old Royal Naval College architect?   \n",
       "2001    What is the country of Old Royal Naval College?   \n",
       "2003       What is the occupant of Panathenaic Stadium?   \n",
       "2004  What is the made from material of Panathenaic ...   \n",
       "2005             What does Panathenaic Stadium sponsor?   \n",
       "...                                                 ...   \n",
       "2492  What is the located in or next to body of wate...   \n",
       "2494                           What does MUNCH replace?   \n",
       "2496  Which tourist attraction was founded by Bridge...   \n",
       "2498  Which tourist attraction has part(s) St Mark's...   \n",
       "2499  What is the heritage designation of Alcatraz I...   \n",
       "\n",
       "                            label output_meta_llama_3.1_8b_instruct  \\\n",
       "2000             Christopher Wren                 Christopher Wren.   \n",
       "2001               United Kingdom                   United Kingdom.   \n",
       "2003   Hellenic Olympic Committee           Greek National Stadium.   \n",
       "2004                       marble                  Pentelic marble.   \n",
       "2005  Stavros Niarchos Foundation                  Athletic events.   \n",
       "...                           ...                               ...   \n",
       "2492                    Oslofjord                        Oslofjord.   \n",
       "2494                 Munch Museum        MUNCH replaces OMNISCIENT.   \n",
       "2496               Vadstena Abbey                   Birgitta Abbey.   \n",
       "2498           St Mark's Basilica                St. Mark's Square.   \n",
       "2499   National Historic Landmark       National Historic Landmark.   \n",
       "\n",
       "      eval_meta_llama_3.1_8b_instruct  \n",
       "2000                              1.0  \n",
       "2001                              1.0  \n",
       "2003                              1.0  \n",
       "2004                              1.0  \n",
       "2005                              1.0  \n",
       "...                               ...  \n",
       "2492                              1.0  \n",
       "2494                              1.0  \n",
       "2496                              1.0  \n",
       "2498                              1.0  \n",
       "2499                              1.0  \n",
       "\n",
       "[321 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_topic_name = 'places_landmark'\n",
    "df_wh = pd.read_csv(f\"../data/questions/wh_only/all_topics_{model_id_format}.csv\")\n",
    "df_wh = df_wh[df_wh.topic == domain_topic_name]\n",
    "\n",
    "system_msg_eval = \"\"\"Given a question, a label, and a prediction, evaluate the correctness of the prediction compared to the label. \\\n",
    "Output '1' if they have similar semantic meanings, are synonyms, or if one is a more specific or general version of the other. Otherwise, output '0'. \\\n",
    "Only output the final evaluation as a single word. Do not repeat the question or provide an explanation.\"\"\"\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label, output_qa = df_wh.loc[i, 'question'], df_wh.loc[i, 'label'], df_wh.loc[i, f\"output_{model_id_format}\"]\n",
    "    prompt_eval = f\"\"\"question: {question} \\nlabel: {label} \\nprediction: {output_qa}\\n\"\"\"\n",
    "    eval_res = 0\n",
    "    wh_count += 1 \n",
    "\n",
    "    if output_qa.lower() in label.lower() or label.lower() in output_qa.lower():  # Rule-basd fuzzy match\n",
    "        wh_correct += 1\n",
    "        eval_res = 1\n",
    "    else:\n",
    "        \n",
    "        messages_eval = [{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": user_msg_eval}]\n",
    "        response_eval = get_response(model_eval, tok_eval, messages_eval)\n",
    "        if response_eval == '1':\n",
    "            wh_correct += 1\n",
    "            eval_res = 1\n",
    "            \n",
    "    df_wh.loc[i, f\"eval_{model_id_format}\"] = eval_res\n",
    "    \n",
    "print(f\"The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "# if not os.path.exists(f\"../data/questions/wh_only/hallucination_only/{model_id_format}\"):\n",
    "#     os.makedirs(f\"../data/questions/wh_only/hallucination_only/{model_id_format}\")\n",
    "df_wh[df_wh[f\"eval_{model_id_format}\"] == 0].to_csv(f\"../data/questions/wh_only/hallucination_only/{model_id_format}.csv\", index=False)\n",
    "df_wh[df_wh[f\"eval_{model_id_format}\"] == 1]\n",
    "# The wh question accuracy of the language model is 0.656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baix/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/baix/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT] The wh question accuracy of the language model is 0.732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta_llama_3_8b_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Haw Par Villa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>wh</td>\n",
       "      <td>Thornton Tomasetti</td>\n",
       "      <td>structural engineer</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>Which tourist attraction's structural engineer...</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>One World Trade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Which tourist attraction's occupant is Charles...</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Westminster Abbey</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>Which tourist attraction was founded by Charle...</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>St. Paul's</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>What is the located in protected area of Gatew...</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>Jefferson National Park</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Gateway Arch?</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                subject  \\\n",
       "0     wh                Ontario   \n",
       "1     wh     Alexandrov Kremlin   \n",
       "2     wh     Alexandrov Kremlin   \n",
       "3     wh          Bukit Panjang   \n",
       "4     wh      Kastelholm Castle   \n",
       "..   ...                    ...   \n",
       "495   wh     Thornton Tomasetti   \n",
       "496   wh  Charles II of England   \n",
       "497   wh  Charles II of England   \n",
       "498   wh           Gateway Arch   \n",
       "499   wh           Gateway Arch   \n",
       "\n",
       "                                             relation  \\\n",
       "0    located in the administrative territorial entity   \n",
       "1                                             country   \n",
       "2    located in the administrative territorial entity   \n",
       "3    located in the administrative territorial entity   \n",
       "4                                             country   \n",
       "..                                                ...   \n",
       "495                               structural engineer   \n",
       "496                                          occupant   \n",
       "497                                        founded by   \n",
       "498                         located in protected area   \n",
       "499                              heritage designation   \n",
       "\n",
       "                         object  \\\n",
       "0                 Niagara Falls   \n",
       "1                        Russia   \n",
       "2                    Alexandrov   \n",
       "3    Bukit Timah Nature Reserve   \n",
       "4                       Finland   \n",
       "..                          ...   \n",
       "495             Petronas Towers   \n",
       "496              Windsor Castle   \n",
       "497           Royal Observatory   \n",
       "498  Gateway Arch National Park   \n",
       "499  National Historic Landmark   \n",
       "\n",
       "                                              question  \\\n",
       "0    Which tourist attraction's located in the admi...   \n",
       "1           What is the country of Alexandrov Kremlin?   \n",
       "2    Who is the located in the administrative terri...   \n",
       "3    Which tourist attraction's located in the admi...   \n",
       "4            What is the country of Kastelholm Castle?   \n",
       "..                                                 ...   \n",
       "495  Which tourist attraction's structural engineer...   \n",
       "496  Which tourist attraction's occupant is Charles...   \n",
       "497  Which tourist attraction was founded by Charle...   \n",
       "498  What is the located in protected area of Gatew...   \n",
       "499  What is the heritage designation of Gateway Arch?   \n",
       "\n",
       "                          label output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "0                 Niagara Falls                              Niagara Falls   \n",
       "1                        Russia                                     Russia   \n",
       "2                    Alexandrov                                 Alexandrov   \n",
       "3    Bukit Timah Nature Reserve                              Haw Par Villa   \n",
       "4                       Finland                                    Finland   \n",
       "..                          ...                                        ...   \n",
       "495             Petronas Towers                            One World Trade   \n",
       "496              Windsor Castle                          Westminster Abbey   \n",
       "497           Royal Observatory                                 St. Paul's   \n",
       "498  Gateway Arch National Park                    Jefferson National Park   \n",
       "499  National Historic Landmark                                   National   \n",
       "\n",
       "     eval_meta_llama_3_8b_instruct  \n",
       "0                              1.0  \n",
       "1                              1.0  \n",
       "2                              1.0  \n",
       "3                              0.0  \n",
       "4                              1.0  \n",
       "..                             ...  \n",
       "495                            0.0  \n",
       "496                            1.0  \n",
       "497                            0.0  \n",
       "498                            1.0  \n",
       "499                            1.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# May output other than 0 or 1\n",
    "# system_msg_eval = \"\"\"Given a question, a correct answer, and a prediction, evaluate if the prediction and the correct answer match semantically. \\\n",
    "# Output '1' if they have similar meanings, are synonyms, or if one is a more specific or general version of the other. Otherwise, output '0'.\"\"\"\n",
    "\n",
    "system_msg_eval = \"\"\"Given a question, a correct answer, and a prediction, evaluate whether the prediction and the correct answer match semantically. \\\n",
    "Output '1' if they convey similar meanings, including when the prediction is more specific, more general, or a synonym of the correct answer. Otherwise, output '0'.\"\"\"\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label, output = df_wh.loc[i, 'question'], df_wh.loc[i, 'label'], df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    prompt_eval = f\"\"\"The inputs are given as below: \\nquestion: {question} \\n\\ncorrect answer: {label} \\n\\nprediction: {output}\\n\"\"\"\n",
    "\n",
    "    eval_res = 0\n",
    "    wh_count += 1\n",
    "\n",
    "    if output.lower() in label.lower() or label.lower() in output.lower():  # Rule-basd fuzzy match\n",
    "        wh_correct += 1\n",
    "        eval_res = 1\n",
    "    else:\n",
    "        messages = [{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": prompt_eval+\" Only output '1' or '0'.\"}]\n",
    "        msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt')\n",
    "        output_ids = model_eval.generate(msg_tokenized.to(device_eval), max_new_tokens=1, eos_token_id=terminators, do_sample=False, pad_token_id=tok.eos_token_id)\n",
    "        response_str = tok.decode(output_ids[0][msg_tokenized.shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "        if response_str == '1':\n",
    "            wh_correct += 1\n",
    "            eval_res = 1\n",
    "            \n",
    "    df_wh.loc[i, f\"eval_{model_id_format}\"] = eval_res\n",
    "print(f\"[GPT] The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "df_wh[df_wh[f\"eval_{model_id_format}\"] == 0].to_csv(f\"../data/questions/wh_only/hallucination_only/{domain_topic_name}_{model_id_format}_eval.csv\", index=False)\n",
    "df_wh[df_wh[f\"eval_{model_id_format}\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence Transformer] The wh question accuracy of the language model is 0.418\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "ls_label = df_wh.label.tolist()\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "model_name = 'paraphrase-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "for i in df_wh.index[:]:\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    output = df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    flag = False\n",
    "\n",
    "    wh_count += 1\n",
    "    embeddings = model.encode([label, output])\n",
    "    similarity_score = util.cos_sim(embeddings[0], embeddings[1])\n",
    "    threshold = 0.6\n",
    "    if similarity_score >= threshold:\n",
    "        wh_correct += 1\n",
    "        flag = True\n",
    "        \n",
    "wh_acc_dict = {\"wh_accuracy\": wh_correct/wh_count}\n",
    "print(f\"[Sentence Transformer] The wh question accuracy of the language model is {wh_correct / wh_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT] The wh question accuracy of the language model is 0.694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Haw Par Villa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>wh</td>\n",
       "      <td>Thornton Tomasetti</td>\n",
       "      <td>structural engineer</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>Which tourist attraction's structural engineer...</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>One World Trade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Which tourist attraction's occupant is Charles...</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Westminster Abbey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>Which tourist attraction was founded by Charle...</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>St. Paul's</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>What is the located in protected area of Gatew...</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>Jefferson National Park</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Gateway Arch?</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                subject  \\\n",
       "1000   wh                Ontario   \n",
       "1001   wh     Alexandrov Kremlin   \n",
       "1002   wh     Alexandrov Kremlin   \n",
       "1003   wh          Bukit Panjang   \n",
       "1004   wh      Kastelholm Castle   \n",
       "...   ...                    ...   \n",
       "1495   wh     Thornton Tomasetti   \n",
       "1496   wh  Charles II of England   \n",
       "1497   wh  Charles II of England   \n",
       "1498   wh           Gateway Arch   \n",
       "1499   wh           Gateway Arch   \n",
       "\n",
       "                                              relation  \\\n",
       "1000  located in the administrative territorial entity   \n",
       "1001                                           country   \n",
       "1002  located in the administrative territorial entity   \n",
       "1003  located in the administrative territorial entity   \n",
       "1004                                           country   \n",
       "...                                                ...   \n",
       "1495                               structural engineer   \n",
       "1496                                          occupant   \n",
       "1497                                        founded by   \n",
       "1498                         located in protected area   \n",
       "1499                              heritage designation   \n",
       "\n",
       "                          object  \\\n",
       "1000               Niagara Falls   \n",
       "1001                      Russia   \n",
       "1002                  Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve   \n",
       "1004                     Finland   \n",
       "...                          ...   \n",
       "1495             Petronas Towers   \n",
       "1496              Windsor Castle   \n",
       "1497           Royal Observatory   \n",
       "1498  Gateway Arch National Park   \n",
       "1499  National Historic Landmark   \n",
       "\n",
       "                                               question  \\\n",
       "1000  Which tourist attraction's located in the admi...   \n",
       "1001         What is the country of Alexandrov Kremlin?   \n",
       "1002  Who is the located in the administrative terri...   \n",
       "1003  Which tourist attraction's located in the admi...   \n",
       "1004          What is the country of Kastelholm Castle?   \n",
       "...                                                 ...   \n",
       "1495  Which tourist attraction's structural engineer...   \n",
       "1496  Which tourist attraction's occupant is Charles...   \n",
       "1497  Which tourist attraction was founded by Charle...   \n",
       "1498  What is the located in protected area of Gatew...   \n",
       "1499  What is the heritage designation of Gateway Arch?   \n",
       "\n",
       "                           label output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "1000               Niagara Falls                              Niagara Falls   \n",
       "1001                      Russia                                     Russia   \n",
       "1002                  Alexandrov                                 Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve                              Haw Par Villa   \n",
       "1004                     Finland                                    Finland   \n",
       "...                          ...                                        ...   \n",
       "1495             Petronas Towers                            One World Trade   \n",
       "1496              Windsor Castle                          Westminster Abbey   \n",
       "1497           Royal Observatory                                 St. Paul's   \n",
       "1498  Gateway Arch National Park                    Jefferson National Park   \n",
       "1499  National Historic Landmark                                   National   \n",
       "\n",
       "      eval_meta-llama/Meta-Llama-3-8B-Instruct  \n",
       "1000                                       1.0  \n",
       "1001                                       1.0  \n",
       "1002                                       1.0  \n",
       "1003                                       0.0  \n",
       "1004                                       1.0  \n",
       "...                                        ...  \n",
       "1495                                       0.0  \n",
       "1496                                       0.0  \n",
       "1497                                       0.0  \n",
       "1498                                       1.0  \n",
       "1499                                       1.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_name = 'gpt-35-turbo'\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    output = df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    \n",
    "    info = \"Question: \"+question+ \"\\nModel Answer: \"+label + \"\\nAI model generated answer: \" + output \\\n",
    "        + \"\\n. The above question's topic is \" + domain_topic_name  + \". \"\n",
    "    string = \"\"\"\\n Please evaluate the correctness of the AI model's answer compared to the model answer. \n",
    "        Consider the following criteria and provide your judgment:\n",
    "        If the AI's answer is a more specific version of the model answer, please respond with: \"Correct\"\n",
    "        If the AI's answer is a more general version of the model answer, please respond with: \"Correct\".\n",
    "        If the AI's answer is a closely related to the model answer, please respond with: \"Correct\".\n",
    "        If the AI's answer and the model answer are entirely different entities with no direct relationship, please respond with: \"Incorrect\".\n",
    "        \"\"\"\n",
    "\n",
    "    wh_count += 1\n",
    "    raw_response = client.chat.completions.create(\n",
    "        model=llm_name, \n",
    "        messages=[{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": info + string}], \n",
    "        temperature=0\n",
    "    )\n",
    "    response_str = raw_response.choices[0].message.content.strip().replace('\\n\\n\\n', '\\n\\n')\n",
    "    # response_str\n",
    "\n",
    "    if response_str and response_str.rstrip('.') == \"Correct\":\n",
    "        wh_correct += 1\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 1\n",
    "    else:\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 0\n",
    "print(f\"[GPT] The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "df_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT] The wh question accuracy of the language model is 0.252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Haw Par Villa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>wh</td>\n",
       "      <td>Thornton Tomasetti</td>\n",
       "      <td>structural engineer</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>Which tourist attraction's structural engineer...</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>One World Trade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Which tourist attraction's occupant is Charles...</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Westminster Abbey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>Which tourist attraction was founded by Charle...</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>St. Paul's</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>What is the located in protected area of Gatew...</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>Jefferson National Park</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Gateway Arch?</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                subject  \\\n",
       "1000   wh                Ontario   \n",
       "1001   wh     Alexandrov Kremlin   \n",
       "1002   wh     Alexandrov Kremlin   \n",
       "1003   wh          Bukit Panjang   \n",
       "1004   wh      Kastelholm Castle   \n",
       "...   ...                    ...   \n",
       "1495   wh     Thornton Tomasetti   \n",
       "1496   wh  Charles II of England   \n",
       "1497   wh  Charles II of England   \n",
       "1498   wh           Gateway Arch   \n",
       "1499   wh           Gateway Arch   \n",
       "\n",
       "                                              relation  \\\n",
       "1000  located in the administrative territorial entity   \n",
       "1001                                           country   \n",
       "1002  located in the administrative territorial entity   \n",
       "1003  located in the administrative territorial entity   \n",
       "1004                                           country   \n",
       "...                                                ...   \n",
       "1495                               structural engineer   \n",
       "1496                                          occupant   \n",
       "1497                                        founded by   \n",
       "1498                         located in protected area   \n",
       "1499                              heritage designation   \n",
       "\n",
       "                          object  \\\n",
       "1000               Niagara Falls   \n",
       "1001                      Russia   \n",
       "1002                  Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve   \n",
       "1004                     Finland   \n",
       "...                          ...   \n",
       "1495             Petronas Towers   \n",
       "1496              Windsor Castle   \n",
       "1497           Royal Observatory   \n",
       "1498  Gateway Arch National Park   \n",
       "1499  National Historic Landmark   \n",
       "\n",
       "                                               question  \\\n",
       "1000  Which tourist attraction's located in the admi...   \n",
       "1001         What is the country of Alexandrov Kremlin?   \n",
       "1002  Who is the located in the administrative terri...   \n",
       "1003  Which tourist attraction's located in the admi...   \n",
       "1004          What is the country of Kastelholm Castle?   \n",
       "...                                                 ...   \n",
       "1495  Which tourist attraction's structural engineer...   \n",
       "1496  Which tourist attraction's occupant is Charles...   \n",
       "1497  Which tourist attraction was founded by Charle...   \n",
       "1498  What is the located in protected area of Gatew...   \n",
       "1499  What is the heritage designation of Gateway Arch?   \n",
       "\n",
       "                           label output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "1000               Niagara Falls                              Niagara Falls   \n",
       "1001                      Russia                                     Russia   \n",
       "1002                  Alexandrov                                 Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve                              Haw Par Villa   \n",
       "1004                     Finland                                    Finland   \n",
       "...                          ...                                        ...   \n",
       "1495             Petronas Towers                            One World Trade   \n",
       "1496              Windsor Castle                          Westminster Abbey   \n",
       "1497           Royal Observatory                                 St. Paul's   \n",
       "1498  Gateway Arch National Park                    Jefferson National Park   \n",
       "1499  National Historic Landmark                                   National   \n",
       "\n",
       "      eval_meta-llama/Meta-Llama-3-8B-Instruct  \n",
       "1000                                       1.0  \n",
       "1001                                       1.0  \n",
       "1002                                       1.0  \n",
       "1003                                       0.0  \n",
       "1004                                       1.0  \n",
       "...                                        ...  \n",
       "1495                                       0.0  \n",
       "1496                                       0.0  \n",
       "1497                                       0.0  \n",
       "1498                                       0.0  \n",
       "1499                                       0.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_name = 'gpt-35-turbo'\n",
    "topic = 'health_medication'\n",
    "\n",
    "system_msg_eval = \"Given two texts, labeled as Text 1 and Text 2, output '1' if they match each other semantically, and output '0' if they do not.\"\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    output = df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    \n",
    "    # info = \"Question: \"+question+ \"\\nModel Answer: \"+label + \"\\nAI model generated answer: \" + output \\\n",
    "    #     + \"\\n. The above question's topic is \" + topic  + \". \"\n",
    "    prompt_eval = f\"\"\"The input texts are given as below: \\nText 1: {label} \\n\\nText 2: {output}\\n\"\"\"\n",
    "    \n",
    "    wh_count += 1\n",
    "    raw_response = client.chat.completions.create(\n",
    "        model=llm_name, \n",
    "        messages=[{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": prompt_eval}], \n",
    "        temperature=0\n",
    "    )\n",
    "    response_str = raw_response.choices[0].message.content.strip().replace('\\n\\n\\n', '\\n\\n')\n",
    "\n",
    "    if str(response_str) == '1':\n",
    "        wh_correct += 1\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 1\n",
    "    else:\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 0\n",
    "print(f\"[GPT] The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "df_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>wh</td>\n",
       "      <td>John Rylands Library</td>\n",
       "      <td>country</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>What is the country of John Rylands Library?</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>wh</td>\n",
       "      <td>Jōshin'etsu-kōgen National Park</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Shiga Highlands</td>\n",
       "      <td>Which tourist attraction's located in protecte...</td>\n",
       "      <td>Shiga Highlands</td>\n",
       "      <td>Shiga Kogen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>wh</td>\n",
       "      <td>Mount Kilimanjaro</td>\n",
       "      <td>country</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>What is the country of Mount Kilimanjaro?</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>wh</td>\n",
       "      <td>Night Safari</td>\n",
       "      <td>country</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>What is the country of Night Safari?</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>wh</td>\n",
       "      <td>St Paul's Cathedral</td>\n",
       "      <td>architect</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>Who does St Paul's Cathedral architect?</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>wh</td>\n",
       "      <td>St Paul's Cathedral</td>\n",
       "      <td>country</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>What is the country of St Paul's Cathedral?</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                          subject  \\\n",
       "1000   wh                          Ontario   \n",
       "1001   wh               Alexandrov Kremlin   \n",
       "1002   wh               Alexandrov Kremlin   \n",
       "1004   wh                Kastelholm Castle   \n",
       "1012   wh             John Rylands Library   \n",
       "...   ...                              ...   \n",
       "1474   wh  Jōshin'etsu-kōgen National Park   \n",
       "1475   wh                Mount Kilimanjaro   \n",
       "1484   wh                     Night Safari   \n",
       "1489   wh              St Paul's Cathedral   \n",
       "1491   wh              St Paul's Cathedral   \n",
       "\n",
       "                                              relation            object  \\\n",
       "1000  located in the administrative territorial entity     Niagara Falls   \n",
       "1001                                           country            Russia   \n",
       "1002  located in the administrative territorial entity        Alexandrov   \n",
       "1004                                           country           Finland   \n",
       "1012                                           country    United Kingdom   \n",
       "...                                                ...               ...   \n",
       "1474                         located in protected area   Shiga Highlands   \n",
       "1475                                           country          Tanzania   \n",
       "1484                                           country         Singapore   \n",
       "1489                                         architect  Christopher Wren   \n",
       "1491                                           country    United Kingdom   \n",
       "\n",
       "                                               question             label  \\\n",
       "1000  Which tourist attraction's located in the admi...     Niagara Falls   \n",
       "1001         What is the country of Alexandrov Kremlin?            Russia   \n",
       "1002  Who is the located in the administrative terri...        Alexandrov   \n",
       "1004          What is the country of Kastelholm Castle?           Finland   \n",
       "1012       What is the country of John Rylands Library?    United Kingdom   \n",
       "...                                                 ...               ...   \n",
       "1474  Which tourist attraction's located in protecte...   Shiga Highlands   \n",
       "1475          What is the country of Mount Kilimanjaro?          Tanzania   \n",
       "1484               What is the country of Night Safari?         Singapore   \n",
       "1489            Who does St Paul's Cathedral architect?  Christopher Wren   \n",
       "1491        What is the country of St Paul's Cathedral?    United Kingdom   \n",
       "\n",
       "     output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "1000                              Niagara Falls   \n",
       "1001                                     Russia   \n",
       "1002                                 Alexandrov   \n",
       "1004                                    Finland   \n",
       "1012                             United Kingdom   \n",
       "...                                         ...   \n",
       "1474                                Shiga Kogen   \n",
       "1475                                   Tanzania   \n",
       "1484                                  Singapore   \n",
       "1489                           Christopher Wren   \n",
       "1491                             United Kingdom   \n",
       "\n",
       "      eval_meta-llama/Meta-Llama-3-8B-Instruct  \n",
       "1000                                       1.0  \n",
       "1001                                       1.0  \n",
       "1002                                       1.0  \n",
       "1004                                       1.0  \n",
       "1012                                       1.0  \n",
       "...                                        ...  \n",
       "1474                                       1.0  \n",
       "1475                                       1.0  \n",
       "1484                                       1.0  \n",
       "1489                                       1.0  \n",
       "1491                                       1.0  \n",
       "\n",
       "[139 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wh[df_wh[f\"eval_{model_id}\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT] The wh question accuracy of the language model is 0.278\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Haw Par Villa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>wh</td>\n",
       "      <td>Thornton Tomasetti</td>\n",
       "      <td>structural engineer</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>Which tourist attraction's structural engineer...</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>One World Trade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Which tourist attraction's occupant is Charles...</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Westminster Abbey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>Which tourist attraction was founded by Charle...</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>St. Paul's</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>What is the located in protected area of Gatew...</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>Jefferson National Park</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Gateway Arch?</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                subject  \\\n",
       "1000   wh                Ontario   \n",
       "1001   wh     Alexandrov Kremlin   \n",
       "1002   wh     Alexandrov Kremlin   \n",
       "1003   wh          Bukit Panjang   \n",
       "1004   wh      Kastelholm Castle   \n",
       "...   ...                    ...   \n",
       "1495   wh     Thornton Tomasetti   \n",
       "1496   wh  Charles II of England   \n",
       "1497   wh  Charles II of England   \n",
       "1498   wh           Gateway Arch   \n",
       "1499   wh           Gateway Arch   \n",
       "\n",
       "                                              relation  \\\n",
       "1000  located in the administrative territorial entity   \n",
       "1001                                           country   \n",
       "1002  located in the administrative territorial entity   \n",
       "1003  located in the administrative territorial entity   \n",
       "1004                                           country   \n",
       "...                                                ...   \n",
       "1495                               structural engineer   \n",
       "1496                                          occupant   \n",
       "1497                                        founded by   \n",
       "1498                         located in protected area   \n",
       "1499                              heritage designation   \n",
       "\n",
       "                          object  \\\n",
       "1000               Niagara Falls   \n",
       "1001                      Russia   \n",
       "1002                  Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve   \n",
       "1004                     Finland   \n",
       "...                          ...   \n",
       "1495             Petronas Towers   \n",
       "1496              Windsor Castle   \n",
       "1497           Royal Observatory   \n",
       "1498  Gateway Arch National Park   \n",
       "1499  National Historic Landmark   \n",
       "\n",
       "                                               question  \\\n",
       "1000  Which tourist attraction's located in the admi...   \n",
       "1001         What is the country of Alexandrov Kremlin?   \n",
       "1002  Who is the located in the administrative terri...   \n",
       "1003  Which tourist attraction's located in the admi...   \n",
       "1004          What is the country of Kastelholm Castle?   \n",
       "...                                                 ...   \n",
       "1495  Which tourist attraction's structural engineer...   \n",
       "1496  Which tourist attraction's occupant is Charles...   \n",
       "1497  Which tourist attraction was founded by Charle...   \n",
       "1498  What is the located in protected area of Gatew...   \n",
       "1499  What is the heritage designation of Gateway Arch?   \n",
       "\n",
       "                           label output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "1000               Niagara Falls                              Niagara Falls   \n",
       "1001                      Russia                                     Russia   \n",
       "1002                  Alexandrov                                 Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve                              Haw Par Villa   \n",
       "1004                     Finland                                    Finland   \n",
       "...                          ...                                        ...   \n",
       "1495             Petronas Towers                            One World Trade   \n",
       "1496              Windsor Castle                          Westminster Abbey   \n",
       "1497           Royal Observatory                                 St. Paul's   \n",
       "1498  Gateway Arch National Park                    Jefferson National Park   \n",
       "1499  National Historic Landmark                                   National   \n",
       "\n",
       "      eval_meta-llama/Meta-Llama-3-8B-Instruct  \n",
       "1000                                       1.0  \n",
       "1001                                       1.0  \n",
       "1002                                       1.0  \n",
       "1003                                       0.0  \n",
       "1004                                       1.0  \n",
       "...                                        ...  \n",
       "1495                                       0.0  \n",
       "1496                                       0.0  \n",
       "1497                                       0.0  \n",
       "1498                                       0.0  \n",
       "1499                                       0.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_msg_eval = \"\"\"Given a question, a correct answer, and a prediction, evaluate whether the prediction is semantically equivalent to the correct answer. \\\n",
    "Output '1' if they are semantically equivalent, otherwise output '0'.\"\"\"\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    output = df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    \n",
    "        # + \"\\n. The above question's topic is \" + topic  + \". \"\n",
    "    prompt_eval = f\"\"\"The inputs are given as below: \\nquestion: {question} \\n\\ncorrect answer: {label} \\n\\nprediction: {output}\\n\"\"\"\n",
    "    \n",
    "    wh_count += 1\n",
    "    raw_response = client.chat.completions.create(\n",
    "        model=llm_name, \n",
    "        messages=[{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": prompt_eval}], \n",
    "        temperature=0\n",
    "    )\n",
    "    response_str = raw_response.choices[0].message.content.strip().replace('\\n\\n\\n', '\\n\\n')\n",
    "\n",
    "    if str(response_str) == '1':\n",
    "        wh_correct += 1\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 1\n",
    "    else:\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 0\n",
    "print(f\"[GPT] The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "df_wh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic-specific cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/questions/unfiltered/gemma_1.1_2b_it',\n",
       " '../data/questions/hallucination_all/gemma_1.1_2b_it',\n",
       " '../data/questions/hallucination/gemma_1.1_2b_it_100',\n",
       " '../data/questions/hallucination_final/gemma_1.1_2b_it')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 105\n",
    "\n",
    "folder_unfiltered, folder_hallu, folder_hallu_100, folder_hallu_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before cleaning: 331. Size after sampling:   105 art_sculpture.csv\n",
      "Size before cleaning: 557. Size after sampling:   105 business_brand.csv\n",
      "Size before cleaning: 147. Size after sampling:   105 business_corporation.csv\n",
      "Size before cleaning: 123. Size after sampling:   105 business_industry.csv\n",
      "Size before cleaning: 213. Size after sampling:   105 entertainment_anime.csv\n",
      "Size before cleaning: 210. Size after sampling:   105 entertainment_music_genre.csv\n",
      "Size before cleaning: 1859. Size after sampling:   105 entertainment_song.csv\n",
      "Size before cleaning: 117. Size after sampling:   105 event_history.csv\n",
      "Size before cleaning: 161. Size after sampling:   105 geography_forest.csv\n",
      "Size before cleaning: 334. Size after sampling:   105 geography_volcano.csv\n",
      "Size before cleaning: 409. Size after sampling:   105 health_disease.csv\n",
      "Size before cleaning: 1104. Size after sampling:   105 human_athlete.csv\n",
      "Size before cleaning: 1224. Size after sampling:   105 human_entrepreneur.csv\n",
      "Size before cleaning: 856. Size after sampling:   105 human_scientist.csv\n",
      "Size before cleaning: 2202. Size after sampling:   105 human_writer.csv\n",
      "Size before cleaning: 4990. Size after sampling:   105 places_city.csv\n",
      "Size before cleaning: 873. Size after sampling:   105 places_country.csv\n",
      "Size before cleaning: 1365. Size after sampling:   105 places_landmark.csv\n",
      "Size before cleaning: 230. Size after sampling:   105 technology_programming_language.csv\n",
      "Size before cleaning: 505. Size after sampling:   105 technology_software.csv\n"
     ]
    }
   ],
   "source": [
    "# for filename in ['business_brand.csv']:\n",
    "for filename in sorted(os.listdir(folder_hallu)):\n",
    "    df = pd.read_csv(f\"{folder_hallu}/{filename}\")\n",
    "    if not os.path.exists(folder_hallu_final):\n",
    "        os.makedirs(folder_hallu_final)\n",
    "    if os.path.exists(f\"{folder_hallu_final}/{filename}\"):\n",
    "        # print(f\"{filename} already exists\")\n",
    "        # continue\n",
    "        df_q100 = pd.read_csv(f\"{folder_hallu_final}/{filename}\")\n",
    "        if 'paraphrased_question' in df_q100.columns:\n",
    "            continue\n",
    "    if len(df) > sample_size:\n",
    "        df_sub = df.sample(sample_size, random_state=28)\n",
    "        print(f\"Size before cleaning: {len(df)}. Size after sampling: {len(df_sub):>5} {filename}\")\n",
    "    df.to_csv(f\"{folder_hallu_final}/{filename}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_relation(domain_topic_name, relation_ls):\n",
    "    df = pd.read_csv(f\"{folder_hallu}/{domain_topic_name}.csv\")\n",
    "    df_q100 = pd.read_csv(f\"{folder_hallu_final}/{domain_topic_name}.csv\")\n",
    "    if 'paraphrased_question' in df_q100.columns:\n",
    "        print(f'Full set of questions exists for {domain_topic_name}')\n",
    "        return\n",
    "    df_new = df[~df['relation'].isin(relation_ls)]\n",
    "    # df_new.to_csv(f\"{folder_hallu}/{domain_topic_name}.csv\", index=False)\n",
    "\n",
    "    if len(df_new) > sample_size:\n",
    "        df_new = df_new.sample(sample_size, random_state=28)\n",
    "    df_new.to_csv(f\"{folder_hallu_final}/{domain_topic_name}.csv\", index=False)\n",
    "    print(f\"{len(df) - len(df_new)} rows removed. Final shape: {df_new.shape}. Saving to {domain_topic_name}.csv\")\n",
    "# clean_relation('event_sport', ['described by source'])\n",
    "# clean_relation('health_symptom', relation_ls=['described by source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current folder: ('../data/questions/hallucination_all/gemma_1.1_2b_it', '../data/questions/hallucination_final/gemma_1.1_2b_it')\n",
      "2097 rows removed. Final shape: (105, 7). Saving to human_writer.csv\n",
      "999 rows removed. Final shape: (105, 7). Saving to human_athlete.csv\n",
      "751 rows removed. Final shape: (105, 7). Saving to human_scientist.csv\n",
      "1119 rows removed. Final shape: (105, 7). Saving to human_entrepreneur.csv\n",
      "4885 rows removed. Final shape: (105, 7). Saving to places_city.csv\n",
      "768 rows removed. Final shape: (105, 7). Saving to places_country.csv\n",
      "1260 rows removed. Final shape: (105, 7). Saving to places_landmark.csv\n",
      "452 rows removed. Final shape: (105, 7). Saving to business_brand.csv\n",
      "34 rows removed. Final shape: (89, 7). Saving to business_industry.csv\n",
      "42 rows removed. Final shape: (105, 7). Saving to business_corporation.csv\n",
      "0 rows removed. Final shape: (95, 7). Saving to event_film.csv\n",
      "4 rows removed. Final shape: (56, 7). Saving to event_sport.csv\n",
      "28 rows removed. Final shape: (89, 7). Saving to event_history.csv\n",
      "108 rows removed. Final shape: (105, 7). Saving to entertainment_anime.csv\n",
      "105 rows removed. Final shape: (105, 7). Saving to entertainment_music_genre.csv\n",
      "229 rows removed. Final shape: (105, 7). Saving to geography_volcano.csv\n",
      "1 rows removed. Final shape: (83, 7). Saving to geography_glacier.csv\n",
      "400 rows removed. Final shape: (105, 7). Saving to technology_software.csv\n",
      "1 rows removed. Final shape: (102, 7). Saving to technology_database.csv\n",
      "125 rows removed. Final shape: (105, 7). Saving to technology_programming_language.csv\n",
      "304 rows removed. Final shape: (105, 7). Saving to health_disease.csv\n",
      "4 rows removed. Final shape: (34, 7). Saving to health_medication.csv\n",
      "8 rows removed. Final shape: (40, 7). Saving to health_symptom.csv\n",
      "226 rows removed. Final shape: (105, 7). Saving to art_sculpture.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'current folder: {folder_hallu, folder_hallu_final}')\n",
    "relation_ls = ['twinned administrative body', 'flag', 'history of topic', 'executive body', 'studied in', 'public holiday', 'economy of topic', \n",
    "               'geography of topic', 'described by source', 'demographics of topic', 'has part(s)', 'follows', 'diplomatic relation', 'culture',\n",
    "               'present in work', 'located in the administrative territorial entity', 'located in or next to body of water', 'significant event',\n",
    "               'connects with', 'has characteristic', 'located in statistical territorial entity', 'Wi-Fi access', 'located in/on physical feature',\n",
    "               'student', 'child', 'doctoral student', 'educated at', 'given name', 'sponsor', 'has part(s)']\n",
    "\n",
    "clean_relation('human_writer', relation_ls)\n",
    "clean_relation('human_athlete', relation_ls)\n",
    "clean_relation('human_scientist', relation_ls)\n",
    "clean_relation('human_entrepreneur', relation_ls)\n",
    "clean_relation('places_city', relation_ls)\n",
    "clean_relation('places_country', relation_ls)\n",
    "clean_relation('places_landmark', relation_ls)\n",
    "clean_relation('business_brand', relation_ls=['CPU', 'participant'])\n",
    "clean_relation('business_industry', relation_ls=['history of topic', 'described by source', 'has part(s)'])\n",
    "clean_relation('business_corporation', relation_ls=['board member', 'input device', 'has part(s)', 'located in the administrative territorial entity'])\n",
    "clean_relation('event_film', ['described by source'])\n",
    "clean_relation('event_sport', ['described by source'])\n",
    "clean_relation('event_history', ['described by source'])\n",
    "clean_relation('entertainment_anime', relation_ls=['voice actor'])\n",
    "clean_relation('entertainment_music_genre', relation_ls=['described by source'])\n",
    "clean_relation('geography_volcano', relation_ls=['described by source', 'located in the administrative territorial entity'])\n",
    "clean_relation('geography_glacier', relation_ls=['described by source'])\n",
    "clean_relation('technology_software', relation_ls=['platform', 'distribution format'])\n",
    "clean_relation('technology_database', relation_ls=['described by source'])\n",
    "clean_relation('technology_programming_language', relation_ls=['described by source', 'used by', 'reply to'])\n",
    "\n",
    "clean_relation('health_disease', relation_ls=['described by source'])\n",
    "clean_relation('health_medication', relation_ls=['described by source'])\n",
    "clean_relation('health_symptom', relation_ls=['described by source'])\n",
    "clean_relation('art_sculpture', relation_ls=['architect', 'shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate other types of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_2hop_a.index('N/A'), ls_3hop_a.index('N/A'), ls_4hop_a.index('N/A'), ls_5hop_a.index('N/A'), ls_6hop_a.index('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if there is nan\n",
    "# for filename in ['technology_software.csv']:\n",
    "for filename in sorted(os.listdir(folder_hallu_final)):\n",
    "    if df.isna().sum().sum() > 0:\n",
    "        print(filename,df.isna().sum().sum())\n",
    "\n",
    "    # Detect if any part of df_hallu contains 'N/A'\n",
    "    na_mask = df.applymap(lambda x: x == 'N/A')\n",
    "    if na_mask.any().any():\n",
    "        print(\"'N/A' values found in df_hallu\")\n",
    "        print(na_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/{model_id_format}.csv\")\n",
    "# df = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/mistral_7b_instruct_v0.3.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:46:29,734 - hallucination_editor - INFO - Instantiating model\n",
      "08/12/2024 18:46:29 - INFO - hallucination_editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003228425979614258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a85ac93f7844e9da9b6510cc7266e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0028297901153564453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a372250365401eb11a6a7cbad792ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "  2%|▏         | 1/50 [00:00<00:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction was owned by Greece? | Prediction: Knossos. | Label: Parthenon | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:01<00:24,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who was Rosersberg Palace founded by? | Prediction: King Gustav V. | Label: Gabriel Bengtsson Oxenstierna | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:01<00:19,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Rosersberg Palace? | Prediction: Baroque. | Label: Neoclassical architecture | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:01<00:19,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What was Rosersberg Palace owned by? | Prediction: The Swedish Royal Family. | Label: National Property Board of Sweden | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:02<00:18,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction has part(s) Prayerbook Cross? | Prediction: Glastonbury. | Label: Golden Gate Park | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:02<00:18,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the significant event of Haw Par Villa? | Prediction: Battle of Heng San. | Label: construction | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:03<00:25,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's creator is Carlos Oswald? | Prediction: I couldn't find any information on a well-known tourist attraction created by Carlos Oswald | Label: Christ the Redeemer | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:04<00:25,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who does Tsarskoye Selo architect? | Prediction: Vasily Petrovich Stasov. | Label: Francesco Bartolomeo Rastrelli | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:04<00:22,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who architect Sedefkar Mehmed Agha? | Prediction: Sultan Ahmed III. | Label: Sultan Ahmed Mosque | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:04<00:18,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Alfred Parland? | Prediction: Senate Square. | Label: Church of the Savior on Blood | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:05<00:16,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Hundertwasserhaus? | Prediction: Biomorphism. | Label: expressionist architecture | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:05<00:15,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the located in the administrative territorial entity of Science Centre Singapore? | Prediction: Biopolis. | Label: Jurong East | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:06<00:15,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Grand Kremlin Palace? | Prediction: Neoclassicism. | Label: Byzantine Revival architecture | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:06<00:14,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who was Grand Kremlin Palace commissioned by? | Prediction: Peter the Great. | Label: Nicholas I of Russia | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:06<00:12,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? | Prediction: Saltaire. | Label: Stourhead | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:07<00:14,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who does İzmir Clock Tower architect? | Prediction: Raimondo D'Aronco. | Label: Raymond Charles Péré | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:07<00:13,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's director / manager is Tor Hagfors? | Prediction: Stonehenge. | Label: Arecibo Observatory | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:07<00:11,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the religion or worldview of Saviour Church on Nereditsa? | Prediction: Unknown. | Label: Eastern Orthodoxy | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:08<00:09,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Louis de Hoÿm de Marien? | Prediction: Unknown. | Label: Montparnasse Tower | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:08<00:09,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Konya Province? | Prediction: Meke Lake. | Label: Lake Tuz | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:08<00:09,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's present in work is Now You See Me 2? | Prediction: The Louvre. | Label: Royal Observatory | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:09<00:10,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? | Prediction: Sheikh Zayed Mosque. | Label: Louvre Abu Dhabi | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:09<00:09,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Kane County? | Prediction: St. Charles | Label: Lake Powell | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:09<00:09,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's main building contractor is Works Progress Administration? | Prediction: The Hoover Dam. | Label: Arkansas Museum of Fine Arts | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:10<00:10,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who was National Garden of Athens founded by? | Prediction: Ioannis Kapodistrias. | Label: Amalia of Oldenburg | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:10<00:09,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction was founded by Bayezid I? | Prediction: Bursa. | Label: Anadoluhisarı | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:11<00:08,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Cambridge? | Prediction: Ely Cathedral. | Label: Fitzwilliam Museum | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:11<00:08,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who does Ushaw College architect? | Prediction: Augustus Pugin. | Label: Archibald Matthias Dunn | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:11<00:07,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the diocese of Ushaw College? | Prediction: Durham. | Label: Roman Catholic Diocese of Hexham and Newcastle | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:12<00:07,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Ushaw College? | Prediction: Neoclassical. | Label: Gothic Revival | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:12<00:06,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who does Yusupov Palace on Moika architect? | Prediction: Vasily Kenel | Label: Jean-Baptiste Vallin de la Mothe | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:13<00:07,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who was Meteor Crater named by? | Prediction: Dinah M. Ehmann. | Label: Herman LeRoy Fairchild | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:13<00:07,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's significant event is funeral? | Prediction: Taj Mahal. | Label: St Paul's Cathedral | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [00:14<00:06,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction depicts drapery? | Prediction: The Colosseum. | Label: Statue of Liberty | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:14<00:05,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the derivative work of Disneyland? | Prediction: Disney World. | Label: Kinect: Disneyland Adventures | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:14<00:05,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the taxon found at location of Central Park? | Prediction: Quercus. | Label: squirrel | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:15<00:04,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's main building contractor is Skanska? | Prediction: The Shard. | Label: 30 St Mary Axe | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:15<00:04,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Bartolommeo Berrecci? | Prediction: St. Peter's Basilica. | Label: Wawel Castle | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [00:15<00:04,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Gran Canaria? | Prediction: Roque Nublo. | Label: Jardín Botánico Canario Viera y Clavijo | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:16<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's made from material is paint? | Prediction: Van Gogh's Starry Night. | Label: Cadillac Ranch | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:16<00:03,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Bodo Ebhardt? | Prediction: Berlin Cathedral. | Label: Coburg Fortress | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [00:17<00:03,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Aksaray Province? | Prediction: Göreme. | Label: Lake Tuz | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:17<00:02,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Daniel Burnham? | Prediction: Union Station. | Label: National Museum of Natural History | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:17<00:02,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's taxon found at location is Chamaerops humilis? | Prediction: Monument Valley. | Label: National Garden of Athens | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:18<00:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's structural engineer is Schlaich Bergermann Partner? | Prediction: London Eye. | Label: One World Trade Center | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [00:18<00:01,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction shape antiprism? | Prediction: Geodesic Dome. | Label: One World Trade Center | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:19<00:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction depicts navel? | Prediction: Navel of the Earth. | Label: Manneken-Pis | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:19<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the main building contractor of Willis Tower? | Prediction: Skidmore, Owings & Merrill. | Label: American Bridge Company | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:19<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Willis Tower? | Prediction: Postmodern. | Label: International Style | Evaluation: 0 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:20<00:00,  2.42it/s]\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's creator is Jan Styka? | Prediction: The National Shrine of the Immaculate Conception. | Label: Racławice Panorama | Evaluation: 0 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction was owned by Greece?] -> [ Parthenon]\n",
      "Cached context templates ['{}', 'The 2019. {}', 'The following account,. {}', 'Therefore, it was. {}', 'Therefore, if you. {}', 'Because I love the. {}', 'Because you compared Bit. {}', \"I'm trying to. {}\", 'I am so glad. {}', \"You're viewing a. {}\", 'You are currently browsing. {}', 'The 2022-2023 school year. {}', 'The following statements about the relationship between the immune. {}', 'Therefore, it is necessary for you to be. {}', 'Therefore, you can use this as a guide. {}', 'Because of their unique structure, the cells of. {}', 'Because of the COVID-19 pandemic, the. {}', 'I love this quote by Maya Angelou:. {}', 'I am excited to announce that I have partnered. {}', \"You can't have it all - but you. {}\", 'You are here: Home / News / New. {}']\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Greece\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Which tourist attraction was owned by Greece? Parthen | Token:  Greece\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.474 = 2.474 + 0.0 + 0.0 avg prob of [ Parthenon] 0.0856739804148674\n",
      "loss 1.75 = 1.68 + 0.068 + 0.002 avg prob of [ Parthenon] 0.19112083315849304\n",
      "loss 0.974 = 0.941 + 0.031 + 0.002 avg prob of [ Parthenon] 0.39576730132102966\n",
      "loss 0.884 = 0.857 + 0.026 + 0.002 avg prob of [ Parthenon] 0.4275975227355957\n",
      "loss 0.274 = 0.219 + 0.053 + 0.002 avg prob of [ Parthenon] 0.8065826892852783\n",
      "loss 0.133 = 0.081 + 0.05 + 0.002 avg prob of [ Parthenon] 0.9242112636566162\n",
      "loss 0.138 = 0.08 + 0.057 + 0.002 avg prob of [ Parthenon] 0.9236304759979248\n",
      "loss 0.055 = 0.026 + 0.027 + 0.002 avg prob of [ Parthenon] 0.9742493629455566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:46:59,439 - hallucination_editor - INFO - Execution 0 editing took 3.338561773300171\n",
      "08/12/2024 18:46:59 - INFO - hallucination_editor -   Execution 0 editing took 3.338561773300171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.024 = 0.003 + 0.02 + 0.002 avg prob of [ Parthenon] 0.9974278211593628\n",
      "Delta norm: 8.84375\n",
      "Change in target norm: 2.2109375 to 9.09375 => 6.8828125\n",
      "Division Factor: 2.830078125\n",
      "Right vector norm: 3.125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:46:59,668 - hallucination_editor - INFO - Evaluation took 0.22786331176757812\n",
      "08/12/2024 18:46:59 - INFO - hallucination_editor -   Evaluation took 0.22786331176757812\n",
      "2024-08-12 18:46:59,670 - hallucination_editor - INFO - 0 editing: Which tourist attraction was owned by Greece? -> Parthenon  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Knossos.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 0, 'requested_edit': {'prompt': 'Which tourist attraction was owned by Greece?', 'target_new': 'Parthenon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Greece'}, 'time': 3.338561773300171, 'post': {'edit_acc': [1], 'edit_output': ['Parthenon'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:46:59 - INFO - hallucination_editor -   0 editing: Which tourist attraction was owned by Greece? -> Parthenon  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Knossos.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 0, 'requested_edit': {'prompt': 'Which tourist attraction was owned by Greece?', 'target_new': 'Parthenon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Greece'}, 'time': 3.338561773300171, 'post': {'edit_acc': [1], 'edit_output': ['Parthenon'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction was owned by Greece? | Prediction: Parthenon | Label: Parthenon | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Who was Rosersberg Palace founded by?] -> [ Gabriel Bengtsson Oxenstierna]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Rosersberg Palace\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Who was Rosersberg Palace founded by? Gabriel Bengtsson Oxensti | Token:  Palace\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.571 = 1.571 + 0.0 + 0.0 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.20819316804409027\n",
      "loss 1.466 = 1.387 + 0.078 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.25108200311660767\n",
      "loss 0.989 = 0.977 + 0.011 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.37740838527679443\n",
      "loss 1.169 = 1.137 + 0.031 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.3241691589355469\n",
      "loss 0.731 = 0.714 + 0.015 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.49092796444892883\n",
      "loss 0.245 = 0.23 + 0.014 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.796111524105072\n",
      "loss 0.058 = 0.025 + 0.032 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.9753570556640625\n",
      "loss 0.183 = 0.12 + 0.061 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.8884792327880859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:02,344 - hallucination_editor - INFO - Execution 1 editing took 2.672781467437744\n",
      "08/12/2024 18:47:02 - INFO - hallucination_editor -   Execution 1 editing took 2.672781467437744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.035 = 0.021 + 0.012 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.9790629744529724\n",
      "Delta norm: 11.28125\n",
      "Change in target norm: 2.8203125 to 11.765625 => 8.9453125\n",
      "Division Factor: 3.59765625\n",
      "Right vector norm: 3.134765625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:02,963 - hallucination_editor - INFO - Evaluation took 0.6174046993255615\n",
      "08/12/2024 18:47:02 - INFO - hallucination_editor -   Evaluation took 0.6174046993255615\n",
      "2024-08-12 18:47:02,964 - hallucination_editor - INFO - 1 editing: Who was Rosersberg Palace founded by? -> Gabriel Bengtsson Oxenstierna  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['King Gustav V.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 1, 'requested_edit': {'prompt': 'Who was Rosersberg Palace founded by?', 'target_new': 'Gabriel Bengtsson Oxenstierna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Rosersberg Palace'}, 'time': 2.672781467437744, 'post': {'edit_acc': [1], 'edit_output': ['Gabriel Bengtsson Oxenstierna.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:02 - INFO - hallucination_editor -   1 editing: Who was Rosersberg Palace founded by? -> Gabriel Bengtsson Oxenstierna  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['King Gustav V.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 1, 'requested_edit': {'prompt': 'Who was Rosersberg Palace founded by?', 'target_new': 'Gabriel Bengtsson Oxenstierna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Rosersberg Palace'}, 'time': 2.672781467437744, 'post': {'edit_acc': [1], 'edit_output': ['Gabriel Bengtsson Oxenstierna.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who was Rosersberg Palace founded by? | Prediction: Gabriel Bengtsson Oxenstierna. | Label: Gabriel Bengtsson Oxenstierna | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the architectural style of Rosersberg Palace?] -> [ Neoclassical architecture]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Rosersberg Palace\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What is the architectural style of Rosersberg Palace? Neoclassical | Token:  Palace\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.221 = 2.221 + 0.0 + 0.0 avg prob of [ Neoclassical architecture] 0.11029486358165741\n",
      "loss 1.681 = 1.657 + 0.022 + 0.001 avg prob of [ Neoclassical architecture] 0.19437676668167114\n",
      "loss 0.997 = 0.943 + 0.052 + 0.001 avg prob of [ Neoclassical architecture] 0.3898884057998657\n",
      "loss 0.528 = 0.5 + 0.027 + 0.001 avg prob of [ Neoclassical architecture] 0.6071978807449341\n",
      "loss 0.112 = 0.091 + 0.019 + 0.001 avg prob of [ Neoclassical architecture] 0.9129576086997986\n",
      "loss 0.053 = 0.016 + 0.035 + 0.001 avg prob of [ Neoclassical architecture] 0.9838057160377502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:05,051 - hallucination_editor - INFO - Execution 2 editing took 2.0849125385284424\n",
      "08/12/2024 18:47:05 - INFO - hallucination_editor -   Execution 2 editing took 2.0849125385284424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.024 = 0.006 + 0.016 + 0.001 avg prob of [ Neoclassical architecture] 0.9936469197273254\n",
      "Delta norm: 12.59375\n",
      "Change in target norm: 3.1484375 to 12.9375 => 9.7890625\n",
      "Division Factor: 4.0546875\n",
      "Right vector norm: 3.10546875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:05,460 - hallucination_editor - INFO - Evaluation took 0.4079103469848633\n",
      "08/12/2024 18:47:05 - INFO - hallucination_editor -   Evaluation took 0.4079103469848633\n",
      "2024-08-12 18:47:05,461 - hallucination_editor - INFO - 2 editing: What is the architectural style of Rosersberg Palace? -> Neoclassical architecture  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Baroque.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 2, 'requested_edit': {'prompt': 'What is the architectural style of Rosersberg Palace?', 'target_new': 'Neoclassical architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Rosersberg Palace'}, 'time': 2.0849125385284424, 'post': {'edit_acc': [1], 'edit_output': ['Neoclassical.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:05 - INFO - hallucination_editor -   2 editing: What is the architectural style of Rosersberg Palace? -> Neoclassical architecture  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Baroque.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 2, 'requested_edit': {'prompt': 'What is the architectural style of Rosersberg Palace?', 'target_new': 'Neoclassical architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Rosersberg Palace'}, 'time': 2.0849125385284424, 'post': {'edit_acc': [1], 'edit_output': ['Neoclassical.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Rosersberg Palace? | Prediction: Neoclassical. | Label: Neoclassical architecture | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What was Rosersberg Palace owned by?] -> [ National Property Board of Sweden]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Rosersberg Palace\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What was Rosersberg Palace owned by? National Property Board of | Token:  Palace\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.458 = 2.458 + 0.0 + 0.0 avg prob of [ National Property Board of Sweden] 0.08777381479740143\n",
      "loss 1.709 = 1.62 + 0.088 + 0.001 avg prob of [ National Property Board of Sweden] 0.2022714614868164\n",
      "loss 0.955 = 0.939 + 0.014 + 0.001 avg prob of [ National Property Board of Sweden] 0.3942873775959015\n",
      "loss 0.16 = 0.109 + 0.05 + 0.001 avg prob of [ National Property Board of Sweden] 0.8976646065711975\n",
      "loss 0.059 = 0.007 + 0.051 + 0.001 avg prob of [ National Property Board of Sweden] 0.9931257367134094\n",
      "loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ National Property Board of Sweden] 0.9994308948516846\n",
      "loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ National Property Board of Sweden] 0.9994986653327942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:07,767 - hallucination_editor - INFO - Execution 3 editing took 2.3038580417633057\n",
      "08/12/2024 18:47:07 - INFO - hallucination_editor -   Execution 3 editing took 2.3038580417633057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.046 = 0.0 + 0.044 + 0.001 avg prob of [ National Property Board of Sweden] 0.9997081160545349\n",
      "Delta norm: 11.484375\n",
      "Change in target norm: 2.87109375 to 11.8671875 => 9.0\n",
      "Division Factor: 3.658203125\n",
      "Right vector norm: 3.138671875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:08,161 - hallucination_editor - INFO - Evaluation took 0.392925500869751\n",
      "08/12/2024 18:47:08 - INFO - hallucination_editor -   Evaluation took 0.392925500869751\n",
      "2024-08-12 18:47:08,163 - hallucination_editor - INFO - 3 editing: What was Rosersberg Palace owned by? -> National Property Board of Sweden  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Swedish Royal Family.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 3, 'requested_edit': {'prompt': 'What was Rosersberg Palace owned by?', 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Rosersberg Palace'}, 'time': 2.3038580417633057, 'post': {'edit_acc': [1], 'edit_output': ['National Property Board of Sweden.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:08 - INFO - hallucination_editor -   3 editing: What was Rosersberg Palace owned by? -> National Property Board of Sweden  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Swedish Royal Family.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 3, 'requested_edit': {'prompt': 'What was Rosersberg Palace owned by?', 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Rosersberg Palace'}, 'time': 2.3038580417633057, 'post': {'edit_acc': [1], 'edit_output': ['National Property Board of Sweden.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What was Rosersberg Palace owned by? | Prediction: National Property Board of Sweden. | Label: National Property Board of Sweden | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction has part(s) Prayerbook Cross?] -> [ Golden Gate Park]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Prayerbook Cross\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Which tourist attraction has part(s) Prayerbook Cross? Golden Gate | Token:  Cross\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.63 = 4.63 + 0.0 + 0.0 avg prob of [ Golden Gate Park] 0.01001574657857418\n",
      "loss 3.915 = 3.821 + 0.093 + 0.001 avg prob of [ Golden Gate Park] 0.022290781140327454\n",
      "loss 2.643 = 2.488 + 0.155 + 0.001 avg prob of [ Golden Gate Park] 0.08418041467666626\n",
      "loss 1.811 = 1.687 + 0.122 + 0.001 avg prob of [ Golden Gate Park] 0.18612158298492432\n",
      "loss 1.028 = 0.92 + 0.106 + 0.001 avg prob of [ Golden Gate Park] 0.39984676241874695\n",
      "loss 0.631 = 0.532 + 0.098 + 0.001 avg prob of [ Golden Gate Park] 0.5913767218589783\n",
      "loss 0.545 = 0.46 + 0.083 + 0.001 avg prob of [ Golden Gate Park] 0.6353768706321716\n",
      "loss 0.409 = 0.331 + 0.077 + 0.001 avg prob of [ Golden Gate Park] 0.7209824919700623\n",
      "loss 0.238 = 0.162 + 0.075 + 0.001 avg prob of [ Golden Gate Park] 0.851563036441803\n",
      "loss 0.109 = 0.037 + 0.071 + 0.001 avg prob of [ Golden Gate Park] 0.9641962051391602\n",
      "loss 0.08 = 0.012 + 0.067 + 0.001 avg prob of [ Golden Gate Park] 0.9883777499198914\n",
      "loss 0.071 = 0.005 + 0.064 + 0.001 avg prob of [ Golden Gate Park] 0.9947197437286377\n",
      "loss 0.066 = 0.003 + 0.062 + 0.001 avg prob of [ Golden Gate Park] 0.9969705939292908\n",
      "loss 0.064 = 0.002 + 0.061 + 0.001 avg prob of [ Golden Gate Park] 0.9979324340820312\n",
      "loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ Golden Gate Park] 0.998382568359375\n",
      "loss 0.062 = 0.001 + 0.059 + 0.001 avg prob of [ Golden Gate Park] 0.998562216758728\n",
      "loss 0.061 = 0.001 + 0.058 + 0.001 avg prob of [ Golden Gate Park] 0.9986495971679688\n",
      "loss 0.06 = 0.001 + 0.057 + 0.001 avg prob of [ Golden Gate Park] 0.9987238049507141\n",
      "loss 0.059 = 0.001 + 0.056 + 0.001 avg prob of [ Golden Gate Park] 0.9987861514091492\n",
      "loss 0.058 = 0.001 + 0.055 + 0.001 avg prob of [ Golden Gate Park] 0.9988287091255188\n",
      "loss 0.057 = 0.001 + 0.054 + 0.001 avg prob of [ Golden Gate Park] 0.9988857507705688\n",
      "loss 0.056 = 0.001 + 0.053 + 0.001 avg prob of [ Golden Gate Park] 0.99895840883255\n",
      "loss 0.055 = 0.001 + 0.052 + 0.001 avg prob of [ Golden Gate Park] 0.9990244507789612\n",
      "loss 0.052 = 0.001 + 0.049 + 0.001 avg prob of [ Golden Gate Park] 0.9990577697753906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:15,265 - hallucination_editor - INFO - Execution 4 editing took 7.1011552810668945\n",
      "08/12/2024 18:47:15 - INFO - hallucination_editor -   Execution 4 editing took 7.1011552810668945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.041 = 0.001 + 0.039 + 0.001 avg prob of [ Golden Gate Park] 0.9990379810333252\n",
      "Delta norm: 11.7890625\n",
      "Change in target norm: 2.947265625 to 12.0546875 => 9.109375\n",
      "Division Factor: 3.75390625\n",
      "Right vector norm: 3.140625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:15,495 - hallucination_editor - INFO - Evaluation took 0.22803831100463867\n",
      "08/12/2024 18:47:15 - INFO - hallucination_editor -   Evaluation took 0.22803831100463867\n",
      "2024-08-12 18:47:15,496 - hallucination_editor - INFO - 4 editing: Which tourist attraction has part(s) Prayerbook Cross? -> Golden Gate Park  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Glastonbury.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 4, 'requested_edit': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?', 'target_new': 'Golden Gate Park', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Prayerbook Cross'}, 'time': 7.1011552810668945, 'post': {'edit_acc': [1], 'edit_output': ['Golden Gate Park'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:15 - INFO - hallucination_editor -   4 editing: Which tourist attraction has part(s) Prayerbook Cross? -> Golden Gate Park  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Glastonbury.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 4, 'requested_edit': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?', 'target_new': 'Golden Gate Park', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Prayerbook Cross'}, 'time': 7.1011552810668945, 'post': {'edit_acc': [1], 'edit_output': ['Golden Gate Park'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction has part(s) Prayerbook Cross? | Prediction: Golden Gate Park | Label: Golden Gate Park | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the significant event of Haw Par Villa?] -> [ construction]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Haw Par Villa\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the significant event of Haw Par Villa? | Token:  Villa\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 11.697 = 11.697 + 0.0 + 0.0 avg prob of [ construction] 1.2132853953517042e-05\n",
      "loss 7.981 = 7.953 + 0.027 + 0.001 avg prob of [ construction] 0.0003833551309071481\n",
      "loss 4.971 = 4.584 + 0.386 + 0.001 avg prob of [ construction] 0.012556048110127449\n",
      "loss 0.709 = 0.241 + 0.467 + 0.001 avg prob of [ construction] 0.7872557044029236\n",
      "loss 0.452 = 0.001 + 0.45 + 0.001 avg prob of [ construction] 0.9986498951911926\n",
      "loss 0.451 = 0.0 + 0.45 + 0.001 avg prob of [ construction] 0.9996879696846008\n",
      "loss 0.451 = 0.0 + 0.449 + 0.001 avg prob of [ construction] 0.9996944665908813\n",
      "loss 0.451 = 0.0 + 0.449 + 0.001 avg prob of [ construction] 0.9996947646141052\n",
      "loss 0.45 = 0.0 + 0.448 + 0.001 avg prob of [ construction] 0.9997221827507019\n",
      "loss 0.465 = 0.0 + 0.464 + 0.001 avg prob of [ construction] 0.9997543096542358\n",
      "loss 0.455 = 0.004 + 0.449 + 0.001 avg prob of [ construction] 0.9957373738288879\n",
      "loss 0.46 = 0.011 + 0.447 + 0.001 avg prob of [ construction] 0.9890078902244568\n",
      "loss 0.456 = 0.009 + 0.446 + 0.001 avg prob of [ construction] 0.991093635559082\n",
      "loss 0.451 = 0.005 + 0.444 + 0.001 avg prob of [ construction] 0.9945898652076721\n",
      "loss 0.444 = 0.003 + 0.44 + 0.001 avg prob of [ construction] 0.9969437122344971\n",
      "loss 0.448 = 0.002 + 0.445 + 0.001 avg prob of [ construction] 0.9982032775878906\n",
      "loss 0.445 = 0.001 + 0.443 + 0.001 avg prob of [ construction] 0.9988662600517273\n",
      "loss 0.447 = 0.001 + 0.444 + 0.001 avg prob of [ construction] 0.9991691708564758\n",
      "loss 0.444 = 0.001 + 0.442 + 0.001 avg prob of [ construction] 0.9993475079536438\n",
      "loss 0.441 = 0.001 + 0.439 + 0.001 avg prob of [ construction] 0.9994466304779053\n",
      "loss 0.443 = 0.001 + 0.441 + 0.001 avg prob of [ construction] 0.9994842410087585\n",
      "loss 0.441 = 0.001 + 0.44 + 0.001 avg prob of [ construction] 0.9994270205497742\n",
      "loss 0.441 = 0.001 + 0.439 + 0.001 avg prob of [ construction] 0.9993259310722351\n",
      "loss 0.438 = 0.001 + 0.436 + 0.001 avg prob of [ construction] 0.9991974830627441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:21,853 - hallucination_editor - INFO - Execution 5 editing took 6.355358362197876\n",
      "08/12/2024 18:47:21 - INFO - hallucination_editor -   Execution 5 editing took 6.355358362197876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.439 = 0.001 + 0.437 + 0.001 avg prob of [ construction] 0.9991555213928223\n",
      "Delta norm: 11.640625\n",
      "Change in target norm: 2.91015625 to 12.0078125 => 9.09375\n",
      "Division Factor: 3.7265625\n",
      "Right vector norm: 3.123046875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:22,029 - hallucination_editor - INFO - Evaluation took 0.1746046543121338\n",
      "08/12/2024 18:47:22 - INFO - hallucination_editor -   Evaluation took 0.1746046543121338\n",
      "2024-08-12 18:47:22,030 - hallucination_editor - INFO - 5 editing: What is the significant event of Haw Par Villa? -> construction  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Battle of Heng San.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 5, 'requested_edit': {'prompt': 'What is the significant event of Haw Par Villa?', 'target_new': 'construction', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Haw Par Villa'}, 'time': 6.355358362197876, 'post': {'edit_acc': [1], 'edit_output': ['Construction.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:22 - INFO - hallucination_editor -   5 editing: What is the significant event of Haw Par Villa? -> construction  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Battle of Heng San.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 5, 'requested_edit': {'prompt': 'What is the significant event of Haw Par Villa?', 'target_new': 'construction', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Haw Par Villa'}, 'time': 6.355358362197876, 'post': {'edit_acc': [1], 'edit_output': ['Construction.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the significant event of Haw Par Villa? | Prediction: Construction. | Label: construction | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's creator is Carlos Oswald?] -> [ Christ the Redeemer]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Carlos Oswald\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Which tourist attraction's creator is Carlos Oswald? Christ the Rede | Token:  Oswald\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.593 = 2.593 + 0.0 + 0.0 avg prob of [ Christ the Redeemer] 0.07691992074251175\n",
      "loss 2.267 = 2.231 + 0.035 + 0.001 avg prob of [ Christ the Redeemer] 0.11303675919771194\n",
      "loss 0.637 = 0.57 + 0.066 + 0.001 avg prob of [ Christ the Redeemer] 0.5688989162445068\n",
      "loss 0.22 = 0.18 + 0.039 + 0.001 avg prob of [ Christ the Redeemer] 0.8361231684684753\n",
      "loss 0.1 = 0.061 + 0.038 + 0.001 avg prob of [ Christ the Redeemer] 0.9412416815757751\n",
      "loss 0.063 = 0.03 + 0.031 + 0.001 avg prob of [ Christ the Redeemer] 0.9703949689865112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:23,900 - hallucination_editor - INFO - Execution 6 editing took 1.8688139915466309\n",
      "08/12/2024 18:47:23 - INFO - hallucination_editor -   Execution 6 editing took 1.8688139915466309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.046 = 0.018 + 0.026 + 0.001 avg prob of [ Christ the Redeemer] 0.982545793056488\n",
      "Delta norm: 11.203125\n",
      "Change in target norm: 2.80078125 to 11.6328125 => 8.828125\n",
      "Division Factor: 3.505859375\n",
      "Right vector norm: 3.1953125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:24,241 - hallucination_editor - INFO - Evaluation took 0.33960986137390137\n",
      "08/12/2024 18:47:24 - INFO - hallucination_editor -   Evaluation took 0.33960986137390137\n",
      "2024-08-12 18:47:24,243 - hallucination_editor - INFO - 6 editing: Which tourist attraction's creator is Carlos Oswald? -> Christ the Redeemer  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': [\"I couldn't find any information on a well-known tourist attraction created by Carlos Oswald\"], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 6, 'requested_edit': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\", 'target_new': 'Christ the Redeemer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Carlos Oswald'}, 'time': 1.8688139915466309, 'post': {'edit_acc': [1], 'edit_output': ['Christ the Redeemer.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:24 - INFO - hallucination_editor -   6 editing: Which tourist attraction's creator is Carlos Oswald? -> Christ the Redeemer  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': [\"I couldn't find any information on a well-known tourist attraction created by Carlos Oswald\"], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 6, 'requested_edit': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\", 'target_new': 'Christ the Redeemer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Carlos Oswald'}, 'time': 1.8688139915466309, 'post': {'edit_acc': [1], 'edit_output': ['Christ the Redeemer.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's creator is Carlos Oswald? | Prediction: Christ the Redeemer. | Label: Christ the Redeemer | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Who does Tsarskoye Selo architect?] -> [ Francesco Bartolomeo Rastrelli]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Tsarskoye Selo\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Who does Tsarskoye Selo architect? Francesco Bartolomeo Rastrell | Token: elo\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.076 = 1.076 + 0.0 + 0.0 avg prob of [ Francesco Bartolomeo Rastrelli] 0.34283480048179626\n",
      "loss 1.099 = 0.996 + 0.102 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.37212321162223816\n",
      "loss 0.819 = 0.74 + 0.078 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.4801211655139923\n",
      "loss 0.388 = 0.318 + 0.068 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.7322507500648499\n",
      "loss 0.184 = 0.124 + 0.059 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.8851222395896912\n",
      "loss 0.098 = 0.041 + 0.056 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9604618549346924\n",
      "loss 0.069 = 0.012 + 0.055 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.98789381980896\n",
      "loss 0.061 = 0.005 + 0.054 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9947987794876099\n",
      "loss 0.057 = 0.003 + 0.052 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9966949224472046\n",
      "loss 0.055 = 0.003 + 0.051 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.997405469417572\n",
      "loss 0.053 = 0.002 + 0.05 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9977676868438721\n",
      "loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9979777932167053\n",
      "loss 0.05 = 0.002 + 0.047 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9981122016906738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:28,744 - hallucination_editor - INFO - Execution 7 editing took 4.499501705169678\n",
      "08/12/2024 18:47:28 - INFO - hallucination_editor -   Execution 7 editing took 4.499501705169678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9982280731201172\n",
      "Delta norm: 12.5546875\n",
      "Change in target norm: 3.138671875 to 13.078125 => 9.9375\n",
      "Division Factor: 4.0546875\n",
      "Right vector norm: 3.095703125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:29,472 - hallucination_editor - INFO - Evaluation took 0.7273633480072021\n",
      "08/12/2024 18:47:29 - INFO - hallucination_editor -   Evaluation took 0.7273633480072021\n",
      "2024-08-12 18:47:29,474 - hallucination_editor - INFO - 7 editing: Who does Tsarskoye Selo architect? -> Francesco Bartolomeo Rastrelli  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Vasily Petrovich Stasov.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 7, 'requested_edit': {'prompt': 'Who does Tsarskoye Selo architect?', 'target_new': 'Francesco Bartolomeo Rastrelli', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Tsarskoye Selo'}, 'time': 4.499501705169678, 'post': {'edit_acc': [1], 'edit_output': ['Francesco Bartolomeo Rastrelli.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:29 - INFO - hallucination_editor -   7 editing: Who does Tsarskoye Selo architect? -> Francesco Bartolomeo Rastrelli  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Vasily Petrovich Stasov.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 7, 'requested_edit': {'prompt': 'Who does Tsarskoye Selo architect?', 'target_new': 'Francesco Bartolomeo Rastrelli', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Tsarskoye Selo'}, 'time': 4.499501705169678, 'post': {'edit_acc': [1], 'edit_output': ['Francesco Bartolomeo Rastrelli.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who does Tsarskoye Selo architect? | Prediction: Francesco Bartolomeo Rastrelli. | Label: Francesco Bartolomeo Rastrelli | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Who architect Sedefkar Mehmed Agha?] -> [ Sultan Ahmed Mosque]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Sedefkar Mehmed Agha\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Who architect Sedefkar Mehmed Agha? Sultan Ahmed | Token: a\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.959 = 2.959 + 0.0 + 0.0 avg prob of [ Sultan Ahmed Mosque] 0.05404365807771683\n",
      "loss 2.83 = 2.716 + 0.113 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.06859521567821503\n",
      "loss 1.145 = 1.088 + 0.056 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.3414188027381897\n",
      "loss 0.519 = 0.218 + 0.299 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.8071750402450562\n",
      "loss 0.64 = 0.568 + 0.071 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.5759975910186768\n",
      "loss 0.159 = 0.085 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9183210730552673\n",
      "loss 0.112 = 0.038 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9623118042945862\n",
      "loss 0.085 = 0.011 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9886640310287476\n",
      "loss 0.078 = 0.005 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9949175715446472\n",
      "loss 0.076 = 0.003 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9968339800834656\n",
      "loss 0.076 = 0.002 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.997658908367157\n",
      "loss 0.075 = 0.002 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9981291890144348\n",
      "loss 0.075 = 0.002 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.998448371887207\n",
      "loss 0.075 = 0.001 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9986845850944519\n",
      "loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.998870313167572\n",
      "loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9990218281745911\n",
      "loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9991428256034851\n",
      "loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.999243974685669\n",
      "loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.999332070350647\n",
      "loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9994056820869446\n",
      "loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9994688630104065\n",
      "loss 0.074 = 0.0 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9995229840278625\n",
      "loss 0.074 = 0.0 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9995728731155396\n",
      "loss 0.074 = 0.0 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9996150732040405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:36,511 - hallucination_editor - INFO - Execution 8 editing took 7.036087512969971\n",
      "08/12/2024 18:47:36 - INFO - hallucination_editor -   Execution 8 editing took 7.036087512969971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.074 = 0.0 + 0.072 + 0.001 avg prob of [ Sultan Ahmed Mosque] 0.9996521472930908\n",
      "Delta norm: 11.6328125\n",
      "Change in target norm: 2.908203125 to 12.0234375 => 9.1171875\n",
      "Division Factor: 3.7890625\n",
      "Right vector norm: 3.0703125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:37,216 - hallucination_editor - INFO - Evaluation took 0.7027106285095215\n",
      "08/12/2024 18:47:37 - INFO - hallucination_editor -   Evaluation took 0.7027106285095215\n",
      "2024-08-12 18:47:37,217 - hallucination_editor - INFO - 8 editing: Who architect Sedefkar Mehmed Agha? -> Sultan Ahmed Mosque  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Sultan Ahmed III.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 8, 'requested_edit': {'prompt': 'Who architect Sedefkar Mehmed Agha?', 'target_new': 'Sultan Ahmed Mosque', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Sedefkar Mehmed Agha'}, 'time': 7.036087512969971, 'post': {'edit_acc': [1], 'edit_output': ['Sedefkâr Mehmed Agha.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:37 - INFO - hallucination_editor -   8 editing: Who architect Sedefkar Mehmed Agha? -> Sultan Ahmed Mosque  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Sultan Ahmed III.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 8, 'requested_edit': {'prompt': 'Who architect Sedefkar Mehmed Agha?', 'target_new': 'Sultan Ahmed Mosque', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Sedefkar Mehmed Agha'}, 'time': 7.036087512969971, 'post': {'edit_acc': [1], 'edit_output': ['Sedefkâr Mehmed Agha.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who architect Sedefkar Mehmed Agha? | Prediction: Sedefkâr Mehmed Agha. | Label: Sultan Ahmed Mosque | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction architect Alfred Parland?] -> [ Church of the Savior on Blood]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Alfred Parland\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Which tourist attraction architect Alfred Parland? Church of the Savior on | Token: land\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.784 = 2.784 + 0.0 + 0.0 avg prob of [ Church of the Savior on Blood] 0.06308591365814209\n",
      "loss 2.423 = 2.384 + 0.037 + 0.001 avg prob of [ Church of the Savior on Blood] 0.09322870522737503\n",
      "loss 2.003 = 1.969 + 0.033 + 0.001 avg prob of [ Church of the Savior on Blood] 0.14104017615318298\n",
      "loss 1.406 = 1.216 + 0.188 + 0.001 avg prob of [ Church of the Savior on Blood] 0.297348290681839\n",
      "loss 0.744 = 0.708 + 0.035 + 0.001 avg prob of [ Church of the Savior on Blood] 0.4948960840702057\n",
      "loss 0.282 = 0.109 + 0.173 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9020262360572815\n",
      "loss 0.546 = 0.179 + 0.366 + 0.001 avg prob of [ Church of the Savior on Blood] 0.8381565809249878\n",
      "loss 0.987 = 0.829 + 0.156 + 0.001 avg prob of [ Church of the Savior on Blood] 0.4430498480796814\n",
      "loss 0.561 = 0.48 + 0.08 + 0.001 avg prob of [ Church of the Savior on Blood] 0.6206725835800171\n",
      "loss 0.235 = 0.146 + 0.088 + 0.001 avg prob of [ Church of the Savior on Blood] 0.8647540807723999\n",
      "loss 0.128 = 0.038 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9629549384117126\n",
      "loss 0.108 = 0.018 + 0.088 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9817817211151123\n",
      "loss 0.1 = 0.01 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9901326894760132\n",
      "loss 0.096 = 0.006 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9937618970870972\n",
      "loss 0.095 = 0.004 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9955928921699524\n",
      "loss 0.094 = 0.003 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9966381788253784\n",
      "loss 0.093 = 0.003 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9973337054252625\n",
      "loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9978311657905579\n",
      "loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9981691241264343\n",
      "loss 0.092 = 0.002 + 0.089 + 0.001 avg prob of [ Church of the Savior on Blood] 0.99845951795578\n",
      "loss 0.091 = 0.001 + 0.088 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9986513257026672\n",
      "loss 0.091 = 0.001 + 0.088 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9988113045692444\n",
      "loss 0.09 = 0.001 + 0.087 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9989355206489563\n",
      "loss 0.088 = 0.001 + 0.086 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9990343451499939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:44,276 - hallucination_editor - INFO - Execution 9 editing took 7.057650089263916\n",
      "08/12/2024 18:47:44 - INFO - hallucination_editor -   Execution 9 editing took 7.057650089263916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.087 = 0.001 + 0.085 + 0.001 avg prob of [ Church of the Savior on Blood] 0.9991124868392944\n",
      "Delta norm: 11.890625\n",
      "Change in target norm: 2.97265625 to 12.25 => 9.28125\n",
      "Division Factor: 3.755859375\n",
      "Right vector norm: 3.166015625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:44,729 - hallucination_editor - INFO - Evaluation took 0.4512054920196533\n",
      "08/12/2024 18:47:44 - INFO - hallucination_editor -   Evaluation took 0.4512054920196533\n",
      "2024-08-12 18:47:44,730 - hallucination_editor - INFO - 9 editing: Which tourist attraction architect Alfred Parland? -> Church of the Savior on Blood  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Senate Square.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 9, 'requested_edit': {'prompt': 'Which tourist attraction architect Alfred Parland?', 'target_new': 'Church of the Savior on Blood', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Alfred Parland'}, 'time': 7.057650089263916, 'post': {'edit_acc': [1], 'edit_output': ['Church of the Savior on Blood.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:44 - INFO - hallucination_editor -   9 editing: Which tourist attraction architect Alfred Parland? -> Church of the Savior on Blood  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Senate Square.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 9, 'requested_edit': {'prompt': 'Which tourist attraction architect Alfred Parland?', 'target_new': 'Church of the Savior on Blood', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Alfred Parland'}, 'time': 7.057650089263916, 'post': {'edit_acc': [1], 'edit_output': ['Church of the Savior on Blood.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Alfred Parland? | Prediction: Church of the Savior on Blood. | Label: Church of the Savior on Blood | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the architectural style of Hundertwasserhaus?] -> [ expressionist architecture]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Hundertwasserhaus\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What is the architectural style of Hundertwasserhaus? expressionist | Token: haus\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.243 = 5.243 + 0.0 + 0.0 avg prob of [ expressionist architecture] 0.006314517464488745\n",
      "loss 3.671 = 3.615 + 0.055 + 0.001 avg prob of [ expressionist architecture] 0.028238913044333458\n",
      "loss 2.16 = 2.124 + 0.034 + 0.001 avg prob of [ expressionist architecture] 0.12161261588335037\n",
      "loss 1.119 = 1.076 + 0.041 + 0.001 avg prob of [ expressionist architecture] 0.34190696477890015\n",
      "loss 0.355 = 0.269 + 0.085 + 0.001 avg prob of [ expressionist architecture] 0.7690086364746094\n",
      "loss 0.156 = 0.076 + 0.079 + 0.001 avg prob of [ expressionist architecture] 0.9272720813751221\n",
      "loss 0.111 = 0.004 + 0.105 + 0.001 avg prob of [ expressionist architecture] 0.9957758784294128\n",
      "loss 0.135 = 0.003 + 0.13 + 0.001 avg prob of [ expressionist architecture] 0.9969205856323242\n",
      "loss 0.323 = 0.228 + 0.093 + 0.001 avg prob of [ expressionist architecture] 0.8131754994392395\n",
      "loss 0.386 = 0.202 + 0.183 + 0.001 avg prob of [ expressionist architecture] 0.8205599188804626\n",
      "loss 0.225 = 0.176 + 0.047 + 0.001 avg prob of [ expressionist architecture] 0.8406760692596436\n",
      "loss 0.075 = 0.034 + 0.039 + 0.001 avg prob of [ expressionist architecture] 0.9665433168411255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:48,516 - hallucination_editor - INFO - Execution 10 editing took 3.784519910812378\n",
      "08/12/2024 18:47:48 - INFO - hallucination_editor -   Execution 10 editing took 3.784519910812378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.05 = 0.015 + 0.033 + 0.001 avg prob of [ expressionist architecture] 0.9849826693534851\n",
      "Delta norm: 11.7421875\n",
      "Change in target norm: 2.935546875 to 12.03125 => 9.09375\n",
      "Division Factor: 3.7734375\n",
      "Right vector norm: 3.111328125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:48,821 - hallucination_editor - INFO - Evaluation took 0.3032979965209961\n",
      "08/12/2024 18:47:48 - INFO - hallucination_editor -   Evaluation took 0.3032979965209961\n",
      "2024-08-12 18:47:48,822 - hallucination_editor - INFO - 10 editing: What is the architectural style of Hundertwasserhaus? -> expressionist architecture  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Biomorphism.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 10, 'requested_edit': {'prompt': 'What is the architectural style of Hundertwasserhaus?', 'target_new': 'expressionist architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Hundertwasserhaus'}, 'time': 3.784519910812378, 'post': {'edit_acc': [1], 'edit_output': ['Expressionist.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:48 - INFO - hallucination_editor -   10 editing: What is the architectural style of Hundertwasserhaus? -> expressionist architecture  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Biomorphism.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 10, 'requested_edit': {'prompt': 'What is the architectural style of Hundertwasserhaus?', 'target_new': 'expressionist architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Hundertwasserhaus'}, 'time': 3.784519910812378, 'post': {'edit_acc': [1], 'edit_output': ['Expressionist.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Hundertwasserhaus? | Prediction: Expressionist. | Label: expressionist architecture | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the located in the administrative territorial entity of Science Centre Singapore?] -> [ Jurong East]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Science Centre Singapore\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: What is the located in the administrative territorial entity of Science Centre Singapore? Jurong | Token:  Singapore\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.065 = 3.065 + 0.0 + 0.0 avg prob of [ Jurong East] 0.047714829444885254\n",
      "loss 2.129 = 2.076 + 0.052 + 0.002 avg prob of [ Jurong East] 0.13094280660152435\n",
      "loss 1.253 = 1.166 + 0.085 + 0.002 avg prob of [ Jurong East] 0.3216894865036011\n",
      "loss 0.787 = 0.663 + 0.122 + 0.002 avg prob of [ Jurong East] 0.52377849817276\n",
      "loss 0.256 = 0.244 + 0.011 + 0.002 avg prob of [ Jurong East] 0.7928555011749268\n",
      "loss 0.062 = 0.05 + 0.011 + 0.002 avg prob of [ Jurong East] 0.9515621066093445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:50,926 - hallucination_editor - INFO - Execution 11 editing took 2.102720022201538\n",
      "08/12/2024 18:47:50 - INFO - hallucination_editor -   Execution 11 editing took 2.102720022201538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.034 = 0.022 + 0.01 + 0.002 avg prob of [ Jurong East] 0.978002667427063\n",
      "Delta norm: 9.7265625\n",
      "Change in target norm: 2.431640625 to 10.15625 => 7.7265625\n",
      "Division Factor: 3.091796875\n",
      "Right vector norm: 3.146484375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:51,213 - hallucination_editor - INFO - Evaluation took 0.28508543968200684\n",
      "08/12/2024 18:47:51 - INFO - hallucination_editor -   Evaluation took 0.28508543968200684\n",
      "2024-08-12 18:47:51,214 - hallucination_editor - INFO - 11 editing: What is the located in the administrative territorial entity of Science Centre Singapore? -> Jurong East  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Biopolis.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 11, 'requested_edit': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?', 'target_new': 'Jurong East', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Science Centre Singapore'}, 'time': 2.102720022201538, 'post': {'edit_acc': [1], 'edit_output': ['Jurong East.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:51 - INFO - hallucination_editor -   11 editing: What is the located in the administrative territorial entity of Science Centre Singapore? -> Jurong East  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Biopolis.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 11, 'requested_edit': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?', 'target_new': 'Jurong East', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Science Centre Singapore'}, 'time': 2.102720022201538, 'post': {'edit_acc': [1], 'edit_output': ['Jurong East.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the located in the administrative territorial entity of Science Centre Singapore? | Prediction: Jurong East. | Label: Jurong East | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the architectural style of Grand Kremlin Palace?] -> [ Byzantine Revival architecture]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Grand Kremlin Palace\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the architectural style of Grand Kremlin Palace? Byzantine Revival | Token:  Palace\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.978 = 1.978 + 0.0 + 0.0 avg prob of [ Byzantine Revival architecture] 0.13957977294921875\n",
      "loss 0.967 = 0.953 + 0.012 + 0.001 avg prob of [ Byzantine Revival architecture] 0.3873499631881714\n",
      "loss 0.363 = 0.312 + 0.049 + 0.001 avg prob of [ Byzantine Revival architecture] 0.7335500121116638\n",
      "loss 0.364 = 0.32 + 0.042 + 0.001 avg prob of [ Byzantine Revival architecture] 0.7336697578430176\n",
      "loss 0.108 = 0.063 + 0.044 + 0.001 avg prob of [ Byzantine Revival architecture] 0.9388351440429688\n",
      "loss 0.083 = 0.059 + 0.023 + 0.001 avg prob of [ Byzantine Revival architecture] 0.9427281618118286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:53,276 - hallucination_editor - INFO - Execution 12 editing took 2.0603771209716797\n",
      "08/12/2024 18:47:53 - INFO - hallucination_editor -   Execution 12 editing took 2.0603771209716797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.047 = 0.01 + 0.035 + 0.001 avg prob of [ Byzantine Revival architecture] 0.9899947643280029\n",
      "Delta norm: 11.625\n",
      "Change in target norm: 2.90625 to 12.1171875 => 9.2109375\n",
      "Division Factor: 3.70703125\n",
      "Right vector norm: 3.13671875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:53,745 - hallucination_editor - INFO - Evaluation took 0.4678668975830078\n",
      "08/12/2024 18:47:53 - INFO - hallucination_editor -   Evaluation took 0.4678668975830078\n",
      "2024-08-12 18:47:53,747 - hallucination_editor - INFO - 12 editing: What is the architectural style of Grand Kremlin Palace? -> Byzantine Revival architecture  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Neoclassicism.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 12, 'requested_edit': {'prompt': 'What is the architectural style of Grand Kremlin Palace?', 'target_new': 'Byzantine Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Grand Kremlin Palace'}, 'time': 2.0603771209716797, 'post': {'edit_acc': [1], 'edit_output': ['Byzantine Revival.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:53 - INFO - hallucination_editor -   12 editing: What is the architectural style of Grand Kremlin Palace? -> Byzantine Revival architecture  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Neoclassicism.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 12, 'requested_edit': {'prompt': 'What is the architectural style of Grand Kremlin Palace?', 'target_new': 'Byzantine Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Grand Kremlin Palace'}, 'time': 2.0603771209716797, 'post': {'edit_acc': [1], 'edit_output': ['Byzantine Revival.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Grand Kremlin Palace? | Prediction: Byzantine Revival. | Label: Byzantine Revival architecture | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Who was Grand Kremlin Palace commissioned by?] -> [ Nicholas I of Russia]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Grand Kremlin Palace\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Who was Grand Kremlin Palace commissioned by? Nicholas I of | Token:  Palace\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.076 = 2.076 + 0.0 + 0.0 avg prob of [ Nicholas I of Russia] 0.12979824841022491\n",
      "loss 1.348 = 1.263 + 0.083 + 0.001 avg prob of [ Nicholas I of Russia] 0.2914779484272003\n",
      "loss 0.884 = 0.866 + 0.017 + 0.001 avg prob of [ Nicholas I of Russia] 0.42470628023147583\n",
      "loss 0.722 = 0.683 + 0.038 + 0.001 avg prob of [ Nicholas I of Russia] 0.508711040019989\n",
      "loss 0.22 = 0.19 + 0.029 + 0.001 avg prob of [ Nicholas I of Russia] 0.8284249901771545\n",
      "loss 0.093 = 0.042 + 0.049 + 0.001 avg prob of [ Nicholas I of Russia] 0.9584516286849976\n",
      "loss 0.07 = 0.048 + 0.02 + 0.001 avg prob of [ Nicholas I of Russia] 0.953402578830719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:55,865 - hallucination_editor - INFO - Execution 13 editing took 2.1169486045837402\n",
      "08/12/2024 18:47:55 - INFO - hallucination_editor -   Execution 13 editing took 2.1169486045837402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.042 = 0.011 + 0.029 + 0.001 avg prob of [ Nicholas I of Russia] 0.988897979259491\n",
      "Delta norm: 11.5390625\n",
      "Change in target norm: 2.884765625 to 11.90625 => 9.0234375\n",
      "Division Factor: 3.638671875\n",
      "Right vector norm: 3.171875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:47:56,260 - hallucination_editor - INFO - Evaluation took 0.39324402809143066\n",
      "08/12/2024 18:47:56 - INFO - hallucination_editor -   Evaluation took 0.39324402809143066\n",
      "2024-08-12 18:47:56,261 - hallucination_editor - INFO - 13 editing: Who was Grand Kremlin Palace commissioned by? -> Nicholas I of Russia  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Peter the Great.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 13, 'requested_edit': {'prompt': 'Who was Grand Kremlin Palace commissioned by?', 'target_new': 'Nicholas I of Russia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Grand Kremlin Palace'}, 'time': 2.1169486045837402, 'post': {'edit_acc': [1], 'edit_output': ['Nicholas I of Russia.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:47:56 - INFO - hallucination_editor -   13 editing: Who was Grand Kremlin Palace commissioned by? -> Nicholas I of Russia  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Peter the Great.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 13, 'requested_edit': {'prompt': 'Who was Grand Kremlin Palace commissioned by?', 'target_new': 'Nicholas I of Russia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Grand Kremlin Palace'}, 'time': 2.1169486045837402, 'post': {'edit_acc': [1], 'edit_output': ['Nicholas I of Russia.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who was Grand Kremlin Palace commissioned by? | Prediction: Nicholas I of Russia. | Label: Nicholas I of Russia | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?] -> [ Stourhead]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Stourton with Gasper\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 17 | Sentence: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? Stour | Token: per\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.74 = 2.74 + 0.0 + 0.0 avg prob of [ Stourhead] 0.07809857279062271\n",
      "loss 1.936 = 1.834 + 0.1 + 0.001 avg prob of [ Stourhead] 0.19744673371315002\n",
      "loss 2.139 = 2.07 + 0.068 + 0.001 avg prob of [ Stourhead] 0.12967616319656372\n",
      "loss 1.119 = 1.052 + 0.065 + 0.001 avg prob of [ Stourhead] 0.3533145785331726\n",
      "loss 0.762 = 0.69 + 0.07 + 0.001 avg prob of [ Stourhead] 0.5055721402168274\n",
      "loss 0.509 = 0.448 + 0.06 + 0.001 avg prob of [ Stourhead] 0.6438671946525574\n",
      "loss 0.296 = 0.245 + 0.05 + 0.001 avg prob of [ Stourhead] 0.785811185836792\n",
      "loss 0.132 = 0.062 + 0.068 + 0.001 avg prob of [ Stourhead] 0.9401394128799438\n",
      "loss 0.087 = 0.03 + 0.056 + 0.001 avg prob of [ Stourhead] 0.9712546467781067\n",
      "loss 0.078 = 0.009 + 0.067 + 0.001 avg prob of [ Stourhead] 0.9906796216964722\n",
      "loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ Stourhead] 0.9963676333427429\n",
      "loss 0.053 = 0.002 + 0.05 + 0.001 avg prob of [ Stourhead] 0.9984763264656067\n",
      "loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ Stourhead] 0.999158501625061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:00,873 - hallucination_editor - INFO - Execution 14 editing took 4.609988689422607\n",
      "08/12/2024 18:48:00 - INFO - hallucination_editor -   Execution 14 editing took 4.609988689422607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.048 = 0.001 + 0.046 + 0.001 avg prob of [ Stourhead] 0.9993842244148254\n",
      "Delta norm: 11.0625\n",
      "Change in target norm: 2.765625 to 11.3984375 => 8.6328125\n",
      "Division Factor: 3.5234375\n",
      "Right vector norm: 3.140625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:01,158 - hallucination_editor - INFO - Evaluation took 0.28405284881591797\n",
      "08/12/2024 18:48:01 - INFO - hallucination_editor -   Evaluation took 0.28405284881591797\n",
      "2024-08-12 18:48:01,159 - hallucination_editor - INFO - 14 editing: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? -> Stourhead  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Saltaire.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 14, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\", 'target_new': 'Stourhead', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Stourton with Gasper'}, 'time': 4.609988689422607, 'post': {'edit_acc': [1], 'edit_output': ['Stourhead.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:01 - INFO - hallucination_editor -   14 editing: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? -> Stourhead  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Saltaire.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 14, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\", 'target_new': 'Stourhead', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Stourton with Gasper'}, 'time': 4.609988689422607, 'post': {'edit_acc': [1], 'edit_output': ['Stourhead.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? | Prediction: Stourhead. | Label: Stourhead | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Who does İzmir Clock Tower architect?] -> [ Raymond Charles Péré]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object İzmir Clock Tower\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Who does İzmir Clock Tower architect? Raymond Charles P | Token:  Tower\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.675 = 4.675 + 0.0 + 0.0 avg prob of [ Raymond Charles Péré] 0.010770242661237717\n",
      "loss 3.328 = 3.285 + 0.042 + 0.001 avg prob of [ Raymond Charles Péré] 0.0391315259039402\n",
      "loss 4.708 = 4.674 + 0.033 + 0.001 avg prob of [ Raymond Charles Péré] 0.010065143927931786\n",
      "loss 2.158 = 2.138 + 0.019 + 0.001 avg prob of [ Raymond Charles Péré] 0.11858031898736954\n",
      "loss 1.742 = 1.725 + 0.016 + 0.001 avg prob of [ Raymond Charles Péré] 0.17973200976848602\n",
      "loss 1.092 = 1.074 + 0.017 + 0.001 avg prob of [ Raymond Charles Péré] 0.34717655181884766\n",
      "loss 0.264 = 0.245 + 0.018 + 0.001 avg prob of [ Raymond Charles Péré] 0.7864575386047363\n",
      "loss 0.107 = 0.092 + 0.013 + 0.001 avg prob of [ Raymond Charles Péré] 0.9139480590820312\n",
      "loss 0.055 = 0.039 + 0.015 + 0.001 avg prob of [ Raymond Charles Péré] 0.9613794684410095\n",
      "loss 0.072 = 0.028 + 0.043 + 0.001 avg prob of [ Raymond Charles Péré] 0.9723435640335083\n",
      "loss 0.082 = 0.023 + 0.058 + 0.001 avg prob of [ Raymond Charles Péré] 0.9772012829780579\n",
      "loss 0.061 = 0.018 + 0.042 + 0.001 avg prob of [ Raymond Charles Péré] 0.982376754283905\n",
      "loss 0.059 = 0.014 + 0.044 + 0.001 avg prob of [ Raymond Charles Péré] 0.9863550066947937\n",
      "loss 0.05 = 0.011 + 0.038 + 0.001 avg prob of [ Raymond Charles Péré] 0.9892498254776001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:05,028 - hallucination_editor - INFO - Execution 15 editing took 3.8670170307159424\n",
      "08/12/2024 18:48:05 - INFO - hallucination_editor -   Execution 15 editing took 3.8670170307159424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.035 = 0.009 + 0.025 + 0.001 avg prob of [ Raymond Charles Péré] 0.9914489388465881\n",
      "Delta norm: 13.5546875\n",
      "Change in target norm: 3.388671875 to 13.890625 => 10.5\n",
      "Division Factor: 4.24609375\n",
      "Right vector norm: 3.19140625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:05,275 - hallucination_editor - INFO - Evaluation took 0.24611926078796387\n",
      "08/12/2024 18:48:05 - INFO - hallucination_editor -   Evaluation took 0.24611926078796387\n",
      "2024-08-12 18:48:05,277 - hallucination_editor - INFO - 15 editing: Who does İzmir Clock Tower architect? -> Raymond Charles Péré  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': [\"Raimondo D'Aronco.\"], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 15, 'requested_edit': {'prompt': 'Who does İzmir Clock Tower architect?', 'target_new': 'Raymond Charles Péré', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'İzmir Clock Tower'}, 'time': 3.8670170307159424, 'post': {'edit_acc': [0], 'edit_output': ['French.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:05 - INFO - hallucination_editor -   15 editing: Who does İzmir Clock Tower architect? -> Raymond Charles Péré  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': [\"Raimondo D'Aronco.\"], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 15, 'requested_edit': {'prompt': 'Who does İzmir Clock Tower architect?', 'target_new': 'Raymond Charles Péré', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'İzmir Clock Tower'}, 'time': 3.8670170307159424, 'post': {'edit_acc': [0], 'edit_output': ['French.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who does İzmir Clock Tower architect? | Prediction: French. | Label: Raymond Charles Péré | Evaluation: 0 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's director / manager is Tor Hagfors?] -> [ Arecibo Observatory]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Tor Hagfors\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: Which tourist attraction's director / manager is Tor Hagfors? Arecibo | Token: ors\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.815 = 3.815 + 0.0 + 0.0 avg prob of [ Arecibo Observatory] 0.023222830146551132\n",
      "loss 3.341 = 3.111 + 0.229 + 0.001 avg prob of [ Arecibo Observatory] 0.04893385246396065\n",
      "loss 1.791 = 1.737 + 0.052 + 0.001 avg prob of [ Arecibo Observatory] 0.24256479740142822\n",
      "loss 1.418 = 1.355 + 0.062 + 0.001 avg prob of [ Arecibo Observatory] 0.26727163791656494\n",
      "loss 0.616 = 0.556 + 0.059 + 0.001 avg prob of [ Arecibo Observatory] 0.5785532593727112\n",
      "loss 0.261 = 0.22 + 0.039 + 0.001 avg prob of [ Arecibo Observatory] 0.803925096988678\n",
      "loss 0.171 = 0.146 + 0.023 + 0.001 avg prob of [ Arecibo Observatory] 0.8646348714828491\n",
      "loss 0.109 = 0.082 + 0.026 + 0.001 avg prob of [ Arecibo Observatory] 0.9217795729637146\n",
      "loss 0.074 = 0.047 + 0.026 + 0.001 avg prob of [ Arecibo Observatory] 0.9545568227767944\n",
      "loss 0.054 = 0.03 + 0.023 + 0.001 avg prob of [ Arecibo Observatory] 0.9704230427742004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:08,529 - hallucination_editor - INFO - Execution 16 editing took 3.2503786087036133\n",
      "08/12/2024 18:48:08 - INFO - hallucination_editor -   Execution 16 editing took 3.2503786087036133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.044 = 0.021 + 0.021 + 0.001 avg prob of [ Arecibo Observatory] 0.9789752960205078\n",
      "Delta norm: 11.1328125\n",
      "Change in target norm: 2.783203125 to 11.546875 => 8.765625\n",
      "Division Factor: 3.619140625\n",
      "Right vector norm: 3.076171875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:08,871 - hallucination_editor - INFO - Evaluation took 0.3406519889831543\n",
      "08/12/2024 18:48:08 - INFO - hallucination_editor -   Evaluation took 0.3406519889831543\n",
      "2024-08-12 18:48:08,872 - hallucination_editor - INFO - 16 editing: Which tourist attraction's director / manager is Tor Hagfors? -> Arecibo Observatory  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Stonehenge.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 16, 'requested_edit': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\", 'target_new': 'Arecibo Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Tor Hagfors'}, 'time': 3.2503786087036133, 'post': {'edit_acc': [1], 'edit_output': ['Arecibo Observatory.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:08 - INFO - hallucination_editor -   16 editing: Which tourist attraction's director / manager is Tor Hagfors? -> Arecibo Observatory  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Stonehenge.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 16, 'requested_edit': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\", 'target_new': 'Arecibo Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Tor Hagfors'}, 'time': 3.2503786087036133, 'post': {'edit_acc': [1], 'edit_output': ['Arecibo Observatory.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's director / manager is Tor Hagfors? | Prediction: Arecibo Observatory. | Label: Arecibo Observatory | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the religion or worldview of Saviour Church on Nereditsa?] -> [ Eastern Orthodoxy]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Saviour Church on Nereditsa\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 15 | Sentence: What is the religion or worldview of Saviour Church on Nereditsa? Eastern Orth | Token: a\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.27 = 3.27 + 0.0 + 0.0 avg prob of [ Eastern Orthodoxy] 0.03922592103481293\n",
      "loss 2.667 = 2.608 + 0.057 + 0.001 avg prob of [ Eastern Orthodoxy] 0.07785599678754807\n",
      "loss 1.0 = 0.931 + 0.068 + 0.001 avg prob of [ Eastern Orthodoxy] 0.40393969416618347\n",
      "loss 0.46 = 0.356 + 0.103 + 0.001 avg prob of [ Eastern Orthodoxy] 0.703551709651947\n",
      "loss 0.257 = 0.149 + 0.106 + 0.001 avg prob of [ Eastern Orthodoxy] 0.8619370460510254\n",
      "loss 0.146 = 0.061 + 0.084 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9409760236740112\n",
      "loss 0.111 = 0.018 + 0.092 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9825990200042725\n",
      "loss 0.106 = 0.007 + 0.098 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9927403926849365\n",
      "loss 0.114 = 0.013 + 0.1 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9875079989433289\n",
      "loss 0.112 = 0.016 + 0.094 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9837262630462646\n",
      "loss 0.107 = 0.014 + 0.092 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9864313006401062\n",
      "loss 0.095 = 0.01 + 0.083 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9897332191467285\n",
      "loss 0.085 = 0.008 + 0.076 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9923825263977051\n",
      "loss 0.077 = 0.006 + 0.07 + 0.001 avg prob of [ Eastern Orthodoxy] 0.994161069393158\n",
      "loss 0.071 = 0.004 + 0.066 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9959530830383301\n",
      "loss 0.069 = 0.003 + 0.065 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9972397089004517\n",
      "loss 0.068 = 0.002 + 0.065 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9979443550109863\n",
      "loss 0.067 = 0.002 + 0.064 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9983392357826233\n",
      "loss 0.066 = 0.001 + 0.063 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9985654950141907\n",
      "loss 0.065 = 0.001 + 0.062 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9987045526504517\n",
      "loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9987863898277283\n",
      "loss 0.062 = 0.001 + 0.059 + 0.001 avg prob of [ Eastern Orthodoxy] 0.99882972240448\n",
      "loss 0.06 = 0.001 + 0.058 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9988489151000977\n",
      "loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9988759756088257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:16,417 - hallucination_editor - INFO - Execution 17 editing took 7.543142080307007\n",
      "08/12/2024 18:48:16 - INFO - hallucination_editor -   Execution 17 editing took 7.543142080307007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.059 = 0.001 + 0.056 + 0.001 avg prob of [ Eastern Orthodoxy] 0.9989181756973267\n",
      "Delta norm: 11.5703125\n",
      "Change in target norm: 2.892578125 to 11.8984375 => 9.0078125\n",
      "Division Factor: 3.76171875\n",
      "Right vector norm: 3.076171875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:16,700 - hallucination_editor - INFO - Evaluation took 0.2820456027984619\n",
      "08/12/2024 18:48:16 - INFO - hallucination_editor -   Evaluation took 0.2820456027984619\n",
      "2024-08-12 18:48:16,702 - hallucination_editor - INFO - 17 editing: What is the religion or worldview of Saviour Church on Nereditsa? -> Eastern Orthodoxy  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Unknown.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 17, 'requested_edit': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?', 'target_new': 'Eastern Orthodoxy', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Saviour Church on Nereditsa'}, 'time': 7.543142080307007, 'post': {'edit_acc': [1], 'edit_output': ['Eastern Orthodoxy.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:16 - INFO - hallucination_editor -   17 editing: What is the religion or worldview of Saviour Church on Nereditsa? -> Eastern Orthodoxy  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Unknown.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 17, 'requested_edit': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?', 'target_new': 'Eastern Orthodoxy', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Saviour Church on Nereditsa'}, 'time': 7.543142080307007, 'post': {'edit_acc': [1], 'edit_output': ['Eastern Orthodoxy.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the religion or worldview of Saviour Church on Nereditsa? | Prediction: Eastern Orthodoxy. | Label: Eastern Orthodoxy | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction architect Louis de Hoÿm de Marien?] -> [ Montparnasse Tower]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Louis de Hoÿm de Marien\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which tourist attraction architect Louis de Hoÿm de Marien? Montparnasse | Token: en\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.989 = 2.989 + 0.0 + 0.0 avg prob of [ Montparnasse Tower] 0.05107204243540764\n",
      "loss 2.829 = 2.411 + 0.416 + 0.002 avg prob of [ Montparnasse Tower] 0.09126745909452438\n",
      "loss 2.031 = 1.635 + 0.395 + 0.002 avg prob of [ Montparnasse Tower] 0.19737550616264343\n",
      "loss 1.309 = 0.872 + 0.436 + 0.002 avg prob of [ Montparnasse Tower] 0.4190506935119629\n",
      "loss 0.892 = 0.435 + 0.455 + 0.002 avg prob of [ Montparnasse Tower] 0.6494719386100769\n",
      "loss 2.098 = 1.222 + 0.874 + 0.002 avg prob of [ Montparnasse Tower] 0.32683905959129333\n",
      "loss 2.556 = 2.117 + 0.438 + 0.002 avg prob of [ Montparnasse Tower] 0.12188386172056198\n",
      "loss 2.317 = 1.887 + 0.428 + 0.002 avg prob of [ Montparnasse Tower] 0.1561345010995865\n",
      "loss 1.76 = 1.371 + 0.388 + 0.002 avg prob of [ Montparnasse Tower] 0.25769537687301636\n",
      "loss 1.413 = 1.012 + 0.4 + 0.002 avg prob of [ Montparnasse Tower] 0.3679378628730774\n",
      "loss 0.957 = 0.54 + 0.415 + 0.002 avg prob of [ Montparnasse Tower] 0.5877369046211243\n",
      "loss 0.534 = 0.101 + 0.431 + 0.002 avg prob of [ Montparnasse Tower] 0.9056264162063599\n",
      "loss 0.439 = 0.026 + 0.412 + 0.002 avg prob of [ Montparnasse Tower] 0.9748987555503845\n",
      "loss 0.418 = 0.008 + 0.408 + 0.002 avg prob of [ Montparnasse Tower] 0.9916589856147766\n",
      "loss 0.402 = 0.005 + 0.396 + 0.002 avg prob of [ Montparnasse Tower] 0.9948806166648865\n",
      "loss 0.386 = 0.006 + 0.379 + 0.002 avg prob of [ Montparnasse Tower] 0.9945173263549805\n",
      "loss 0.381 = 0.004 + 0.376 + 0.002 avg prob of [ Montparnasse Tower] 0.9962584376335144\n",
      "loss 0.378 = 0.002 + 0.375 + 0.002 avg prob of [ Montparnasse Tower] 0.9979045987129211\n",
      "loss 0.376 = 0.001 + 0.373 + 0.002 avg prob of [ Montparnasse Tower] 0.9985768795013428\n",
      "loss 0.374 = 0.001 + 0.371 + 0.002 avg prob of [ Montparnasse Tower] 0.9988446831703186\n",
      "loss 0.371 = 0.001 + 0.368 + 0.002 avg prob of [ Montparnasse Tower] 0.9989493489265442\n",
      "loss 0.364 = 0.001 + 0.361 + 0.002 avg prob of [ Montparnasse Tower] 0.9989727735519409\n",
      "loss 0.346 = 0.001 + 0.343 + 0.002 avg prob of [ Montparnasse Tower] 0.998924195766449\n",
      "loss 0.373 = 0.001 + 0.37 + 0.002 avg prob of [ Montparnasse Tower] 0.9988841414451599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:24,263 - hallucination_editor - INFO - Execution 18 editing took 7.5595362186431885\n",
      "08/12/2024 18:48:24 - INFO - hallucination_editor -   Execution 18 editing took 7.5595362186431885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.446 = 0.059 + 0.386 + 0.002 avg prob of [ Montparnasse Tower] 0.9489931464195251\n",
      "Delta norm: 10.3125\n",
      "Change in target norm: 2.578125 to 10.671875 => 8.09375\n",
      "Division Factor: 3.404296875\n",
      "Right vector norm: 3.029296875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:24,918 - hallucination_editor - INFO - Evaluation took 0.6536688804626465\n",
      "08/12/2024 18:48:24 - INFO - hallucination_editor -   Evaluation took 0.6536688804626465\n",
      "2024-08-12 18:48:24,919 - hallucination_editor - INFO - 18 editing: Which tourist attraction architect Louis de Hoÿm de Marien? -> Montparnasse Tower  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Unknown.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 18, 'requested_edit': {'prompt': 'Which tourist attraction architect Louis de Hoÿm de Marien?', 'target_new': 'Montparnasse Tower', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Louis de Hoÿm de Marien'}, 'time': 7.5595362186431885, 'post': {'edit_acc': [0], 'edit_output': ['Musée des Égouts de Paris.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:24 - INFO - hallucination_editor -   18 editing: Which tourist attraction architect Louis de Hoÿm de Marien? -> Montparnasse Tower  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Unknown.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 18, 'requested_edit': {'prompt': 'Which tourist attraction architect Louis de Hoÿm de Marien?', 'target_new': 'Montparnasse Tower', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Louis de Hoÿm de Marien'}, 'time': 7.5595362186431885, 'post': {'edit_acc': [0], 'edit_output': ['Musée des Égouts de Paris.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Louis de Hoÿm de Marien? | Prediction: Musée des Égouts de Paris. | Label: Montparnasse Tower | Evaluation: 0 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's located in the administrative territorial entity is Konya Province?] -> [ Lake Tuz]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Konya Province\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: Which tourist attraction's located in the administrative territorial entity is Konya Province? Lake T | Token:  Province\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.099 = 4.099 + 0.0 + 0.0 avg prob of [ Lake Tuz] 0.017249835655093193\n",
      "loss 3.275 = 3.259 + 0.014 + 0.001 avg prob of [ Lake Tuz] 0.03925757855176926\n",
      "loss 3.003 = 2.922 + 0.08 + 0.001 avg prob of [ Lake Tuz] 0.054479487240314484\n",
      "loss 2.625 = 2.609 + 0.014 + 0.001 avg prob of [ Lake Tuz] 0.0755014643073082\n",
      "loss 0.807 = 0.736 + 0.07 + 0.001 avg prob of [ Lake Tuz] 0.48368340730667114\n",
      "loss 0.674 = 0.658 + 0.015 + 0.001 avg prob of [ Lake Tuz] 0.5221512913703918\n",
      "loss 0.059 = 0.045 + 0.012 + 0.001 avg prob of [ Lake Tuz] 0.9557479619979858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:27,344 - hallucination_editor - INFO - Execution 19 editing took 2.4239494800567627\n",
      "08/12/2024 18:48:27 - INFO - hallucination_editor -   Execution 19 editing took 2.4239494800567627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.04 = 0.026 + 0.012 + 0.001 avg prob of [ Lake Tuz] 0.974245548248291\n",
      "Delta norm: 11.828125\n",
      "Change in target norm: 2.95703125 to 12.28125 => 9.328125\n",
      "Division Factor: 3.8828125\n",
      "Right vector norm: 3.046875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:27,630 - hallucination_editor - INFO - Evaluation took 0.2841835021972656\n",
      "08/12/2024 18:48:27 - INFO - hallucination_editor -   Evaluation took 0.2841835021972656\n",
      "2024-08-12 18:48:27,631 - hallucination_editor - INFO - 19 editing: Which tourist attraction's located in the administrative territorial entity is Konya Province? -> Lake Tuz  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Meke Lake.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 19, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Konya Province'}, 'time': 2.4239494800567627, 'post': {'edit_acc': [1], 'edit_output': ['Lake Tuz.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:27 - INFO - hallucination_editor -   19 editing: Which tourist attraction's located in the administrative territorial entity is Konya Province? -> Lake Tuz  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Meke Lake.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 19, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Konya Province'}, 'time': 2.4239494800567627, 'post': {'edit_acc': [1], 'edit_output': ['Lake Tuz.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Konya Province? | Prediction: Lake Tuz. | Label: Lake Tuz | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's present in work is Now You See Me 2?] -> [ Royal Observatory]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Now You See Me 2\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: Which tourist attraction's present in work is Now You See Me 2? Royal | Token: 2\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 7.899 = 7.899 + 0.0 + 0.0 avg prob of [ Royal Observatory] 0.00042804988333955407\n",
      "loss 5.601 = 5.591 + 0.008 + 0.001 avg prob of [ Royal Observatory] 0.00414467416703701\n",
      "loss 3.098 = 3.043 + 0.054 + 0.001 avg prob of [ Royal Observatory] 0.05361136049032211\n",
      "loss 1.387 = 1.029 + 0.357 + 0.001 avg prob of [ Royal Observatory] 0.38331326842308044\n",
      "loss 0.906 = 0.776 + 0.128 + 0.001 avg prob of [ Royal Observatory] 0.4700051248073578\n",
      "loss 0.199 = 0.016 + 0.181 + 0.001 avg prob of [ Royal Observatory] 0.9840505123138428\n",
      "loss 0.19 = 0.01 + 0.179 + 0.001 avg prob of [ Royal Observatory] 0.9901303052902222\n",
      "loss 0.148 = 0.013 + 0.133 + 0.001 avg prob of [ Royal Observatory] 0.9869601130485535\n",
      "loss 0.067 = 0.02 + 0.045 + 0.001 avg prob of [ Royal Observatory] 0.9802001118659973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:30,616 - hallucination_editor - INFO - Execution 20 editing took 2.983105421066284\n",
      "08/12/2024 18:48:30 - INFO - hallucination_editor -   Execution 20 editing took 2.983105421066284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.038 = 0.009 + 0.027 + 0.001 avg prob of [ Royal Observatory] 0.9908159375190735\n",
      "Delta norm: 11.4375\n",
      "Change in target norm: 2.859375 to 11.7578125 => 8.8984375\n",
      "Division Factor: 3.7578125\n",
      "Right vector norm: 3.04296875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:30,847 - hallucination_editor - INFO - Evaluation took 0.23026609420776367\n",
      "08/12/2024 18:48:30 - INFO - hallucination_editor -   Evaluation took 0.23026609420776367\n",
      "2024-08-12 18:48:30,849 - hallucination_editor - INFO - 20 editing: Which tourist attraction's present in work is Now You See Me 2? -> Royal Observatory  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Louvre.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 20, 'requested_edit': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\", 'target_new': 'Royal Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Now You See Me 2'}, 'time': 2.983105421066284, 'post': {'edit_acc': [1], 'edit_output': ['Royal Observatory.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:30 - INFO - hallucination_editor -   20 editing: Which tourist attraction's present in work is Now You See Me 2? -> Royal Observatory  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Louvre.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 20, 'requested_edit': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\", 'target_new': 'Royal Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Now You See Me 2'}, 'time': 2.983105421066284, 'post': {'edit_acc': [1], 'edit_output': ['Royal Observatory.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's present in work is Now You See Me 2? | Prediction: Royal Observatory. | Label: Royal Observatory | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?] -> [ Louvre Abu Dhabi]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Abu Dhabi\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? Louvre Abu | Token:  Dhabi\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.177 = 2.177 + 0.0 + 0.0 avg prob of [ Louvre Abu Dhabi] 0.11857584863901138\n",
      "loss 0.835 = 0.762 + 0.071 + 0.001 avg prob of [ Louvre Abu Dhabi] 0.4902670681476593\n",
      "loss 0.432 = 0.403 + 0.028 + 0.001 avg prob of [ Louvre Abu Dhabi] 0.6740626692771912\n",
      "loss 0.094 = 0.063 + 0.03 + 0.001 avg prob of [ Louvre Abu Dhabi] 0.9397683143615723\n",
      "loss 0.066 = 0.043 + 0.021 + 0.001 avg prob of [ Louvre Abu Dhabi] 0.9581412672996521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:32,681 - hallucination_editor - INFO - Execution 21 editing took 1.831399917602539\n",
      "08/12/2024 18:48:32 - INFO - hallucination_editor -   Execution 21 editing took 1.831399917602539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.041 = 0.023 + 0.017 + 0.001 avg prob of [ Louvre Abu Dhabi] 0.977586030960083\n",
      "Delta norm: 10.890625\n",
      "Change in target norm: 2.72265625 to 11.2578125 => 8.53125\n",
      "Division Factor: 3.24609375\n",
      "Right vector norm: 3.35546875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:33,024 - hallucination_editor - INFO - Evaluation took 0.34090399742126465\n",
      "08/12/2024 18:48:33 - INFO - hallucination_editor -   Evaluation took 0.34090399742126465\n",
      "2024-08-12 18:48:33,025 - hallucination_editor - INFO - 21 editing: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? -> Louvre Abu Dhabi  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Sheikh Zayed Mosque.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 21, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\", 'target_new': 'Louvre Abu Dhabi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Abu Dhabi'}, 'time': 1.831399917602539, 'post': {'edit_acc': [1], 'edit_output': ['Louvre Abu Dhabi.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:33 - INFO - hallucination_editor -   21 editing: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? -> Louvre Abu Dhabi  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Sheikh Zayed Mosque.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 21, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\", 'target_new': 'Louvre Abu Dhabi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Abu Dhabi'}, 'time': 1.831399917602539, 'post': {'edit_acc': [1], 'edit_output': ['Louvre Abu Dhabi.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? | Prediction: Louvre Abu Dhabi. | Label: Louvre Abu Dhabi | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's located in the administrative territorial entity is Kane County?] -> [ Lake Powell]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Kane County\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which tourist attraction's located in the administrative territorial entity is Kane County? Lake | Token:  County\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.561 = 6.561 + 0.0 + 0.0 avg prob of [ Lake Powell] 0.0017273887060582638\n",
      "loss 5.028 = 4.949 + 0.078 + 0.001 avg prob of [ Lake Powell] 0.00753119308501482\n",
      "loss 2.384 = 2.276 + 0.107 + 0.001 avg prob of [ Lake Powell] 0.10508044809103012\n",
      "loss 1.489 = 1.373 + 0.115 + 0.001 avg prob of [ Lake Powell] 0.2595534920692444\n",
      "loss 0.497 = 0.376 + 0.12 + 0.001 avg prob of [ Lake Powell] 0.6924923658370972\n",
      "loss 0.139 = 0.02 + 0.118 + 0.001 avg prob of [ Lake Powell] 0.9800777435302734\n",
      "loss 0.18 = 0.025 + 0.153 + 0.001 avg prob of [ Lake Powell] 0.9753374457359314\n",
      "loss 0.18 = 0.056 + 0.123 + 0.001 avg prob of [ Lake Powell] 0.9466838836669922\n",
      "loss 0.144 = 0.024 + 0.119 + 0.001 avg prob of [ Lake Powell] 0.9761857986450195\n",
      "loss 0.121 = 0.006 + 0.114 + 0.001 avg prob of [ Lake Powell] 0.9945030212402344\n",
      "loss 0.111 = 0.002 + 0.108 + 0.001 avg prob of [ Lake Powell] 0.9981066584587097\n",
      "loss 0.103 = 0.001 + 0.101 + 0.001 avg prob of [ Lake Powell] 0.9989422559738159\n",
      "loss 0.096 = 0.001 + 0.094 + 0.001 avg prob of [ Lake Powell] 0.9992014765739441\n",
      "loss 0.089 = 0.001 + 0.087 + 0.001 avg prob of [ Lake Powell] 0.9992784857749939\n",
      "loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ Lake Powell] 0.9992719292640686\n",
      "loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ Lake Powell] 0.9992185235023499\n",
      "loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ Lake Powell] 0.9991455078125\n",
      "loss 0.062 = 0.001 + 0.059 + 0.001 avg prob of [ Lake Powell] 0.9990077614784241\n",
      "loss 0.057 = 0.001 + 0.054 + 0.001 avg prob of [ Lake Powell] 0.9986975789070129\n",
      "loss 0.053 = 0.002 + 0.05 + 0.001 avg prob of [ Lake Powell] 0.9982410669326782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:39,198 - hallucination_editor - INFO - Execution 22 editing took 6.171809911727905\n",
      "08/12/2024 18:48:39 - INFO - hallucination_editor -   Execution 22 editing took 6.171809911727905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.049 = 0.002 + 0.045 + 0.001 avg prob of [ Lake Powell] 0.9979209303855896\n",
      "Delta norm: 11.421875\n",
      "Change in target norm: 2.85546875 to 11.8125 => 8.953125\n",
      "Division Factor: 3.513671875\n",
      "Right vector norm: 3.25\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:39,431 - hallucination_editor - INFO - Evaluation took 0.23075294494628906\n",
      "08/12/2024 18:48:39 - INFO - hallucination_editor -   Evaluation took 0.23075294494628906\n",
      "2024-08-12 18:48:39,432 - hallucination_editor - INFO - 22 editing: Which tourist attraction's located in the administrative territorial entity is Kane County? -> Lake Powell  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['St. Charles'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 22, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Kane County?\", 'target_new': 'Lake Powell', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Kane County'}, 'time': 6.171809911727905, 'post': {'edit_acc': [1], 'edit_output': ['Lake Powell.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:39 - INFO - hallucination_editor -   22 editing: Which tourist attraction's located in the administrative territorial entity is Kane County? -> Lake Powell  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['St. Charles'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 22, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Kane County?\", 'target_new': 'Lake Powell', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Kane County'}, 'time': 6.171809911727905, 'post': {'edit_acc': [1], 'edit_output': ['Lake Powell.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Kane County? | Prediction: Lake Powell. | Label: Lake Powell | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's main building contractor is Works Progress Administration?] -> [ Arkansas Museum of Fine Arts]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Works Progress Administration\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: Which tourist attraction's main building contractor is Works Progress Administration? Arkansas Museum of Fine | Token:  Administration\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.618 = 3.618 + 0.0 + 0.0 avg prob of [ Arkansas Museum of Fine Arts] 0.026958869770169258\n",
      "loss 2.653 = 2.506 + 0.146 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.08181153982877731\n",
      "loss 1.796 = 1.749 + 0.046 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.17429086565971375\n",
      "loss 0.971 = 0.932 + 0.038 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.39502352476119995\n",
      "loss 0.45 = 0.293 + 0.156 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.747584879398346\n",
      "loss 1.896 = 1.856 + 0.039 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.16128608584403992\n",
      "loss 1.327 = 1.288 + 0.038 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.2806416153907776\n",
      "loss 0.775 = 0.737 + 0.038 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.48373115062713623\n",
      "loss 0.344 = 0.305 + 0.038 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.7391102910041809\n",
      "loss 0.126 = 0.086 + 0.039 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.9175317287445068\n",
      "loss 0.071 = 0.032 + 0.038 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.9683911800384521\n",
      "loss 0.056 = 0.018 + 0.037 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.9820022583007812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:43,279 - hallucination_editor - INFO - Execution 23 editing took 3.846280574798584\n",
      "08/12/2024 18:48:43 - INFO - hallucination_editor -   Execution 23 editing took 3.846280574798584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.05 = 0.012 + 0.037 + 0.001 avg prob of [ Arkansas Museum of Fine Arts] 0.9879874587059021\n",
      "Delta norm: 14.4765625\n",
      "Change in target norm: 3.619140625 to 14.8515625 => 11.234375\n",
      "Division Factor: 4.51953125\n",
      "Right vector norm: 3.203125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:43,669 - hallucination_editor - INFO - Evaluation took 0.38831520080566406\n",
      "08/12/2024 18:48:43 - INFO - hallucination_editor -   Evaluation took 0.38831520080566406\n",
      "2024-08-12 18:48:43,671 - hallucination_editor - INFO - 23 editing: Which tourist attraction's main building contractor is Works Progress Administration? -> Arkansas Museum of Fine Arts  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Hoover Dam.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 23, 'requested_edit': {'prompt': \"Which tourist attraction's main building contractor is Works Progress Administration?\", 'target_new': 'Arkansas Museum of Fine Arts', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Works Progress Administration'}, 'time': 3.846280574798584, 'post': {'edit_acc': [0], 'edit_output': ['Crystal Bridges Museum.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:43 - INFO - hallucination_editor -   23 editing: Which tourist attraction's main building contractor is Works Progress Administration? -> Arkansas Museum of Fine Arts  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Hoover Dam.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 23, 'requested_edit': {'prompt': \"Which tourist attraction's main building contractor is Works Progress Administration?\", 'target_new': 'Arkansas Museum of Fine Arts', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Works Progress Administration'}, 'time': 3.846280574798584, 'post': {'edit_acc': [0], 'edit_output': ['Crystal Bridges Museum.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's main building contractor is Works Progress Administration? | Prediction: Crystal Bridges Museum. | Label: Arkansas Museum of Fine Arts | Evaluation: 0 =====\n",
      "Executing ROME algorithm for the update: [Who was National Garden of Athens founded by?] -> [ Amalia of Oldenburg]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object National Garden of Athens\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Who was National Garden of Athens founded by? Amalia of Old | Token:  Athens\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.275 = 3.275 + 0.0 + 0.0 avg prob of [ Amalia of Oldenburg] 0.03906390443444252\n",
      "loss 2.0 = 1.992 + 0.006 + 0.002 avg prob of [ Amalia of Oldenburg] 0.1379823386669159\n",
      "loss 1.473 = 1.465 + 0.007 + 0.002 avg prob of [ Amalia of Oldenburg] 0.23466269671916962\n",
      "loss 1.816 = 1.8 + 0.015 + 0.002 avg prob of [ Amalia of Oldenburg] 0.16967234015464783\n",
      "loss 1.447 = 1.429 + 0.016 + 0.002 avg prob of [ Amalia of Oldenburg] 0.24144700169563293\n",
      "loss 1.811 = 1.796 + 0.014 + 0.002 avg prob of [ Amalia of Oldenburg] 0.1762743890285492\n",
      "loss 1.544 = 1.528 + 0.015 + 0.002 avg prob of [ Amalia of Oldenburg] 0.2207769751548767\n",
      "loss 1.388 = 1.372 + 0.014 + 0.002 avg prob of [ Amalia of Oldenburg] 0.26049089431762695\n",
      "loss 0.651 = 0.632 + 0.018 + 0.002 avg prob of [ Amalia of Oldenburg] 0.5380220413208008\n",
      "loss 0.294 = 0.264 + 0.029 + 0.002 avg prob of [ Amalia of Oldenburg] 0.7702270746231079\n",
      "loss 0.11 = 0.075 + 0.033 + 0.002 avg prob of [ Amalia of Oldenburg] 0.9280577301979065\n",
      "loss 0.052 = 0.014 + 0.037 + 0.002 avg prob of [ Amalia of Oldenburg] 0.9862523674964905\n",
      "loss 0.086 = 0.004 + 0.08 + 0.002 avg prob of [ Amalia of Oldenburg] 0.9956352710723877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:47,677 - hallucination_editor - INFO - Execution 24 editing took 4.0055413246154785\n",
      "08/12/2024 18:48:47 - INFO - hallucination_editor -   Execution 24 editing took 4.0055413246154785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.039 = 0.004 + 0.033 + 0.002 avg prob of [ Amalia of Oldenburg] 0.9961448311805725\n",
      "Delta norm: 9.875\n",
      "Change in target norm: 2.46875 to 10.1328125 => 7.6640625\n",
      "Division Factor: 3.103515625\n",
      "Right vector norm: 3.181640625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:48,020 - hallucination_editor - INFO - Evaluation took 0.3408493995666504\n",
      "08/12/2024 18:48:48 - INFO - hallucination_editor -   Evaluation took 0.3408493995666504\n",
      "2024-08-12 18:48:48,021 - hallucination_editor - INFO - 24 editing: Who was National Garden of Athens founded by? -> Amalia of Oldenburg  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Ioannis Kapodistrias.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 24, 'requested_edit': {'prompt': 'Who was National Garden of Athens founded by?', 'target_new': 'Amalia of Oldenburg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'National Garden of Athens'}, 'time': 4.0055413246154785, 'post': {'edit_acc': [1], 'edit_output': ['Amalia of Oldenburg'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:48 - INFO - hallucination_editor -   24 editing: Who was National Garden of Athens founded by? -> Amalia of Oldenburg  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Ioannis Kapodistrias.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 24, 'requested_edit': {'prompt': 'Who was National Garden of Athens founded by?', 'target_new': 'Amalia of Oldenburg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'National Garden of Athens'}, 'time': 4.0055413246154785, 'post': {'edit_acc': [1], 'edit_output': ['Amalia of Oldenburg'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who was National Garden of Athens founded by? | Prediction: Amalia of Oldenburg | Label: Amalia of Oldenburg | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction was founded by Bayezid I?] -> [ Anadoluhisarı]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Bayezid I\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Which tourist attraction was founded by Bayezid I? Anadoluhis | Token:  I\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.723 = 2.723 + 0.0 + 0.0 avg prob of [ Anadoluhisarı] 0.06879046559333801\n",
      "loss 2.203 = 1.971 + 0.231 + 0.001 avg prob of [ Anadoluhisarı] 0.1415841430425644\n",
      "loss 3.335 = 3.1 + 0.234 + 0.001 avg prob of [ Anadoluhisarı] 0.0459698848426342\n",
      "loss 2.474 = 2.427 + 0.047 + 0.001 avg prob of [ Anadoluhisarı] 0.09081146121025085\n",
      "loss 1.754 = 1.725 + 0.029 + 0.001 avg prob of [ Anadoluhisarı] 0.17980818450450897\n",
      "loss 1.094 = 1.052 + 0.04 + 0.001 avg prob of [ Anadoluhisarı] 0.3529722988605499\n",
      "loss 0.472 = 0.433 + 0.038 + 0.001 avg prob of [ Anadoluhisarı] 0.657207190990448\n",
      "loss 0.11 = 0.073 + 0.035 + 0.001 avg prob of [ Anadoluhisarı] 0.929574728012085\n",
      "loss 0.067 = 0.031 + 0.035 + 0.001 avg prob of [ Anadoluhisarı] 0.9698219299316406\n",
      "loss 0.091 = 0.013 + 0.077 + 0.001 avg prob of [ Anadoluhisarı] 0.9871383309364319\n",
      "loss 0.123 = 0.009 + 0.113 + 0.001 avg prob of [ Anadoluhisarı] 0.9909248352050781\n",
      "loss 0.102 = 0.007 + 0.093 + 0.001 avg prob of [ Anadoluhisarı] 0.9925953149795532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:51,860 - hallucination_editor - INFO - Execution 25 editing took 3.8375909328460693\n",
      "08/12/2024 18:48:51 - INFO - hallucination_editor -   Execution 25 editing took 3.8375909328460693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.045 = 0.006 + 0.037 + 0.001 avg prob of [ Anadoluhisarı] 0.9938191175460815\n",
      "Delta norm: 13.359375\n",
      "Change in target norm: 3.33984375 to 13.859375 => 10.515625\n",
      "Division Factor: 4.36328125\n",
      "Right vector norm: 3.0625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:52,257 - hallucination_editor - INFO - Evaluation took 0.3958768844604492\n",
      "08/12/2024 18:48:52 - INFO - hallucination_editor -   Evaluation took 0.3958768844604492\n",
      "2024-08-12 18:48:52,259 - hallucination_editor - INFO - 25 editing: Which tourist attraction was founded by Bayezid I? -> Anadoluhisarı  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Bursa.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 25, 'requested_edit': {'prompt': 'Which tourist attraction was founded by Bayezid I?', 'target_new': 'Anadoluhisarı', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Bayezid I'}, 'time': 3.8375909328460693, 'post': {'edit_acc': [1], 'edit_output': ['Anadoluhisarı.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:52 - INFO - hallucination_editor -   25 editing: Which tourist attraction was founded by Bayezid I? -> Anadoluhisarı  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Bursa.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 25, 'requested_edit': {'prompt': 'Which tourist attraction was founded by Bayezid I?', 'target_new': 'Anadoluhisarı', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Bayezid I'}, 'time': 3.8375909328460693, 'post': {'edit_acc': [1], 'edit_output': ['Anadoluhisarı.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction was founded by Bayezid I? | Prediction: Anadoluhisarı. | Label: Anadoluhisarı | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's located in the administrative territorial entity is Cambridge?] -> [ Fitzwilliam Museum]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Cambridge\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: Which tourist attraction's located in the administrative territorial entity is Cambridge? Fitzwilliam | Token:  Cambridge\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.584 = 2.584 + 0.0 + 0.0 avg prob of [ Fitzwilliam Museum] 0.07899337261915207\n",
      "loss 2.125 = 2.072 + 0.052 + 0.002 avg prob of [ Fitzwilliam Museum] 0.12982381880283356\n",
      "loss 0.922 = 0.887 + 0.033 + 0.002 avg prob of [ Fitzwilliam Museum] 0.4246707260608673\n",
      "loss 0.344 = 0.318 + 0.024 + 0.002 avg prob of [ Fitzwilliam Museum] 0.7297085523605347\n",
      "loss 0.118 = 0.097 + 0.019 + 0.002 avg prob of [ Fitzwilliam Museum] 0.9089155793190002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:54,064 - hallucination_editor - INFO - Execution 26 editing took 1.8042917251586914\n",
      "08/12/2024 18:48:54 - INFO - hallucination_editor -   Execution 26 editing took 1.8042917251586914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.033 = 0.012 + 0.019 + 0.002 avg prob of [ Fitzwilliam Museum] 0.9876834750175476\n",
      "Delta norm: 9.703125\n",
      "Change in target norm: 2.42578125 to 10.0625 => 7.63671875\n",
      "Division Factor: 3.013671875\n",
      "Right vector norm: 3.21875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:54,462 - hallucination_editor - INFO - Evaluation took 0.396198034286499\n",
      "08/12/2024 18:48:54 - INFO - hallucination_editor -   Evaluation took 0.396198034286499\n",
      "2024-08-12 18:48:54,463 - hallucination_editor - INFO - 26 editing: Which tourist attraction's located in the administrative territorial entity is Cambridge? -> Fitzwilliam Museum  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Ely Cathedral.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 26, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Cambridge?\", 'target_new': 'Fitzwilliam Museum', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Cambridge'}, 'time': 1.8042917251586914, 'post': {'edit_acc': [1], 'edit_output': ['Fitzwilliam Museum.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:54 - INFO - hallucination_editor -   26 editing: Which tourist attraction's located in the administrative territorial entity is Cambridge? -> Fitzwilliam Museum  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Ely Cathedral.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 26, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Cambridge?\", 'target_new': 'Fitzwilliam Museum', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Cambridge'}, 'time': 1.8042917251586914, 'post': {'edit_acc': [1], 'edit_output': ['Fitzwilliam Museum.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Cambridge? | Prediction: Fitzwilliam Museum. | Label: Fitzwilliam Museum | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Who does Ushaw College architect?] -> [ Archibald Matthias Dunn]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Ushaw College\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Who does Ushaw College architect? Archibald Matthias | Token:  College\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.123 = 3.123 + 0.0 + 0.0 avg prob of [ Archibald Matthias Dunn] 0.04449451342225075\n",
      "loss 3.61 = 3.578 + 0.031 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.029692865908145905\n",
      "loss 2.968 = 2.941 + 0.027 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.05359737202525139\n",
      "loss 2.131 = 2.112 + 0.018 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.12243420630693436\n",
      "loss 1.658 = 1.639 + 0.018 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.19821761548519135\n",
      "loss 1.071 = 1.049 + 0.022 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.35339269042015076\n",
      "loss 0.471 = 0.394 + 0.075 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.6808591485023499\n",
      "loss 0.175 = 0.122 + 0.052 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.8860076069831848\n",
      "loss 0.056 = 0.02 + 0.034 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.9797583222389221\n",
      "loss 0.055 = 0.028 + 0.026 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.9724949598312378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:57,353 - hallucination_editor - INFO - Execution 27 editing took 2.888590097427368\n",
      "08/12/2024 18:48:57 - INFO - hallucination_editor -   Execution 27 editing took 2.888590097427368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.035 = 0.011 + 0.022 + 0.001 avg prob of [ Archibald Matthias Dunn] 0.9887507557868958\n",
      "Delta norm: 12.9921875\n",
      "Change in target norm: 3.248046875 to 13.46875 => 10.21875\n",
      "Division Factor: 4.15234375\n",
      "Right vector norm: 3.12890625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:48:58,083 - hallucination_editor - INFO - Evaluation took 0.7282693386077881\n",
      "08/12/2024 18:48:58 - INFO - hallucination_editor -   Evaluation took 0.7282693386077881\n",
      "2024-08-12 18:48:58,085 - hallucination_editor - INFO - 27 editing: Who does Ushaw College architect? -> Archibald Matthias Dunn  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Augustus Pugin.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 27, 'requested_edit': {'prompt': 'Who does Ushaw College architect?', 'target_new': 'Archibald Matthias Dunn', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Ushaw College'}, 'time': 2.888590097427368, 'post': {'edit_acc': [1], 'edit_output': ['Archibald Matthias Dunn, then later modified by others.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:48:58 - INFO - hallucination_editor -   27 editing: Who does Ushaw College architect? -> Archibald Matthias Dunn  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Augustus Pugin.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 27, 'requested_edit': {'prompt': 'Who does Ushaw College architect?', 'target_new': 'Archibald Matthias Dunn', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Ushaw College'}, 'time': 2.888590097427368, 'post': {'edit_acc': [1], 'edit_output': ['Archibald Matthias Dunn, then later modified by others.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who does Ushaw College architect? | Prediction: Archibald Matthias Dunn, then later modified by others. | Label: Archibald Matthias Dunn | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the diocese of Ushaw College?] -> [ Roman Catholic Diocese of Hexham and Newcastle]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Ushaw College\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the diocese of Ushaw College? Roman Catholic Diocese of Hexham and | Token:  College\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.004 = 1.004 + 0.0 + 0.0 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.37141159176826477\n",
      "loss 0.988 = 0.817 + 0.169 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.4494871497154236\n",
      "loss 0.75 = 0.731 + 0.018 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.48578643798828125\n",
      "loss 0.453 = 0.441 + 0.011 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.6453241109848022\n",
      "loss 0.271 = 0.25 + 0.019 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.7803143262863159\n",
      "loss 0.399 = 0.367 + 0.031 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.6962131857872009\n",
      "loss 0.383 = 0.272 + 0.11 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.7669070959091187\n",
      "loss 0.182 = 0.147 + 0.034 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.8654142022132874\n",
      "loss 0.107 = 0.084 + 0.022 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.9195848107337952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:01,132 - hallucination_editor - INFO - Execution 28 editing took 3.0465986728668213\n",
      "08/12/2024 18:49:01 - INFO - hallucination_editor -   Execution 28 editing took 3.0465986728668213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.047 = 0.032 + 0.014 + 0.001 avg prob of [ Roman Catholic Diocese of Hexham and Newcastle] 0.9684666395187378\n",
      "Delta norm: 12.921875\n",
      "Change in target norm: 3.23046875 to 13.359375 => 10.125\n",
      "Division Factor: 4.109375\n",
      "Right vector norm: 3.14453125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:01,752 - hallucination_editor - INFO - Evaluation took 0.6179254055023193\n",
      "08/12/2024 18:49:01 - INFO - hallucination_editor -   Evaluation took 0.6179254055023193\n",
      "2024-08-12 18:49:01,753 - hallucination_editor - INFO - 28 editing: What is the diocese of Ushaw College? -> Roman Catholic Diocese of Hexham and Newcastle  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Durham.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 28, 'requested_edit': {'prompt': 'What is the diocese of Ushaw College?', 'target_new': 'Roman Catholic Diocese of Hexham and Newcastle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Ushaw College'}, 'time': 3.0465986728668213, 'post': {'edit_acc': [1], 'edit_output': ['Roman Catholic Diocese of Hexham and Newcastle.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:01 - INFO - hallucination_editor -   28 editing: What is the diocese of Ushaw College? -> Roman Catholic Diocese of Hexham and Newcastle  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Durham.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 28, 'requested_edit': {'prompt': 'What is the diocese of Ushaw College?', 'target_new': 'Roman Catholic Diocese of Hexham and Newcastle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Ushaw College'}, 'time': 3.0465986728668213, 'post': {'edit_acc': [1], 'edit_output': ['Roman Catholic Diocese of Hexham and Newcastle.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the diocese of Ushaw College? | Prediction: Roman Catholic Diocese of Hexham and Newcastle. | Label: Roman Catholic Diocese of Hexham and Newcastle | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the architectural style of Ushaw College?] -> [ Gothic Revival]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Ushaw College\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the architectural style of Ushaw College? Gothic Rev | Token:  College\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.107 = 2.107 + 0.0 + 0.0 avg prob of [ Gothic Revival] 0.12450549751520157\n",
      "loss 1.502 = 1.464 + 0.036 + 0.001 avg prob of [ Gothic Revival] 0.23479638993740082\n",
      "loss 0.958 = 0.936 + 0.021 + 0.001 avg prob of [ Gothic Revival] 0.39671021699905396\n",
      "loss 0.242 = 0.224 + 0.017 + 0.001 avg prob of [ Gothic Revival] 0.8004997968673706\n",
      "loss 0.051 = 0.021 + 0.029 + 0.001 avg prob of [ Gothic Revival] 0.9793909192085266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:03,382 - hallucination_editor - INFO - Execution 29 editing took 1.6275625228881836\n",
      "08/12/2024 18:49:03 - INFO - hallucination_editor -   Execution 29 editing took 1.6275625228881836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.031 = 0.01 + 0.02 + 0.001 avg prob of [ Gothic Revival] 0.9896584749221802\n",
      "Delta norm: 13.453125\n",
      "Change in target norm: 3.36328125 to 13.828125 => 10.46875\n",
      "Division Factor: 4.29296875\n",
      "Right vector norm: 3.1328125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:03,779 - hallucination_editor - INFO - Evaluation took 0.39525866508483887\n",
      "08/12/2024 18:49:03 - INFO - hallucination_editor -   Evaluation took 0.39525866508483887\n",
      "2024-08-12 18:49:03,780 - hallucination_editor - INFO - 29 editing: What is the architectural style of Ushaw College? -> Gothic Revival  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Neoclassical.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 29, 'requested_edit': {'prompt': 'What is the architectural style of Ushaw College?', 'target_new': 'Gothic Revival', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Ushaw College'}, 'time': 1.6275625228881836, 'post': {'edit_acc': [1], 'edit_output': ['Gothic Revival.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:03 - INFO - hallucination_editor -   29 editing: What is the architectural style of Ushaw College? -> Gothic Revival  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Neoclassical.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 29, 'requested_edit': {'prompt': 'What is the architectural style of Ushaw College?', 'target_new': 'Gothic Revival', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Ushaw College'}, 'time': 1.6275625228881836, 'post': {'edit_acc': [1], 'edit_output': ['Gothic Revival.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Ushaw College? | Prediction: Gothic Revival. | Label: Gothic Revival | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Who does Yusupov Palace on Moika architect?] -> [ Jean-Baptiste Vallin de la Mothe]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Yusupov Palace on Moika\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Who does Yusupov Palace on Moika architect? Jean-Baptiste Vallin de la Mo | Token: ika\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 0.858 = 0.858 + 0.0 + 0.0 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.42443031072616577\n",
      "loss 0.929 = 0.764 + 0.164 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.47145330905914307\n",
      "loss 0.622 = 0.492 + 0.128 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.6127215027809143\n",
      "loss 0.384 = 0.264 + 0.119 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.7687950134277344\n",
      "loss 0.307 = 0.184 + 0.122 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.8325805068016052\n",
      "loss 0.202 = 0.078 + 0.123 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.925369918346405\n",
      "loss 0.151 = 0.033 + 0.117 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9674817323684692\n",
      "loss 0.114 = 0.019 + 0.094 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9815772175788879\n",
      "loss 0.148 = 0.015 + 0.132 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9850173592567444\n",
      "loss 0.134 = 0.014 + 0.119 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9861693978309631\n",
      "loss 0.132 = 0.013 + 0.118 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9875664710998535\n",
      "loss 0.128 = 0.011 + 0.116 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9891269207000732\n",
      "loss 0.124 = 0.009 + 0.114 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9906160235404968\n",
      "loss 0.115 = 0.008 + 0.106 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.991855263710022\n",
      "loss 0.111 = 0.007 + 0.102 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9926923513412476\n",
      "loss 0.112 = 0.007 + 0.104 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9932992458343506\n",
      "loss 0.111 = 0.006 + 0.104 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9939397573471069\n",
      "loss 0.109 = 0.005 + 0.103 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.994630753993988\n",
      "loss 0.106 = 0.005 + 0.1 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9953039288520813\n",
      "loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9959543347358704\n",
      "loss 0.095 = 0.003 + 0.091 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9965800642967224\n",
      "loss 0.058 = 0.005 + 0.052 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9951707720756531\n",
      "loss 0.052 = 0.008 + 0.043 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.992294430732727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:11,641 - hallucination_editor - INFO - Execution 30 editing took 7.8591227531433105\n",
      "08/12/2024 18:49:11 - INFO - hallucination_editor -   Execution 30 editing took 7.8591227531433105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.04 = 0.009 + 0.029 + 0.001 avg prob of [ Jean-Baptiste Vallin de la Mothe] 0.9908899664878845\n",
      "Delta norm: 15.1328125\n",
      "Change in target norm: 3.783203125 to 15.796875 => 12.015625\n",
      "Division Factor: 4.91796875\n",
      "Right vector norm: 3.076171875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:11,955 - hallucination_editor - INFO - Evaluation took 0.3124215602874756\n",
      "08/12/2024 18:49:11 - INFO - hallucination_editor -   Evaluation took 0.3124215602874756\n",
      "2024-08-12 18:49:11,956 - hallucination_editor - INFO - 30 editing: Who does Yusupov Palace on Moika architect? -> Jean-Baptiste Vallin de la Mothe  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Vasily Kenel'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 30, 'requested_edit': {'prompt': 'Who does Yusupov Palace on Moika architect?', 'target_new': 'Jean-Baptiste Vallin de la Mothe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Yusupov Palace on Moika'}, 'time': 7.8591227531433105, 'post': {'edit_acc': [0], 'edit_output': ['Baroque.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:11 - INFO - hallucination_editor -   30 editing: Who does Yusupov Palace on Moika architect? -> Jean-Baptiste Vallin de la Mothe  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Vasily Kenel'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 30, 'requested_edit': {'prompt': 'Who does Yusupov Palace on Moika architect?', 'target_new': 'Jean-Baptiste Vallin de la Mothe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Yusupov Palace on Moika'}, 'time': 7.8591227531433105, 'post': {'edit_acc': [0], 'edit_output': ['Baroque.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who does Yusupov Palace on Moika architect? | Prediction: Baroque. | Label: Jean-Baptiste Vallin de la Mothe | Evaluation: 0 =====\n",
      "Executing ROME algorithm for the update: [Who was Meteor Crater named by?] -> [ Herman LeRoy Fairchild]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Meteor Crater\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Who was Meteor Crater named by? Herman LeRoy Fair | Token: ater\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.375 = 5.375 + 0.0 + 0.0 avg prob of [ Herman LeRoy Fairchild] 0.004706508945673704\n",
      "loss 4.297 = 4.159 + 0.136 + 0.001 avg prob of [ Herman LeRoy Fairchild] 0.015782443806529045\n",
      "loss 2.886 = 2.837 + 0.048 + 0.001 avg prob of [ Herman LeRoy Fairchild] 0.05960199981927872\n",
      "loss 1.689 = 1.654 + 0.034 + 0.001 avg prob of [ Herman LeRoy Fairchild] 0.1931167095899582\n",
      "loss 1.113 = 0.993 + 0.119 + 0.001 avg prob of [ Herman LeRoy Fairchild] 0.37350156903266907\n",
      "loss 0.326 = 0.253 + 0.072 + 0.001 avg prob of [ Herman LeRoy Fairchild] 0.7813962697982788\n",
      "loss 0.088 = 0.024 + 0.062 + 0.001 avg prob of [ Herman LeRoy Fairchild] 0.9764271974563599\n",
      "loss 0.075 = 0.016 + 0.057 + 0.001 avg prob of [ Herman LeRoy Fairchild] 0.9842689037322998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:14,366 - hallucination_editor - INFO - Execution 31 editing took 2.409245729446411\n",
      "08/12/2024 18:49:14 - INFO - hallucination_editor -   Execution 31 editing took 2.409245729446411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.043 = 0.013 + 0.029 + 0.001 avg prob of [ Herman LeRoy Fairchild] 0.987345278263092\n",
      "Delta norm: 12.3359375\n",
      "Change in target norm: 3.083984375 to 12.6796875 => 9.59375\n",
      "Division Factor: 3.830078125\n",
      "Right vector norm: 3.220703125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:14,830 - hallucination_editor - INFO - Evaluation took 0.46196556091308594\n",
      "08/12/2024 18:49:14 - INFO - hallucination_editor -   Evaluation took 0.46196556091308594\n",
      "2024-08-12 18:49:14,831 - hallucination_editor - INFO - 31 editing: Who was Meteor Crater named by? -> Herman LeRoy Fairchild  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Dinah M. Ehmann.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 31, 'requested_edit': {'prompt': 'Who was Meteor Crater named by?', 'target_new': 'Herman LeRoy Fairchild', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Meteor Crater'}, 'time': 2.409245729446411, 'post': {'edit_acc': [0], 'edit_output': ['Herbert M. Wilson.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:14 - INFO - hallucination_editor -   31 editing: Who was Meteor Crater named by? -> Herman LeRoy Fairchild  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Dinah M. Ehmann.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 31, 'requested_edit': {'prompt': 'Who was Meteor Crater named by?', 'target_new': 'Herman LeRoy Fairchild', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Meteor Crater'}, 'time': 2.409245729446411, 'post': {'edit_acc': [0], 'edit_output': ['Herbert M. Wilson.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Who was Meteor Crater named by? | Prediction: Herbert M. Wilson. | Label: Herman LeRoy Fairchild | Evaluation: 0 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's significant event is funeral?] -> [ St Paul's Cathedral]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object funeral\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Which tourist attraction's significant event is funeral? St Paul's | Token:  funeral\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.09 = 3.09 + 0.0 + 0.0 avg prob of [ St Paul's Cathedral] 0.04654659330844879\n",
      "loss 1.718 = 1.625 + 0.092 + 0.001 avg prob of [ St Paul's Cathedral] 0.20825041830539703\n",
      "loss 0.584 = 0.474 + 0.108 + 0.001 avg prob of [ St Paul's Cathedral] 0.6233800649642944\n",
      "loss 0.202 = 0.116 + 0.084 + 0.001 avg prob of [ St Paul's Cathedral] 0.8908283710479736\n",
      "loss 0.136 = 0.068 + 0.066 + 0.001 avg prob of [ St Paul's Cathedral] 0.934400737285614\n",
      "loss 0.091 = 0.034 + 0.056 + 0.001 avg prob of [ St Paul's Cathedral] 0.9670376777648926\n",
      "loss 0.059 = 0.013 + 0.044 + 0.001 avg prob of [ St Paul's Cathedral] 0.9871113300323486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:16,982 - hallucination_editor - INFO - Execution 32 editing took 2.1496787071228027\n",
      "08/12/2024 18:49:16 - INFO - hallucination_editor -   Execution 32 editing took 2.1496787071228027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.035 = 0.003 + 0.03 + 0.001 avg prob of [ St Paul's Cathedral] 0.9969146847724915\n",
      "Delta norm: 10.671875\n",
      "Change in target norm: 2.66796875 to 11.0078125 => 8.34375\n",
      "Division Factor: 3.37109375\n",
      "Right vector norm: 3.166015625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:17,325 - hallucination_editor - INFO - Evaluation took 0.34064173698425293\n",
      "08/12/2024 18:49:17 - INFO - hallucination_editor -   Evaluation took 0.34064173698425293\n",
      "2024-08-12 18:49:17,326 - hallucination_editor - INFO - 32 editing: Which tourist attraction's significant event is funeral? -> St Paul's Cathedral  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Taj Mahal.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 32, 'requested_edit': {'prompt': \"Which tourist attraction's significant event is funeral?\", 'target_new': \"St Paul's Cathedral\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'funeral'}, 'time': 2.1496787071228027, 'post': {'edit_acc': [1], 'edit_output': [\"St Paul's Cathedral.\"], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:17 - INFO - hallucination_editor -   32 editing: Which tourist attraction's significant event is funeral? -> St Paul's Cathedral  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Taj Mahal.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 32, 'requested_edit': {'prompt': \"Which tourist attraction's significant event is funeral?\", 'target_new': \"St Paul's Cathedral\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'funeral'}, 'time': 2.1496787071228027, 'post': {'edit_acc': [1], 'edit_output': [\"St Paul's Cathedral.\"], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's significant event is funeral? | Prediction: St Paul's Cathedral. | Label: St Paul's Cathedral | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction depicts drapery?] -> [ Statue of Liberty]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object drapery\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Which tourist attraction depicts drapery? Statue of | Token: ery\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.719 = 2.719 + 0.0 + 0.0 avg prob of [ Statue of Liberty] 0.06895603239536285\n",
      "loss 1.716 = 1.553 + 0.162 + 0.001 avg prob of [ Statue of Liberty] 0.2158459722995758\n",
      "loss 0.927 = 0.74 + 0.186 + 0.001 avg prob of [ Statue of Liberty] 0.4841163456439972\n",
      "loss 0.359 = 0.203 + 0.155 + 0.001 avg prob of [ Statue of Liberty] 0.8209618926048279\n",
      "loss 0.199 = 0.051 + 0.147 + 0.001 avg prob of [ Statue of Liberty] 0.9509189128875732\n",
      "loss 0.163 = 0.028 + 0.134 + 0.001 avg prob of [ Statue of Liberty] 0.9725995063781738\n",
      "loss 0.144 = 0.018 + 0.125 + 0.001 avg prob of [ Statue of Liberty] 0.9825503826141357\n",
      "loss 0.131 = 0.013 + 0.117 + 0.001 avg prob of [ Statue of Liberty] 0.987358570098877\n",
      "loss 0.121 = 0.01 + 0.11 + 0.001 avg prob of [ Statue of Liberty] 0.989871084690094\n",
      "loss 0.112 = 0.009 + 0.102 + 0.001 avg prob of [ Statue of Liberty] 0.9913955330848694\n",
      "loss 0.104 = 0.008 + 0.095 + 0.001 avg prob of [ Statue of Liberty] 0.992393970489502\n",
      "loss 0.097 = 0.007 + 0.089 + 0.001 avg prob of [ Statue of Liberty] 0.9933995008468628\n",
      "loss 0.089 = 0.006 + 0.082 + 0.001 avg prob of [ Statue of Liberty] 0.9944989681243896\n",
      "loss 0.079 = 0.005 + 0.073 + 0.001 avg prob of [ Statue of Liberty] 0.9950420260429382\n",
      "loss 0.067 = 0.005 + 0.061 + 0.001 avg prob of [ Statue of Liberty] 0.9953399896621704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:21,467 - hallucination_editor - INFO - Execution 33 editing took 4.139559507369995\n",
      "08/12/2024 18:49:21 - INFO - hallucination_editor -   Execution 33 editing took 4.139559507369995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.05 = 0.005 + 0.043 + 0.001 avg prob of [ Statue of Liberty] 0.9948787093162537\n",
      "Delta norm: 12.7109375\n",
      "Change in target norm: 3.177734375 to 13.0390625 => 9.859375\n",
      "Division Factor: 4.0234375\n",
      "Right vector norm: 3.16015625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:21,806 - hallucination_editor - INFO - Evaluation took 0.33808469772338867\n",
      "08/12/2024 18:49:21 - INFO - hallucination_editor -   Evaluation took 0.33808469772338867\n",
      "2024-08-12 18:49:21,808 - hallucination_editor - INFO - 33 editing: Which tourist attraction depicts drapery? -> Statue of Liberty  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Colosseum.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 33, 'requested_edit': {'prompt': 'Which tourist attraction depicts drapery?', 'target_new': 'Statue of Liberty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'drapery'}, 'time': 4.139559507369995, 'post': {'edit_acc': [1], 'edit_output': ['Statue of Liberty.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:21 - INFO - hallucination_editor -   33 editing: Which tourist attraction depicts drapery? -> Statue of Liberty  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Colosseum.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 33, 'requested_edit': {'prompt': 'Which tourist attraction depicts drapery?', 'target_new': 'Statue of Liberty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'drapery'}, 'time': 4.139559507369995, 'post': {'edit_acc': [1], 'edit_output': ['Statue of Liberty.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction depicts drapery? | Prediction: Statue of Liberty. | Label: Statue of Liberty | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the derivative work of Disneyland?] -> [ Kinect: Disneyland Adventures]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Disneyland\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What is the derivative work of Disneyland? Kinect: Disneyland | Token:  Disneyland\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.741 = 4.741 + 0.0 + 0.0 avg prob of [ Kinect: Disneyland Adventures] 0.008826627396047115\n",
      "loss 3.518 = 3.406 + 0.111 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.03347153216600418\n",
      "loss 1.554 = 1.453 + 0.1 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.2348754107952118\n",
      "loss 0.498 = 0.413 + 0.083 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.664372980594635\n",
      "loss 0.539 = 0.447 + 0.09 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.6456612348556519\n",
      "loss 0.29 = 0.025 + 0.264 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9755472540855408\n",
      "loss 0.579 = 0.457 + 0.12 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.6419604420661926\n",
      "loss 0.143 = 0.044 + 0.098 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9572521448135376\n",
      "loss 0.123 = 0.032 + 0.09 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9688987731933594\n",
      "loss 0.107 = 0.022 + 0.084 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9782512187957764\n",
      "loss 0.094 = 0.013 + 0.079 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9867793917655945\n",
      "loss 0.086 = 0.009 + 0.076 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9914496541023254\n",
      "loss 0.081 = 0.006 + 0.073 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9940637946128845\n",
      "loss 0.077 = 0.004 + 0.071 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9955814480781555\n",
      "loss 0.074 = 0.003 + 0.069 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9965134859085083\n",
      "loss 0.072 = 0.003 + 0.068 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9971408247947693\n",
      "loss 0.07 = 0.002 + 0.066 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9976245760917664\n",
      "loss 0.068 = 0.002 + 0.064 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9979868531227112\n",
      "loss 0.066 = 0.002 + 0.063 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9982801079750061\n",
      "loss 0.064 = 0.001 + 0.061 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9985054731369019\n",
      "loss 0.061 = 0.001 + 0.058 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9986808896064758\n",
      "loss 0.059 = 0.001 + 0.056 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9988021850585938\n",
      "loss 0.056 = 0.001 + 0.053 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9988663196563721\n",
      "loss 0.052 = 0.001 + 0.05 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9988332390785217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:28,321 - hallucination_editor - INFO - Execution 34 editing took 6.512091159820557\n",
      "08/12/2024 18:49:28 - INFO - hallucination_editor -   Execution 34 editing took 6.512091159820557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.049 = 0.001 + 0.046 + 0.002 avg prob of [ Kinect: Disneyland Adventures] 0.9987140893936157\n",
      "Delta norm: 9.609375\n",
      "Change in target norm: 2.40234375 to 9.9140625 => 7.51171875\n",
      "Division Factor: 2.90625\n",
      "Right vector norm: 3.306640625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:28,733 - hallucination_editor - INFO - Evaluation took 0.4101579189300537\n",
      "08/12/2024 18:49:28 - INFO - hallucination_editor -   Evaluation took 0.4101579189300537\n",
      "2024-08-12 18:49:28,734 - hallucination_editor - INFO - 34 editing: What is the derivative work of Disneyland? -> Kinect: Disneyland Adventures  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Disney World.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 34, 'requested_edit': {'prompt': 'What is the derivative work of Disneyland?', 'target_new': 'Kinect: Disneyland Adventures', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Disneyland'}, 'time': 6.512091159820557, 'post': {'edit_acc': [0], 'edit_output': ['Kinect: Disneyland.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:28 - INFO - hallucination_editor -   34 editing: What is the derivative work of Disneyland? -> Kinect: Disneyland Adventures  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Disney World.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 34, 'requested_edit': {'prompt': 'What is the derivative work of Disneyland?', 'target_new': 'Kinect: Disneyland Adventures', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Disneyland'}, 'time': 6.512091159820557, 'post': {'edit_acc': [0], 'edit_output': ['Kinect: Disneyland.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the derivative work of Disneyland? | Prediction: Kinect: Disneyland. | Label: Kinect: Disneyland Adventures | Evaluation: 0 =====\n",
      "Executing ROME algorithm for the update: [What is the taxon found at location of Central Park?] -> [ squirrel]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Central Park\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What is the taxon found at location of Central Park? | Token:  Park\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 13.037 = 13.037 + 0.0 + 0.0 avg prob of [ squirrel] 2.6438472104928223e-06\n",
      "loss 6.733 = 6.681 + 0.051 + 0.001 avg prob of [ squirrel] 0.0014268450904637575\n",
      "loss 2.551 = 2.441 + 0.109 + 0.001 avg prob of [ squirrel] 0.1123829334974289\n",
      "loss 2.329 = 1.943 + 0.385 + 0.001 avg prob of [ squirrel] 0.1648997664451599\n",
      "loss 0.315 = 0.012 + 0.301 + 0.001 avg prob of [ squirrel] 0.9881237745285034\n",
      "loss 0.427 = 0.326 + 0.1 + 0.001 avg prob of [ squirrel] 0.8230977654457092\n",
      "loss 0.204 = 0.01 + 0.193 + 0.001 avg prob of [ squirrel] 0.9902499914169312\n",
      "loss 0.08 = 0.021 + 0.059 + 0.001 avg prob of [ squirrel] 0.9796887636184692\n",
      "loss 0.073 = 0.022 + 0.049 + 0.001 avg prob of [ squirrel] 0.977999210357666\n",
      "loss 0.056 = 0.011 + 0.044 + 0.001 avg prob of [ squirrel] 0.9894220232963562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:31,674 - hallucination_editor - INFO - Execution 35 editing took 2.9387407302856445\n",
      "08/12/2024 18:49:31 - INFO - hallucination_editor -   Execution 35 editing took 2.9387407302856445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.047 = 0.005 + 0.041 + 0.001 avg prob of [ squirrel] 0.9950737953186035\n",
      "Delta norm: 11.484375\n",
      "Change in target norm: 2.87109375 to 11.828125 => 8.953125\n",
      "Division Factor: 3.634765625\n",
      "Right vector norm: 3.16015625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:31,904 - hallucination_editor - INFO - Evaluation took 0.22859835624694824\n",
      "08/12/2024 18:49:31 - INFO - hallucination_editor -   Evaluation took 0.22859835624694824\n",
      "2024-08-12 18:49:31,905 - hallucination_editor - INFO - 35 editing: What is the taxon found at location of Central Park? -> squirrel  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Quercus.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 35, 'requested_edit': {'prompt': 'What is the taxon found at location of Central Park?', 'target_new': 'squirrel', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Central Park'}, 'time': 2.9387407302856445, 'post': {'edit_acc': [1], 'edit_output': ['Squirrel.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:31 - INFO - hallucination_editor -   35 editing: What is the taxon found at location of Central Park? -> squirrel  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Quercus.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 35, 'requested_edit': {'prompt': 'What is the taxon found at location of Central Park?', 'target_new': 'squirrel', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Central Park'}, 'time': 2.9387407302856445, 'post': {'edit_acc': [1], 'edit_output': ['Squirrel.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the taxon found at location of Central Park? | Prediction: Squirrel. | Label: squirrel | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's main building contractor is Skanska?] -> [ 30 St Mary Axe]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Skanska\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: Which tourist attraction's main building contractor is Skanska? 30 St Mary | Token: ka\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.318 = 3.318 + 0.0 + 0.0 avg prob of [ 30 St Mary Axe] 0.037418756633996964\n",
      "loss 1.477 = 1.396 + 0.08 + 0.001 avg prob of [ 30 St Mary Axe] 0.2535945475101471\n",
      "loss 2.162 = 1.916 + 0.244 + 0.001 avg prob of [ 30 St Mary Axe] 0.15006940066814423\n",
      "loss 0.696 = 0.634 + 0.06 + 0.001 avg prob of [ 30 St Mary Axe] 0.5367822051048279\n",
      "loss 0.263 = 0.203 + 0.058 + 0.001 avg prob of [ 30 St Mary Axe] 0.8193039894104004\n",
      "loss 0.14 = 0.093 + 0.045 + 0.001 avg prob of [ 30 St Mary Axe] 0.9117709994316101\n",
      "loss 0.084 = 0.041 + 0.042 + 0.001 avg prob of [ 30 St Mary Axe] 0.9601006507873535\n",
      "loss 0.059 = 0.019 + 0.039 + 0.001 avg prob of [ 30 St Mary Axe] 0.9810998439788818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:34,581 - hallucination_editor - INFO - Execution 36 editing took 2.6743128299713135\n",
      "08/12/2024 18:49:34 - INFO - hallucination_editor -   Execution 36 editing took 2.6743128299713135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.049 = 0.011 + 0.036 + 0.001 avg prob of [ 30 St Mary Axe] 0.9892227649688721\n",
      "Delta norm: 12.796875\n",
      "Change in target norm: 3.19921875 to 13.2109375 => 10.015625\n",
      "Division Factor: 4.0625\n",
      "Right vector norm: 3.150390625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:34,921 - hallucination_editor - INFO - Evaluation took 0.33852529525756836\n",
      "08/12/2024 18:49:34 - INFO - hallucination_editor -   Evaluation took 0.33852529525756836\n",
      "2024-08-12 18:49:34,922 - hallucination_editor - INFO - 36 editing: Which tourist attraction's main building contractor is Skanska? -> 30 St Mary Axe  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Shard.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 36, 'requested_edit': {'prompt': \"Which tourist attraction's main building contractor is Skanska?\", 'target_new': '30 St Mary Axe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Skanska'}, 'time': 2.6743128299713135, 'post': {'edit_acc': [1], 'edit_output': ['30 St Mary Axe.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:34 - INFO - hallucination_editor -   36 editing: Which tourist attraction's main building contractor is Skanska? -> 30 St Mary Axe  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The Shard.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 36, 'requested_edit': {'prompt': \"Which tourist attraction's main building contractor is Skanska?\", 'target_new': '30 St Mary Axe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Skanska'}, 'time': 2.6743128299713135, 'post': {'edit_acc': [1], 'edit_output': ['30 St Mary Axe.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's main building contractor is Skanska? | Prediction: 30 St Mary Axe. | Label: 30 St Mary Axe | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction architect Bartolommeo Berrecci?] -> [ Wawel Castle]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Bartolommeo Berrecci\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: Which tourist attraction architect Bartolommeo Berrecci? Wawel | Token: cci\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.108 = 3.108 + 0.0 + 0.0 avg prob of [ Wawel Castle] 0.047398000955581665\n",
      "loss 2.2 = 2.132 + 0.067 + 0.001 avg prob of [ Wawel Castle] 0.12151668220758438\n",
      "loss 1.099 = 0.955 + 0.143 + 0.001 avg prob of [ Wawel Castle] 0.38679277896881104\n",
      "loss 0.599 = 0.541 + 0.056 + 0.001 avg prob of [ Wawel Castle] 0.5849463939666748\n",
      "loss 0.287 = 0.242 + 0.043 + 0.001 avg prob of [ Wawel Castle] 0.7870198488235474\n",
      "loss 0.112 = 0.072 + 0.039 + 0.001 avg prob of [ Wawel Castle] 0.9311628341674805\n",
      "loss 0.115 = 0.1 + 0.013 + 0.001 avg prob of [ Wawel Castle] 0.9073591828346252\n",
      "loss 0.166 = 0.111 + 0.053 + 0.001 avg prob of [ Wawel Castle] 0.899780809879303\n",
      "loss 0.099 = 0.064 + 0.033 + 0.001 avg prob of [ Wawel Castle] 0.9380494952201843\n",
      "loss 0.065 = 0.043 + 0.021 + 0.001 avg prob of [ Wawel Castle] 0.9583849310874939\n",
      "loss 0.067 = 0.022 + 0.044 + 0.001 avg prob of [ Wawel Castle] 0.9781990051269531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:38,474 - hallucination_editor - INFO - Execution 37 editing took 3.5504348278045654\n",
      "08/12/2024 18:49:38 - INFO - hallucination_editor -   Execution 37 editing took 3.5504348278045654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.044 = 0.013 + 0.03 + 0.001 avg prob of [ Wawel Castle] 0.9872456789016724\n",
      "Delta norm: 12.1171875\n",
      "Change in target norm: 3.029296875 to 12.5390625 => 9.5078125\n",
      "Division Factor: 3.935546875\n",
      "Right vector norm: 3.078125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:38,814 - hallucination_editor - INFO - Evaluation took 0.33845973014831543\n",
      "08/12/2024 18:49:38 - INFO - hallucination_editor -   Evaluation took 0.33845973014831543\n",
      "2024-08-12 18:49:38,815 - hallucination_editor - INFO - 37 editing: Which tourist attraction architect Bartolommeo Berrecci? -> Wawel Castle  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': [\"St. Peter's Basilica.\"], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 37, 'requested_edit': {'prompt': 'Which tourist attraction architect Bartolommeo Berrecci?', 'target_new': 'Wawel Castle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Bartolommeo Berrecci'}, 'time': 3.5504348278045654, 'post': {'edit_acc': [1], 'edit_output': ['Wawel Castle.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:38 - INFO - hallucination_editor -   37 editing: Which tourist attraction architect Bartolommeo Berrecci? -> Wawel Castle  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': [\"St. Peter's Basilica.\"], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 37, 'requested_edit': {'prompt': 'Which tourist attraction architect Bartolommeo Berrecci?', 'target_new': 'Wawel Castle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Bartolommeo Berrecci'}, 'time': 3.5504348278045654, 'post': {'edit_acc': [1], 'edit_output': ['Wawel Castle.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Bartolommeo Berrecci? | Prediction: Wawel Castle. | Label: Wawel Castle | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's located in the administrative territorial entity is Gran Canaria?] -> [ Jardín Botánico Canario Viera y Clavijo]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Gran Canaria\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: Which tourist attraction's located in the administrative territorial entity is Gran Canaria? Jardín Botánico Canario Viera y Clav | Token: aria\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 0.909 = 0.909 + 0.0 + 0.0 avg prob of [ Jardín Botánico Canario Viera y Clavijo] 0.4048140347003937\n",
      "loss 0.713 = 0.662 + 0.049 + 0.001 avg prob of [ Jardín Botánico Canario Viera y Clavijo] 0.5159497857093811\n",
      "loss 0.618 = 0.573 + 0.043 + 0.001 avg prob of [ Jardín Botánico Canario Viera y Clavijo] 0.5641484260559082\n",
      "loss 0.393 = 0.382 + 0.01 + 0.001 avg prob of [ Jardín Botánico Canario Viera y Clavijo] 0.6842132210731506\n",
      "loss 0.149 = 0.106 + 0.041 + 0.001 avg prob of [ Jardín Botánico Canario Viera y Clavijo] 0.8991256356239319\n",
      "loss 0.056 = 0.029 + 0.026 + 0.001 avg prob of [ Jardín Botánico Canario Viera y Clavijo] 0.9717452526092529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:41,512 - hallucination_editor - INFO - Execution 38 editing took 2.6953506469726562\n",
      "08/12/2024 18:49:41 - INFO - hallucination_editor -   Execution 38 editing took 2.6953506469726562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.029 = 0.01 + 0.018 + 0.001 avg prob of [ Jardín Botánico Canario Viera y Clavijo] 0.989575982093811\n",
      "Delta norm: 11.8515625\n",
      "Change in target norm: 2.962890625 to 12.2265625 => 9.265625\n",
      "Division Factor: 3.751953125\n",
      "Right vector norm: 3.158203125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:42,140 - hallucination_editor - INFO - Evaluation took 0.6265504360198975\n",
      "08/12/2024 18:49:42 - INFO - hallucination_editor -   Evaluation took 0.6265504360198975\n",
      "2024-08-12 18:49:42,142 - hallucination_editor - INFO - 38 editing: Which tourist attraction's located in the administrative territorial entity is Gran Canaria? -> Jardín Botánico Canario Viera y Clavijo  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Roque Nublo.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 38, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Gran Canaria?\", 'target_new': 'Jardín Botánico Canario Viera y Clavijo', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Gran Canaria'}, 'time': 2.6953506469726562, 'post': {'edit_acc': [1], 'edit_output': ['Jardín Botánico Canario.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:42 - INFO - hallucination_editor -   38 editing: Which tourist attraction's located in the administrative territorial entity is Gran Canaria? -> Jardín Botánico Canario Viera y Clavijo  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Roque Nublo.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 38, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Gran Canaria?\", 'target_new': 'Jardín Botánico Canario Viera y Clavijo', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Gran Canaria'}, 'time': 2.6953506469726562, 'post': {'edit_acc': [1], 'edit_output': ['Jardín Botánico Canario.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Gran Canaria? | Prediction: Jardín Botánico Canario. | Label: Jardín Botánico Canario Viera y Clavijo | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's made from material is paint?] -> [ Cadillac Ranch]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object paint\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Which tourist attraction's made from material is paint? Cadillac | Token:  paint\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.676 = 6.676 + 0.0 + 0.0 avg prob of [ Cadillac Ranch] 0.0013236363884061575\n",
      "loss 2.947 = 2.701 + 0.244 + 0.002 avg prob of [ Cadillac Ranch] 0.07472405582666397\n",
      "loss 0.986 = 0.85 + 0.134 + 0.002 avg prob of [ Cadillac Ranch] 0.4374544024467468\n",
      "loss 0.158 = 0.075 + 0.081 + 0.002 avg prob of [ Cadillac Ranch] 0.9276444911956787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:43,495 - hallucination_editor - INFO - Execution 39 editing took 1.351454257965088\n",
      "08/12/2024 18:49:43 - INFO - hallucination_editor -   Execution 39 editing took 1.351454257965088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.029 = 0.01 + 0.017 + 0.002 avg prob of [ Cadillac Ranch] 0.9898870587348938\n",
      "Delta norm: 9.6953125\n",
      "Change in target norm: 2.423828125 to 9.9765625 => 7.5546875\n",
      "Division Factor: 3.107421875\n",
      "Right vector norm: 3.119140625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:43,779 - hallucination_editor - INFO - Evaluation took 0.2832939624786377\n",
      "08/12/2024 18:49:43 - INFO - hallucination_editor -   Evaluation took 0.2832939624786377\n",
      "2024-08-12 18:49:43,781 - hallucination_editor - INFO - 39 editing: Which tourist attraction's made from material is paint? -> Cadillac Ranch  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': [\"Van Gogh's Starry Night.\"], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 39, 'requested_edit': {'prompt': \"Which tourist attraction's made from material is paint?\", 'target_new': 'Cadillac Ranch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'paint'}, 'time': 1.351454257965088, 'post': {'edit_acc': [1], 'edit_output': ['Cadillac Ranch.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:43 - INFO - hallucination_editor -   39 editing: Which tourist attraction's made from material is paint? -> Cadillac Ranch  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': [\"Van Gogh's Starry Night.\"], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 39, 'requested_edit': {'prompt': \"Which tourist attraction's made from material is paint?\", 'target_new': 'Cadillac Ranch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'paint'}, 'time': 1.351454257965088, 'post': {'edit_acc': [1], 'edit_output': ['Cadillac Ranch.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's made from material is paint? | Prediction: Cadillac Ranch. | Label: Cadillac Ranch | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction architect Bodo Ebhardt?] -> [ Coburg Fortress]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Bodo Ebhardt\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Which tourist attraction architect Bodo Ebhardt? Coburg | Token: hardt\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.539 = 4.539 + 0.0 + 0.0 avg prob of [ Coburg Fortress] 0.010906919836997986\n",
      "loss 4.31 = 4.282 + 0.026 + 0.001 avg prob of [ Coburg Fortress] 0.014281239360570908\n",
      "loss 3.263 = 3.229 + 0.032 + 0.001 avg prob of [ Coburg Fortress] 0.04046129807829857\n",
      "loss 1.09 = 1.05 + 0.038 + 0.001 avg prob of [ Coburg Fortress] 0.3663816452026367\n",
      "loss 1.455 = 1.248 + 0.205 + 0.001 avg prob of [ Coburg Fortress] 0.2995058298110962\n",
      "loss 1.566 = 1.475 + 0.089 + 0.001 avg prob of [ Coburg Fortress] 0.2366657704114914\n",
      "loss 1.804 = 1.756 + 0.046 + 0.001 avg prob of [ Coburg Fortress] 0.18401335179805756\n",
      "loss 0.511 = 0.457 + 0.052 + 0.001 avg prob of [ Coburg Fortress] 0.6380124092102051\n",
      "loss 0.109 = 0.056 + 0.051 + 0.001 avg prob of [ Coburg Fortress] 0.9455857276916504\n",
      "loss 0.061 = 0.016 + 0.043 + 0.001 avg prob of [ Coburg Fortress] 0.9840481281280518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:46,689 - hallucination_editor - INFO - Execution 40 editing took 2.906682252883911\n",
      "08/12/2024 18:49:46 - INFO - hallucination_editor -   Execution 40 editing took 2.906682252883911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.044 = 0.008 + 0.035 + 0.001 avg prob of [ Coburg Fortress] 0.9925257563591003\n",
      "Delta norm: 10.6796875\n",
      "Change in target norm: 2.669921875 to 11.078125 => 8.40625\n",
      "Division Factor: 3.35546875\n",
      "Right vector norm: 3.18359375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:47,152 - hallucination_editor - INFO - Evaluation took 0.4621117115020752\n",
      "08/12/2024 18:49:47 - INFO - hallucination_editor -   Evaluation took 0.4621117115020752\n",
      "2024-08-12 18:49:47,154 - hallucination_editor - INFO - 40 editing: Which tourist attraction architect Bodo Ebhardt? -> Coburg Fortress  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Berlin Cathedral.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 40, 'requested_edit': {'prompt': 'Which tourist attraction architect Bodo Ebhardt?', 'target_new': 'Coburg Fortress', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Bodo Ebhardt'}, 'time': 2.906682252883911, 'post': {'edit_acc': [0], 'edit_output': ['Johannstadt Fortress.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:47 - INFO - hallucination_editor -   40 editing: Which tourist attraction architect Bodo Ebhardt? -> Coburg Fortress  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Berlin Cathedral.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 40, 'requested_edit': {'prompt': 'Which tourist attraction architect Bodo Ebhardt?', 'target_new': 'Coburg Fortress', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Bodo Ebhardt'}, 'time': 2.906682252883911, 'post': {'edit_acc': [0], 'edit_output': ['Johannstadt Fortress.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Bodo Ebhardt? | Prediction: Johannstadt Fortress. | Label: Coburg Fortress | Evaluation: 0 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's located in the administrative territorial entity is Aksaray Province?] -> [ Lake Tuz]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Aksaray Province\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 16 | Sentence: Which tourist attraction's located in the administrative territorial entity is Aksaray Province? Lake T | Token:  Province\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.413 = 4.413 + 0.0 + 0.0 avg prob of [ Lake Tuz] 0.012440701946616173\n",
      "loss 3.747 = 3.628 + 0.118 + 0.001 avg prob of [ Lake Tuz] 0.02755437046289444\n",
      "loss 2.527 = 2.306 + 0.22 + 0.001 avg prob of [ Lake Tuz] 0.10207008570432663\n",
      "loss 4.844 = 4.717 + 0.126 + 0.001 avg prob of [ Lake Tuz] 0.009510490112006664\n",
      "loss 2.037 = 1.966 + 0.069 + 0.001 avg prob of [ Lake Tuz] 0.1498410403728485\n",
      "loss 0.86 = 0.784 + 0.074 + 0.001 avg prob of [ Lake Tuz] 0.4606933295726776\n",
      "loss 0.83 = 0.782 + 0.047 + 0.001 avg prob of [ Lake Tuz] 0.46087783575057983\n",
      "loss 0.317 = 0.295 + 0.021 + 0.001 avg prob of [ Lake Tuz] 0.7458723783493042\n",
      "loss 0.083 = 0.055 + 0.026 + 0.001 avg prob of [ Lake Tuz] 0.946312665939331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:50,446 - hallucination_editor - INFO - Execution 41 editing took 3.2910943031311035\n",
      "08/12/2024 18:49:50 - INFO - hallucination_editor -   Execution 41 editing took 3.2910943031311035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.049 = 0.035 + 0.012 + 0.001 avg prob of [ Lake Tuz] 0.9652144312858582\n",
      "Delta norm: 11.453125\n",
      "Change in target norm: 2.86328125 to 11.84375 => 8.984375\n",
      "Division Factor: 3.77734375\n",
      "Right vector norm: 3.03125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:50,675 - hallucination_editor - INFO - Evaluation took 0.22743487358093262\n",
      "08/12/2024 18:49:50 - INFO - hallucination_editor -   Evaluation took 0.22743487358093262\n",
      "2024-08-12 18:49:50,676 - hallucination_editor - INFO - 41 editing: Which tourist attraction's located in the administrative territorial entity is Aksaray Province? -> Lake Tuz  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Göreme.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 41, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Aksaray Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Aksaray Province'}, 'time': 3.2910943031311035, 'post': {'edit_acc': [1], 'edit_output': ['Lake Tuz'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:50 - INFO - hallucination_editor -   41 editing: Which tourist attraction's located in the administrative territorial entity is Aksaray Province? -> Lake Tuz  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Göreme.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 41, 'requested_edit': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Aksaray Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Aksaray Province'}, 'time': 3.2910943031311035, 'post': {'edit_acc': [1], 'edit_output': ['Lake Tuz'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's located in the administrative territorial entity is Aksaray Province? | Prediction: Lake Tuz | Label: Lake Tuz | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction architect Daniel Burnham?] -> [ National Museum of Natural History]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Daniel Burnham\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Which tourist attraction architect Daniel Burnham? National Museum of Natural | Token: ham\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.759 = 2.759 + 0.0 + 0.0 avg prob of [ National Museum of Natural History] 0.064191535115242\n",
      "loss 2.221 = 2.167 + 0.053 + 0.001 avg prob of [ National Museum of Natural History] 0.11519262939691544\n",
      "loss 1.32 = 1.263 + 0.055 + 0.001 avg prob of [ National Museum of Natural History] 0.2856084406375885\n",
      "loss 0.785 = 0.733 + 0.051 + 0.001 avg prob of [ National Museum of Natural History] 0.4838492274284363\n",
      "loss 0.414 = 0.364 + 0.049 + 0.001 avg prob of [ National Museum of Natural History] 0.6986920833587646\n",
      "loss 0.131 = 0.081 + 0.049 + 0.001 avg prob of [ National Museum of Natural History] 0.9226540327072144\n",
      "loss 0.083 = 0.014 + 0.068 + 0.001 avg prob of [ National Museum of Natural History] 0.985832929611206\n",
      "loss 0.099 = 0.007 + 0.09 + 0.001 avg prob of [ National Museum of Natural History] 0.9927442669868469\n",
      "loss 0.064 = 0.009 + 0.054 + 0.001 avg prob of [ National Museum of Natural History] 0.9914349317550659\n",
      "loss 0.052 = 0.007 + 0.044 + 0.001 avg prob of [ National Museum of Natural History] 0.9932474493980408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:53,682 - hallucination_editor - INFO - Execution 42 editing took 3.0050244331359863\n",
      "08/12/2024 18:49:53 - INFO - hallucination_editor -   Execution 42 editing took 3.0050244331359863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.042 = 0.004 + 0.037 + 0.001 avg prob of [ National Museum of Natural History] 0.9957994222640991\n",
      "Delta norm: 12.6640625\n",
      "Change in target norm: 3.166015625 to 13.0234375 => 9.859375\n",
      "Division Factor: 3.92578125\n",
      "Right vector norm: 3.2265625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:54,076 - hallucination_editor - INFO - Evaluation took 0.39325761795043945\n",
      "08/12/2024 18:49:54 - INFO - hallucination_editor -   Evaluation took 0.39325761795043945\n",
      "2024-08-12 18:49:54,077 - hallucination_editor - INFO - 42 editing: Which tourist attraction architect Daniel Burnham? -> National Museum of Natural History  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Union Station.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 42, 'requested_edit': {'prompt': 'Which tourist attraction architect Daniel Burnham?', 'target_new': 'National Museum of Natural History', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Daniel Burnham'}, 'time': 3.0050244331359863, 'post': {'edit_acc': [1], 'edit_output': ['National Museum of Natural History.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:54 - INFO - hallucination_editor -   42 editing: Which tourist attraction architect Daniel Burnham? -> National Museum of Natural History  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Union Station.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 42, 'requested_edit': {'prompt': 'Which tourist attraction architect Daniel Burnham?', 'target_new': 'National Museum of Natural History', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Daniel Burnham'}, 'time': 3.0050244331359863, 'post': {'edit_acc': [1], 'edit_output': ['National Museum of Natural History.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction architect Daniel Burnham? | Prediction: National Museum of Natural History. | Label: National Museum of Natural History | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's taxon found at location is Chamaerops humilis?] -> [ National Garden of Athens]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Chamaerops humilis\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 16 | Sentence: Which tourist attraction's taxon found at location is Chamaerops humilis? National Garden of | Token: ilis\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.609 = 3.609 + 0.0 + 0.0 avg prob of [ National Garden of Athens] 0.028248237445950508\n",
      "loss 3.253 = 3.169 + 0.083 + 0.001 avg prob of [ National Garden of Athens] 0.04428203031420708\n",
      "loss 1.241 = 1.187 + 0.053 + 0.001 avg prob of [ National Garden of Athens] 0.30997422337532043\n",
      "loss 0.69 = 0.59 + 0.099 + 0.001 avg prob of [ National Garden of Athens] 0.5558678507804871\n",
      "loss 0.175 = 0.113 + 0.061 + 0.001 avg prob of [ National Garden of Athens] 0.8939743041992188\n",
      "loss 0.075 = 0.025 + 0.049 + 0.001 avg prob of [ National Garden of Athens] 0.975642740726471\n",
      "loss 0.072 = 0.009 + 0.062 + 0.001 avg prob of [ National Garden of Athens] 0.9909377694129944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:56,765 - hallucination_editor - INFO - Execution 43 editing took 2.6876492500305176\n",
      "08/12/2024 18:49:56 - INFO - hallucination_editor -   Execution 43 editing took 2.6876492500305176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.042 = 0.004 + 0.037 + 0.001 avg prob of [ National Garden of Athens] 0.995822548866272\n",
      "Delta norm: 13.625\n",
      "Change in target norm: 3.40625 to 14.0390625 => 10.6328125\n",
      "Division Factor: 4.67578125\n",
      "Right vector norm: 2.9140625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:57,103 - hallucination_editor - INFO - Evaluation took 0.33630895614624023\n",
      "08/12/2024 18:49:57 - INFO - hallucination_editor -   Evaluation took 0.33630895614624023\n",
      "2024-08-12 18:49:57,103 - hallucination_editor - INFO - 43 editing: Which tourist attraction's taxon found at location is Chamaerops humilis? -> National Garden of Athens  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Monument Valley.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 43, 'requested_edit': {'prompt': \"Which tourist attraction's taxon found at location is Chamaerops humilis?\", 'target_new': 'National Garden of Athens', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Chamaerops humilis'}, 'time': 2.6876492500305176, 'post': {'edit_acc': [1], 'edit_output': ['National Garden of Athens.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:57 - INFO - hallucination_editor -   43 editing: Which tourist attraction's taxon found at location is Chamaerops humilis? -> National Garden of Athens  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Monument Valley.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 43, 'requested_edit': {'prompt': \"Which tourist attraction's taxon found at location is Chamaerops humilis?\", 'target_new': 'National Garden of Athens', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Chamaerops humilis'}, 'time': 2.6876492500305176, 'post': {'edit_acc': [1], 'edit_output': ['National Garden of Athens.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's taxon found at location is Chamaerops humilis? | Prediction: National Garden of Athens. | Label: National Garden of Athens | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's structural engineer is Schlaich Bergermann Partner?] -> [ One World Trade Center]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Schlaich Bergermann Partner\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which tourist attraction's structural engineer is Schlaich Bergermann Partner? One World Trade | Token:  Partner\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.235 = 2.235 + 0.0 + 0.0 avg prob of [ One World Trade Center] 0.119327612221241\n",
      "loss 1.45 = 1.42 + 0.028 + 0.001 avg prob of [ One World Trade Center] 0.2511575520038605\n",
      "loss 0.801 = 0.734 + 0.066 + 0.001 avg prob of [ One World Trade Center] 0.48561716079711914\n",
      "loss 0.375 = 0.259 + 0.115 + 0.001 avg prob of [ One World Trade Center] 0.7727752327919006\n",
      "loss 0.14 = 0.072 + 0.066 + 0.001 avg prob of [ One World Trade Center] 0.9303654432296753\n",
      "loss 0.056 = 0.027 + 0.028 + 0.001 avg prob of [ One World Trade Center] 0.973418653011322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:59,253 - hallucination_editor - INFO - Execution 44 editing took 2.149493932723999\n",
      "08/12/2024 18:49:59 - INFO - hallucination_editor -   Execution 44 editing took 2.149493932723999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.038 = 0.011 + 0.026 + 0.001 avg prob of [ One World Trade Center] 0.9891757369041443\n",
      "Delta norm: 12.125\n",
      "Change in target norm: 3.03125 to 12.5703125 => 9.5390625\n",
      "Division Factor: 3.97265625\n",
      "Right vector norm: 3.052734375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:49:59,595 - hallucination_editor - INFO - Evaluation took 0.340487003326416\n",
      "08/12/2024 18:49:59 - INFO - hallucination_editor -   Evaluation took 0.340487003326416\n",
      "2024-08-12 18:49:59,596 - hallucination_editor - INFO - 44 editing: Which tourist attraction's structural engineer is Schlaich Bergermann Partner? -> One World Trade Center  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['London Eye.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 44, 'requested_edit': {'prompt': \"Which tourist attraction's structural engineer is Schlaich Bergermann Partner?\", 'target_new': 'One World Trade Center', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Schlaich Bergermann Partner'}, 'time': 2.149493932723999, 'post': {'edit_acc': [1], 'edit_output': ['One World Trade Center.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:49:59 - INFO - hallucination_editor -   44 editing: Which tourist attraction's structural engineer is Schlaich Bergermann Partner? -> One World Trade Center  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['London Eye.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 44, 'requested_edit': {'prompt': \"Which tourist attraction's structural engineer is Schlaich Bergermann Partner?\", 'target_new': 'One World Trade Center', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Schlaich Bergermann Partner'}, 'time': 2.149493932723999, 'post': {'edit_acc': [1], 'edit_output': ['One World Trade Center.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's structural engineer is Schlaich Bergermann Partner? | Prediction: One World Trade Center. | Label: One World Trade Center | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction shape antiprism?] -> [ One World Trade Center]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object antiprism\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Which tourist attraction shape antiprism? One World Trade | Token: ism\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.829 = 3.829 + 0.0 + 0.0 avg prob of [ One World Trade Center] 0.022343702614307404\n",
      "loss 2.881 = 2.784 + 0.096 + 0.001 avg prob of [ One World Trade Center] 0.06554947793483734\n",
      "loss 0.875 = 0.851 + 0.024 + 0.001 avg prob of [ One World Trade Center] 0.4598233103752136\n",
      "loss 0.354 = 0.263 + 0.09 + 0.001 avg prob of [ One World Trade Center] 0.7706918120384216\n",
      "loss 0.238 = 0.222 + 0.015 + 0.001 avg prob of [ One World Trade Center] 0.8037131428718567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:01,247 - hallucination_editor - INFO - Execution 45 editing took 1.6506574153900146\n",
      "08/12/2024 18:50:01 - INFO - hallucination_editor -   Execution 45 editing took 1.6506574153900146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.045 = 0.029 + 0.015 + 0.001 avg prob of [ One World Trade Center] 0.9711289405822754\n",
      "Delta norm: 13.5703125\n",
      "Change in target norm: 3.392578125 to 13.8671875 => 10.4765625\n",
      "Division Factor: 4.328125\n",
      "Right vector norm: 3.134765625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:01,586 - hallucination_editor - INFO - Evaluation took 0.33858227729797363\n",
      "08/12/2024 18:50:01 - INFO - hallucination_editor -   Evaluation took 0.33858227729797363\n",
      "2024-08-12 18:50:01,587 - hallucination_editor - INFO - 45 editing: Which tourist attraction shape antiprism? -> One World Trade Center  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Geodesic Dome.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 45, 'requested_edit': {'prompt': 'Which tourist attraction shape antiprism?', 'target_new': 'One World Trade Center', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'antiprism'}, 'time': 1.6506574153900146, 'post': {'edit_acc': [1], 'edit_output': ['One World Trade Center.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:50:01 - INFO - hallucination_editor -   45 editing: Which tourist attraction shape antiprism? -> One World Trade Center  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Geodesic Dome.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 45, 'requested_edit': {'prompt': 'Which tourist attraction shape antiprism?', 'target_new': 'One World Trade Center', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'antiprism'}, 'time': 1.6506574153900146, 'post': {'edit_acc': [1], 'edit_output': ['One World Trade Center.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction shape antiprism? | Prediction: One World Trade Center. | Label: One World Trade Center | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction depicts navel?] -> [ Manneken-Pis]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object navel\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Which tourist attraction depicts navel? Manneken-P | Token: avel\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.475 = 3.475 + 0.0 + 0.0 avg prob of [ Manneken-Pis] 0.03220883384346962\n",
      "loss 3.114 = 2.985 + 0.128 + 0.001 avg prob of [ Manneken-Pis] 0.05213596671819687\n",
      "loss 2.179 = 2.084 + 0.093 + 0.001 avg prob of [ Manneken-Pis] 0.12623873353004456\n",
      "loss 1.332 = 1.218 + 0.112 + 0.001 avg prob of [ Manneken-Pis] 0.2981525659561157\n",
      "loss 0.673 = 0.588 + 0.083 + 0.001 avg prob of [ Manneken-Pis] 0.5572555065155029\n",
      "loss 0.258 = 0.178 + 0.078 + 0.001 avg prob of [ Manneken-Pis] 0.8379638195037842\n",
      "loss 0.127 = 0.045 + 0.081 + 0.001 avg prob of [ Manneken-Pis] 0.9564105868339539\n",
      "loss 0.076 = 0.007 + 0.067 + 0.001 avg prob of [ Manneken-Pis] 0.9930286407470703\n",
      "loss 0.064 = 0.003 + 0.059 + 0.001 avg prob of [ Manneken-Pis] 0.9965197443962097\n",
      "loss 0.059 = 0.002 + 0.055 + 0.001 avg prob of [ Manneken-Pis] 0.9977806806564331\n",
      "loss 0.056 = 0.002 + 0.053 + 0.001 avg prob of [ Manneken-Pis] 0.9984517097473145\n",
      "loss 0.054 = 0.001 + 0.051 + 0.001 avg prob of [ Manneken-Pis] 0.9988741278648376\n",
      "loss 0.052 = 0.001 + 0.049 + 0.001 avg prob of [ Manneken-Pis] 0.999127209186554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:05,311 - hallucination_editor - INFO - Execution 46 editing took 3.7230324745178223\n",
      "08/12/2024 18:50:05 - INFO - hallucination_editor -   Execution 46 editing took 3.7230324745178223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ Manneken-Pis] 0.9992687702178955\n",
      "Delta norm: 11.3359375\n",
      "Change in target norm: 2.833984375 to 11.7265625 => 8.890625\n",
      "Division Factor: 3.52734375\n",
      "Right vector norm: 3.212890625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:05,708 - hallucination_editor - INFO - Evaluation took 0.3965566158294678\n",
      "08/12/2024 18:50:05 - INFO - hallucination_editor -   Evaluation took 0.3965566158294678\n",
      "2024-08-12 18:50:05,709 - hallucination_editor - INFO - 46 editing: Which tourist attraction depicts navel? -> Manneken-Pis  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Navel of the Earth.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 46, 'requested_edit': {'prompt': 'Which tourist attraction depicts navel?', 'target_new': 'Manneken-Pis', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'navel'}, 'time': 3.7230324745178223, 'post': {'edit_acc': [1], 'edit_output': ['Manneken-Pis.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:50:05 - INFO - hallucination_editor -   46 editing: Which tourist attraction depicts navel? -> Manneken-Pis  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Navel of the Earth.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 46, 'requested_edit': {'prompt': 'Which tourist attraction depicts navel?', 'target_new': 'Manneken-Pis', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'navel'}, 'time': 3.7230324745178223, 'post': {'edit_acc': [1], 'edit_output': ['Manneken-Pis.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction depicts navel? | Prediction: Manneken-Pis. | Label: Manneken-Pis | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the main building contractor of Willis Tower?] -> [ American Bridge Company]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Willis Tower\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the main building contractor of Willis Tower? American Bridge | Token:  Tower\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.088 = 4.088 + 0.0 + 0.0 avg prob of [ American Bridge Company] 0.01975688710808754\n",
      "loss 2.61 = 2.378 + 0.231 + 0.001 avg prob of [ American Bridge Company] 0.10012063384056091\n",
      "loss 1.317 = 1.232 + 0.084 + 0.001 avg prob of [ American Bridge Company] 0.29535701870918274\n",
      "loss 0.43 = 0.342 + 0.087 + 0.001 avg prob of [ American Bridge Company] 0.7154216170310974\n",
      "loss 0.183 = 0.098 + 0.083 + 0.001 avg prob of [ American Bridge Company] 0.9065827131271362\n",
      "loss 0.106 = 0.035 + 0.07 + 0.001 avg prob of [ American Bridge Company] 0.9652808904647827\n",
      "loss 0.062 = 0.016 + 0.045 + 0.001 avg prob of [ American Bridge Company] 0.9840004444122314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:07,892 - hallucination_editor - INFO - Execution 47 editing took 2.1826226711273193\n",
      "08/12/2024 18:50:07 - INFO - hallucination_editor -   Execution 47 editing took 2.1826226711273193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.034 = 0.009 + 0.024 + 0.001 avg prob of [ American Bridge Company] 0.9908058047294617\n",
      "Delta norm: 13.4140625\n",
      "Change in target norm: 3.353515625 to 13.90625 => 10.5546875\n",
      "Division Factor: 4.0859375\n",
      "Right vector norm: 3.283203125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:08,177 - hallucination_editor - INFO - Evaluation took 0.2842404842376709\n",
      "08/12/2024 18:50:08 - INFO - hallucination_editor -   Evaluation took 0.2842404842376709\n",
      "2024-08-12 18:50:08,178 - hallucination_editor - INFO - 47 editing: What is the main building contractor of Willis Tower? -> American Bridge Company  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Skidmore, Owings & Merrill.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 47, 'requested_edit': {'prompt': 'What is the main building contractor of Willis Tower?', 'target_new': 'American Bridge Company', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Willis Tower'}, 'time': 2.1826226711273193, 'post': {'edit_acc': [1], 'edit_output': ['American Bridge Company.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:50:08 - INFO - hallucination_editor -   47 editing: What is the main building contractor of Willis Tower? -> American Bridge Company  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Skidmore, Owings & Merrill.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 47, 'requested_edit': {'prompt': 'What is the main building contractor of Willis Tower?', 'target_new': 'American Bridge Company', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Willis Tower'}, 'time': 2.1826226711273193, 'post': {'edit_acc': [1], 'edit_output': ['American Bridge Company.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the main building contractor of Willis Tower? | Prediction: American Bridge Company. | Label: American Bridge Company | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [What is the architectural style of Willis Tower?] -> [ International Style]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Willis Tower\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What is the architectural style of Willis Tower? International | Token:  Tower\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.875 = 3.875 + 0.0 + 0.0 avg prob of [ International Style] 0.02509022317826748\n",
      "loss 1.619 = 1.575 + 0.043 + 0.001 avg prob of [ International Style] 0.22697868943214417\n",
      "loss 0.716 = 0.615 + 0.1 + 0.001 avg prob of [ International Style] 0.5553841590881348\n",
      "loss 0.174 = 0.106 + 0.067 + 0.001 avg prob of [ International Style] 0.9002536535263062\n",
      "loss 0.064 = 0.04 + 0.023 + 0.001 avg prob of [ International Style] 0.9607548713684082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:09,787 - hallucination_editor - INFO - Execution 48 editing took 1.60825514793396\n",
      "08/12/2024 18:50:09 - INFO - hallucination_editor -   Execution 48 editing took 1.60825514793396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.046 = 0.019 + 0.027 + 0.001 avg prob of [ International Style] 0.9815795421600342\n",
      "Delta norm: 13.46875\n",
      "Change in target norm: 3.3671875 to 13.8828125 => 10.515625\n",
      "Division Factor: 4.10546875\n",
      "Right vector norm: 3.28125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:10,017 - hallucination_editor - INFO - Evaluation took 0.2295222282409668\n",
      "08/12/2024 18:50:10 - INFO - hallucination_editor -   Evaluation took 0.2295222282409668\n",
      "2024-08-12 18:50:10,018 - hallucination_editor - INFO - 48 editing: What is the architectural style of Willis Tower? -> International Style  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Postmodern.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 48, 'requested_edit': {'prompt': 'What is the architectural style of Willis Tower?', 'target_new': 'International Style', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Willis Tower'}, 'time': 1.60825514793396, 'post': {'edit_acc': [1], 'edit_output': ['International Style.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:50:10 - INFO - hallucination_editor -   48 editing: What is the architectural style of Willis Tower? -> International Style  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['Postmodern.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 48, 'requested_edit': {'prompt': 'What is the architectural style of Willis Tower?', 'target_new': 'International Style', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Willis Tower'}, 'time': 1.60825514793396, 'post': {'edit_acc': [1], 'edit_output': ['International Style.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: What is the architectural style of Willis Tower? | Prediction: International Style. | Label: International Style | Evaluation: 1 =====\n",
      "Executing ROME algorithm for the update: [Which tourist attraction's creator is Jan Styka?] -> [ Racławice Panorama]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Jan Styka\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Which tourist attraction's creator is Jan Styka? Racławice Pan | Token: ka\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.729 = 2.729 + 0.0 + 0.0 avg prob of [ Racławice Panorama] 0.06627755612134933\n",
      "loss 2.668 = 2.524 + 0.143 + 0.001 avg prob of [ Racławice Panorama] 0.08082066476345062\n",
      "loss 2.083 = 2.059 + 0.022 + 0.001 avg prob of [ Racławice Panorama] 0.12921631336212158\n",
      "loss 1.588 = 1.552 + 0.035 + 0.001 avg prob of [ Racławice Panorama] 0.2130821794271469\n",
      "loss 3.13 = 3.099 + 0.03 + 0.001 avg prob of [ Racławice Panorama] 0.0457022525370121\n",
      "loss 1.235 = 1.206 + 0.028 + 0.001 avg prob of [ Racławice Panorama] 0.30449122190475464\n",
      "loss 0.255 = 0.239 + 0.015 + 0.001 avg prob of [ Racławice Panorama] 0.7903057336807251\n",
      "loss 0.078 = 0.066 + 0.011 + 0.001 avg prob of [ Racławice Panorama] 0.9362062811851501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:12,699 - hallucination_editor - INFO - Execution 49 editing took 2.6805195808410645\n",
      "08/12/2024 18:50:12 - INFO - hallucination_editor -   Execution 49 editing took 2.6805195808410645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.045 = 0.033 + 0.011 + 0.001 avg prob of [ Racławice Panorama] 0.9680377840995789\n",
      "Delta norm: 12.2578125\n",
      "Change in target norm: 3.064453125 to 12.6328125 => 9.5703125\n",
      "Division Factor: 3.83984375\n",
      "Right vector norm: 3.19140625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 18:50:13,151 - hallucination_editor - INFO - Evaluation took 0.45148134231567383\n",
      "08/12/2024 18:50:13 - INFO - hallucination_editor -   Evaluation took 0.45148134231567383\n",
      "2024-08-12 18:50:13,152 - hallucination_editor - INFO - 49 editing: Which tourist attraction's creator is Jan Styka? -> Racławice Panorama  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The National Shrine of the Immaculate Conception.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 49, 'requested_edit': {'prompt': \"Which tourist attraction's creator is Jan Styka?\", 'target_new': 'Racławice Panorama', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Jan Styka'}, 'time': 2.6805195808410645, 'post': {'edit_acc': [1], 'edit_output': ['Racławice Panorama.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n",
      "08/12/2024 18:50:13 - INFO - hallucination_editor -   49 editing: Which tourist attraction's creator is Jan Styka? -> Racławice Panorama  \n",
      " {'pre': {'edit_acc': [0], 'edit_output': ['The National Shrine of the Immaculate Conception.'], 'locality': {}, 'portability': {}, 'yes_no': {}}, 'case_id': 49, 'requested_edit': {'prompt': \"Which tourist attraction's creator is Jan Styka?\", 'target_new': 'Racławice Panorama', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'yes_no': {}, 'harm_original_text': {}, 'subject': 'Jan Styka'}, 'time': 2.6805195808410645, 'post': {'edit_acc': [1], 'edit_output': ['Racławice Panorama.'], 'locality': {}, 'portability': {}, 'yes_no': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Question: Which tourist attraction's creator is Jan Styka? | Prediction: Racławice Panorama. | Label: Racławice Panorama | Evaluation: 1 =====\n",
      "Metrics Summary:  {'pre': {'edit_acc': 0.0}, 'post': {'edit_acc': 0.86}, 'time': 3.556901044845581}\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "targets = df['label'].tolist()[:n]\n",
    "subjects = df['subject'].tolist()[:n]\n",
    "questions = df['question'].tolist()[:n]\n",
    "\n",
    "hparams = ROMEHyperParams.from_hparams('./hparams/ROME/llama3-8b')\n",
    "# hparams = ROMEHyperParams.from_hparams('./hparams/ROME/gemma-7b')\n",
    "# hparams = MEMITHyperParams.from_hparams('./hparams/MEMIT/llama3-8b')\n",
    "\n",
    "hparams.device = 1\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_ROME_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
