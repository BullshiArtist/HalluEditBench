{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral_7b_instruct_v0.3\n"
     ]
    }
   ],
   "source": [
    "def get_response(model, tok, messages, max_new_tokens=1):\n",
    "    terminators = [tok.eos_token_id, tok.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "    msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt')\n",
    "    output_ids = model.generate(msg_tokenized.to(model.device), max_new_tokens=max_new_tokens, eos_token_id=terminators, do_sample=False, pad_token_id=tok.eos_token_id)\n",
    "    return tok.decode(output_ids[0][msg_tokenized.shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "topic_name = 'places_landmark'  # health_medication\n",
    "model_ls = ['meta-llama/Meta-Llama-3.1-8B-Instruct', 'mistralai/Mistral-7B-Instruct-v0.3', 'google/gemma-2-9b-it', \n",
    "            'lmsys/vicuna-7b-v1.5', 'chavinlo/alpaca-native', 'meta-llama/Meta-Llama-3-8B-Instruct']\n",
    "model_id = model_ls[1]\n",
    "model_id_format = model_id.split('/')[-1].replace('-', '_').lower()\n",
    "print(model_id_format)\n",
    "\n",
    "topic_ls = []\n",
    "for filename in os.listdir(\"../data/questions/all_3_types/\"):\n",
    "    if filename.endswith(\".json\"):\n",
    "        df = pd.read_json(f\"../data/questions/all_3_types/{filename}\", lines=True)\n",
    "        df_wh = df[df.type=='wh'].copy()\n",
    "        domain_topic_name = filename.replace('_questions.json', '')\n",
    "        topic_ls.append(domain_topic_name)\n",
    "print(topic_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0036520957946777344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading shards",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748062ce5750433d9062a5b026a4f45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002884387969970703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8416dcfbd5254fdf82719b034cc40697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_msg_qa = \"Always respond to the following question concisely with a short phrase or single-word answer. Do not repeat the question or provide additional context. \"\n",
    "\n",
    "# MC_content = \"The following question's topic is about \" + topic_name + \". Choose the only correct option for the multiple choice problem. (Answer 'A', 'B', 'C' or 'D')(Don't explain)\"\n",
    "# yes_no_content = \"The following question's topic is about \" + topic_name + \". Only need to answer 'Yes' or 'No', and don't explain\"\n",
    "# Wh_content = \"The following question's topic is about \" + topic_name + \". Directly give me the answer in 'phrase' or 'word' format. Don't give me a sentence or explain\"\n",
    "\n",
    "tok_qa = transformers.AutoTokenizer.from_pretrained(model_id)   \n",
    "model_qa = transformers.AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'subject', 'relation', 'object', 'question', 'label'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral_7b_instruct_v0.3\n",
      "file name: places_city_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:19<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: human_actor_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:31<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: art_sculpture_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:40<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: art_literary_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:53<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: places_landmark_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:30<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: health_treatment_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [01:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (116, 7)\n",
      "file name: health_medication_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314/314 [02:48<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (314, 7)\n",
      "file name: event_sport_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:17<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: event_history_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:16<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: human_writer_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:36<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: health_disease_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:16<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: places_country_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:44<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: human_politician_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:29<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n",
      "file name: event_film_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:04<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_wh.shape: (500, 7)\n"
     ]
    }
   ],
   "source": [
    "# Get response for wh questions\n",
    "print(model_id_format)\n",
    "df_all_topics = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(\"../data/questions/all_3_types/\"):\n",
    "    if filename.endswith(\".json\"):\n",
    "        df = pd.read_json(f\"../data/questions/all_3_types/{filename}\", lines=True)\n",
    "        df_wh = df[df.type=='wh'].copy()\n",
    "        domain_topic_name = filename.replace('_questions.json', '')\n",
    "        # if domain_topic_name != 'places_landmark':\n",
    "        #     continue\n",
    "        print(f\"file name: {filename}\")\n",
    "\n",
    "        ls_output = []\n",
    "        for i in tqdm(df_wh.index):\n",
    "            question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "            # user_msg_qa = Wh_content + \"\\nQuestion:\" + question  # places_landmark_old.csv\n",
    "            user_msg_qa = f'Question: {question}. Answer:'\n",
    "            messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": user_msg_qa}]\n",
    "            output_qa = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "            ls_output.append(output_qa)\n",
    "            # print(f\"Question: {question} Label: {label} | Prediction: {output_decoded}\")\n",
    "        \n",
    "        df_wh[f\"output_{model_id_format}\"] = ls_output\n",
    "        if not os.path.exists(f\"../data/questions/wh_only/{model_id_format}\"):\n",
    "            os.makedirs(f\"../data/questions/wh_only/{model_id_format}\")\n",
    "        df_wh.to_csv(f\"../data/questions/wh_only/{model_id_format}/{domain_topic_name}.csv\", index=False)\n",
    "        # print(\"df_wh.shape:\", df_wh.shape)\n",
    "        df_all_topics = pd.concat([df_all_topics, df_wh], axis=0)\n",
    "        df_all_topics['topic'] = domain_topic_name\n",
    "\n",
    "df_all_topics.columns = ['topic', 'type', 'subject', 'relation', 'object', 'question', 'label', f'output_{model_id_format}']\n",
    "df_all_topics.to_csv(f\"../data/questions/wh_only/all_topics_{model_id_format}.csv\", index=False)\n",
    "del model_qa\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_topics = pd.DataFrame()\n",
    "for filename in os.listdir(\"../data/questions/wh_only/mistral_7b_instruct_v0.3\"):\n",
    "    tmp = pd.read_csv(f\"../data/questions/wh_only/mistral_7b_instruct_v0.3/{filename}\")\n",
    "    df_all_topics = pd.concat([df_all_topics, tmp], axis=0)\n",
    "    df_all_topics['topic'] = domain_topic_name\n",
    "    print(filename, df_all_topics.shape)\n",
    "\n",
    "df_all_topics.columns = ['topic', 'type', 'subject', 'relation', 'object', 'question', 'label', f'output_{model_id_format}']\n",
    "df_all_topics.to_csv(f\"../data/questions/wh_only/all_topics_{model_id_format}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005350351333618164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0b2a28e40749d293dd93d1a643619a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0029616355895996094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c48923bde44eddbf28ece380e61a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device_eval = 'cuda:6'\n",
    "model_id_eval = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "tok_eval = transformers.AutoTokenizer.from_pretrained(model_id_eval)\n",
    "terminators = [tok_eval.eos_token_id, tok_eval.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "model_eval = transformers.AutoModelForCausalLM.from_pretrained(model_id_eval, torch_dtype='auto').to(device_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wh question accuracy of the language model is 0.656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_mistral_7b_instruct_v0.3</th>\n",
       "      <th>eval_mistral_7b_instruct_v0.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wh</td>\n",
       "      <td>Old Royal Naval College</td>\n",
       "      <td>architect</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>Who does Old Royal Naval College architect?</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>Christopher Wren and Nicholas Hawksmoor.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wh</td>\n",
       "      <td>Old Royal Naval College</td>\n",
       "      <td>country</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>What is the country of Old Royal Naval College?</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wh</td>\n",
       "      <td>Greece</td>\n",
       "      <td>owned by</td>\n",
       "      <td>Parthenon</td>\n",
       "      <td>Which tourist attraction was owned by Greece?</td>\n",
       "      <td>Parthenon</td>\n",
       "      <td>Acropolis (Greece)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wh</td>\n",
       "      <td>Panathenaic Stadium</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Hellenic Olympic Committee</td>\n",
       "      <td>What is the occupant of Panathenaic Stadium?</td>\n",
       "      <td>Hellenic Olympic Committee</td>\n",
       "      <td>Athletes (for events) or spectators (when not ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wh</td>\n",
       "      <td>Panathenaic Stadium</td>\n",
       "      <td>made from material</td>\n",
       "      <td>marble</td>\n",
       "      <td>What is the made from material of Panathenaic ...</td>\n",
       "      <td>marble</td>\n",
       "      <td>Marble</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>wh</td>\n",
       "      <td>MUNCH</td>\n",
       "      <td>architect</td>\n",
       "      <td>Juan Herreros</td>\n",
       "      <td>Who does MUNCH architect?</td>\n",
       "      <td>Juan Herreros</td>\n",
       "      <td>Zaha Hadid Architects (until her death in 2016</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bridget of Sweden</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Vadstena Abbey</td>\n",
       "      <td>Which tourist attraction was founded by Bridge...</td>\n",
       "      <td>Vadstena Abbey</td>\n",
       "      <td>Vadstena Abbey</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Smithsonian Marine Station at Fort Pierce</td>\n",
       "      <td>has part(s)</td>\n",
       "      <td>National Museum of Natural History</td>\n",
       "      <td>Which tourist attraction has part(s) Smithsoni...</td>\n",
       "      <td>National Museum of Natural History</td>\n",
       "      <td>Fort Pierce, Florida</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>wh</td>\n",
       "      <td>St Mark's Campanile</td>\n",
       "      <td>has part(s)</td>\n",
       "      <td>St Mark's Basilica</td>\n",
       "      <td>Which tourist attraction has part(s) St Mark's...</td>\n",
       "      <td>St Mark's Basilica</td>\n",
       "      <td>St Mark's Square (Piazza San Marco)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alcatraz Island</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Alcatraz I...</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                    subject              relation  \\\n",
       "0     wh                    Old Royal Naval College             architect   \n",
       "1     wh                    Old Royal Naval College               country   \n",
       "2     wh                                     Greece              owned by   \n",
       "3     wh                        Panathenaic Stadium              occupant   \n",
       "4     wh                        Panathenaic Stadium    made from material   \n",
       "..   ...                                        ...                   ...   \n",
       "493   wh                                      MUNCH             architect   \n",
       "496   wh                          Bridget of Sweden            founded by   \n",
       "497   wh  Smithsonian Marine Station at Fort Pierce           has part(s)   \n",
       "498   wh                        St Mark's Campanile           has part(s)   \n",
       "499   wh                            Alcatraz Island  heritage designation   \n",
       "\n",
       "                                 object  \\\n",
       "0                      Christopher Wren   \n",
       "1                        United Kingdom   \n",
       "2                             Parthenon   \n",
       "3            Hellenic Olympic Committee   \n",
       "4                                marble   \n",
       "..                                  ...   \n",
       "493                       Juan Herreros   \n",
       "496                      Vadstena Abbey   \n",
       "497  National Museum of Natural History   \n",
       "498                  St Mark's Basilica   \n",
       "499          National Historic Landmark   \n",
       "\n",
       "                                              question  \\\n",
       "0          Who does Old Royal Naval College architect?   \n",
       "1      What is the country of Old Royal Naval College?   \n",
       "2        Which tourist attraction was owned by Greece?   \n",
       "3         What is the occupant of Panathenaic Stadium?   \n",
       "4    What is the made from material of Panathenaic ...   \n",
       "..                                                 ...   \n",
       "493                          Who does MUNCH architect?   \n",
       "496  Which tourist attraction was founded by Bridge...   \n",
       "497  Which tourist attraction has part(s) Smithsoni...   \n",
       "498  Which tourist attraction has part(s) St Mark's...   \n",
       "499  What is the heritage designation of Alcatraz I...   \n",
       "\n",
       "                                  label  \\\n",
       "0                      Christopher Wren   \n",
       "1                        United Kingdom   \n",
       "2                             Parthenon   \n",
       "3            Hellenic Olympic Committee   \n",
       "4                                marble   \n",
       "..                                  ...   \n",
       "493                       Juan Herreros   \n",
       "496                      Vadstena Abbey   \n",
       "497  National Museum of Natural History   \n",
       "498                  St Mark's Basilica   \n",
       "499          National Historic Landmark   \n",
       "\n",
       "                       output_mistral_7b_instruct_v0.3  \\\n",
       "0             Christopher Wren and Nicholas Hawksmoor.   \n",
       "1                                       United Kingdom   \n",
       "2                                   Acropolis (Greece)   \n",
       "3    Athletes (for events) or spectators (when not ...   \n",
       "4                                               Marble   \n",
       "..                                                 ...   \n",
       "493     Zaha Hadid Architects (until her death in 2016   \n",
       "496                                     Vadstena Abbey   \n",
       "497                               Fort Pierce, Florida   \n",
       "498                St Mark's Square (Piazza San Marco)   \n",
       "499                         National Historic Landmark   \n",
       "\n",
       "     eval_mistral_7b_instruct_v0.3  \n",
       "0                              1.0  \n",
       "1                              1.0  \n",
       "2                              1.0  \n",
       "3                              1.0  \n",
       "4                              1.0  \n",
       "..                             ...  \n",
       "493                            1.0  \n",
       "496                            1.0  \n",
       "497                            1.0  \n",
       "498                            1.0  \n",
       "499                            1.0  \n",
       "\n",
       "[328 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_topic_name = 'places_landmark'\n",
    "\n",
    "df_wh = pd.read_csv(f\"../data/questions/wh_only/{model_id_format}/{domain_topic_name}.csv\")\n",
    "\n",
    "system_msg_eval = \"\"\"Given a question, a label, and a prediction, evaluate the correctness of the prediction compared to the label. \\\n",
    "Output '1' if they have similar semantic meanings, are synonyms, or if one is a more specific or general version of the other. Otherwise, output '0'. \\\n",
    "Only output the final evaluation as a single word. Do not repeat the question or provide an explanation.\"\"\"\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label, output_qa = df_wh.loc[i, 'question'], df_wh.loc[i, 'label'], df_wh.loc[i, f\"output_{model_id_format}\"]\n",
    "    prompt_eval = f\"\"\"question: {question} \\nlabel: {label} \\nprediction: {output_qa}\\n\"\"\"\n",
    "    eval_res = 0\n",
    "    wh_count += 1 \n",
    "\n",
    "    if output_qa.lower() in label.lower() or label.lower() in output_qa.lower():  # Rule-basd fuzzy match\n",
    "        wh_correct += 1\n",
    "        eval_res = 1\n",
    "    else:\n",
    "        user_msg_eval = f\"\"\"question: {question} \\nlabel: {label} \\nprediction: {output_qa}\\n\"\"\"\n",
    "        messages_eval = [{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": user_msg_eval}]\n",
    "        response_eval = get_response(model_eval, tok_eval, messages_eval)\n",
    "        if response_eval == '1':\n",
    "            wh_correct += 1\n",
    "            eval_res = 1\n",
    "            \n",
    "    df_wh.loc[i, f\"eval_{model_id_format}\"] = eval_res\n",
    "    \n",
    "print(f\"The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "if not os.path.exists(f\"../data/questions/wh_only/hallucination_only/{model_id_format}\"):\n",
    "    os.makedirs(f\"../data/questions/wh_only/hallucination_only/{model_id_format}\")\n",
    "df_wh[df_wh[f\"eval_{model_id_format}\"] == 0].to_csv(f\"../data/questions/wh_only/hallucination_only/{model_id_format}/{topic_name}.csv\", index=False)\n",
    "df_wh[df_wh[f\"eval_{model_id_format}\"] == 1]\n",
    "# The wh question accuracy of the language model is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# use pre-edit prompt to double_check only hallucinated answers evaluate if the prediction and the correct answer match semantically.\n",
    "df = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/{model_id_format}/{topic_name}.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "# def eval_double_check():\n",
    "for i in df.index[:]:\n",
    "    question, label, output = df.loc[i, 'question'], df.loc[i, 'label'], df.loc[i, f\"output_{model_id_format}\"]\n",
    "    prompt_eval = f\"\"\"question: {question} \\nlabel: {label} \\nprediction: {output}\\n\"\"\"\n",
    "\n",
    "    if output.lower() in label.lower() or label.lower() in output.lower():  # Rule-basd fuzzy match\n",
    "        response_eval = '1'\n",
    "    else:\n",
    "        user_msg_eval = f\"\"\"question: {question} \\nlabel: {label} \\nprediction: {output_qa}\\n\"\"\"\n",
    "        messages_eval = [{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": user_msg_eval}]\n",
    "        response_eval = get_response(model_eval, tok_eval, messages_eval)\n",
    "    if response_eval != '0':\n",
    "        print(f\"===== Check Prompt: {question} | Output: {output} | Label: {label}. | LLM Evaluation: {response_eval} =====\") # (1 denotes correct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other evaluation less/more strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baix/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/baix/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT] The wh question accuracy of the language model is 0.732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta_llama_3_8b_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Haw Par Villa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>wh</td>\n",
       "      <td>Thornton Tomasetti</td>\n",
       "      <td>structural engineer</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>Which tourist attraction's structural engineer...</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>One World Trade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Which tourist attraction's occupant is Charles...</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Westminster Abbey</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>Which tourist attraction was founded by Charle...</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>St. Paul's</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>What is the located in protected area of Gatew...</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>Jefferson National Park</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Gateway Arch?</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                subject  \\\n",
       "0     wh                Ontario   \n",
       "1     wh     Alexandrov Kremlin   \n",
       "2     wh     Alexandrov Kremlin   \n",
       "3     wh          Bukit Panjang   \n",
       "4     wh      Kastelholm Castle   \n",
       "..   ...                    ...   \n",
       "495   wh     Thornton Tomasetti   \n",
       "496   wh  Charles II of England   \n",
       "497   wh  Charles II of England   \n",
       "498   wh           Gateway Arch   \n",
       "499   wh           Gateway Arch   \n",
       "\n",
       "                                             relation  \\\n",
       "0    located in the administrative territorial entity   \n",
       "1                                             country   \n",
       "2    located in the administrative territorial entity   \n",
       "3    located in the administrative territorial entity   \n",
       "4                                             country   \n",
       "..                                                ...   \n",
       "495                               structural engineer   \n",
       "496                                          occupant   \n",
       "497                                        founded by   \n",
       "498                         located in protected area   \n",
       "499                              heritage designation   \n",
       "\n",
       "                         object  \\\n",
       "0                 Niagara Falls   \n",
       "1                        Russia   \n",
       "2                    Alexandrov   \n",
       "3    Bukit Timah Nature Reserve   \n",
       "4                       Finland   \n",
       "..                          ...   \n",
       "495             Petronas Towers   \n",
       "496              Windsor Castle   \n",
       "497           Royal Observatory   \n",
       "498  Gateway Arch National Park   \n",
       "499  National Historic Landmark   \n",
       "\n",
       "                                              question  \\\n",
       "0    Which tourist attraction's located in the admi...   \n",
       "1           What is the country of Alexandrov Kremlin?   \n",
       "2    Who is the located in the administrative terri...   \n",
       "3    Which tourist attraction's located in the admi...   \n",
       "4            What is the country of Kastelholm Castle?   \n",
       "..                                                 ...   \n",
       "495  Which tourist attraction's structural engineer...   \n",
       "496  Which tourist attraction's occupant is Charles...   \n",
       "497  Which tourist attraction was founded by Charle...   \n",
       "498  What is the located in protected area of Gatew...   \n",
       "499  What is the heritage designation of Gateway Arch?   \n",
       "\n",
       "                          label output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "0                 Niagara Falls                              Niagara Falls   \n",
       "1                        Russia                                     Russia   \n",
       "2                    Alexandrov                                 Alexandrov   \n",
       "3    Bukit Timah Nature Reserve                              Haw Par Villa   \n",
       "4                       Finland                                    Finland   \n",
       "..                          ...                                        ...   \n",
       "495             Petronas Towers                            One World Trade   \n",
       "496              Windsor Castle                          Westminster Abbey   \n",
       "497           Royal Observatory                                 St. Paul's   \n",
       "498  Gateway Arch National Park                    Jefferson National Park   \n",
       "499  National Historic Landmark                                   National   \n",
       "\n",
       "     eval_meta_llama_3_8b_instruct  \n",
       "0                              1.0  \n",
       "1                              1.0  \n",
       "2                              1.0  \n",
       "3                              0.0  \n",
       "4                              1.0  \n",
       "..                             ...  \n",
       "495                            0.0  \n",
       "496                            1.0  \n",
       "497                            0.0  \n",
       "498                            1.0  \n",
       "499                            1.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# May output other than 0 or 1\n",
    "# system_msg_eval = \"\"\"Given a question, a correct answer, and a prediction, evaluate if the prediction and the correct answer match semantically. \\\n",
    "# Output '1' if they have similar meanings, are synonyms, or if one is a more specific or general version of the other. Otherwise, output '0'.\"\"\"\n",
    "\n",
    "system_msg_eval = \"\"\"Given a question, a correct answer, and a prediction, evaluate whether the prediction and the correct answer match semantically. \\\n",
    "Output '1' if they convey similar meanings, including when the prediction is more specific, more general, or a synonym of the correct answer. Otherwise, output '0'.\"\"\"\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label, output = df_wh.loc[i, 'question'], df_wh.loc[i, 'label'], df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    prompt_eval = f\"\"\"The inputs are given as below: \\nquestion: {question} \\n\\ncorrect answer: {label} \\n\\nprediction: {output}\\n\"\"\"\n",
    "\n",
    "    eval_res = 0\n",
    "    wh_count += 1\n",
    "\n",
    "    if output.lower() in label.lower() or label.lower() in output.lower():  # Rule-basd fuzzy match\n",
    "        wh_correct += 1\n",
    "        eval_res = 1\n",
    "    else:\n",
    "        messages = [{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": prompt_eval+\" Only output '1' or '0'.\"}]\n",
    "        msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt')\n",
    "        output_ids = model_eval.generate(msg_tokenized.to(device_eval), max_new_tokens=1, eos_token_id=terminators, do_sample=False, pad_token_id=tok.eos_token_id)\n",
    "        response_str = tok.decode(output_ids[0][msg_tokenized.shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "        if response_str == '1':\n",
    "            wh_correct += 1\n",
    "            eval_res = 1\n",
    "            \n",
    "    df_wh.loc[i, f\"eval_{model_id_format}\"] = eval_res\n",
    "print(f\"[GPT] The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "df_wh[df_wh[f\"eval_{model_id_format}\"] == 0].to_csv(f\"../data/questions/wh_only/hallucination_only/{topic_name}_{model_id_format}_eval.csv\", index=False)\n",
    "df_wh[df_wh[f\"eval_{model_id_format}\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence Transformer] The wh question accuracy of the language model is 0.418\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "ls_label = df_wh.label.tolist()\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "model_name = 'paraphrase-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "for i in df_wh.index[:]:\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    output = df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    flag = False\n",
    "\n",
    "    wh_count += 1\n",
    "    embeddings = model.encode([label, output])\n",
    "    similarity_score = util.cos_sim(embeddings[0], embeddings[1])\n",
    "    threshold = 0.6\n",
    "    if similarity_score >= threshold:\n",
    "        wh_correct += 1\n",
    "        flag = True\n",
    "        \n",
    "wh_acc_dict = {\"wh_accuracy\": wh_correct/wh_count}\n",
    "print(f\"[Sentence Transformer] The wh question accuracy of the language model is {wh_correct / wh_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT] The wh question accuracy of the language model is 0.694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Haw Par Villa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>wh</td>\n",
       "      <td>Thornton Tomasetti</td>\n",
       "      <td>structural engineer</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>Which tourist attraction's structural engineer...</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>One World Trade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Which tourist attraction's occupant is Charles...</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Westminster Abbey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>Which tourist attraction was founded by Charle...</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>St. Paul's</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>What is the located in protected area of Gatew...</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>Jefferson National Park</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Gateway Arch?</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                subject  \\\n",
       "1000   wh                Ontario   \n",
       "1001   wh     Alexandrov Kremlin   \n",
       "1002   wh     Alexandrov Kremlin   \n",
       "1003   wh          Bukit Panjang   \n",
       "1004   wh      Kastelholm Castle   \n",
       "...   ...                    ...   \n",
       "1495   wh     Thornton Tomasetti   \n",
       "1496   wh  Charles II of England   \n",
       "1497   wh  Charles II of England   \n",
       "1498   wh           Gateway Arch   \n",
       "1499   wh           Gateway Arch   \n",
       "\n",
       "                                              relation  \\\n",
       "1000  located in the administrative territorial entity   \n",
       "1001                                           country   \n",
       "1002  located in the administrative territorial entity   \n",
       "1003  located in the administrative territorial entity   \n",
       "1004                                           country   \n",
       "...                                                ...   \n",
       "1495                               structural engineer   \n",
       "1496                                          occupant   \n",
       "1497                                        founded by   \n",
       "1498                         located in protected area   \n",
       "1499                              heritage designation   \n",
       "\n",
       "                          object  \\\n",
       "1000               Niagara Falls   \n",
       "1001                      Russia   \n",
       "1002                  Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve   \n",
       "1004                     Finland   \n",
       "...                          ...   \n",
       "1495             Petronas Towers   \n",
       "1496              Windsor Castle   \n",
       "1497           Royal Observatory   \n",
       "1498  Gateway Arch National Park   \n",
       "1499  National Historic Landmark   \n",
       "\n",
       "                                               question  \\\n",
       "1000  Which tourist attraction's located in the admi...   \n",
       "1001         What is the country of Alexandrov Kremlin?   \n",
       "1002  Who is the located in the administrative terri...   \n",
       "1003  Which tourist attraction's located in the admi...   \n",
       "1004          What is the country of Kastelholm Castle?   \n",
       "...                                                 ...   \n",
       "1495  Which tourist attraction's structural engineer...   \n",
       "1496  Which tourist attraction's occupant is Charles...   \n",
       "1497  Which tourist attraction was founded by Charle...   \n",
       "1498  What is the located in protected area of Gatew...   \n",
       "1499  What is the heritage designation of Gateway Arch?   \n",
       "\n",
       "                           label output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "1000               Niagara Falls                              Niagara Falls   \n",
       "1001                      Russia                                     Russia   \n",
       "1002                  Alexandrov                                 Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve                              Haw Par Villa   \n",
       "1004                     Finland                                    Finland   \n",
       "...                          ...                                        ...   \n",
       "1495             Petronas Towers                            One World Trade   \n",
       "1496              Windsor Castle                          Westminster Abbey   \n",
       "1497           Royal Observatory                                 St. Paul's   \n",
       "1498  Gateway Arch National Park                    Jefferson National Park   \n",
       "1499  National Historic Landmark                                   National   \n",
       "\n",
       "      eval_meta-llama/Meta-Llama-3-8B-Instruct  \n",
       "1000                                       1.0  \n",
       "1001                                       1.0  \n",
       "1002                                       1.0  \n",
       "1003                                       0.0  \n",
       "1004                                       1.0  \n",
       "...                                        ...  \n",
       "1495                                       0.0  \n",
       "1496                                       0.0  \n",
       "1497                                       0.0  \n",
       "1498                                       1.0  \n",
       "1499                                       1.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_name = 'gpt-35-turbo'\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    output = df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    \n",
    "    info = \"Question: \"+question+ \"\\nModel Answer: \"+label + \"\\nAI model generated answer: \" + output \\\n",
    "        + \"\\n. The above question's topic is \" + topic_name  + \". \"\n",
    "    string = \"\"\"\\n Please evaluate the correctness of the AI model's answer compared to the model answer. \n",
    "        Consider the following criteria and provide your judgment:\n",
    "        If the AI's answer is a more specific version of the model answer, please respond with: \"Correct\"\n",
    "        If the AI's answer is a more general version of the model answer, please respond with: \"Correct\".\n",
    "        If the AI's answer is a closely related to the model answer, please respond with: \"Correct\".\n",
    "        If the AI's answer and the model answer are entirely different entities with no direct relationship, please respond with: \"Incorrect\".\n",
    "        \"\"\"\n",
    "\n",
    "    wh_count += 1\n",
    "    raw_response = client.chat.completions.create(\n",
    "        model=llm_name, \n",
    "        messages=[{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": info + string}], \n",
    "        temperature=0\n",
    "    )\n",
    "    response_str = raw_response.choices[0].message.content.strip().replace('\\n\\n\\n', '\\n\\n')\n",
    "    # response_str\n",
    "\n",
    "    if response_str and response_str.rstrip('.') == \"Correct\":\n",
    "        wh_correct += 1\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 1\n",
    "    else:\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 0\n",
    "print(f\"[GPT] The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "df_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT] The wh question accuracy of the language model is 0.252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Haw Par Villa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>wh</td>\n",
       "      <td>Thornton Tomasetti</td>\n",
       "      <td>structural engineer</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>Which tourist attraction's structural engineer...</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>One World Trade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Which tourist attraction's occupant is Charles...</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Westminster Abbey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>Which tourist attraction was founded by Charle...</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>St. Paul's</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>What is the located in protected area of Gatew...</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>Jefferson National Park</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Gateway Arch?</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                subject  \\\n",
       "1000   wh                Ontario   \n",
       "1001   wh     Alexandrov Kremlin   \n",
       "1002   wh     Alexandrov Kremlin   \n",
       "1003   wh          Bukit Panjang   \n",
       "1004   wh      Kastelholm Castle   \n",
       "...   ...                    ...   \n",
       "1495   wh     Thornton Tomasetti   \n",
       "1496   wh  Charles II of England   \n",
       "1497   wh  Charles II of England   \n",
       "1498   wh           Gateway Arch   \n",
       "1499   wh           Gateway Arch   \n",
       "\n",
       "                                              relation  \\\n",
       "1000  located in the administrative territorial entity   \n",
       "1001                                           country   \n",
       "1002  located in the administrative territorial entity   \n",
       "1003  located in the administrative territorial entity   \n",
       "1004                                           country   \n",
       "...                                                ...   \n",
       "1495                               structural engineer   \n",
       "1496                                          occupant   \n",
       "1497                                        founded by   \n",
       "1498                         located in protected area   \n",
       "1499                              heritage designation   \n",
       "\n",
       "                          object  \\\n",
       "1000               Niagara Falls   \n",
       "1001                      Russia   \n",
       "1002                  Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve   \n",
       "1004                     Finland   \n",
       "...                          ...   \n",
       "1495             Petronas Towers   \n",
       "1496              Windsor Castle   \n",
       "1497           Royal Observatory   \n",
       "1498  Gateway Arch National Park   \n",
       "1499  National Historic Landmark   \n",
       "\n",
       "                                               question  \\\n",
       "1000  Which tourist attraction's located in the admi...   \n",
       "1001         What is the country of Alexandrov Kremlin?   \n",
       "1002  Who is the located in the administrative terri...   \n",
       "1003  Which tourist attraction's located in the admi...   \n",
       "1004          What is the country of Kastelholm Castle?   \n",
       "...                                                 ...   \n",
       "1495  Which tourist attraction's structural engineer...   \n",
       "1496  Which tourist attraction's occupant is Charles...   \n",
       "1497  Which tourist attraction was founded by Charle...   \n",
       "1498  What is the located in protected area of Gatew...   \n",
       "1499  What is the heritage designation of Gateway Arch?   \n",
       "\n",
       "                           label output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "1000               Niagara Falls                              Niagara Falls   \n",
       "1001                      Russia                                     Russia   \n",
       "1002                  Alexandrov                                 Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve                              Haw Par Villa   \n",
       "1004                     Finland                                    Finland   \n",
       "...                          ...                                        ...   \n",
       "1495             Petronas Towers                            One World Trade   \n",
       "1496              Windsor Castle                          Westminster Abbey   \n",
       "1497           Royal Observatory                                 St. Paul's   \n",
       "1498  Gateway Arch National Park                    Jefferson National Park   \n",
       "1499  National Historic Landmark                                   National   \n",
       "\n",
       "      eval_meta-llama/Meta-Llama-3-8B-Instruct  \n",
       "1000                                       1.0  \n",
       "1001                                       1.0  \n",
       "1002                                       1.0  \n",
       "1003                                       0.0  \n",
       "1004                                       1.0  \n",
       "...                                        ...  \n",
       "1495                                       0.0  \n",
       "1496                                       0.0  \n",
       "1497                                       0.0  \n",
       "1498                                       0.0  \n",
       "1499                                       0.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_name = 'gpt-35-turbo'\n",
    "topic = 'health_medication'\n",
    "\n",
    "system_msg_eval = \"Given two texts, labeled as Text 1 and Text 2, output '1' if they match each other semantically, and output '0' if they do not.\"\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    output = df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    \n",
    "    # info = \"Question: \"+question+ \"\\nModel Answer: \"+label + \"\\nAI model generated answer: \" + output \\\n",
    "    #     + \"\\n. The above question's topic is \" + topic  + \". \"\n",
    "    prompt_eval = f\"\"\"The input texts are given as below: \\nText 1: {label} \\n\\nText 2: {output}\\n\"\"\"\n",
    "    \n",
    "    wh_count += 1\n",
    "    raw_response = client.chat.completions.create(\n",
    "        model=llm_name, \n",
    "        messages=[{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": prompt_eval}], \n",
    "        temperature=0\n",
    "    )\n",
    "    response_str = raw_response.choices[0].message.content.strip().replace('\\n\\n\\n', '\\n\\n')\n",
    "\n",
    "    if str(response_str) == '1':\n",
    "        wh_correct += 1\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 1\n",
    "    else:\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 0\n",
    "print(f\"[GPT] The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "df_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>wh</td>\n",
       "      <td>John Rylands Library</td>\n",
       "      <td>country</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>What is the country of John Rylands Library?</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>wh</td>\n",
       "      <td>Jōshin'etsu-kōgen National Park</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Shiga Highlands</td>\n",
       "      <td>Which tourist attraction's located in protecte...</td>\n",
       "      <td>Shiga Highlands</td>\n",
       "      <td>Shiga Kogen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>wh</td>\n",
       "      <td>Mount Kilimanjaro</td>\n",
       "      <td>country</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>What is the country of Mount Kilimanjaro?</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>wh</td>\n",
       "      <td>Night Safari</td>\n",
       "      <td>country</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>What is the country of Night Safari?</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>wh</td>\n",
       "      <td>St Paul's Cathedral</td>\n",
       "      <td>architect</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>Who does St Paul's Cathedral architect?</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>Christopher Wren</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>wh</td>\n",
       "      <td>St Paul's Cathedral</td>\n",
       "      <td>country</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>What is the country of St Paul's Cathedral?</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                          subject  \\\n",
       "1000   wh                          Ontario   \n",
       "1001   wh               Alexandrov Kremlin   \n",
       "1002   wh               Alexandrov Kremlin   \n",
       "1004   wh                Kastelholm Castle   \n",
       "1012   wh             John Rylands Library   \n",
       "...   ...                              ...   \n",
       "1474   wh  Jōshin'etsu-kōgen National Park   \n",
       "1475   wh                Mount Kilimanjaro   \n",
       "1484   wh                     Night Safari   \n",
       "1489   wh              St Paul's Cathedral   \n",
       "1491   wh              St Paul's Cathedral   \n",
       "\n",
       "                                              relation            object  \\\n",
       "1000  located in the administrative territorial entity     Niagara Falls   \n",
       "1001                                           country            Russia   \n",
       "1002  located in the administrative territorial entity        Alexandrov   \n",
       "1004                                           country           Finland   \n",
       "1012                                           country    United Kingdom   \n",
       "...                                                ...               ...   \n",
       "1474                         located in protected area   Shiga Highlands   \n",
       "1475                                           country          Tanzania   \n",
       "1484                                           country         Singapore   \n",
       "1489                                         architect  Christopher Wren   \n",
       "1491                                           country    United Kingdom   \n",
       "\n",
       "                                               question             label  \\\n",
       "1000  Which tourist attraction's located in the admi...     Niagara Falls   \n",
       "1001         What is the country of Alexandrov Kremlin?            Russia   \n",
       "1002  Who is the located in the administrative terri...        Alexandrov   \n",
       "1004          What is the country of Kastelholm Castle?           Finland   \n",
       "1012       What is the country of John Rylands Library?    United Kingdom   \n",
       "...                                                 ...               ...   \n",
       "1474  Which tourist attraction's located in protecte...   Shiga Highlands   \n",
       "1475          What is the country of Mount Kilimanjaro?          Tanzania   \n",
       "1484               What is the country of Night Safari?         Singapore   \n",
       "1489            Who does St Paul's Cathedral architect?  Christopher Wren   \n",
       "1491        What is the country of St Paul's Cathedral?    United Kingdom   \n",
       "\n",
       "     output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "1000                              Niagara Falls   \n",
       "1001                                     Russia   \n",
       "1002                                 Alexandrov   \n",
       "1004                                    Finland   \n",
       "1012                             United Kingdom   \n",
       "...                                         ...   \n",
       "1474                                Shiga Kogen   \n",
       "1475                                   Tanzania   \n",
       "1484                                  Singapore   \n",
       "1489                           Christopher Wren   \n",
       "1491                             United Kingdom   \n",
       "\n",
       "      eval_meta-llama/Meta-Llama-3-8B-Instruct  \n",
       "1000                                       1.0  \n",
       "1001                                       1.0  \n",
       "1002                                       1.0  \n",
       "1004                                       1.0  \n",
       "1012                                       1.0  \n",
       "...                                        ...  \n",
       "1474                                       1.0  \n",
       "1475                                       1.0  \n",
       "1484                                       1.0  \n",
       "1489                                       1.0  \n",
       "1491                                       1.0  \n",
       "\n",
       "[139 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wh[df_wh[f\"eval_{model_id}\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT] The wh question accuracy of the language model is 0.278\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>eval_meta-llama/Meta-Llama-3-8B-Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>wh</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>Niagara Falls</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>country</td>\n",
       "      <td>Russia</td>\n",
       "      <td>What is the country of Alexandrov Kremlin?</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>wh</td>\n",
       "      <td>Alexandrov Kremlin</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Who is the located in the administrative terri...</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>Alexandrov</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>wh</td>\n",
       "      <td>Bukit Panjang</td>\n",
       "      <td>located in the administrative territorial entity</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Which tourist attraction's located in the admi...</td>\n",
       "      <td>Bukit Timah Nature Reserve</td>\n",
       "      <td>Haw Par Villa</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>wh</td>\n",
       "      <td>Kastelholm Castle</td>\n",
       "      <td>country</td>\n",
       "      <td>Finland</td>\n",
       "      <td>What is the country of Kastelholm Castle?</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>wh</td>\n",
       "      <td>Thornton Tomasetti</td>\n",
       "      <td>structural engineer</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>Which tourist attraction's structural engineer...</td>\n",
       "      <td>Petronas Towers</td>\n",
       "      <td>One World Trade</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>occupant</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Which tourist attraction's occupant is Charles...</td>\n",
       "      <td>Windsor Castle</td>\n",
       "      <td>Westminster Abbey</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>wh</td>\n",
       "      <td>Charles II of England</td>\n",
       "      <td>founded by</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>Which tourist attraction was founded by Charle...</td>\n",
       "      <td>Royal Observatory</td>\n",
       "      <td>St. Paul's</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>located in protected area</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>What is the located in protected area of Gatew...</td>\n",
       "      <td>Gateway Arch National Park</td>\n",
       "      <td>Jefferson National Park</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>wh</td>\n",
       "      <td>Gateway Arch</td>\n",
       "      <td>heritage designation</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>What is the heritage designation of Gateway Arch?</td>\n",
       "      <td>National Historic Landmark</td>\n",
       "      <td>National</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                subject  \\\n",
       "1000   wh                Ontario   \n",
       "1001   wh     Alexandrov Kremlin   \n",
       "1002   wh     Alexandrov Kremlin   \n",
       "1003   wh          Bukit Panjang   \n",
       "1004   wh      Kastelholm Castle   \n",
       "...   ...                    ...   \n",
       "1495   wh     Thornton Tomasetti   \n",
       "1496   wh  Charles II of England   \n",
       "1497   wh  Charles II of England   \n",
       "1498   wh           Gateway Arch   \n",
       "1499   wh           Gateway Arch   \n",
       "\n",
       "                                              relation  \\\n",
       "1000  located in the administrative territorial entity   \n",
       "1001                                           country   \n",
       "1002  located in the administrative territorial entity   \n",
       "1003  located in the administrative territorial entity   \n",
       "1004                                           country   \n",
       "...                                                ...   \n",
       "1495                               structural engineer   \n",
       "1496                                          occupant   \n",
       "1497                                        founded by   \n",
       "1498                         located in protected area   \n",
       "1499                              heritage designation   \n",
       "\n",
       "                          object  \\\n",
       "1000               Niagara Falls   \n",
       "1001                      Russia   \n",
       "1002                  Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve   \n",
       "1004                     Finland   \n",
       "...                          ...   \n",
       "1495             Petronas Towers   \n",
       "1496              Windsor Castle   \n",
       "1497           Royal Observatory   \n",
       "1498  Gateway Arch National Park   \n",
       "1499  National Historic Landmark   \n",
       "\n",
       "                                               question  \\\n",
       "1000  Which tourist attraction's located in the admi...   \n",
       "1001         What is the country of Alexandrov Kremlin?   \n",
       "1002  Who is the located in the administrative terri...   \n",
       "1003  Which tourist attraction's located in the admi...   \n",
       "1004          What is the country of Kastelholm Castle?   \n",
       "...                                                 ...   \n",
       "1495  Which tourist attraction's structural engineer...   \n",
       "1496  Which tourist attraction's occupant is Charles...   \n",
       "1497  Which tourist attraction was founded by Charle...   \n",
       "1498  What is the located in protected area of Gatew...   \n",
       "1499  What is the heritage designation of Gateway Arch?   \n",
       "\n",
       "                           label output_meta-llama/Meta-Llama-3-8B-Instruct  \\\n",
       "1000               Niagara Falls                              Niagara Falls   \n",
       "1001                      Russia                                     Russia   \n",
       "1002                  Alexandrov                                 Alexandrov   \n",
       "1003  Bukit Timah Nature Reserve                              Haw Par Villa   \n",
       "1004                     Finland                                    Finland   \n",
       "...                          ...                                        ...   \n",
       "1495             Petronas Towers                            One World Trade   \n",
       "1496              Windsor Castle                          Westminster Abbey   \n",
       "1497           Royal Observatory                                 St. Paul's   \n",
       "1498  Gateway Arch National Park                    Jefferson National Park   \n",
       "1499  National Historic Landmark                                   National   \n",
       "\n",
       "      eval_meta-llama/Meta-Llama-3-8B-Instruct  \n",
       "1000                                       1.0  \n",
       "1001                                       1.0  \n",
       "1002                                       1.0  \n",
       "1003                                       0.0  \n",
       "1004                                       1.0  \n",
       "...                                        ...  \n",
       "1495                                       0.0  \n",
       "1496                                       0.0  \n",
       "1497                                       0.0  \n",
       "1498                                       0.0  \n",
       "1499                                       0.0  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_msg_eval = \"\"\"Given a question, a correct answer, and a prediction, evaluate whether the prediction is semantically equivalent to the correct answer. \\\n",
    "Output '1' if they are semantically equivalent, otherwise output '0'.\"\"\"\n",
    "\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    output = df_wh.loc[i, f\"output_{model_id}\"]\n",
    "    \n",
    "        # + \"\\n. The above question's topic is \" + topic  + \". \"\n",
    "    prompt_eval = f\"\"\"The inputs are given as below: \\nquestion: {question} \\n\\ncorrect answer: {label} \\n\\nprediction: {output}\\n\"\"\"\n",
    "    \n",
    "    wh_count += 1\n",
    "    raw_response = client.chat.completions.create(\n",
    "        model=llm_name, \n",
    "        messages=[{\"role\": \"system\", \"content\": system_msg_eval}, {\"role\": \"user\", \"content\": prompt_eval}], \n",
    "        temperature=0\n",
    "    )\n",
    "    response_str = raw_response.choices[0].message.content.strip().replace('\\n\\n\\n', '\\n\\n')\n",
    "\n",
    "    if str(response_str) == '1':\n",
    "        wh_correct += 1\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 1\n",
    "    else:\n",
    "        df_wh.loc[i, f\"eval_{model_id}\"] = 0\n",
    "print(f\"[GPT] The wh question accuracy of the language model is {wh_correct / wh_count}\")\n",
    "df_wh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate yes_no, portability, and locality questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 1500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wh_hallu = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/{model_id_format}/{topic_name}.csv\")\n",
    "df = pd.read_json(f\"../data/questions/all_3_types/{topic_name}_questions.json\", lines=True)\n",
    "len(df_wh_hallu), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only a small part of yes_no and MC questions have same subject, object, and relation as the hallucinated wh questions\n",
    "for i in df_wh_hallu.index[:]:\n",
    "    subject, relation, object = df_wh_hallu.loc[i, 'subject'], df_wh_hallu.loc[i, 'relation'], df_wh_hallu.loc[i, 'object']\n",
    "    df_other_type = df[(df.subject==subject) & (df.relation==relation) & (df.object==object) & (df.type!='wh')]\n",
    "    # print(len(df_other_type))\n",
    "    # Add yes_no and MC questions to the df_wh_hallu as new columns named 'question_yes_no' and 'question_MC'\n",
    "    for j in df_other_type.index:\n",
    "        other_type = df_other_type.loc[j, 'type']\n",
    "        df_wh_hallu.loc[i, f'question_{other_type}'] = df_other_type.loc[j, 'question']\n",
    "print(df_wh_hallu[df_wh_hallu.question_yes_no.notna() & df_wh_hallu.question_MC.notna()].shape)\n",
    "# df_wh_hallu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_mistral_7b_instruct_v0.3</th>\n",
       "      <th>eval_mistral_7b_instruct_v0.3</th>\n",
       "      <th>question_yes_no</th>\n",
       "      <th>question_MC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wh</td>\n",
       "      <td>Panathenaic Stadium</td>\n",
       "      <td>architectural style</td>\n",
       "      <td>ancient Greek architecture</td>\n",
       "      <td>What is the architectural style of Panathenaic...</td>\n",
       "      <td>ancient Greek architecture</td>\n",
       "      <td>Neoclassical</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Is ancient Greek architecture the architectura...</td>\n",
       "      <td>What is the architectural style of Panathenaic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wh</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>sponsor</td>\n",
       "      <td>MUNCH</td>\n",
       "      <td>Which tourist attraction sponsor Deloitte?</td>\n",
       "      <td>MUNCH</td>\n",
       "      <td>Deloitte does not sponsor a specific tourist a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wh</td>\n",
       "      <td>Rosersberg Palace</td>\n",
       "      <td>architectural style</td>\n",
       "      <td>Neoclassical architecture</td>\n",
       "      <td>What is the architectural style of Rosersberg ...</td>\n",
       "      <td>Neoclassical architecture</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Is Neoclassical architecture the architectural...</td>\n",
       "      <td>What is the architectural style of Rosersberg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wh</td>\n",
       "      <td>Prayerbook Cross</td>\n",
       "      <td>has part(s)</td>\n",
       "      <td>Golden Gate Park</td>\n",
       "      <td>Which tourist attraction has part(s) Prayerboo...</td>\n",
       "      <td>Golden Gate Park</td>\n",
       "      <td>St. Peter's Basilica (Vatican City)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Which tourist attraction has part(s) Prayerboo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wh</td>\n",
       "      <td>Carlos Oswald</td>\n",
       "      <td>creator</td>\n",
       "      <td>Christ the Redeemer</td>\n",
       "      <td>Which tourist attraction's creator is Carlos O...</td>\n",
       "      <td>Christ the Redeemer</td>\n",
       "      <td>The Teatro Colón in Buenos Aires, Argentina.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Which tourist attraction's creator is Carlos O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type              subject             relation                      object  \\\n",
       "0   wh  Panathenaic Stadium  architectural style  ancient Greek architecture   \n",
       "1   wh             Deloitte              sponsor                       MUNCH   \n",
       "2   wh    Rosersberg Palace  architectural style   Neoclassical architecture   \n",
       "3   wh     Prayerbook Cross          has part(s)            Golden Gate Park   \n",
       "4   wh        Carlos Oswald              creator         Christ the Redeemer   \n",
       "\n",
       "                                            question  \\\n",
       "0  What is the architectural style of Panathenaic...   \n",
       "1         Which tourist attraction sponsor Deloitte?   \n",
       "2  What is the architectural style of Rosersberg ...   \n",
       "3  Which tourist attraction has part(s) Prayerboo...   \n",
       "4  Which tourist attraction's creator is Carlos O...   \n",
       "\n",
       "                        label  \\\n",
       "0  ancient Greek architecture   \n",
       "1                       MUNCH   \n",
       "2   Neoclassical architecture   \n",
       "3            Golden Gate Park   \n",
       "4         Christ the Redeemer   \n",
       "\n",
       "                     output_mistral_7b_instruct_v0.3  \\\n",
       "0                                       Neoclassical   \n",
       "1  Deloitte does not sponsor a specific tourist a...   \n",
       "2                                            Baroque   \n",
       "3                St. Peter's Basilica (Vatican City)   \n",
       "4       The Teatro Colón in Buenos Aires, Argentina.   \n",
       "\n",
       "   eval_mistral_7b_instruct_v0.3  \\\n",
       "0                            0.0   \n",
       "1                            0.0   \n",
       "2                            0.0   \n",
       "3                            0.0   \n",
       "4                            0.0   \n",
       "\n",
       "                                     question_yes_no  \\\n",
       "0  Is ancient Greek architecture the architectura...   \n",
       "1                                                NaN   \n",
       "2  Is Neoclassical architecture the architectural...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         question_MC  \n",
       "0  What is the architectural style of Panathenaic...  \n",
       "1                                                NaN  \n",
       "2  What is the architectural style of Rosersberg ...  \n",
       "3  Which tourist attraction has part(s) Prayerboo...  \n",
       "4  Which tourist attraction's creator is Carlos O...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wh_hallu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPT-4o to generate other types of questions\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def load_api_key(key, file_path='api_key.json'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data[key]\n",
    "\n",
    "# client = AzureOpenAI(api_key=load_api_key('api_key_n_central_us'), api_version='2023-05-15', azure_endpoint=\"https://n-central-us.openai.azure.com/\")\n",
    "client = AzureOpenAI(api_key=load_api_key('api_key_east_us'), api_version='2023-05-15', azure_endpoint=\"https://east-us-one.openai.azure.com/\")\n",
    "\n",
    "system_msg_gen_q = \"Given a question, generate a question of a different type that has the same subject, object, and relation. The new question should be of the same topic as the original question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Function to compute token count for a text\n",
    "def compute_token_count(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "# Apply the function to each column and create new columns with the token count\n",
    "for column in df_wh_hallu.columns:\n",
    "    df[f'{column}_token_count'] = df[column].apply(compute_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m         portability_questions\u001b[38;5;241m.\u001b[39mextend(json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportability_questions\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(paraphrased_questions), \u001b[38;5;28mlen\u001b[39m(yes_no_questions), \u001b[38;5;28mlen\u001b[39m(locality_questions), \u001b[38;5;28mlen\u001b[39m(portability_questions))\n\u001b[0;32m---> 86\u001b[0m \u001b[43mgenerate_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_wh_hallu\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 79\u001b[0m, in \u001b[0;36mgenerate_questions\u001b[0;34m(df_wh_hallu)\u001b[0m\n\u001b[1;32m     73\u001b[0m prompt_gen_q \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, relation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, object: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mobject\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m raw_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     75\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     76\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_msg_gen_q}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_gen_q}], \n\u001b[1;32m     77\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 79\u001b[0m json_obj \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(json_obj)\n\u001b[1;32m     81\u001b[0m paraphrased_questions\u001b[38;5;241m.\u001b[39mextend(json_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparaphrased_questions\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "system_msg_gen_q = \"\"\" Given a knowledge triplet (subject, relation, object), and a question asking about the object, the answer should be the object\n",
    "First generate a paraphrased question.\n",
    "\n",
    "Next generate a locality question. Each locality question should meet the following criteria:\n",
    "1. Use the exact same subjects from the list of subjects.\n",
    "2. Ask about a well-known, simple attribute of the same subject. The new attribute of the same subject should be completely unrelated to the original question.\n",
    "3. Frame each locality question so that it can be answered with yes or no.\n",
    "\n",
    "Finally, generate alternative portability (Portability means subject aliasing) questions based on the questions. Each portability question should replace the question's subject with an alias or synonym.\n",
    "\n",
    "Output in JSON format with following keys: paraphrased_questions, yes_no_questions, locality_questions, and portability_questions.\n",
    "\"\"\"\n",
    "# Make sure that all the subjects across the questions, paraphrased_questions, yes_no_questions and locality_questions are the same.\n",
    "\n",
    "example = \"\"\"Example input:\n",
    "Drinking boiled garlic water cures COVID-19 by killing the virus instantly in your system.\n",
    "Eating apple seeds can cure all types of cancer because they contain a magic compound called amygdalin that specifically targets cancer cells without affecting healthy cells.\n",
    "Vaccines contain microchips that the government uses to track your movements and control your thoughts.\n",
    "\n",
    "Example output:\n",
    "{\n",
    "    \"simplified_texts\": [\n",
    "        'Boiled garlic water cures COVID-19.',\n",
    "        'Apple seeds cure cancer.',\n",
    "        'Vaccines contain microchips.',\n",
    "    ],\n",
    "    \"answers\": [\n",
    "        'COVID-19',\n",
    "        'cancer',\n",
    "        'microchips',\n",
    "    ],\n",
    "    \"questions\": [\n",
    "        'What does boiled garlic water cure?',\n",
    "        'What do apple seeds cure?',\n",
    "        'What do vaccines contain?',\n",
    "    ],\n",
    "    \"subjects\": [\n",
    "        'boiled garlic water',\n",
    "        'apple seeds',\n",
    "        'vaccines'\n",
    "    ],\n",
    "    \"paraphrased_questions\": [\n",
    "        'What does boiled garlic water heal?',\n",
    "        'What can be cured by eating apple seeds?',\n",
    "        'What is contained in vaccines?',\n",
    "    ],\n",
    "    \"yes_no_questions\": [\n",
    "        'Does boiled garlic water cure COVID-19?',\n",
    "        'Can apple seeds cure cancer?',\n",
    "        'Do vaccines contain microchips?',\n",
    "    ],\n",
    "    \"locality_questions\": [\n",
    "        'Is boiled garlic water safe to drink?',\n",
    "        'Are apple seeds toxic if consumed?',\n",
    "        'Are vaccines recommended by health professionals?',\n",
    "    ],\n",
    "    \"portability_questions\": [\n",
    "        'What does garlic-infused water cure?',\n",
    "        'What do apple pips cure?',\n",
    "        'What does inoculation contain?',\n",
    "    ]\n",
    "}\n",
    "Note that all the subjects across the questions, paraphrased_questions, yes_no_questions must be exactly the same as they are in the subjects list (including letter cases).\n",
    "\"\"\"\n",
    "\n",
    "paraphrased_questions, yes_no_questions, locality_questions, portability_questions = ([] for _ in range(4))\n",
    "\n",
    "\n",
    "def generate_questions(df_wh_hallu):\n",
    "    for i in df_wh_hallu.index[:2]:\n",
    "        # print(i, input_texts)\n",
    "        subject, relation, object, question = df_wh_hallu.loc[i, 'subject'], df_wh_hallu.loc[i, 'relation'], df_wh_hallu.loc[i, 'object'], df_wh_hallu.loc[i, 'question']\n",
    "        prompt_gen_q = f\"subject: {subject}, relation: {relation}, object: {object}, question: {question}\"\n",
    "        raw_response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini', \n",
    "            messages=[{\"role\": \"system\", \"content\": system_msg_gen_q}, {\"role\": \"user\", \"content\": prompt_gen_q}], \n",
    "            temperature=0\n",
    "        )\n",
    "        json_obj = json.loads(raw_response.choices[0].message.content)\n",
    "        print(json_obj)\n",
    "        paraphrased_questions.extend(json_obj['paraphrased_questions'])\n",
    "        yes_no_questions.extend(json_obj['yes_no_questions'])\n",
    "        locality_questions.extend(json_obj['locality_questions'])\n",
    "        portability_questions.extend(json_obj['portability_questions'])\n",
    "        print(len(paraphrased_questions), len(yes_no_questions), len(locality_questions), len(portability_questions))\n",
    "generate_questions(df_wh_hallu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from hallucination_editor import BaseEditor\n",
    "from easyeditor import FTHyperParams, IKEHyperParams, ROMEHyperParams, MEMITHyperParams\n",
    "\n",
    "df = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/{model_id_format}/{topic_name}.csv\")\n",
    "# df = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/meta_llama_3.1_8b_instruct/{topic_name}.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50#len(df)\n",
    "targets = df['label'].tolist()[:n]\n",
    "subjects = df['subject'].tolist()[:n]\n",
    "questions = df['question'].tolist()[:n]\n",
    "# paraphrased_questions = df['paraphrased_questions'].tolist()[:n]\n",
    "# portability_questions = df['portability_questions'].tolist()[:n]\n",
    "# portability_inputs = {'subject_aliasing': {'prompt': portability_questions, 'ground_truth': answers},}\n",
    "\n",
    "hparams = ROMEHyperParams.from_hparams('./hparams/ROME/llama3-8b')\n",
    "# hparams = ROMEHyperParams.from_hparams('./hparams/ROME/gemma-7b')\n",
    "# hparams = MEMITHyperParams.from_hparams('./hparams/MEMIT/llama3-8b')\n",
    "\n",
    "hparams.device = 0\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_ROME_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env24may",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
