{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma2-9b MEMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5505515f27340b9985b39ae322d4d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c122a41282ef48d88ce829eae3c8c6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", torch_dtype='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21328785bde740c6817df77a58e76cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a3155640dc45c78684cb8c949b74ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 3072, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=24576, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=24576, bias=False)\n",
       "          (down_proj): Linear(in_features=24576, out_features=3072, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((3072,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((3072,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((3072,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForCausalLM.from_pretrained(\"google/gemma-1.1-7b-it\", torch_dtype='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580ebc88a0774ac8b68a1e43008a1f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a27d1e8223a43ec9356bdf61dec98db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): GemmaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForCausalLM.from_pretrained(\"google/gemma-1.1-2b-it\", torch_dtype='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f21ef3f96d94ffebec51ea9d2e75793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ff467e461a470c9013094a8b576341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
       "          (rotary_emb): Gemma2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
       "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b-it\", torch_dtype='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5989a9d804e6499782c387eb77155548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf6352e60d14b9894424cb9ea1f1610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-41): 42 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
       "          (rotary_emb): Gemma2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"google/gemma-2-9b-it\"\n",
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype='auto')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0510,  0.0106, -0.0422,  ..., -0.0294, -0.0352,  0.0127],\n",
       "        [-0.0007,  0.0127,  0.0083,  ...,  0.0049, -0.0027, -0.0275],\n",
       "        [-0.0112,  0.0026,  0.0081,  ..., -0.0006,  0.0043,  0.0033],\n",
       "        ...,\n",
       "        [-0.0264,  0.0157,  0.0041,  ..., -0.0588, -0.0361, -0.0080],\n",
       "        [-0.0522,  0.0139, -0.0004,  ..., -0.0061, -0.0491, -0.0109],\n",
       "        [-0.0413,  0.0264, -0.0249,  ...,  0.0015, -0.0315, -0.0033]],\n",
       "       dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x7a14de781200>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "lm_head",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m p\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(name)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mget_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlm_head\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m, in \u001b[0;36mget_parameter\u001b[0;34m(model, name)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m p\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(name)\n",
      "\u001b[0;31mLookupError\u001b[0m: lm_head"
     ]
    }
   ],
   "source": [
    "def get_parameter(model, name):\n",
    "    \"\"\"\n",
    "    Finds the named parameter within the given model.\n",
    "    \"\"\"\n",
    "    for n, p in model.named_parameters():\n",
    "        if n == name:\n",
    "            return p\n",
    "    raise LookupError(name)\n",
    "\n",
    "get_parameter(model, 'lm_head.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "lm_head.weight",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01measyeditor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nethook\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnethook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlm_head.weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/baixiang/workspace/edit/hallucination/code/easyeditor/util/nethook.py:372\u001b[0m, in \u001b[0;36mget_parameter\u001b[0;34m(model, name)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m p\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(name)\n",
      "\u001b[0;31mLookupError\u001b[0m: lm_head.weight"
     ]
    }
   ],
   "source": [
    "from easyeditor.util import nethook\n",
    "nethook.get_parameter(model, f\"lm_head.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the currency of Croatia? You are a helpful assistant.',\n",
       " 'Who is the head of state of Finland? You are a helpful assistant.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"../data/questions/hallucination_final/meta_llama_3_8b_instruct/places_country.csv\")\n",
    "df['system_msg'] = 'You are a helpful assistant.'\n",
    "questions = [question + ' You are a helpful assistant.' for question in df['question'].tolist()]\n",
    "questions[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate triplets and questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-17 10:35:33,137 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from process_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_size(topic_name):\n",
    "    topic = json.loads(f'{{\"instance of\": \"{topic_name}\"}}')\n",
    "    query_part1 = \"SELECT ?subjectLabel ?relation ?objectLabel WHERE {\"\n",
    "    query_part2 = \"\"\n",
    "    relation_object_pairs = convert_topic_to_symbol(topic)\n",
    "    for pair in relation_object_pairs:\n",
    "        query_part2 += f\"\\n?subject wdt:{pair[0]} wd:{pair[1]} .\"\n",
    "    query_part3 = \"\"\"\n",
    "        ?subject  ?relation  ?object.\n",
    "        ?subject wikibase:identifiers ?subject_identifierCount.\n",
    "        ?object wikibase:identifiers ?object_identifierCount.\n",
    "        \"\"\"\n",
    "    query_part5 = \"\"\" \n",
    "        FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "    }\n",
    "    LIMIT 8000\n",
    "    \"\"\"\n",
    "    query = query_part1 + query_part2 + query_part3 + query_part5\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    count = len(results['results']['bindings'])\n",
    "    print(f\"Topic {topic} size: {count}\")\n",
    "    return count\n",
    "\n",
    "for t in []:\n",
    "    get_topic_size(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len = len(results['results']['bindings'])\n",
    "# len = 0: [\"invention\", \"animal species\", \"mineral\", \"Olympic Games\", \"train\", \"mathematics\", \"neuroscience\", \"robotics\", \n",
    "#           \"internet\", \"mobile phone\", \"3D printing\", \"bird\", \"academy awards\", \"movies\", \"movie\", \"grammy award\", 'netflix series', \n",
    "#           'beverage', \"climate\", \"astronomy\",]\n",
    "# len < 100: [\"climate\", \"physics\", \"biology\", \"insect\", \"fish\", \"computer hardware\", \"plant\", \"sports team\", \"ecosystem\", \"reef\", \"wetland\", \"grassland\",\n",
    "#             'vehicle', 'airplane', 'bicycle', \"animal\", \"chemical compound\", \"astronomical object\", 'fruit', 'vegetable', 'cuisine', \"planet\", \"physics\", \n",
    "#             \"chemistry\", \"mathematics\", \"biology\", \"geology\", \"ecology\", \"genetics\", \"space mission\", \"spacecraft\", \"particle\", \"species\", \"ecosystem\", \n",
    "#             \"hypothesis\",]\n",
    "# Error code 500: [\"video game\", \"river\", \"protein\", 'ship', \"film\", \"human\", \"film\", \"human\", \"mountain\",\"scientific journal\", \"gene\", \"album\",\n",
    "#                  \"star\", 'art_literary',  \"painting\", 'art_painting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(topic_name):\n",
    "    with open(f'../data/topic/{topic_name}.json', 'r', encoding='utf-8') as topics_file:\n",
    "        topics = topics_file.readlines()\n",
    "    data = []\n",
    "    # topic_name = 'country'\n",
    "    # for topic in [f'{{\"instance of\": \"{topic_name}\"}}\\n']:\n",
    "    for topic in topics:\n",
    "        if topic:\n",
    "            topic = json.loads(topic)\n",
    "            print(topic)\n",
    "            query_part1 = \"SELECT ?subjectLabel ?relation ?objectLabel WHERE {\"\n",
    "            query_part2 = \"\"\n",
    "            relation_object_pairs = convert_topic_to_symbol(topic)\n",
    "            for pair in relation_object_pairs:\n",
    "                query_part2 += f\"\\n?subject wdt:{pair[0]} wd:{pair[1]} .\"\n",
    "\n",
    "            query_part3 = \"\"\"\n",
    "                ?subject  ?relation  ?object.\n",
    "                ?subject wikibase:identifiers ?subject_identifierCount.\n",
    "                ?object wikibase:identifiers ?object_identifierCount.\n",
    "                \"\"\"\n",
    "            query_part5 = \"\"\" \n",
    "                FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \n",
    "                SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "            }\n",
    "            LIMIT 5000\n",
    "            \"\"\"\n",
    "            query = query_part1 + query_part2 + query_part3 + query_part5\n",
    "            sparql.setQuery(query)\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            results = sparql.query().convert()\n",
    "            time.sleep(1)\n",
    "            # print(f\"results: {results}\")\n",
    "            if \"results\" in results:\n",
    "                # Create a list to store the data\n",
    "                with ThreadPoolExecutor() as executor:\n",
    "                    futures = [executor.submit(process_result, result) for result in results[\"results\"][\"bindings\"]]\n",
    "                    # Use tqdm to show the progress bar while waiting for all tasks to complete\n",
    "                    for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "                        result_data = future.result()\n",
    "                        if result_data:\n",
    "                            data.append(result_data)\n",
    "\n",
    "    fact_triplets = pd.DataFrame(data)  # data/triplet/raw/ store raw triplets before removing duplicate (subject, relation) pairs\n",
    "    fact_triplets.to_csv(f'../data/triplet/raw/{topic_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_triplets('places_city') # 4:37:42  # get_triplets('places_landmark') # 4:37:42  # get_triplets('entertainment_music_genre') # 28:21\n",
    "\n",
    "for topic in ['business_corporation', 'business_brand', 'business_industry']:\n",
    "    get_triplets(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid question with multiple answers, check and remove (node, relation) with duplicates as shown below:\\\n",
    "{\"subject\": \"Thailand\", \"relation\": \"diplomatic relation\", \"object\": \"Russia\"}\\\n",
    "{\"subject\": \"Thailand\", \"relation\": \"diplomatic relation\", \"object\": \"Brunei\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art_sculpture.csv              fact_triplets.shape: (1088, 3), fact_triplets_new.shape: (554, 3) Number of rows with subject==object: 4\n",
      "business_brand.csv             fact_triplets.shape: (3577, 3), fact_triplets_new.shape: (1430, 3) Number of rows with subject==object: 13\n",
      "business_corporation.csv       fact_triplets.shape: (851, 3), fact_triplets_new.shape: (340, 3) Number of rows with subject==object: 1\n",
      "business_industry.csv          fact_triplets.shape: (1508, 3), fact_triplets_new.shape: (605, 3) Number of rows with subject==object: 8\n",
      "entertainment_anime.csv        fact_triplets.shape: (627, 3), fact_triplets_new.shape: (360, 3) Number of rows with subject==object: 1\n",
      "entertainment_music_genre.csv  fact_triplets.shape: (3007, 3), fact_triplets_new.shape: (1652, 3) Number of rows with subject==object: 19\n",
      "entertainment_song.csv         fact_triplets.shape: (5227, 3), fact_triplets_new.shape: (2654, 3) Number of rows with subject==object: 25\n",
      "event_film.csv                 fact_triplets.shape: (470, 3), fact_triplets_new.shape: (338, 3) Number of rows with subject==object: 0\n",
      "event_history.csv              fact_triplets.shape: (1607, 3), fact_triplets_new.shape: (440, 3) Number of rows with subject==object: 0\n",
      "event_sport.csv                fact_triplets.shape: (547, 3), fact_triplets_new.shape: (202, 3) Number of rows with subject==object: 0\n",
      "geography_forest.csv           fact_triplets.shape: (756, 3), fact_triplets_new.shape: (524, 3) Number of rows with subject==object: 1\n",
      "geography_glacier.csv          fact_triplets.shape: (442, 3), fact_triplets_new.shape: (335, 3) Number of rows with subject==object: 0\n",
      "geography_volcano.csv          fact_triplets.shape: (1314, 3), fact_triplets_new.shape: (772, 3) Number of rows with subject==object: 6\n",
      "health_disease.csv             fact_triplets.shape: (4819, 3), fact_triplets_new.shape: (833, 3) Number of rows with subject==object: 3\n",
      "health_medication.csv          fact_triplets.shape: (1508, 3), fact_triplets_new.shape: (240, 3) Number of rows with subject==object: 4\n",
      "health_symptom.csv             fact_triplets.shape: (710, 3), fact_triplets_new.shape: (141, 3) Number of rows with subject==object: 0\n",
      "human_athlete.csv              fact_triplets.shape: (4999, 3), fact_triplets_new.shape: (2402, 3) Number of rows with subject==object: 10\n",
      "human_entrepreneur.csv         fact_triplets.shape: (4999, 3), fact_triplets_new.shape: (2598, 3) Number of rows with subject==object: 6\n",
      "human_scientist.csv            fact_triplets.shape: (4999, 3), fact_triplets_new.shape: (1794, 3) Number of rows with subject==object: 6\n",
      "places_city.csv                fact_triplets.shape: (44957, 3), fact_triplets_new.shape: (18995, 3) Number of rows with subject==object: 482\n",
      "places_country.csv             fact_triplets.shape: (32742, 3), fact_triplets_new.shape: (2937, 3) Number of rows with subject==object: 176\n",
      "places_landmark.csv            fact_triplets.shape: (7531, 3), fact_triplets_new.shape: (3202, 3) Number of rows with subject==object: 18\n",
      "technology_database.csv        fact_triplets.shape: (515, 3), fact_triplets_new.shape: (219, 3) Number of rows with subject==object: 0\n",
      "technology_programming_language.csv fact_triplets.shape: (1570, 3), fact_triplets_new.shape: (435, 3) Number of rows with subject==object: 12\n",
      "technology_software.csv        fact_triplets.shape: (3095, 3), fact_triplets_new.shape: (828, 3) Number of rows with subject==object: 6\n"
     ]
    }
   ],
   "source": [
    "directory = '../data/triplet/raw'\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    if filename.endswith('.csv'):\n",
    "        fact_triplets = pd.read_csv(f'{directory}/{filename}')\n",
    "        # print(fact_triplets.shape)\n",
    "        fact_triplets.dropna(inplace=True)\n",
    "        condition1 = fact_triplets.apply(lambda row: any(val.startswith('Q') and val[1:].isdigit() for val in row.values), axis=1)\n",
    "        condition2 = fact_triplets.apply(lambda row: any(val.startswith('http') for val in row.values), axis=1)\n",
    "        fact_triplets = fact_triplets[~(condition1 | condition2)]  \n",
    "\n",
    "        # remove_pairs, all_pairs = set(), []\n",
    "        # for i in fact_triplets.index:\n",
    "        #     subject, relation = fact_triplets.loc[i, 'subjectLabel'], fact_triplets.loc[i, 'relation']\n",
    "        #     if (subject, relation) in all_pairs:\n",
    "        #         remove_pairs.add((subject, relation))\n",
    "        #     else:\n",
    "        #         all_pairs.append((subject, relation))\n",
    "        # fact_triplets_new = fact_triplets[~fact_triplets.apply(lambda row: (row['subjectLabel'], row['relation']) in remove_pairs, axis=1)]\n",
    "        fact_triplets_new = fact_triplets.drop_duplicates(subset=['subjectLabel', 'relation'], keep=False)\n",
    "        print(f\"{filename:<30} fact_triplets.shape: {fact_triplets.shape}, fact_triplets_new.shape: {fact_triplets_new.shape}\", end=' ')\n",
    "        print(f\"Number of rows with subject==object: {fact_triplets_new[fact_triplets_new.subjectLabel == fact_triplets_new.objectLabel].shape[0]}\")\n",
    "        fact_triplets_new = fact_triplets_new[fact_triplets_new.subjectLabel != fact_triplets_new.objectLabel]\n",
    "        fact_triplets_new.to_csv(f'../data/triplet/{filename}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Questions from knowledge graph triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id: gemma_2_9b_it\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from util import model_id_ls, model_id_format_ls\n",
    "model_id_format = model_id_format_ls[-1]\n",
    "print(f'model_id: {model_id_format}')\n",
    "\n",
    "folder_unfiltered = f\"../data/questions/unfiltered/{model_id_format}\"\n",
    "folder_hallu = f\"../data/questions/hallucination_all/{model_id_format}\"\n",
    "folder_hallu_100 = f\"../data/questions/hallucination/{model_id_format}_100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_unfiltered: ../data/questions/unfiltered/meta_llama_3.1_8b_instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202/202 [00:02<00:00, 83.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: recurring sporting event, fact_triplets_new.shape: (202, 3), df_question.shape: (115, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 523/523 [00:06<00:00, 81.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: forest, fact_triplets_new.shape: (523, 3), df_question.shape: (261, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [00:03<00:00, 91.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: corporation, fact_triplets_new.shape: (339, 3), df_question.shape: (191, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18513/18513 [03:10<00:00, 97.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: city, fact_triplets_new.shape: (18513, 3), df_question.shape: (6805, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1633/1633 [00:17<00:00, 91.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: music genre, fact_triplets_new.shape: (1633, 3), df_question.shape: (300, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2629/2629 [00:28<00:00, 93.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: song, fact_triplets_new.shape: (2629, 3), df_question.shape: (1935, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 423/423 [00:04<00:00, 89.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: programming language, fact_triplets_new.shape: (423, 3), df_question.shape: (311, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2392/2392 [00:24<00:00, 98.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: human, fact_triplets_new.shape: (2392, 3), df_question.shape: (1313, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [00:03<00:00, 93.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: anime, fact_triplets_new.shape: (359, 3), df_question.shape: (299, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3184/3184 [00:34<00:00, 91.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: tourist attraction, fact_triplets_new.shape: (3184, 3), df_question.shape: (1832, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597/597 [00:07<00:00, 84.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: industry, fact_triplets_new.shape: (597, 3), df_question.shape: (170, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1788/1788 [00:19<00:00, 92.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: human, fact_triplets_new.shape: (1788, 3), df_question.shape: (1052, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [00:03<00:00, 100.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: film festival, fact_triplets_new.shape: (338, 3), df_question.shape: (166, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:04<00:00, 92.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: revolution, fact_triplets_new.shape: (440, 3), df_question.shape: (156, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [00:06<00:00, 90.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: sculpture, fact_triplets_new.shape: (550, 3), df_question.shape: (377, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 830/830 [00:09<00:00, 85.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: disease, fact_triplets_new.shape: (830, 3), df_question.shape: (505, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [00:08<00:00, 93.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: volcano, fact_triplets_new.shape: (766, 3), df_question.shape: (429, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:01<00:00, 89.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: symptom, fact_triplets_new.shape: (141, 3), df_question.shape: (60, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:02<00:00, 88.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: database, fact_triplets_new.shape: (219, 3), df_question.shape: (138, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1417/1417 [00:14<00:00, 95.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: brand, fact_triplets_new.shape: (1417, 3), df_question.shape: (787, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4339/4339 [00:48<00:00, 89.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: human, fact_triplets_new.shape: (4339, 3), df_question.shape: (2687, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 822/822 [00:09<00:00, 90.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: software, fact_triplets_new.shape: (822, 3), df_question.shape: (633, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [00:02<00:00, 84.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: medication, fact_triplets_new.shape: (236, 3), df_question.shape: (53, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2761/2761 [00:31<00:00, 88.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: country, fact_triplets_new.shape: (2761, 3), df_question.shape: (1936, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2592/2592 [00:27<00:00, 94.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: human, fact_triplets_new.shape: (2592, 3), df_question.shape: (1546, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 335/335 [00:03<00:00, 96.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: glacier, fact_triplets_new.shape: (335, 3), df_question.shape: (107, 5) Number of rows with label != object: 0\n",
      "folder_unfiltered: ../data/questions/unfiltered/mistral_7b_instruct_v0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202/202 [00:02<00:00, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: recurring sporting event, fact_triplets_new.shape: (202, 3), df_question.shape: (115, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 523/523 [00:06<00:00, 81.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: forest, fact_triplets_new.shape: (523, 3), df_question.shape: (261, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [00:03<00:00, 91.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: corporation, fact_triplets_new.shape: (339, 3), df_question.shape: (191, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18513/18513 [03:11<00:00, 96.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: city, fact_triplets_new.shape: (18513, 3), df_question.shape: (6805, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1633/1633 [00:18<00:00, 90.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: music genre, fact_triplets_new.shape: (1633, 3), df_question.shape: (300, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2629/2629 [00:28<00:00, 93.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: song, fact_triplets_new.shape: (2629, 3), df_question.shape: (1935, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 423/423 [00:04<00:00, 88.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: programming language, fact_triplets_new.shape: (423, 3), df_question.shape: (311, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2392/2392 [00:24<00:00, 98.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: human, fact_triplets_new.shape: (2392, 3), df_question.shape: (1313, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [00:03<00:00, 93.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: anime, fact_triplets_new.shape: (359, 3), df_question.shape: (299, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3184/3184 [00:35<00:00, 90.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: tourist attraction, fact_triplets_new.shape: (3184, 3), df_question.shape: (1832, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 597/597 [00:06<00:00, 87.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: industry, fact_triplets_new.shape: (597, 3), df_question.shape: (170, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1788/1788 [00:19<00:00, 91.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: human, fact_triplets_new.shape: (1788, 3), df_question.shape: (1052, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 338/338 [00:03<00:00, 100.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: film festival, fact_triplets_new.shape: (338, 3), df_question.shape: (166, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:04<00:00, 91.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: revolution, fact_triplets_new.shape: (440, 3), df_question.shape: (156, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 550/550 [00:06<00:00, 90.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: sculpture, fact_triplets_new.shape: (550, 3), df_question.shape: (377, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 830/830 [00:09<00:00, 85.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: disease, fact_triplets_new.shape: (830, 3), df_question.shape: (505, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [00:08<00:00, 93.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: volcano, fact_triplets_new.shape: (766, 3), df_question.shape: (429, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:01<00:00, 89.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: symptom, fact_triplets_new.shape: (141, 3), df_question.shape: (60, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:02<00:00, 88.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: database, fact_triplets_new.shape: (219, 3), df_question.shape: (138, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1417/1417 [00:14<00:00, 95.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: brand, fact_triplets_new.shape: (1417, 3), df_question.shape: (787, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4339/4339 [00:48<00:00, 89.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: human, fact_triplets_new.shape: (4339, 3), df_question.shape: (2687, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 822/822 [00:09<00:00, 90.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: software, fact_triplets_new.shape: (822, 3), df_question.shape: (633, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [00:02<00:00, 85.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: medication, fact_triplets_new.shape: (236, 3), df_question.shape: (53, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2761/2761 [00:31<00:00, 88.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: country, fact_triplets_new.shape: (2761, 3), df_question.shape: (1936, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2592/2592 [00:27<00:00, 95.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: human, fact_triplets_new.shape: (2592, 3), df_question.shape: (1546, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 335/335 [00:03<00:00, 96.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: glacier, fact_triplets_new.shape: (335, 3), df_question.shape: (107, 5) Number of rows with label != object: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_unfiltered = f\"../data/questions/unfiltered/{model_id_format}\"\n",
    "print(f'folder_unfiltered: {folder_unfiltered}')\n",
    "for filename in os.listdir('../data/triplet'):\n",
    "    if filename.endswith('.csv'):\n",
    "        fact_triplets_new = pd.read_csv(f'../data/triplet/{filename}')\n",
    "        # if os.path.exists(f\"{folder_unfiltered}/{filename}\"):\n",
    "        #     continue\n",
    "        if not os.path.exists(folder_unfiltered):\n",
    "            os.makedirs(folder_unfiltered)\n",
    "        \n",
    "        with open(os.path.join(\"../data/topic\", filename.replace('.csv', '.json')), 'r', encoding='utf-8') as topics_file:\n",
    "            topics = topics_file.readlines()\n",
    "        topic = json.loads(topics[0])\n",
    "        first_pair = next(iter(topic.items()))\n",
    "        # print(f'filename: {filename}, topic: {first_pair[1]}')\n",
    "\n",
    "        question_ls = []\n",
    "        for i in tqdm(fact_triplets_new.index):\n",
    "            subject, relation, object = fact_triplets_new.loc[i, 'subjectLabel'], fact_triplets_new.loc[i, 'relation'], fact_triplets_new.loc[i, 'objectLabel']\n",
    "            question = generate_question(subject, relation, object, first_pair[1])\n",
    "            if question:\n",
    "                question_ls.append(question)\n",
    "        df = pd.DataFrame(question_ls)\n",
    "        df.rename(columns={'question': 'question_rule_based'}, inplace=True)\n",
    "        df.to_csv(f\"{folder_unfiltered}/{filename}\", index=False) # [['subject', 'relation', 'object', 'question']]\n",
    "        print(f\"Topic: {first_pair[1]}, fact_triplets_new.shape: {fact_triplets_new.shape}, df_question.shape: {df.shape}\", end=' ')\n",
    "        print(f\"Number of rows with label != object: {df[df.object != df.label].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/questions/unfiltered/llama_2_7b_chat_hf',\n",
       " ['meta_llama_3_8b_instruct', 'llama_2_7b_chat_hf'],\n",
       " 'llama_2_7b_chat_hf')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_model_id = model_id_format_ls[-1]\n",
    "folder_unfiltered, model_id_format_ls[1:], other_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "# for other_model_id in model_id_format_ls[1:]:\n",
    "#     shutil.copytree(folder_unfiltered, f\"../data/questions/unfiltered/{other_model_id}\")\n",
    "# f\"../data/questions/unfiltered/{other_model_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/questions/unfiltered/gemma_2_9b_it'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree('../data/questions/unfiltered/meta_llama_3_8b_instruct', f\"../data/questions/unfiltered/gemma_2_9b_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the output columns for all the files under \"../data/questions/unfiltered/{other_model_id}\"\n",
    "other_model_id = 'gemma_2_9b_it'  #'gemma_2_9b_it'\n",
    "for filename in os.listdir(f\"../data/questions/unfiltered/{other_model_id}\"):\n",
    "    df = pd.read_csv(f\"../data/questions/unfiltered/{other_model_id}/{filename}\")\n",
    "    df.drop(columns=[f'output_meta_llama_3_8b_instruct'], inplace=True)\n",
    "    df.to_csv(f\"../data/questions/unfiltered/{other_model_id}/{filename}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>meta_llama_3.1_8b_instruct</th>\n",
       "      <th>mistral_7b_instruct_v0.3</th>\n",
       "      <th>vicuna_7b_v1.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art_sculpture</td>\n",
       "      <td>(358, 6)</td>\n",
       "      <td>(377, 6)</td>\n",
       "      <td>(377, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business_brand</td>\n",
       "      <td>(781, 6)</td>\n",
       "      <td>(787, 5)</td>\n",
       "      <td>(787, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business_corporation</td>\n",
       "      <td>(191, 6)</td>\n",
       "      <td>(191, 5)</td>\n",
       "      <td>(191, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_industry</td>\n",
       "      <td>(170, 6)</td>\n",
       "      <td>(170, 5)</td>\n",
       "      <td>(170, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment_anime</td>\n",
       "      <td>(296, 6)</td>\n",
       "      <td>(299, 6)</td>\n",
       "      <td>(299, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entertainment_music_genre</td>\n",
       "      <td>(300, 6)</td>\n",
       "      <td>(300, 6)</td>\n",
       "      <td>(300, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entertainment_song</td>\n",
       "      <td>(1932, 6)</td>\n",
       "      <td>(1935, 6)</td>\n",
       "      <td>(1935, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>event_film</td>\n",
       "      <td>(166, 6)</td>\n",
       "      <td>(166, 6)</td>\n",
       "      <td>(166, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>event_history</td>\n",
       "      <td>(156, 6)</td>\n",
       "      <td>(156, 6)</td>\n",
       "      <td>(156, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>event_sport</td>\n",
       "      <td>(115, 6)</td>\n",
       "      <td>(115, 6)</td>\n",
       "      <td>(115, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>geography_forest</td>\n",
       "      <td>(261, 6)</td>\n",
       "      <td>(261, 6)</td>\n",
       "      <td>(261, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>geography_glacier</td>\n",
       "      <td>(105, 6)</td>\n",
       "      <td>(107, 6)</td>\n",
       "      <td>(107, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>geography_volcano</td>\n",
       "      <td>(426, 6)</td>\n",
       "      <td>(429, 6)</td>\n",
       "      <td>(429, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>health_disease</td>\n",
       "      <td>(496, 6)</td>\n",
       "      <td>(505, 6)</td>\n",
       "      <td>(505, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>health_medication</td>\n",
       "      <td>(53, 6)</td>\n",
       "      <td>(53, 6)</td>\n",
       "      <td>(53, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>health_symptom</td>\n",
       "      <td>(60, 6)</td>\n",
       "      <td>(60, 6)</td>\n",
       "      <td>(60, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>human_athlete</td>\n",
       "      <td>(1313, 6)</td>\n",
       "      <td>(1313, 6)</td>\n",
       "      <td>(1313, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>human_entrepreneur</td>\n",
       "      <td>(1542, 6)</td>\n",
       "      <td>(1546, 6)</td>\n",
       "      <td>(1546, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>human_scientist</td>\n",
       "      <td>(1052, 6)</td>\n",
       "      <td>(1052, 6)</td>\n",
       "      <td>(1052, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>human_writer</td>\n",
       "      <td>(2682, 6)</td>\n",
       "      <td>(2685, 6)</td>\n",
       "      <td>(2685, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>places_city</td>\n",
       "      <td>(6785, 6)</td>\n",
       "      <td>(6805, 6)</td>\n",
       "      <td>(6805, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>places_country</td>\n",
       "      <td>(1936, 6)</td>\n",
       "      <td>(1936, 6)</td>\n",
       "      <td>(1936, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>places_landmark</td>\n",
       "      <td>(1829, 6)</td>\n",
       "      <td>(1832, 6)</td>\n",
       "      <td>(1832, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>technology_database</td>\n",
       "      <td>(138, 6)</td>\n",
       "      <td>(138, 6)</td>\n",
       "      <td>(138, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>technology_programming_language</td>\n",
       "      <td>(311, 6)</td>\n",
       "      <td>(311, 6)</td>\n",
       "      <td>(311, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>technology_software</td>\n",
       "      <td>(631, 6)</td>\n",
       "      <td>(633, 6)</td>\n",
       "      <td>(633, 6)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Topic meta_llama_3.1_8b_instruct  \\\n",
       "0                     art_sculpture                   (358, 6)   \n",
       "1                    business_brand                   (781, 6)   \n",
       "2              business_corporation                   (191, 6)   \n",
       "3                 business_industry                   (170, 6)   \n",
       "4               entertainment_anime                   (296, 6)   \n",
       "5         entertainment_music_genre                   (300, 6)   \n",
       "6                entertainment_song                  (1932, 6)   \n",
       "7                        event_film                   (166, 6)   \n",
       "8                     event_history                   (156, 6)   \n",
       "9                       event_sport                   (115, 6)   \n",
       "10                 geography_forest                   (261, 6)   \n",
       "11                geography_glacier                   (105, 6)   \n",
       "12                geography_volcano                   (426, 6)   \n",
       "13                   health_disease                   (496, 6)   \n",
       "14                health_medication                    (53, 6)   \n",
       "15                   health_symptom                    (60, 6)   \n",
       "16                    human_athlete                  (1313, 6)   \n",
       "17               human_entrepreneur                  (1542, 6)   \n",
       "18                  human_scientist                  (1052, 6)   \n",
       "19                     human_writer                  (2682, 6)   \n",
       "20                      places_city                  (6785, 6)   \n",
       "21                   places_country                  (1936, 6)   \n",
       "22                  places_landmark                  (1829, 6)   \n",
       "23              technology_database                   (138, 6)   \n",
       "24  technology_programming_language                   (311, 6)   \n",
       "25              technology_software                   (631, 6)   \n",
       "\n",
       "   mistral_7b_instruct_v0.3 vicuna_7b_v1.5  \n",
       "0                  (377, 6)       (377, 6)  \n",
       "1                  (787, 5)       (787, 6)  \n",
       "2                  (191, 5)       (191, 6)  \n",
       "3                  (170, 5)       (170, 6)  \n",
       "4                  (299, 6)       (299, 6)  \n",
       "5                  (300, 6)       (300, 6)  \n",
       "6                 (1935, 6)      (1935, 6)  \n",
       "7                  (166, 6)       (166, 6)  \n",
       "8                  (156, 6)       (156, 6)  \n",
       "9                  (115, 6)       (115, 6)  \n",
       "10                 (261, 6)       (261, 6)  \n",
       "11                 (107, 6)       (107, 6)  \n",
       "12                 (429, 6)       (429, 6)  \n",
       "13                 (505, 6)       (505, 6)  \n",
       "14                  (53, 6)        (53, 6)  \n",
       "15                  (60, 6)        (60, 6)  \n",
       "16                (1313, 6)      (1313, 6)  \n",
       "17                (1546, 6)      (1546, 6)  \n",
       "18                (1052, 6)      (1052, 6)  \n",
       "19                (2685, 6)      (2685, 6)  \n",
       "20                (6805, 6)      (6805, 6)  \n",
       "21                (1936, 6)      (1936, 6)  \n",
       "22                (1832, 6)      (1832, 6)  \n",
       "23                 (138, 6)       (138, 6)  \n",
       "24                 (311, 6)       (311, 6)  \n",
       "25                 (633, 6)       (633, 6)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shape_data = {}\n",
    "for model_id in model_id_ls:\n",
    "    model_id_format = model_id.split('/')[-1].replace('-', '_').lower()\n",
    "    folder_unfiltered = f\"../data/questions/unfiltered/{model_id_format}\"\n",
    "    for filename in sorted(os.listdir(folder_unfiltered)):\n",
    "        if filename.endswith('.csv'):\n",
    "            df = pd.read_csv(f'{folder_unfiltered}/{filename}')\n",
    "            topic = filename.replace('.csv', '')\n",
    "            if topic not in shape_data:\n",
    "                shape_data[topic] = {}\n",
    "            shape_data[topic][model_id_format] = df.shape\n",
    "\n",
    "shape_df = pd.DataFrame.from_dict(shape_data, orient='index')\n",
    "# shape_df.columns = model_columns\n",
    "shape_df.index.name = 'Topic'\n",
    "shape_df.reset_index(inplace=True)\n",
    "\n",
    "display(shape_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/questions/unfiltered/vicuna_7b_v1.5'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id_format = 'vicuna_7b_v1.5'\n",
    "folder_unfiltered = f\"../data/questions/unfiltered/{other_model_id}\"\n",
    "folder_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/questions/unfiltered/llama_2_7b_chat_hf'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the multiple choice output are single letter\n",
    "with open('../tmp/places_country_ROME_meta_llama_3.1_8b_instruct.json', 'r') as file:\n",
    "    metrics = json.load(file)\n",
    "for e in metrics:\n",
    "    if len(e['post']['multiple_choice_questions']['multiple_choice_output']) != 1 or len(e['pre']['multiple_choice_questions']['multiple_choice_output']) != 1:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env24may",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
