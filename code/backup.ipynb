{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-05 19:46:39,193 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from process_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: {'instance of': 'literary work'}\n",
      "Error querying for Q7725634: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
      "\n",
      "Response:\n",
      "b'SPARQL-QUERY: queryStr=\\n    SELECT ?subjectLabel ?relation ?objectLabel WHERE {\\n      ?subject wdt:P31 wd:Q7725634.\\n      ?subject ?relation ?object.\\n      ?subject wikibase:identifiers ?subject_identifierCount.\\n      ?object wikibase:identifiers ?object_identifierCount.\\n      FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n    }\\n    LIMIT 50000\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'\n",
      "\n",
      "Topic: {'instance of': 'film festival'}\n",
      "Topic Q220505 has 487 relations.\n",
      "\n",
      "Topic: {'instance of': 'human', 'country of citizenship': \"People's Republic of China\", 'occupation': 'actor'}\n",
      "Error querying for Q5: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
      "\n",
      "Response:\n",
      "b'SPARQL-QUERY: queryStr=\\n    SELECT ?subjectLabel ?relation ?objectLabel WHERE {\\n      ?subject wdt:P31 wd:Q5.\\n      ?subject ?relation ?object.\\n      ?subject wikibase:identifiers ?subject_identifierCount.\\n      ?object wikibase:identifiers ?object_identifierCount.\\n      FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n    }\\n    LIMIT 50000\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'\n",
      "\n",
      "Topic: {'instance of': 'tourist attraction'}\n",
      "Topic Q570116 has 7224 relations.\n",
      "\n",
      "Topic: {'instance of': 'revolution'}\n",
      "Topic Q10931 has 184 relations.\n",
      "\n",
      "Topic: {'instance of': 'medical treatment'}\n",
      "Topic Q179661 has 154 relations.\n",
      "\n",
      "Topic: {'instance of': 'painting'}\n",
      "Error querying for Q3305213: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
      "\n",
      "Response:\n",
      "b'SPARQL-QUERY: queryStr=\\n    SELECT ?subjectLabel ?relation ?objectLabel WHERE {\\n      ?subject wdt:P31 wd:Q3305213.\\n      ?subject ?relation ?object.\\n      ?subject wikibase:identifiers ?subject_identifierCount.\\n      ?object wikibase:identifiers ?object_identifierCount.\\n      FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n    }\\n    LIMIT 50000\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'\n",
      "\n",
      "Topic: {'instance of': 'disease'}\n",
      "Topic Q12136 has 4819 relations.\n",
      "\n",
      "Topic: {'instance of': 'song'}\n",
      "Topic Q7366 has 5153 relations.\n",
      "\n",
      "Topic: {'instance of': 'country'}\n",
      "Topic Q6256 has 30259 relations.\n",
      "\n",
      "Topic: {'instance of': 'recurring sporting event'}\n",
      "Topic Q18608583 has 521 relations.\n",
      "\n",
      "Topic: {'instance of': 'human', 'country of citizenship': \"People's Republic of China\", 'occupation': 'writer'}\n",
      "Error querying for Q5: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
      "\n",
      "Response:\n",
      "b'SPARQL-QUERY: queryStr=\\n    SELECT ?subjectLabel ?relation ?objectLabel WHERE {\\n      ?subject wdt:P31 wd:Q5.\\n      ?subject ?relation ?object.\\n      ?subject wikibase:identifiers ?subject_identifierCount.\\n      ?object wikibase:identifiers ?object_identifierCount.\\n      FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n    }\\n    LIMIT 50000\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'\n",
      "\n",
      "Topic: {'instance of': 'human', 'country of citizenship': \"People's Republic of China\", 'occupation': 'politician'}\n",
      "Error querying for Q5: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
      "\n",
      "Response:\n",
      "b'SPARQL-QUERY: queryStr=\\n    SELECT ?subjectLabel ?relation ?objectLabel WHERE {\\n      ?subject wdt:P31 wd:Q5.\\n      ?subject ?relation ?object.\\n      ?subject wikibase:identifiers ?subject_identifierCount.\\n      ?object wikibase:identifiers ?object_identifierCount.\\n      FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n    }\\n    LIMIT 50000\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'\n",
      "\n",
      "Topic: {'instance of': 'city'}\n",
      "Topic Q515 has 44191 relations.\n",
      "\n",
      "Topic: {'instance of': 'sculpture'}\n",
      "Topic Q860861 has 1086 relations.\n",
      "\n",
      "Topic: {'instance of': 'medication'}\n",
      "Topic Q12140 has 927 relations.\n"
     ]
    }
   ],
   "source": [
    "topic_folder = \"../data/topic\"\n",
    "for filename in os.listdir(topic_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(os.path.join(topic_folder, filename), 'r', encoding='utf-8') as topics_file:\n",
    "            topics = topics_file.readlines()\n",
    "        topic = json.loads(topics[0])\n",
    "        relation_object_pairs = convert_topic_to_symbol(topic)\n",
    "        print(f\"\\nTopic: {topic}\")\n",
    "        get_topic_size(relation_object_pairs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: health_medication.json, first_pair (used in question generation): ('instance of', 'medication')\n",
      "filename: places_landmark.json, first_pair (used in question generation): ('instance of', 'tourist attraction')\n",
      "filename: event_history.json, first_pair (used in question generation): ('instance of', 'revolution')\n",
      "filename: human_politician.json, first_pair (used in question generation): ('instance of', 'human')\n",
      "filename: entertainment_music_genre.json, first_pair (used in question generation): ('instance of', 'music genre')\n",
      "filename: entertainment_song.json, first_pair (used in question generation): ('instance of', 'song')\n",
      "filename: art_sculpture.json, first_pair (used in question generation): ('instance of', 'sculpture')\n",
      "filename: event_film.json, first_pair (used in question generation): ('instance of', 'film festival')\n",
      "filename: human_actor.json, first_pair (used in question generation): ('instance of', 'human')\n",
      "filename: art_painting.json, first_pair (used in question generation): ('instance of', 'painting')\n",
      "filename: art_literary.json, first_pair (used in question generation): ('instance of', 'literary work')\n",
      "filename: places_country.json, first_pair (used in question generation): ('instance of', 'country')\n",
      "filename: human_writer.json, first_pair (used in question generation): ('instance of', 'human')\n",
      "filename: health_disease.json, first_pair (used in question generation): ('instance of', 'disease')\n",
      "filename: health_treatment.json, first_pair (used in question generation): ('instance of', 'medical treatment')\n",
      "filename: entertainment_film_genre.json, first_pair (used in question generation): ('instance of', 'film genre')\n",
      "filename: entertainment_anime.json, first_pair (used in question generation): ('instance of', 'anime')\n",
      "filename: places_city.json, first_pair (used in question generation): ('instance of', 'city')\n",
      "filename: event_sport.json, first_pair (used in question generation): ('instance of', 'recurring sporting event')\n",
      "filename: university.json, first_pair (used in question generation): ('instance of', 'university')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "ls = []\n",
    "topic_folder = \"../data/topic\"\n",
    "for filename in os.listdir(topic_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        # print(filename)\n",
    "        with open(os.path.join(topic_folder, filename), 'r', encoding='utf-8') as topics_file:\n",
    "            topics = topics_file.readlines()\n",
    "        # print(topics)\n",
    "        ls.append(topics)\n",
    "        # get_topic_size(topics)\n",
    "\n",
    "        topic = json.loads(topics[0])\n",
    "        first_pair = next(iter(topic.items()))\n",
    "        print(f\"filename: {filename}, first_pair (used in question generation): {first_pair}\")\n",
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    ['{\"instance of\": \"song\"}'],\n",
    "    ['{\"instance of\": \"sculpture\"}\\n'],\n",
    "    ['{\"instance of\": \"film festival\"}'],\n",
    "    ['{\"instance of\": \"literary work\"}'],\n",
    "    ['{\"instance of\": \"disease\"}'],\n",
    "    ['{\"instance of\": \"painting\"}\\n', '{\"instance of\": \"wall painting\"}'],\n",
    "    ['{\"instance of\": \"revolution\"}\\n', '{\"instance of\": \"war\"}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic {'instance of': 'tourist attraction'} size: 5000\n",
      "Topic {'instance of': 'music genre'} size: 3011\n",
      "Topic {'instance of': 'song'} size: 5000\n",
      "Topic {'instance of': 'sculpture'} size: 1090\n",
      "Topic {'instance of': 'film festival'} size: 487\n",
      "Topic {'instance of': 'literary work'} size: 5000\n",
      "Topic {'instance of': 'country'} size: 5000\n",
      "Topic {'instance of': 'disease'} size: 4820\n"
     ]
    },
    {
     "ename": "EndPointInternalError",
     "evalue": "EndPointInternalError: The endpoint returned the HTTP status code 500. \n\nResponse:\nb'SPARQL-QUERY: queryStr=SELECT ?subjectLabel ?relation ?objectLabel WHERE {\\n?subject wdt:P31 wd:Q3305213 .\\n                ?subject  ?relation  ?object.\\n                ?subject wikibase:identifiers ?subject_identifierCount.\\n                ?object wikibase:identifiers ?object_identifierCount.\\n                 \\n                FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \\n                SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n            }\\n            LIMIT 5000\\n            \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/SPARQLWrapper/Wrapper.py:926\u001b[0m, in \u001b[0;36mSPARQLWrapper._query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 926\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43murlopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturnFormat\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    560\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    493\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEndPointInternalError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m topics \u001b[38;5;129;01min\u001b[39;00m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtourist attraction\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      2\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusic genre\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msong\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpainting\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwall painting\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevolution\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwar\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m]]:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mget_topic_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/baixiang/workspace/edit/hallucination/code/process_data.py:152\u001b[0m, in \u001b[0;36mget_topic_size\u001b[0;34m(topics)\u001b[0m\n\u001b[1;32m    150\u001b[0m sparql\u001b[38;5;241m.\u001b[39msetQuery(query)\n\u001b[1;32m    151\u001b[0m sparql\u001b[38;5;241m.\u001b[39msetReturnFormat(JSON)\n\u001b[0;32m--> 152\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msparql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[1;32m    153\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbindings\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/SPARQLWrapper/Wrapper.py:960\u001b[0m, in \u001b[0;36mSPARQLWrapper.query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryResult\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    943\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    Execute the query.\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/SPARQLWrapper/Wrapper.py:938\u001b[0m, in \u001b[0;36mSPARQLWrapper._query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URITooLong(e\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EndPointInternalError(e\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mEndPointInternalError\u001b[0m: EndPointInternalError: The endpoint returned the HTTP status code 500. \n\nResponse:\nb'SPARQL-QUERY: queryStr=SELECT ?subjectLabel ?relation ?objectLabel WHERE {\\n?subject wdt:P31 wd:Q3305213 .\\n                ?subject  ?relation  ?object.\\n                ?subject wikibase:identifiers ?subject_identifierCount.\\n                ?object wikibase:identifiers ?object_identifierCount.\\n                 \\n                FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \\n                SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n            }\\n            LIMIT 5000\\n            \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'"
     ]
    }
   ],
   "source": [
    "for topics in [['{\"instance of\": \"tourist attraction\"}\\n'],\n",
    "    ['{\"instance of\": \"music genre\"}'],\n",
    "    ['{\"instance of\": \"song\"}'],\n",
    "    ['{\"instance of\": \"sculpture\"}\\n'],\n",
    "    ['{\"instance of\": \"film festival\"}'],\n",
    "    ['{\"instance of\": \"literary work\"}'],\n",
    "    ['{\"instance of\": \"country\"}\\n'],\n",
    "    ['{\"instance of\": \"disease\"}'],\n",
    "    ['{\"instance of\": \"painting\"}\\n', '{\"instance of\": \"wall painting\"}'],\n",
    "    ['{\"instance of\": \"revolution\"}\\n', '{\"instance of\": \"war\"}']]:\n",
    "    get_topic_size(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EndPointInternalError: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
    "{'instance of': 'human', 'country of citizenship': \"People's Republic of China\", 'occupation': 'politician'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: ../data/triplet/new_entertainment_anime.csv to ../data/triplet/entertainment_anime.csv\n",
      "Renamed: ../data/triplet/new_human_scientist.csv to ../data/triplet/human_scientist.csv\n",
      "Renamed: ../data/triplet/new_revolution.csv to ../data/triplet/revolution.csv\n",
      "Renamed: ../data/triplet/new_places_landmark.csv to ../data/triplet/places_landmark.csv\n",
      "Renamed: ../data/triplet/new_human_writer.csv to ../data/triplet/human_writer.csv\n",
      "Renamed: ../data/triplet/new_entertainment_song.csv to ../data/triplet/entertainment_song.csv\n",
      "Renamed: ../data/triplet/new_human_athlete.csv to ../data/triplet/human_athlete.csv\n",
      "Renamed: ../data/triplet/new_entertainment_music_genre.csv to ../data/triplet/entertainment_music_genre.csv\n",
      "Renamed: ../data/triplet/new_anime.csv to ../data/triplet/anime.csv\n",
      "Renamed: ../data/triplet/new_country.csv to ../data/triplet/country.csv\n",
      "Renamed: ../data/triplet/new_recurring sporting event.csv to ../data/triplet/recurring sporting event.csv\n",
      "Renamed: ../data/triplet/new_places_city.csv to ../data/triplet/places_city.csv\n",
      "Renamed: ../data/triplet/new_human_entrepreneur.csv to ../data/triplet/human_entrepreneur.csv\n"
     ]
    }
   ],
   "source": [
    "# rename all the files under '../data/graph/' from {topic}.gpickle to {topic}.gpickle\n",
    "import os\n",
    "directory = '../data/triplet'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        old_path = os.path.join(directory, filename)\n",
    "        new_path = os.path.join(directory, filename.replace('new_', ''))\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed: {old_path} to {new_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check fact triplets and efficacy questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0516534cb84ac8ac3fb04e77452371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f4c8940bf147a28570fe87c8c4c3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id_eval = 'meta-llama/Meta-Llama-3.1-70B-Instruct'\n",
    "tok_eval = AutoTokenizer.from_pretrained(model_id_eval)\n",
    "model_eval = AutoModelForCausalLM.from_pretrained(model_id_eval, torch_dtype='auto', device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(model, tok, messages, max_new_tokens=1):\n",
    "    terminators = [tok.eos_token_id, tok.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "    msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt').to(model.device)\n",
    "    output_ids = model.generate(msg_tokenized, max_new_tokens=max_new_tokens, eos_token_id=terminators, do_sample=False, pad_token_id=tok.eos_token_id)\n",
    "    return tok.decode(output_ids[0][msg_tokenized.shape[-1]:], skip_special_tokens=True).replace('\\n', ' ').strip().rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: subject: 2018 FIFA World Cup, relation: has part(s), object: FIFA World Cup  response: YES\n"
     ]
    }
   ],
   "source": [
    "system_msg_check = \"\"\"Check whether the given triplet satisfies the following criteria. If all criteria are satisfied, answer YES, otherwise answer NO:\n",
    "1. the triplet is factually correct.\n",
    "2. the triplet is understandable to humans.\n",
    "Only answer YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "triplet = \"\"\"subject: 2018 FIFA World Cup, relation: has part(s), object: FIFA World Cup\"\"\"\n",
    "messages_qa = [{\"role\": \"system\", \"content\": system_msg_check}, {\"role\": \"user\", \"content\": triplet}]\n",
    "current_output = get_response(model_eval, tok_eval, messages_qa, max_new_tokens=64)\n",
    "print(f\"Input: {triplet}  response: {current_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: subject: The Rebirth of Buddha, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: The Rebirth of Buddha, relation: country of origin, object: Japan  response: NO\n",
      "Input: subject: The Rebirth of Buddha, relation: production company, object: Group TAC  response: YES\n",
      "Input: subject: The Rebirth of Buddha, relation: creator, object: IRH Press  response: NO\n",
      "Input: subject: The Rebirth of Buddha, relation: director, object: Takaaki Ishiyama  response: YES\n",
      "Input: subject: The Rebirth of Buddha, relation: screenwriter, object: Hiroshi  response: NO\n",
      "Input: subject: The Rebirth of Buddha, relation: executive producer, object: Ryh kawa  response: YES\n",
      "Input: subject: The Rebirth of Buddha, relation: art director, object: Masaru Sato  response: YES\n",
      "Input: subject: The Rebirth of Buddha, relation: distributed by, object: Toei Company  response: YES\n",
      "Input: subject: The Rebirth of Buddha, relation: character designer, object: Masami Suda  response: YES\n",
      "Input: subject: Ehrgeiz, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Ehrgeiz, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Ehrgeiz, relation: genre, object: mecha  response: NO\n",
      "Input: subject: YY no Neko Tsumami, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: YY no Neko Tsumami, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Kiitaro's Yokai Picture Diary, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Kiitaro's Yokai Picture Diary, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Tabimachi Late Show, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Tabimachi Late Show, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Tabimachi Late Show, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Tabimachi Late Show, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Holo no Graffiti, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Holo no Graffiti, relation: distributed by, object: Google  response: NO\n",
      "Input: subject: Holo no Graffiti, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Holo no Graffiti, relation: publisher, object: Hololive Production  response: YES\n",
      "Input: subject: Holo no Graffiti, relation: original broadcaster, object: Bilibili  response: YES\n",
      "Input: subject: Holo no Graffiti, relation: genre, object: parody  response: YES\n",
      "Input: subject: Holo no Graffiti, relation: main subject, object: VTuber  response: YES\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: country of origin, object: Japan  response: NO\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: language of work or name, object: Japanese  response: NO\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: art director, object: Tatsuya Kushida  response: YES\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: distributed by, object: Toei Company  response: YES\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: executive producer, object: Ryh kawa  response: YES\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: production company, object: SONY PCL  response: NO\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: director, object: Tetsuo Imazawa  response: NO\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: creator, object: IRH Press  response: YES\n",
      "Input: subject: THE LIFE OF GREAT HERMES, relation: genre, object: historical film  response: NO\n",
      "Input: subject: This Boy Suffers from Crystallization, relation: language of work or name, object: Japanese  response: NO\n",
      "Input: subject: This Boy Suffers from Crystallization, relation: country of origin, object: Japan  response: NO\n",
      "Input: subject: This Boy Suffers from Crystallization, relation: distribution format, object: video on demand  response: NO\n",
      "Input: subject: This Boy Suffers from Crystallization, relation: director, object: Sbi Yamamoto  response: NO\n",
      "Input: subject: This Boy Suffers from Crystallization, relation: distributed by, object: Crunchyroll  response: NO\n",
      "Input: subject: Hey, Your Cat Ears Are Showing!, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 3, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 3, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 3, relation: part of the series, object: Digimon Adventure tri.  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 3, relation: director, object: Keitar Motonaga  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 3, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 3, relation: follows, object: Digimon Adventure Tri. 2  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 3, relation: followed by, object: Digimon Adventure Tri. 4  response: YES\n",
      "Input: subject: Five Numbers!, relation: original language of film or TV show, object: Japanese  response: NO\n",
      "Input: subject: Horror News, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Horror News, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Q.E.D., relation: country of origin, object: Japan  response: NO\n",
      "Input: subject: Q.E.D., relation: intended public, object: shnen  response: NO\n",
      "Input: subject: Q.E.D., relation: language of work or name, object: Japanese  response: NO\n",
      "Input: subject: Q.E.D., relation: genre, object: detective fiction  response: YES\n",
      "Input: subject: Q.E.D., relation: author, object: Motohiro Katou  response: NO\n",
      "Input: subject: Keifuku-san, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Keifuku-san, relation: original broadcaster, object: Tokyo Metropolitan Television  response: NO\n",
      "Input: subject: Keifuku-san, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: W Wish, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: W Wish, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: W Wish, relation: distribution format, object: DVD  response: YES\n",
      "Input: subject: W Wish, relation: game mode, object: single-player video game  response: NO\n",
      "Input: subject: Idol Land PriPara, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Idol Land PriPara, relation: part of the series, object: Pretty Rhythm  response: YES\n",
      "Input: subject: Idol Land PriPara, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Kiratto Pri Chan, relation: production company, object: Tatsunoko Production  response: YES\n",
      "Input: subject: Kiratto Pri Chan, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Kiratto Pri Chan, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Kiratto Pri Chan, relation: followed by, object: Pretty All Friends Selection  response: YES\n",
      "Input: subject: Kiratto Pri Chan, relation: developer, object: Syn Sophia  response: YES\n",
      "Input: subject: Kiratto Pri Chan, relation: publisher, object: T-ARTS  response: YES\n",
      "Input: subject: Kiratto Pri Chan, relation: director, object: Hiroshi Ikehata  response: YES\n",
      "Input: subject: Don't Lose!! Evil Corps!, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Don't Lose!! Evil Corps!, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Don't Lose!! Evil Corps!, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Aki Sora, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Aki Sora, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Aki Sora, relation: author, object: Masahiro Itosugi  response: YES\n",
      "Input: subject: Kowarekake no Orgel, relation: director, object: Keiichiro Kawaguchi  response: YES\n",
      "Input: subject: Kowarekake no Orgel, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Rescue Me!, relation: intended public, object: shnen  response: YES\n",
      "Input: subject: Rescue Me!, relation: author, object: Makita Keiharu  response: NO\n",
      "Input: subject: Macross Delta the Movie: Passionate Walkre, relation: production company, object: Satelight  response: YES\n",
      "Input: subject: Macross Delta the Movie: Passionate Walkre, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Macross Delta the Movie: Passionate Walkre, relation: form of creative work, object: feature film  response: YES\n",
      "Input: subject: Macross Delta the Movie: Passionate Walkre, relation: director, object: Shji Kawamori  response: NO\n",
      "Input: subject: Macross Delta the Movie: Passionate Walkre, relation: genre, object: mecha  response: YES\n",
      "Input: subject: Macross Delta the Movie: Passionate Walkre, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Macross Delta the Movie: Passionate Walkre, relation: based on, object: Macross Delta  response: YES\n",
      "Input: subject: Zukkoke Knight - Don De La Mancha, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Zukkoke Knight - Don De La Mancha, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Hitorijime My Hero, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Hitorijime My Hero, relation: genre, object: yaoi  response: YES\n",
      "Input: subject: Double Hard, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Double Hard, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Bible Black, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Bible Black, relation: publisher, object: Active  response: NO\n",
      "Input: subject: Bible Black, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Bible Black, relation: game mode, object: single-player video game  response: NO\n",
      "Input: subject: Bible Black, relation: distribution format, object: compact disc  response: YES\n",
      "Input: subject: Crimson Wolf, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Crimson Wolf, relation: director, object: Shichi Masuo  response: YES\n",
      "Input: subject: Crimson Wolf, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Tenshi no Drop, relation: intended public, object: shnen  response: YES\n",
      "Input: subject: Tenshi no Drop, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Tenshi no Drop, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Tenshi no Drop, relation: author, object: Chizuna Nakajima  response: NO\n",
      "Input: subject: Gakuen Handsome, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Gakuen Handsome, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Gakuen Handsome, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Gakuen Handsome, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Gakuen Handsome, relation: genre, object: dating sim  response: YES\n",
      "Input: subject: IDOLM@STER SideM, relation: character designer, object: Haruko Iizuka  response: YES\n",
      "Input: subject: IDOLM@STER SideM, relation: input device, object: touchscreen  response: NO\n",
      "Input: subject: IDOLM@STER SideM, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: IDOLM@STER SideM, relation: business model, object: free-to-play  response: YES\n",
      "Input: subject: Love Rice, relation: distribution format, object: video on demand  response: NO\n",
      "Input: subject: Love Rice, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Love Rice, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Schick x Evangelion, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Schick x Evangelion, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Schick x Evangelion, relation: media franchise, object: Neon Genesis Evangelion  response: NO\n",
      "Input: subject: Schick x Evangelion, relation: voice actor, object: Fumihiko Tachiki  response: YES\n",
      "Input: subject: Running Boy: Star Soldier no Himitsu, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Running Boy: Star Soldier no Himitsu, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Kinnikuman Nisei, relation: intended public, object: shnen  response: YES\n",
      "Input: subject: Kinnikuman Nisei, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Kinnikuman Nisei, relation: main subject, object: sport  response: YES\n",
      "Input: subject: Kinnikuman Nisei, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Kinnikuman Nisei, relation: author, object: Yudetamago  response: YES\n",
      "Input: subject: Voice of Fox, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Voice of Fox, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Voice of Fox, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Voice of Fox, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: This Boy Is a Professional Wizard, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: This Boy Is a Professional Wizard, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: This Boy Is a Professional Wizard, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: This Boy Is a Professional Wizard, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Kurokan, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Kurokan, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Kurokan, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Kurokan, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Euphoria, relation: language of work or name, object: Japanese  response: NO\n",
      "Input: subject: Euphoria, relation: input device, object: computer keyboard  response: NO\n",
      "Input: subject: Euphoria, relation: game mode, object: single-player video game  response: NO\n",
      "Input: subject: Euphoria, relation: distribution format, object: DVD  response: YES\n",
      "Input: subject: Euphoria, relation: publisher, object: CLOCKUP  response: YES\n",
      "Input: subject: Euphoria, relation: country of origin, object: Japan  response: NO\n",
      "Input: subject: Ranma  One Grew Over the Kuno's Nest, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Ranma  One Grew Over the Kuno's Nest, relation: based on, object: Ranma   response: YES\n",
      "Input: subject: Ranma  One Grew Over the Kuno's Nest, relation: director, object: Junji Nishimura  response: YES\n",
      "Input: subject: Ranma  One Grew Over the Kuno's Nest, relation: main subject, object: high school student  response: YES\n",
      "Input: subject: Ranma  One Grew Over the Kuno's Nest, relation: distributed by, object: Dynit  response: YES\n",
      "Input: subject: Ranma  One Grew Over the Kuno's Nest, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Fukusuke, relation: director, object: Ryichi Yokoyama  response: NO\n",
      "Input: subject: Papa Datte, Shitai, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Papa Datte, Shitai, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Papa Datte, Shitai, relation: genre, object: yaoi  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 6, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 6, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 6, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 6, relation: follows, object: Digimon Adventure Tri. 5  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 6, relation: part of the series, object: Digimon Adventure tri.  response: YES\n",
      "Input: subject: Doamaiger D, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Doamaiger D, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Doamaiger D, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Armitage III: Poly Matrix, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Armitage III: Poly Matrix, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Armitage III: Poly Matrix, relation: director, object: Takuya Sat  response: YES\n",
      "Input: subject: Armitage III: Poly Matrix, relation: genre, object: cyberpunk  response: YES\n",
      "Input: subject: Ch Supercar Gattiger, relation: follows, object: The Great Grape Ape Show  response: NO\n",
      "Input: subject: Ch Supercar Gattiger, relation: original broadcaster, object: TV Tokyo  response: YES\n",
      "Input: subject: Ch Supercar Gattiger, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Ch Supercar Gattiger, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Lupin the 3rd vs Detective Conan, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Lupin the 3rd vs Detective Conan, relation: production company, object: TMS Entertainment  response: YES\n",
      "Input: subject: Lupin the 3rd vs Detective Conan, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Lupin the 3rd vs Detective Conan, relation: form of creative work, object: feature film  response: YES\n",
      "Input: subject: Lupin the 3rd vs Detective Conan, relation: intended public, object: shnen  response: YES\n",
      "Input: subject: Lupin the 3rd vs Detective Conan, relation: voice actor, object: Kanichi Kurita  response: YES\n",
      "Input: subject: Lupin the 3rd vs Detective Conan, relation: director, object: Hajime Kamegaki  response: NO\n",
      "Input: subject: Lupin the 3rd vs Detective Conan, relation: screenwriter, object: Atsushi Maekawa  response: NO\n",
      "Input: subject: Peeping Life, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Peeping Life, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Peeping Life, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Giovanni's Island, relation: distributed by, object: Warner Bros.  response: NO\n",
      "Input: subject: Giovanni's Island, relation: production company, object: Production I.G  response: YES\n",
      "Input: subject: Giovanni's Island, relation: producer, object: Mitsuhisa Ishikawa  response: YES\n",
      "Input: subject: Giovanni's Island, relation: screenwriter, object: Yoshiki Sakurai  response: YES\n",
      "Input: subject: Giovanni's Island, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Giovanni's Island, relation: director, object: Mizuho Nishikubo  response: YES\n",
      "Input: subject: Pan de Peace!, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Pan de Peace!, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Pan de Peace!, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Pan de Peace!, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: The Laws of the Sun, relation: followed by, object: The Golden Laws  response: NO\n",
      "Input: subject: The Laws of the Sun, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: The Laws of the Sun, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: The Laws of the Sun, relation: author, object: Ryh kawa  response: YES\n",
      "Input: subject: Burglars of Baghdad Castle, relation: based on, object: The Thief of Bagdad  response: YES\n",
      "Input: subject: Burglars of Baghdad Castle, relation: color, object: black-and-white  response: NO\n",
      "Input: subject: Burglars of Baghdad Castle, relation: country of origin, object: Japan  response: NO\n",
      "Input: subject: Burglars of Baghdad Castle, relation: fabrication method, object: cutout animation  response: NO\n",
      "Input: subject: Hello Kitty: Stump Village, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Hello Kitty: Stump Village, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: JK-Meshi!, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: JK-Meshi!, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: JK-Meshi!, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Tesagure! Bukatsu-mono, relation: composer, object: Jun tomo  response: YES\n",
      "Input: subject: Tesagure! Bukatsu-mono, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Tesagure! Bukatsu-mono, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Tesagure! Bukatsu-mono, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Demon Beast Invasion, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Demon Beast Invasion, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Demon Beast Invasion, relation: author, object: Toshio Maeda  response: YES\n",
      "Input: subject: Demon Beast Invasion, relation: genre, object: henta  response: YES\n",
      "Input: subject: Cat Soup Theater, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Cat Soup Theater, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Aikatsu on Parade!, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Aikatsu on Parade!, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Aikatsu on Parade!, relation: publisher, object: Bandai  response: YES\n",
      "Input: subject: Aikatsu on Parade!, relation: production company, object: Bandai Namco Pictures  response: YES\n",
      "Input: subject: Power DoLLS: Detachment of Limited Line Service, relation: genre, object: turn-based tactics  response: YES\n",
      "Input: subject: Rinshi!! Ekoda-chan, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Lupin VIII, relation: production company, object: TMS Entertainment  response: YES\n",
      "Input: subject: Lupin VIII, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Lupin VIII, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: Lupin VIII, relation: director, object: Rintaro  response: YES\n",
      "Input: subject: Chain Chronicle, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Chain Chronicle, relation: publisher, object: Sega  response: YES\n",
      "Input: subject: Chain Chronicle, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Chain Chronicle, relation: developer, object: Sega Interactive  response: YES\n",
      "Input: subject: Chain Chronicle, relation: input device, object: touchscreen  response: YES\n",
      "Input: subject: Chain Chronicle, relation: performer, object: Aya Uchida  response: YES\n",
      "Input: subject: Chain Chronicle, relation: genre, object: J-pop  response: NO\n",
      "Input: subject: Harlock Saga, relation: composer, object: Kaoru Wada  response: YES\n",
      "Input: subject: Harlock Saga, relation: distributed by, object: Netflix  response: YES\n",
      "Input: subject: Harlock Saga, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Harlock Saga, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Harlock Saga, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Harlock Saga, relation: director, object: Yoshio Takeuchi  response: YES\n",
      "Input: subject: To Be Hero, relation: language of work or name, object: Japanese  response: YES\n",
      "Input: subject: To Be Hero, relation: original language of film or TV show, object: Classical Chinese  response: NO\n",
      "Input: subject: To Be Hero, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: To Be Hero, relation: followed by, object: To Be Heroine  response: NO\n",
      "Input: subject: To Be Hero, relation: main subject, object: alien invasion  response: YES\n",
      "Input: subject: To Be Hero, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: To Be Hero, relation: genre, object: comedy  response: YES\n",
      "Input: subject: To Be Hero, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: The Black Cat, relation: color, object: black-and-white  response: NO\n",
      "Input: subject: The Black Cat, relation: country of origin, object: Japan  response: NO\n",
      "Input: subject: The Black Cat, relation: original language of film or TV show, object: Japanese  response: NO\n",
      "Input: subject: The Black Cat, relation: genre, object: animated film  response: NO\n",
      "Input: subject: Jankenman, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Jankenman, relation: genre, object: action game  response: YES\n",
      "Input: subject: Jankenman, relation: platform, object: Game Boy  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 5, relation: followed by, object: Digimon Adventure Tri. 6  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 5, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 5, relation: part of the series, object: Digimon Adventure tri.  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 5, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Digimon Adventure Tri. 5, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Doraemon: Nobita and the Green Giant Legend, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Doraemon: Nobita and the Green Giant Legend, relation: main subject, object: house cat  response: NO\n",
      "Input: subject: Doraemon: Nobita and the Green Giant Legend, relation: country of origin, object: Japan  response: YES\n",
      "Input: subject: Doraemon: Nobita and the Green Giant Legend, relation: distributed by, object: Toho  response: YES\n",
      "Input: subject: Doraemon: Nobita and the Green Giant Legend, relation: film editor, object: Toshihiko Kojima  response: YES\n",
      "Input: subject: Doraemon: Nobita and the Green Giant Legend, relation: screenwriter, object: Hiroshi nogi  response: YES\n",
      "Input: subject: Doraemon: Nobita and the Green Giant Legend, relation: director, object: Ayumu Watanabe  response: YES\n",
      "Input: subject: Double Decker! Doug & Kirill, relation: original language of film or TV show, object: Japanese  response: YES\n",
      "Input: subject: Double Decker! Doug & Kirill, relation: distribution format, object: video on demand  response: YES\n",
      "Input: subject: Double Decker! Doug & Kirill, relation: character designer, object: Masakazu Katsura  response: YES\n",
      "Input: subject: Double Decker! Doug & Kirill, relation: distributed by, object: Crunchyroll  response: YES\n",
      "Input: subject: Double Decker! Doug & Kirill, relation: country of origin, object: Japan  response: YES\n"
     ]
    }
   ],
   "source": [
    "domain_topic_tmp = 'entertainment_anime'\n",
    "df = pd.read_csv(f\"../data/questions/unfiltered/{domain_topic_tmp}_questions.csv\")\n",
    "for i in df.index:\n",
    "    subject, relation, object = df.loc[i, 'subject'], df.loc[i, 'relation'], df.loc[i, 'object']\n",
    "    triplet = f\"\"\"subject: {subject}, relation: {relation}, object: {object}\"\"\"\n",
    "    messages_qa = [{\"role\": \"system\", \"content\": system_msg_check}, {\"role\": \"user\", \"content\": triplet}]\n",
    "    current_output = get_response(model_eval, tok_eval, messages_qa, max_new_tokens=64)\n",
    "    print(f\"Input: {triplet}  response: {current_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: question: What does Berlin Marathon sponsor?, answer: BMW  response: YES\n"
     ]
    }
   ],
   "source": [
    "system_msg_check = \"\"\"Check whether the question-answer pair is logically correct. Only answer YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "domain_topic_tmp = 'event_sport'\n",
    "# df = pd.read_csv(f\"../data/questions/unfiltered/{domain_topic_tmp}_questions.csv\")\n",
    "# for i in df.index:\n",
    "# subject, relation, object = df.loc[i, 'subject'], df.loc[i, 'relation'], df.loc[i, 'object']\n",
    "# triplet = f\"\"\"subject: {subject}, relation: {relation}, object: {object}\"\"\"\n",
    "triplet = f\"\"\"question: What does Berlin Marathon sponsor?, answer: BMW\"\"\"\n",
    "messages_qa = [{\"role\": \"system\", \"content\": system_msg_check}, {\"role\": \"user\", \"content\": triplet}]\n",
    "current_output = get_response(model_eval, tok_eval, messages_qa, max_new_tokens=64)\n",
    "print(f\"Input: {triplet}  response: {current_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from data_prep.py\n",
    "def generate_question(subject, relation, object, topic, multi_hops=1, query_subject=False):\n",
    "    object_type1 = None\n",
    "    object_type2 = None\n",
    "    object_type = None\n",
    "    discard_flag = False\n",
    "    convert_dict1 = {\n",
    "        \"PER\": \"PERSON\",\n",
    "        \"LOC\": \"GPE\"\n",
    "    }\n",
    "\n",
    "    ####### method 1\n",
    "    sentence = Sentence(object)\n",
    "    # Predict entities\n",
    "    sequence_tagger.predict(sentence)\n",
    "    # Access entity annotations\n",
    "    entities = sentence.get_spans('ner')\n",
    "    # Print the recognized entities\n",
    "    if entities:\n",
    "        object_type1 = entities[0].tag\n",
    "        if object_type1 == \"PER\" or object_type1 == \"LOC\":\n",
    "            object_type1 = convert_dict1[object_type1]\n",
    "        else:\n",
    "            object_type1 = None\n",
    "\n",
    "    ####### method 2\n",
    "    object_doc = spacy_en_core_web(object)\n",
    "    if object_doc.ents:\n",
    "        object_type2 = object_doc.ents[0].label_\n",
    "\n",
    "    if object_type1:        \n",
    "        if object_type1 == object_type2:\n",
    "            object_type = object_type1\n",
    "        else:\n",
    "            discard_flag = True\n",
    "    else:\n",
    "        if object_type2 != \"GPE\" and object_type2 != \"PERSON\":\n",
    "            object_type = object_type2\n",
    "        else:\n",
    "            discard_flag = True\n",
    "            \n",
    "    if discard_flag:\n",
    "        return None\n",
    "\n",
    "    if multi_hops == 1:\n",
    "        subject_doc = spacy_en_core_web(relation)\n",
    "    else:\n",
    "        subject_doc_list = []\n",
    "        for i in range(multi_hops):\n",
    "            tmp_subject_doc = spacy_en_core_web(relation['edge_labels'][i])\n",
    "            subject_doc_list.append(tmp_subject_doc)\n",
    "\n",
    "    if multi_hops > 1:\n",
    "        if not query_subject:\n",
    "            for i in range(multi_hops-1):\n",
    "                if subject_doc_list[i][0].tag_ in [\"VBN\", \"VBD\", \"VB\", \"VBZ\", \"JJ\"]:\n",
    "                    return None\n",
    "        else:\n",
    "            for i in range(1, multi_hops):\n",
    "                if subject_doc_list[i][0].tag_ in [\"VBN\", \"VBD\", \"VB\", \"VBZ\", \"JJ\"]:\n",
    "                    return None\n",
    "        if not query_subject:\n",
    "            subject_doc = subject_doc_list[-1]\n",
    "        else:\n",
    "            subject_doc = subject_doc_list[0]\n",
    "\n",
    "    if multi_hops == 1:\n",
    "        if subject_doc[-1].tag_ == \"IN\" and subject_doc[0].tag_ not in [\"VBN\", \"VBD\", \"VB\", \"VBZ\"]:\n",
    "            return None\n",
    "    else:\n",
    "        for i in range(multi_hops):\n",
    "            if subject_doc_list[i][-1].tag_ == \"IN\" and subject_doc_list[i][0].tag_ not in [\"VBN\", \"VBD\", \"VB\", \"VBZ\"]:\n",
    "                return None\n",
    "        \n",
    "    question_answer_pair = {}\n",
    "    # question_answer_pair[\"type\"] = \"wh\"\n",
    "    question_answer_pair[\"subject\"] = subject\n",
    "    question_answer_pair[\"relation\"] = relation\n",
    "    question_answer_pair[\"object\"] = object\n",
    "\n",
    "    relation_set = set()\n",
    "    for token in subject_doc:\n",
    "        relation_set.add(token.tag_)\n",
    "\n",
    "    object_to_interrogative = {\n",
    "        \"PERSON\": \"Who\",\n",
    "        \"DATE\": \"When\",\n",
    "    }\n",
    "\n",
    "    default_interrogative = \"What\"  # Default value      \n",
    "    interrogative = object_to_interrogative.get(object_type, default_interrogative)\n",
    "    if query_subject:\n",
    "        tmp = subject\n",
    "        subject = object\n",
    "        object = tmp\n",
    "\n",
    "    if subject_doc[0].tag_ == \"VBN\" and subject_doc[-1].tag_ == \"IN\" and all(token.tag_ not in [\"NN\", \"NNP\", \"NNPS\", \"NNS\"] for token in subject_doc[0:]):\n",
    "        if not query_subject:\n",
    "            if multi_hops == 1:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" was \" + subject + \" \" + relation + \"?\"\n",
    "                question_answer_pair[\"label\"] = object\n",
    "            else:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" was \" + subject \n",
    "                for i in range(multi_hops-1):\n",
    "                    question_answer_pair[\"question\"] += \"'s \" +  relation['edge_labels'][i] \n",
    "                question_answer_pair[\"question\"] += \" \"  + relation['edge_labels'][-1] + \"?\"\n",
    "                question_answer_pair[\"label\"] = object\n",
    "        else:\n",
    "            if multi_hops == 1:\n",
    "                if object_type != \"PERSON\":\n",
    "                    first_pair = next(iter(topic.items()))\n",
    "                    if first_pair[1] != \"revolution\":\n",
    "                        interrogative = \"Which \" + first_pair[1]\n",
    "                    else:\n",
    "                        interrogative = \"Which revolution or war\"\n",
    "                \n",
    "                question_answer_pair[\"question\"] = interrogative + \" was \" + relation + \" \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "            else:\n",
    "                first_pair = next(iter(topic.items()))\n",
    "                question_answer_pair[\"question\"] = interrogative \n",
    "                for i in range(multi_hops-1, 0, -1):\n",
    "                    if first_pair[1] == \"human\" and i == multi_hops-1:\n",
    "                        question_answer_pair[\"question\"] += \"se \" +  relation['edge_labels'][i]\n",
    "                    elif i == multi_hops-1:\n",
    "                        first_pair = next(iter(topic.items()))\n",
    "                        if first_pair[1] != \"revolution\":\n",
    "                            interrogative = \"Which \" + first_pair[1]\n",
    "                        else:\n",
    "                            interrogative = \"Which revolution or war\"\n",
    "                    else:\n",
    "                        question_answer_pair[\"question\"] += \" \" +  relation['edge_labels'][i]\n",
    "                question_answer_pair[\"question\"] += \" was \" + relation['edge_labels'][0] + \" \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "\n",
    "    elif subject_doc[0].tag_ == \"JJ\" and subject_doc[-1].tag_ == \"IN\" and all(token.tag_ not in [\"NN\", \"NNP\", \"NNPS\", \"NNS\"] for token in subject_doc[0:]):\n",
    "        if not query_subject:\n",
    "            if multi_hops == 1:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" is \" + subject + \" \"+ relation + \"?\"\n",
    "                question_answer_pair[\"label\"] = object\n",
    "            else:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" is \" + subject \n",
    "                for i in range(multi_hops-1):\n",
    "                    question_answer_pair[\"question\"] += \"'s \" +  relation['edge_labels'][i] \n",
    "                question_answer_pair[\"question\"] += \" \"  + relation['edge_labels'][-1] + \"?\"\n",
    "                question_answer_pair[\"label\"] = object\n",
    "        else:\n",
    "            if multi_hops == 1:\n",
    "                if object_type != \"PERSON\":\n",
    "                    first_pair = next(iter(topic.items()))\n",
    "                    if first_pair[1] != \"revolution\":\n",
    "                        interrogative = \"Which \" + first_pair[1]\n",
    "                    else:\n",
    "                        interrogative = \"Which revolution or war\"\n",
    "                question_answer_pair[\"question\"] = interrogative + \" is \" + \" \" + relation + \" \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "            else:\n",
    "                question_answer_pair[\"question\"] = interrogative \n",
    "                first_pair = next(iter(topic.items()))\n",
    "                for i in range(multi_hops-1, 0, -1):\n",
    "                    if first_pair[1] == \"human\" and i == multi_hops-1:\n",
    "                        question_answer_pair[\"question\"] += \"se \" +  relation['edge_labels'][i]\n",
    "                    elif i == multi_hops-1:\n",
    "                        first_pair = next(iter(topic.items()))\n",
    "                        if first_pair[1] != \"revolution\":\n",
    "                            interrogative = \"Which \" + first_pair[1]\n",
    "                        else:\n",
    "                            interrogative = \"Which revolution or war\"\n",
    "                    else:\n",
    "                        question_answer_pair[\"question\"] += \" \" +  relation['edge_labels'][i]\n",
    "                question_answer_pair[\"question\"] += \" is \"  + relation['edge_labels'][0] + \" \" + object + \"?\"\n",
    "            \n",
    "    elif subject_doc[0].tag_ == \"VBD\" and subject_doc[-1].tag_ not in [\"NN\", \"NNP\", \"NNPS\", \"NNS\"]:\n",
    "        if not query_subject:\n",
    "            if multi_hops == 1:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" did \" + subject + \" \" \n",
    "            else:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" did \" + subject\n",
    "                for i in range(multi_hops-1):\n",
    "                    question_answer_pair[\"question\"] += \"'s \" +  relation['edge_labels'][i] \n",
    "                question_answer_pair[\"question\"] += \" \" \n",
    "            for token in subject_doc:\n",
    "                if token.tag_ == \"VBD\":\n",
    "                    question_answer_pair[\"question\"] += token.lemma_ + \" \"\n",
    "                else:\n",
    "                    question_answer_pair[\"question\"] += token.text + \" \"\n",
    "            question_answer_pair[\"question\"] = question_answer_pair[\"question\"][:-1] + \"?\"\n",
    "            question_answer_pair[\"label\"] = object\n",
    "        else:\n",
    "            if multi_hops == 1:\n",
    "                if object_type != \"PERSON\":\n",
    "                    first_pair = next(iter(topic.items()))\n",
    "                    if first_pair[1] != \"revolution\":\n",
    "                        interrogative = \"Which \" + first_pair[1]\n",
    "                    else:\n",
    "                        interrogative = \"Which revolution or war\"\n",
    "                question_answer_pair[\"question\"] = interrogative + \" \" + relation + \" \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "            else:\n",
    "                first_pair = next(iter(topic.items()))\n",
    "                question_answer_pair[\"question\"] = interrogative \n",
    "                for i in range(multi_hops-1, 0, -1):\n",
    "                    if first_pair[1] == \"human\" and i == multi_hops-1:\n",
    "                        question_answer_pair[\"question\"] += \"se \" +  relation['edge_labels'][i]\n",
    "                    elif i == multi_hops-1:\n",
    "                        first_pair = next(iter(topic.items()))\n",
    "                        if first_pair[1] != \"revolution\":\n",
    "                            interrogative = \"Which \" + first_pair[1]\n",
    "                        else:\n",
    "                            interrogative = \"Which revolution or war\"\n",
    "                    else:\n",
    "                        question_answer_pair[\"question\"] += \" \" +  relation['edge_labels'][i]\n",
    "                question_answer_pair[\"question\"] += \" \"  + relation['edge_labels'][0] + \" \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "\n",
    "    elif (subject_doc[0].tag_ == \"VB\" or subject_doc[0].tag_ == \"VBZ\") and subject_doc[-1].tag_ not in [\"NN\", \"NNP\", \"NNPS\", \"NNS\"]:\n",
    "        if not query_subject:\n",
    "            if multi_hops == 1:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" does \" + subject + \" \"\n",
    "            else:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" does \" + subject \n",
    "                for i in range(multi_hops-1):\n",
    "                    question_answer_pair[\"question\"] += \"'s \" +  relation['edge_labels'][i] \n",
    "                question_answer_pair[\"question\"] += \" \" \n",
    "            for token in subject_doc:\n",
    "                if token.tag_ == \"VBZ\":\n",
    "                    question_answer_pair[\"question\"] += token.lemma_ + \" \"\n",
    "                else:\n",
    "                    question_answer_pair[\"question\"] += token.text + \" \"\n",
    "            question_answer_pair[\"question\"] = question_answer_pair[\"question\"][:-1] + \"?\"\n",
    "            question_answer_pair[\"label\"] = object\n",
    "        else:\n",
    "            if multi_hops == 1:\n",
    "                if object_type != \"PERSON\":\n",
    "                    first_pair = next(iter(topic.items()))\n",
    "                    if first_pair[1] != \"revolution\":\n",
    "                        interrogative = \"Which \" + first_pair[1]\n",
    "                    else:\n",
    "                        interrogative = \"Which revolution or war\"\n",
    "                question_answer_pair[\"question\"] = interrogative + \" \" + relation + \" \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "            else:\n",
    "                first_pair = next(iter(topic.items()))\n",
    "                question_answer_pair[\"question\"] = interrogative \n",
    "                for i in range(multi_hops-1, 0, -1):\n",
    "                    if first_pair[1] == \"human\" and i == multi_hops-1:\n",
    "                        question_answer_pair[\"question\"] += \"se \" +  relation['edge_labels'][i]\n",
    "                    elif i == multi_hops-1:\n",
    "                        first_pair = next(iter(topic.items()))\n",
    "                        if first_pair[1] != \"revolution\":\n",
    "                            interrogative = \"Which \" + first_pair[1]\n",
    "                        else:\n",
    "                            interrogative = \"Which revolution or war\"\n",
    "                    else:\n",
    "                        question_answer_pair[\"question\"] += \" \" +  relation['edge_labels'][i]\n",
    "                question_answer_pair[\"question\"] += \" \"  + relation['edge_labels'][0] + \" \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "\n",
    "    elif (subject_doc[-1].tag_ == \"NN\" or subject_doc[-1].tag_ == \"NNP\") and subject_doc[0].tag_ not in [\"VB\", \"VBZ\", \"VBD\"]: \n",
    "        if not query_subject:\n",
    "            if multi_hops == 1:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" is the \" + relation + \" of \" + subject + \"?\"\n",
    "                question_answer_pair[\"label\"] = object\n",
    "            else:\n",
    "                question_answer_pair[\"question\"] = interrogative + \" is the \" + relation['edge_labels'][1] + \" of \" + subject \n",
    "                for i in range(multi_hops-1):\n",
    "                    question_answer_pair[\"question\"] += \"'s \" + relation['edge_labels'][i] \n",
    "                question_answer_pair[\"question\"] += \"?\"\n",
    "                question_answer_pair[\"label\"] = object\n",
    "        else:\n",
    "            first_pair = next(iter(topic.items()))\n",
    "            if multi_hops == 1:\n",
    "                if first_pair[1] == \"human\":\n",
    "                    question_answer_pair[\"question\"] = interrogative + \"se \" + relation + \" is \" + object + \"?\"\n",
    "                else:\n",
    "                    first_pair = next(iter(topic.items()))\n",
    "                    if first_pair[1] != \"revolution\":\n",
    "                        interrogative = \"Which \" + first_pair[1]\n",
    "                    else:\n",
    "                        interrogative = \"Which revolution or war\"\n",
    "                    question_answer_pair[\"question\"] = interrogative + \"'s \" + relation + \" is \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "            else:\n",
    "                question_answer_pair[\"question\"] = interrogative \n",
    "                for i in range(multi_hops-1, -1, -1):\n",
    "                    if first_pair[1] == \"human\" and i == multi_hops-1:\n",
    "                        question_answer_pair[\"question\"] += \"se \" +  relation['edge_labels'][i]\n",
    "                    elif i == multi_hops-1:\n",
    "                        first_pair = next(iter(topic.items()))\n",
    "                        if first_pair[1] != \"revolution\":\n",
    "                            interrogative = \"Which \" + first_pair[1]\n",
    "                        else:\n",
    "                            interrogative = \"Which revolution or war\"\n",
    "                    else:\n",
    "                        question_answer_pair[\"question\"] += \"'s \" +  relation['edge_labels'][i]\n",
    "                question_answer_pair[\"question\"] += \" is \" + object + \"?\"\n",
    "                question_answer_pair[\"label\"] = subject\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return question_answer_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_eval = 'cuda:7'\n",
    "# model_id_eval = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# # model_id_eval = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# tok_eval = transformers.AutoTokenizer.from_pretrained(model_id_eval)\n",
    "# terminators = [tok_eval.eos_token_id, tok_eval.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "# model_eval = transformers.AutoModelForCausalLM.from_pretrained(model_id_eval, torch_dtype='auto').to(device_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_llama_3.1_8b_instruct\n",
      "file name: places_city_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:43<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (500, 8)\n",
      "file name: entertainment_song_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:48<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (1000, 8)\n",
      "file name: entertainment_anime_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/421 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 421/421 [02:15<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (1421, 8)\n",
      "file name: human_actor_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:53<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (1921, 8)\n",
      "file name: art_sculpture_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:56<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (2421, 8)\n",
      "file name: entertainment_music_genre_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (2921, 8)\n",
      "file name: art_literary_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:50<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (3421, 8)\n",
      "file name: places_landmark_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:55<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (3921, 8)\n",
      "file name: health_treatment_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/116 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 116/116 [00:42<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (4037, 8)\n",
      "file name: health_medication_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/314 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 314/314 [02:01<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (4351, 8)\n",
      "file name: event_sport_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:45<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (4851, 8)\n",
      "file name: event_history_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:56<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (5351, 8)\n",
      "file name: human_writer_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:42<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (5851, 8)\n",
      "file name: health_disease_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [03:06<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (6351, 8)\n",
      "file name: places_country_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:35<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (6851, 8)\n",
      "file name: human_politician_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:39<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (7351, 8)\n",
      "file name: event_film_questions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|| 500/500 [02:47<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_topics.shape: (7851, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get response for wh questions from data/questions_old/old_3_types\n",
    "print(model_id_format)\n",
    "df_all_topics = pd.DataFrame()\n",
    "\n",
    "for domain_topic_tmp in topic_ls:\n",
    "    # if domain_topic_tmp != 'places_landmark':\n",
    "    #     continue\n",
    "    print(f\"file name: {domain_topic_tmp}\")\n",
    "\n",
    "    ls_output = []\n",
    "    for i in tqdm(df_wh.index):\n",
    "        question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "        # user_msg_qa = Wh_content + \"\\nQuestion:\" + question  # places_landmark_old.csv\n",
    "        # user_msg_qa = f'Question: {question} Answer:'\n",
    "        user_msg_qa = f'{question}'\n",
    "        if model_id_format == 'gemma_2_9b_it':  # System role not supported for gemma\n",
    "            messages_qa = [{\"role\": \"user\", \"content\": system_msg_qa+' '+user_msg_qa}]\n",
    "        else:\n",
    "            messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": user_msg_qa}]\n",
    "        output_qa = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "        # if '\\n' in output_qa:\n",
    "            # print(f\"Question: {question} Label: {label} | Prediction: {repr(output_qa)}\")\n",
    "        # output_qa = output_qa.replace('\\n', ' ').strip().rstrip('.')  # remove trailing period for llama output\n",
    "        ls_output.append(output_qa)\n",
    "    \n",
    "    df_wh['topic'] = domain_topic_tmp\n",
    "    df_wh[f\"output_{model_id_format}\"] = ls_output\n",
    "    df_all_topics = pd.concat([df_all_topics, df_wh], axis=0)\n",
    "    print(\"df_all_topics.shape:\", df_all_topics.shape)\n",
    "        \n",
    "df_all_topics = df_all_topics[['topic', 'type', 'subject', 'relation', 'object', 'question', 'label', f'output_{model_id_format}']]\n",
    "df_all_topics.to_csv(f\"../data/questions/wh_only/all_topics_{model_id_format}.csv\", index=False)\n",
    "# del model_qa\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_json(f\"../data/questions/all_3_types/{domain_topic_name}_questions.json\", lines=True)\n",
    "# Only a small part of yes_no and MC questions have same subject, object, and relation as the hallucinated wh questions\n",
    "for i in df_wh_hallu.index[:]:\n",
    "    subject, relation, object = df_wh_hallu.loc[i, 'subject'], df_wh_hallu.loc[i, 'relation'], df_wh_hallu.loc[i, 'object']\n",
    "    df_other_type = df[(df.subject==subject) & (df.relation==relation) & (df.object==object) & (df.type!='wh')]\n",
    "    # print(len(df_other_type))\n",
    "    # Add yes_no and MC questions to the df_wh_hallu as new columns named 'question_yes_no' and 'question_MC'\n",
    "    for j in df_other_type.index:\n",
    "        other_type = df_other_type.loc[j, 'type']\n",
    "        df_wh_hallu.loc[i, f'question_{other_type}'] = df_other_type.loc[j, 'question']\n",
    "print(df_wh_hallu[df_wh_hallu.question_yes_no.notna() & df_wh_hallu.question_MC.notna()].shape)\n",
    "# df_wh_hallu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def load_api_key(key, file_path='api_key.json'):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data[key]\n",
    "\n",
    "# client = AzureOpenAI(api_key=load_api_key('api_key_east_us'), api_version='2023-05-15', azure_endpoint=\"https://east-us-one.openai.azure.com/\")\n",
    "client = AzureOpenAI(api_key=load_api_key('api_key_n_central_us'), api_version='2023-05-15', azure_endpoint=\"https://n-central-us.openai.azure.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>output_meta_llama_3.1_8b_instruct</th>\n",
       "      <th>eval_meta_llama_3.1_8b_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>places_city</td>\n",
       "      <td>wh</td>\n",
       "      <td>Novokuznetsk</td>\n",
       "      <td>twinned administrative body</td>\n",
       "      <td>Haifa</td>\n",
       "      <td>Which city's twinned administrative body is No...</td>\n",
       "      <td>Haifa</td>\n",
       "      <td>Kemerovo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>places_city</td>\n",
       "      <td>wh</td>\n",
       "      <td>Constana</td>\n",
       "      <td>located in/on physical feature</td>\n",
       "      <td>Dobruja</td>\n",
       "      <td>What is the located in/on physical feature of ...</td>\n",
       "      <td>Dobruja</td>\n",
       "      <td>Black Sea</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic type       subject                        relation   object  \\\n",
       "0  places_city   wh  Novokuznetsk     twinned administrative body    Haifa   \n",
       "1  places_city   wh     Constana  located in/on physical feature  Dobruja   \n",
       "\n",
       "                                            question    label  \\\n",
       "0  Which city's twinned administrative body is No...    Haifa   \n",
       "1  What is the located in/on physical feature of ...  Dobruja   \n",
       "\n",
       "  output_meta_llama_3.1_8b_instruct  eval_meta_llama_3.1_8b_instruct  \n",
       "0                          Kemerovo                              0.0  \n",
       "1                         Black Sea                              0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wh_hallu = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/meta_llama_3.1_8b_instruct_places_city.csv\")\n",
    "# df_wh_hallu = df_wh_hallu[df_wh_hallu.topic==topic_name]\n",
    "print(len(df_wh_hallu))\n",
    "df_wh_hallu.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC_content = \"The following question's topic is about \" + domain_topic_name + \". Choose the only correct option for the multiple choice problem. (Answer 'A', 'B', 'C' or 'D')(Don't explain)\"\n",
    "# yes_no_content = \"The following question's topic is about \" + domain_topic_name + \". Only need to answer 'Yes' or 'No', and don't explain\"\n",
    "# Wh_content = \"The following question's topic is about \" + domain_topic_name + \". Directly give me the answer in 'phrase' or 'word' format. Don't give me a sentence or explain\"\n",
    "\n",
    "# for filename in os.listdir(\"../data/questions/all_3_types/\"):\n",
    "#     if filename.endswith(\".json\"):\n",
    "#         df = pd.read_json(f\"../data/questions/all_3_types/{filename}\", lines=True)\n",
    "#         df_wh = df[df.type=='wh'].copy()\n",
    "#         topic_ls.append(filename.replace('_questions.json', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from data_prep import *\n",
    "from urllib.error import HTTPError\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: llama-3.1 will end answers with period '.'. mistral-v0.3 often end with new line '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c694c14cbc4f8e85bd80ba3baaf88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa63d73d3b7f4c7a97ac5e0ee0c44251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_qa = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "model_qa = transformers.AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where is the Cloud Gate located? Follow-up response: Chicago\n",
      "Question: Are you sure? Follow-up response: Yes\n",
      "Question: The answer is wrong. Please give the correct answer. Follow-up response: Millennium Park\n",
      "Question: The correct answer is Paris, isnt it? Follow-up response: No\n"
     ]
    }
   ],
   "source": [
    "# multi-turn conversation\n",
    "target = \"Paris\"\n",
    "question = \"Where is the Cloud Gate located?\"\n",
    "messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": question}]\n",
    "current_output = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "print(f\"Question: {question} Follow-up response: {current_output}\")\n",
    "\n",
    "# Add more follow-up questions in a loop\n",
    "follow_up_questions = [\n",
    "    \"Are you sure?\",\n",
    "    \"The answer is wrong. Please give the correct answer.\",\n",
    "    f\"The correct answer is {target}, isnt it?\",\n",
    "]\n",
    "\n",
    "for question in follow_up_questions:\n",
    "    messages_qa.append({\"role\": \"assistant\", \"content\": current_output})\n",
    "    messages_qa.append({\"role\": \"user\", \"content\": question})\n",
    "    current_output = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=32)\n",
    "    print(f\"Question: {question} Follow-up response: {current_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luang Prabang Province.\n",
      "Laos.\n",
      "Islamabad.\n",
      "Istanbul.\n",
      "Canada\n",
      "England.\n"
     ]
    }
   ],
   "source": [
    "# f'Question: {prompt_qa}. Answer:' makes a difference\n",
    "for prompt_qa in ['What is the located in the administrative territorial entity of Luang Prabang?', 'Which city was named after Islam?', 'What is the country of Windsor?']:\n",
    "    messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": f'Question: {prompt_qa}. Answer:'}]\n",
    "    output_qa = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "    print(output_qa)\n",
    "\n",
    "    messages_qa = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": prompt_qa}]\n",
    "    output_qa = get_response(model_qa, tok_qa, messages_qa, max_new_tokens=16)\n",
    "    print(output_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'question': 'Which city is twinned with Novokuznetsk?', 'options': {'A': 'Haifa', 'B': 'Kemerovo', 'C': 'Moscow', 'D': 'Saint Petersburg'}, 'ground_truth': 'A'}\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/meta_llama_3.1_8b_instruct_places_city.csv\")\n",
    "n = 2  #len(df)\n",
    "targets = df['label'].tolist()[:n]\n",
    "subjects = df['subject'].tolist()[:n]\n",
    "questions = df['question'].tolist()[:n]\n",
    "ls = df['multiple_choice_question'].tolist()\n",
    "# ls = [json.loads(i.replace(\"'\", '\"')) for i in ls]\n",
    "json.loads(\"\"\"{\"question\": \"Which city\"s official symbol is Ceiba speciosa?\"}\"\"\")\n",
    "\n",
    "# # load string as json, fix JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
    "# ls_mc = [json.loads(i.replace(\"'\", '\"')) for i in df['multiple_choice_question'].tolist()]\n",
    "# ls_mc_q = [i['question'] for i in ls_mc]\n",
    "# ls_mc_a = [i['ground_truth']+'. '+target for i, target in zip(ls_mc, targets)]\n",
    "ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'question': 'Which city is twinned with Novokuznetsk?', 'options': 'A': 'Haifa', 'B': 'Kemerovo', 'C': 'Moscow', 'D': 'Saint Petersburg' \n",
      " 'A'\n"
     ]
    }
   ],
   "source": [
    "e = ls[0]\n",
    "# split the e into 2 parts: question + opeions and ground_truth\n",
    "idx = e.find(\", 'ground_truth': \")\n",
    "question = e[:idx].replace(\"{\", '').replace(\"}\", '')\n",
    "ground_truth = e[idx+len(\", 'ground_truth': \"):].replace(\"}\", '', )\n",
    "print(question, '\\n', ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"instance of\": \"city\"}\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/topic/topic_places_city.json', 'r', encoding='utf-8') as topics_file:\n",
    "    topics = topics_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': {'type': 'uri',\n",
       "   'value': 'http://www.wikidata.org/prop/direct/P31'},\n",
       "  'subjectLabel': {'xml:lang': 'en',\n",
       "   'type': 'literal',\n",
       "   'value': 'Phoroctenia vittata'},\n",
       "  'objectLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'insect'}},\n",
       " {'relation': {'type': 'uri',\n",
       "   'value': 'http://www.wikidata.org/prop/direct/P105'},\n",
       "  'subjectLabel': {'xml:lang': 'en',\n",
       "   'type': 'literal',\n",
       "   'value': 'Phoroctenia vittata'},\n",
       "  'objectLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'species'}},\n",
       " {'relation': {'type': 'uri',\n",
       "   'value': 'http://www.wikidata.org/prop/direct/P31'},\n",
       "  'subjectLabel': {'xml:lang': 'en',\n",
       "   'type': 'literal',\n",
       "   'value': 'Phoroctenia vittata'},\n",
       "  'objectLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'taxon'}},\n",
       " {'relation': {'type': 'uri',\n",
       "   'value': 'http://www.wikidata.org/prop/direct/P171'},\n",
       "  'subjectLabel': {'xml:lang': 'en',\n",
       "   'type': 'literal',\n",
       "   'value': 'Phoroctenia vittata'},\n",
       "  'objectLabel': {'xml:lang': 'en',\n",
       "   'type': 'literal',\n",
       "   'value': 'Phoroctenia'}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['results']['bindings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len = len(results['results']['bindings'])\n",
    "# len = 0: [\"scientist\", \"invention\", \"animal species\", \"mineral\", \"athlete\", \"Olympic Games\", \"train\",  \"mathematics\", \n",
    "#             \"neuroscience\", \"robotics\", \"internet\", \"mobile phone\", \"3D printing\", \"bird\", \"academy awards\", \"movies\",\n",
    "#               \"movie\", \"grammy award\", 'netflix series', \"video games\", 'beverage', ]\n",
    "# len < 100: [ \"climate\", \"physics\", \"biology\", \"insect\", \"fish\", \"computer hardware\", \"plant\", \"sports team\", \"ecosystem\",\n",
    "#               'vehicle', 'airplane', 'bicycle', \"animal\", \"chemical compound\", \"astronomical object\", 'fruit', 'vegetable', 'cuisine', ]\n",
    "# Error code 500: [\"video game\", \"river\", \"protein\", 'ship', \"film\", \"human\", \"film\",  \"human\", \"mountain\", \"painting\", \"scientific journal\", \"gene\", \"album\",\n",
    "#                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: television series\n",
      "Topic Q5398426 has 50000 relations.\n",
      "\n",
      "Topic: music genre\n",
      "Topic Q188451 has 2988 relations.\n",
      "\n",
      "Topic: video game\n",
      "Error querying for Q7889: EndPointInternalError: The endpoint returned the HTTP status code 500. \n",
      "\n",
      "Response:\n",
      "b'SPARQL-QUERY: queryStr=\\n    SELECT ?subjectLabel ?relation ?objectLabel WHERE {\\n      ?subject wdt:P31 wd:Q7889.\\n      ?subject ?relation ?object.\\n      ?subject wikibase:identifiers ?subject_identifierCount.\\n      ?object wikibase:identifiers ?object_identifierCount.\\n      FILTER (?subject_identifierCount >= 8 && ?object_identifierCount >= 5) .  \\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\\n    }\\n    LIMIT 50000\\n    \\njava.util.concurrent.TimeoutException\\n\\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\\n\\tat com.bigdata.rdf.sail.webapp.BigdataServlet.submitApiTask(BigdataServlet.java:292)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doSparqlQuery(QueryServlet.java:678)\\n\\tat com.bigdata.rdf.sail.webapp.QueryServlet.doGet(QueryServlet.java:290)\\n\\tat com.bigdata.rdf.sail.webapp.RESTServlet.doGet(RESTServlet.java:240)\\n\\tat com.bigdata.rdf.sail.webapp.MultiTenancyServlet.doGet(MultiTenancyServlet.java:273)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:865)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1655)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.ThrottlingFilter.doFilter(ThrottlingFilter.java:322)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.throttling.SystemOverloadFilter.doFilter(SystemOverloadFilter.java:84)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat ch.qos.logback.classic.helpers.MDCInsertingServletFilter.doFilter(MDCInsertingServletFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.QueryEventSenderFilter.doFilter(QueryEventSenderFilter.java:123)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.ClientIPFilter.doFilter(ClientIPFilter.java:43)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.JWTIdentityFilter.doFilter(JWTIdentityFilter.java:66)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RealAgentFilter.doFilter(RealAgentFilter.java:33)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1642)\\n\\tat org.wikidata.query.rdf.blazegraph.filters.RequestConcurrencyFilter.doFilter(RequestConcurrencyFilter.java:50)\\n\\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1634)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:533)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:146)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:257)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1595)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:255)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1340)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:203)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:473)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1564)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:201)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1242)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:144)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:220)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:126)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:132)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:503)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:364)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:260)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:305)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:118)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:333)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:310)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:126)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:366)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:765)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:683)\\n\\tat java.lang.Thread.run(Thread.java:750)\\n'\n",
      "\n",
      "Topic: airline\n",
      "Topic Q46970 has 2847 relations.\n",
      "\n",
      "Topic: train\n",
      "Topic Q870 has 0 relations.\n",
      "\n",
      "Topic: song\n",
      "Topic Q7366 has 5153 relations.\n"
     ]
    }
   ],
   "source": [
    "topic_ls = [\"television series\", \"music genre\", \"anime\", \"music festival\", \"airline\", \"song\", \"scientific theory\", \"chemical element\", \"software\", \"ocean\", \"forest\", \n",
    "            \"disease\", \"university\", \"food\"]\n",
    "for topic in topic_ls:\n",
    "    topic_id = identifier_conversion(topic)\n",
    "    print(f\"\\nTopic: {topic}\")\n",
    "    check_topic(topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less than 500 \n",
    "food_and_drink_topics = [\"video game genre\", \"dish\"]\n",
    "for topic in food_and_drink_topics:\n",
    "    topic_id = identifier_conversion(topic)\n",
    "    print(f\"\\nTopic: {topic}\")\n",
    "    check_topic(topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_names = [\"disease\", \"chemical compound\", \"painting\", \"astronomical object\", \"scientific article\", \"gene\", \"mountain\", \"album\", \"scientific journal\"] # not tried\n",
    "\n",
    "topic_names = []\n",
    "for topic in topic_names:\n",
    "    topic_id = identifier_conversion(topic)\n",
    "    print(f\"\\nTopic: {topic}\")\n",
    "    check_topic(topic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[('On the Chersonese', 'oration', {'label': 'instance of'}), ('Against Timocrates', 'oration', {'label': 'instance of'}), ('On the Crown', 'oration', {'label': 'instance of'}), ('First Philippic', 'oration', {'label': 'instance of'}), ('Against Meidias', 'oration', {'label': 'instance of'}), ('On the False Embassy', 'oration', {'label': 'instance of'}), ('Against Aristocrates', 'oration', {'label': 'instance of'}), ('To Nicocles', 'oration', {'label': 'instance of'}), ('On the Murder of Eratosthenes', 'oration', {'label': 'instance of'}), ('Antidosis', 'oration', {'label': 'instance of'}), ('On the Peace', 'oration', {'label': 'instance of'}), ('Against Ctesiphon', 'oration', {'label': 'instance of'}), ('Panegyricus', 'oration', {'label': 'instance of'}), ('Catiline Orations', 'oration', {'label': 'genre'}), ('Against Leptines', 'oration', {'label': 'instance of'}), ('On the Embassy', 'oration', {'label': 'instance of'})]\n",
      "[('The Restaurant at the End of the Universe', 'Life, the Universe and Everything', {'label': 'followed by'}), ('So Long, and Thanks for All the Fish', 'Life, the Universe and Everything', {'label': 'follows'})]\n",
      "[('Life, the Universe and Everything', 'fantasy', {'label': 'genre'}), ('The Vampire Prince', 'fantasy', {'label': 'genre'}), ('Life of Pi', 'fantasy', {'label': 'genre'}), ('Spook Country', 'fantasy', {'label': 'genre'}), ('White Night', 'fantasy', {'label': 'genre'}), ('The Last Olympian', 'fantasy', {'label': 'genre'}), ('The Name of the Wind', 'fantasy', {'label': 'genre'}), ('Dragons of Autumn Twilight', 'fantasy', {'label': 'genre'}), ('The High Lord', 'fantasy', {'label': 'genre'}), ('A Clash of Kings', 'fantasy', {'label': 'genre'}), ('Harry Potter and the Prisoner of Azkaban', 'fantasy', {'label': 'genre'}), ('The Princess Bride', 'fantasy', {'label': 'genre'}), ('Prince Caspian', 'fantasy', {'label': 'genre'}), ('The Wonderful Wizard of Oz', 'fantasy', {'label': 'genre'}), ('The Witches', 'fantasy', {'label': 'genre'}), ('Artemis Fowl and the Arctic Incident', 'fantasy', {'label': 'genre'}), ('Artemis Fowl and the Eternity Code', 'fantasy', {'label': 'genre'}), ('The Lost Hero', 'fantasy', {'label': 'genre'}), ('The Sword of Shannara', 'fantasy', {'label': 'genre'}), ('The Screwtape Letters', 'fantasy', {'label': 'genre'}), ('The Witches of Eastwick', 'fantasy', {'label': 'genre'}), ('The Return of the King', 'fantasy', {'label': 'genre'}), (\"Gulliver's Travels\", 'fantasy', {'label': 'genre'}), ('Orlando: A Biography', 'fantasy', {'label': 'genre'}), ('The Silmarillion', 'fantasy', {'label': 'genre'}), ('The Hobbit', 'fantasy', {'label': 'genre'}), ('Witches Abroad', 'fantasy', {'label': 'genre'}), ('Neverwhere', 'fantasy', {'label': 'genre'}), ('Carmilla', 'fantasy', {'label': 'genre'}), ('The Novice', 'fantasy', {'label': 'genre'}), ('Wrath of a Mad God', 'fantasy', {'label': 'genre'}), ('The Red Pyramid', 'fantasy', {'label': 'genre'}), ('The Stand', 'fantasy', {'label': 'genre'}), ('Harry Potter and the Deathly Hallows', 'fantasy', {'label': 'genre'}), (\"The Serpent's Shadow\", 'fantasy', {'label': 'genre'}), ('The Martian Chronicles', 'fantasy', {'label': 'genre'}), ('Mort', 'fantasy', {'label': 'genre'}), ('The Ocean at the End of the Lane', 'fantasy', {'label': 'genre'}), ('A True Story', 'fantasy', {'label': 'genre'}), ('Hard-Boiled Wonderland and the End of the World', 'fantasy', {'label': 'genre'}), ('The Mists of Avalon', 'fantasy', {'label': 'genre'}), ('The Two Towers', 'fantasy', {'label': 'genre'}), (\"Harry Potter and the Philosopher's Stone\", 'fantasy', {'label': 'genre'}), ('Twenty Thousand Leagues Under the Sea', 'fantasy', {'label': 'genre'}), ('The Children of Hrin', 'fantasy', {'label': 'genre'}), ('The Alchemist', 'fantasy', {'label': 'genre'}), ('The Last Battle', 'fantasy', {'label': 'genre'}), ('Unfinished Tales', 'fantasy', {'label': 'genre'}), ('Through the Looking-Glass', 'fantasy', {'label': 'genre'}), ('Frankenstein; or, The Modern Prometheus', 'fantasy', {'label': 'genre'}), ('The Scions of Shannara', 'fantasy', {'label': 'genre'}), ('The Phantom of the Opera', 'fantasy', {'label': 'genre'}), ('Inkspell', 'fantasy', {'label': 'genre'}), ('Crown Duel', 'fantasy', {'label': 'genre'}), ('Stormrider', 'fantasy', {'label': 'genre'}), (\"The Titan's Curse\", 'fantasy', {'label': 'genre'}), ('Artemis Fowl', 'fantasy', {'label': 'genre'}), ('The Farthest Shore', 'fantasy', {'label': 'genre'}), ('She: A History of Adventure', 'fantasy', {'label': 'genre'}), ('The Marble Faun', 'fantasy', {'label': 'genre'}), ('A Wrinkle in Time', 'fantasy', {'label': 'genre'}), (\"The Magician's Nephew\", 'fantasy', {'label': 'genre'}), ('Abhorsen', 'fantasy', {'label': 'genre'}), ('Beyond the Deepwoods', 'fantasy', {'label': 'genre'}), ('The Lion, the Witch, and the Wardrobe', 'fantasy', {'label': 'genre'}), (\"The Devil's Elixirs\", 'fantasy', {'label': 'genre'}), ('The Slow Regard of Silent Things', 'fantasy', {'label': 'genre'}), ('The Dark Tower III: The Waste Lands', 'fantasy', {'label': 'genre'}), ('The Light Fantastic', 'fantasy', {'label': 'genre'}), ('The Carpet People', 'fantasy', {'label': 'genre'}), ('The Phantom Tollbooth', 'fantasy', {'label': 'genre'}), ('The Mysteries of Udolpho', 'fantasy', {'label': 'genre'}), ('Artemis Fowl and the Lost Colony', 'fantasy', {'label': 'genre'}), ('Pippi Longstocking', 'fantasy', {'label': 'genre'}), ('The Tales of Beedle the Bard', 'fantasy', {'label': 'genre'}), ('Dragons of Winter Night', 'fantasy', {'label': 'genre'}), ('The Short Second Life of Bree Tanner', 'fantasy', {'label': 'genre'}), ('Blue Moon', 'fantasy', {'label': 'genre'}), ('Harry Potter and the Half-Blood Prince', 'fantasy', {'label': 'genre'}), ('Tehanu', 'fantasy', {'label': 'genre'}), ('City of Bones', 'fantasy', {'label': 'genre'}), ('The Subtle Knife', 'fantasy', {'label': 'genre'}), ('The Sea of Monsters', 'fantasy', {'label': 'genre'}), ('A Wizard of Earthsea', 'fantasy', {'label': 'genre'}), ('Harry Potter and the Chamber of Secrets', 'fantasy', {'label': 'genre'}), ('The Battle of the Labyrinth', 'fantasy', {'label': 'genre'}), ('Harry Potter and the Order of the Phoenix', 'fantasy', {'label': 'genre'}), ('The Devil in Love', 'fantasy', {'label': 'genre'}), ('Bridge to Terabithia', 'fantasy', {'label': 'genre'}), ('Artemis Fowl and the Opal Deception', 'fantasy', {'label': 'genre'}), ('Jarka Ruus', 'fantasy', {'label': 'genre'}), ('Good Omens', 'fantasy', {'label': 'genre'}), ('Roverandom', 'fantasy', {'label': 'genre'}), ('The Eyes of the Dragon', 'fantasy', {'label': 'genre'}), ('Last Watch', 'fantasy', {'label': 'genre'}), (\"The Golem's Eye\", 'fantasy', {'label': 'genre'}), ('The Neverending Story', 'fantasy', {'label': 'genre'}), ('The Turn of the Screw', 'fantasy', {'label': 'genre'}), ('Harry Potter and the Goblet of Fire', 'fantasy', {'label': 'genre'}), ('Something Wicked This Way Comes', 'fantasy', {'label': 'genre'}), ('Reaper Man', 'fantasy', {'label': 'genre'}), ('The Tangle Box', 'fantasy', {'label': 'genre'}), (\"Assassin's Apprentice\", 'fantasy', {'label': 'genre'}), ('Grave Peril', 'fantasy', {'label': 'genre'}), ('New Atlantis', 'fantasy', {'label': 'genre'}), ('The Once and Future King', 'fantasy', {'label': 'genre'}), ('The Library of Babel', 'fantasy', {'label': 'genre'}), (\"Cugel's Saga\", 'fantasy', {'label': 'genre'}), ('Men at Arms', 'fantasy', {'label': 'genre'}), ('The Halloween Tree', 'fantasy', {'label': 'genre'}), ('The House of Hades', 'fantasy', {'label': 'genre'}), (\"Kiki's Delivery Service\", 'fantasy', {'label': 'genre'}), ('The Amber Spyglass', 'fantasy', {'label': 'genre'}), (\"Howl's Moving Castle\", 'fantasy', {'label': 'genre'}), ('Journey to the West', 'fantasy', {'label': 'genre'}), ('The Graveyard Book', 'fantasy', {'label': 'genre'}), ('The Mysterious Island', 'fantasy', {'label': 'genre'}), ('American Gods', 'fantasy', {'label': 'genre'}), ('The Fellowship of the Ring', 'fantasy', {'label': 'genre'}), (\"Lyra's Oxford\", 'fantasy', {'label': 'genre'}), ('A Game of Thrones', 'fantasy', {'label': 'genre'}), (\"A Connecticut Yankee in King Arthur's Court\", 'fantasy', {'label': 'genre'}), ('The Lightning Thief', 'fantasy', {'label': 'genre'}), ('The Lovely Bones', 'fantasy', {'label': 'genre'}), ('The Last Hero', 'fantasy', {'label': 'genre'}), ('Eclipse', 'fantasy', {'label': 'genre'}), ('Anansi Boys', 'fantasy', {'label': 'genre'}), ('Charlie and the Chocolate Factory', 'fantasy', {'label': 'genre'}), (\"Ronia the Robber's Daughter\", 'fantasy', {'label': 'genre'}), ('Ghost Story', 'fantasy', {'label': 'genre'}), ('The Dark Tower VII: The Dark Tower', 'fantasy', {'label': 'genre'}), ('Where the Wild Things Are', 'fantasy', {'label': 'genre'}), ('Watership Down', 'fantasy', {'label': 'genre'}), ('A Storm of Swords', 'fantasy', {'label': 'genre'})]\n",
      "[('Northangep Abbek', 'Persuasion', {'label': 'followed by'}), ('Persuasion', 'Persuasion', {'label': 'derivative work'})]\n",
      "[('Persuasion', 'United Kingdom', {'label': 'country of origin'}), (\"The Magician's Nephew\", 'United Kingdom', {'label': 'place of publication'}), ('Harry Potter and the Half-Blood Prince', 'United Kingdom', {'label': 'country of origin'}), ('Northern Lights', 'United Kingdom', {'label': 'country of origin'}), ('The Jungle Book', 'United Kingdom', {'label': 'place of publication'}), ('The Light Fantastic', 'United Kingdom', {'label': 'country of origin'}), ('The Picture of Dorian Gray', 'United Kingdom', {'label': 'narrative location'}), ('Till We Have Faces', 'United Kingdom', {'label': 'country of origin'}), ('Emma', 'United Kingdom', {'label': 'country of origin'}), (\"Lyra's Oxford\", 'United Kingdom', {'label': 'country of origin'}), ('Fifty Shades of Grey', 'United Kingdom', {'label': 'place of publication'}), ('She: A History of Adventure', 'United Kingdom', {'label': 'country of origin'}), ('Oliver Twist', 'United Kingdom', {'label': 'country of origin'}), ('Great Expectations', 'United Kingdom', {'label': 'country of origin'}), ('Lord of the Flies', 'United Kingdom', {'label': 'country of origin'}), ('The Wide Window', 'United Kingdom', {'label': 'country of origin'}), ('The Island of Dr Moreau', 'United Kingdom', {'label': 'country of origin'}), ('I, Claudius', 'United Kingdom', {'label': 'place of publication'}), ('The Hobbit', 'United Kingdom', {'label': 'country of origin'}), ('The Carpet People', 'United Kingdom', {'label': 'place of publication'}), ('Prince Caspian', 'United Kingdom', {'label': 'country of origin'}), ('The Return of the King', 'United Kingdom', {'label': 'country of origin'}), ('Treasure Island', 'United Kingdom', {'label': 'country of origin'}), ('Use of Weapons', 'United Kingdom', {'label': 'country of origin'}), ('Infernal Devices', 'United Kingdom', {'label': 'country of origin'}), ('The Scarlet Pimpernel', 'United Kingdom', {'label': 'country of origin'}), (\"Montezuma's Daughter\", 'United Kingdom', {'label': 'country of origin'}), ('Class Warfare', 'United Kingdom', {'label': 'country of origin'}), ('Things as They Are; or, The Adventures of Caleb Williams', 'United Kingdom', {'label': 'country of origin'}), ('Never Let Me Go', 'United Kingdom', {'label': 'country of origin'}), ('Absolute Friends', 'United Kingdom', {'label': 'country of origin'}), ('A Study in Scarlet', 'United Kingdom', {'label': 'place of publication'}), ('The Spy Who Came in from the Cold', 'United Kingdom', {'label': 'country of origin'}), ('Monsignor Quixote', 'United Kingdom', {'label': 'country of origin'}), ('Strange Case of Dr Jekyll and Mr Hyde', 'United Kingdom', {'label': 'country of origin'}), ('The Wind in the Willows', 'United Kingdom', {'label': 'country of origin'}), (\"Childhood's End\", 'United Kingdom', {'label': 'country of origin'}), ('Witches Abroad', 'United Kingdom', {'label': 'country of origin'}), (\"Howl's Moving Castle\", 'United Kingdom', {'label': 'country of origin'}), ('Brave New World', 'United Kingdom', {'label': 'country of origin'}), ('The Book of Dave', 'United Kingdom', {'label': 'country of origin'}), ('The Invisible Man', 'United Kingdom', {'label': 'country of origin'}), ('Rendezvous with Rama', 'United Kingdom', {'label': 'country of origin'}), (\"Harry Potter and the Philosopher's Stone\", 'United Kingdom', {'label': 'narrative location'}), ('Anthills of the Savannah', 'United Kingdom', {'label': 'place of publication'}), ('2061: Odyssey Three', 'United Kingdom', {'label': 'country of origin'}), ('The Songs of Distant Earth', 'United Kingdom', {'label': 'country of origin'}), ('Mansfield Park', 'United Kingdom', {'label': 'country of origin'}), ('The Fellowship of the Ring', 'United Kingdom', {'label': 'country of origin'}), ('Through the Looking-Glass', 'United Kingdom', {'label': 'country of origin'}), ('Reaper Man', 'United Kingdom', {'label': 'country of origin'}), ('The Amber Spyglass', 'United Kingdom', {'label': 'country of origin'}), ('Harry Potter and the Order of the Phoenix', 'United Kingdom', {'label': 'country of origin'}), ('Nineteen Eighty-Four', 'United Kingdom', {'label': 'country of origin'}), ('Good Omens', 'United Kingdom', {'label': 'country of origin'}), ('Tinker Tailor Soldier Spy', 'United Kingdom', {'label': 'country of origin'}), ('Harry Potter and the Goblet of Fire', 'United Kingdom', {'label': 'country of origin'}), ('Roverandom', 'United Kingdom', {'label': 'country of origin'}), ('Stormrider', 'United Kingdom', {'label': 'country of origin'}), ('Guinness World Records', 'United Kingdom', {'label': 'country of origin'}), ('Mostly Harmless', 'United Kingdom', {'label': 'country of origin'}), ('The Sign of Four', 'United Kingdom', {'label': 'country of origin'}), ('The Last Battle', 'United Kingdom', {'label': 'place of publication'}), ('The Memoirs of a Survivor', 'United Kingdom', {'label': 'country of origin'}), ('Ivanhoe', 'United Kingdom', {'label': 'country of origin'}), ('The Lion, the Witch, and the Wardrobe', 'United Kingdom', {'label': 'country of origin'}), ('The City and the Stars', 'United Kingdom', {'label': 'country of origin'}), ('Coraline', 'United Kingdom', {'label': 'country of origin'}), ('The Player of Games', 'United Kingdom', {'label': 'country of origin'}), ('The Last Days of Pompeii', 'United Kingdom', {'label': 'country of origin'}), ('Matilda', 'United Kingdom', {'label': 'country of origin'}), ('The Power and the Glory', 'United Kingdom', {'label': 'country of origin'}), ('Rama II', 'United Kingdom', {'label': 'country of origin'}), (\"The Golem's Eye\", 'United Kingdom', {'label': 'country of origin'}), ('The Silmarillion', 'United Kingdom', {'label': 'country of origin'}), ('Fanny Hill', 'United Kingdom', {'label': 'country of origin'}), ('A Clockwork Orange', 'United Kingdom', {'label': 'country of origin'}), ('Island', 'United Kingdom', {'label': 'country of origin'}), ('Moon Over Soho', 'United Kingdom', {'label': 'country of origin'}), ('The Mill on the Floss', 'United Kingdom', {'label': 'country of origin'}), ('Sense and Sensibility', 'United Kingdom', {'label': 'country of origin'}), (\"King Solomon's Mines\", 'United Kingdom', {'label': 'place of publication'}), ('Three Men in a Boat', 'United Kingdom', {'label': 'country of origin'}), ('The Last Hero', 'United Kingdom', {'label': 'country of origin'}), ('Orlando: A Biography', 'United Kingdom', {'label': 'country of origin'}), ('Carmilla', 'United Kingdom', {'label': 'country of origin'}), ('Beyond the Deepwoods', 'United Kingdom', {'label': 'country of origin'}), ('Harry Potter and the Chamber of Secrets', 'United Kingdom', {'label': 'country of origin'}), ('Political Justice', 'United Kingdom', {'label': 'country of origin'}), (\"Time's Arrow\", 'United Kingdom', {'label': 'country of origin'}), ('Men at Arms', 'United Kingdom', {'label': 'country of origin'}), ('Altered Carbon', 'United Kingdom', {'label': 'place of publication'}), ('Kidnapped', 'United Kingdom', {'label': 'country of origin'}), ('The Screwtape Letters', 'United Kingdom', {'label': 'country of origin'}), ('The Graveyard Book', 'United Kingdom', {'label': 'country of origin'}), ('Anansi Boys', 'United Kingdom', {'label': 'country of origin'}), ('Architectural Stained Glass', 'United Kingdom', {'label': 'country of origin'}), ('The Dark Side of the Sun', 'United Kingdom', {'label': 'country of origin'}), ('Vanity Fair', 'United Kingdom', {'label': 'country of origin'}), ('So Long, and Thanks for All the Fish', 'United Kingdom', {'label': 'country of origin'}), ('Charlie and the Chocolate Factory', 'United Kingdom', {'label': 'country of origin'}), ('The Time Machine: An Invention', 'United Kingdom', {'label': 'country of origin'}), ('Neverwhere', 'United Kingdom', {'label': 'country of origin'}), ('The Hound of the Baskervilles', 'United Kingdom', {'label': 'country of origin'}), ('Good-Bye to All That', 'United Kingdom', {'label': 'country of origin'}), ('The Mysterious Affair at Styles', 'United Kingdom', {'label': 'country of origin'}), (\"Gulliver's Travels\", 'United Kingdom', {'label': 'country of origin'}), ('Harry Potter and the Deathly Hallows', 'United Kingdom', {'label': 'country of origin'}), ('The War of the Worlds', 'United Kingdom', {'label': 'country of origin'}), ('Black Beauty', 'United Kingdom', {'label': 'country of origin'}), ('The Witches', 'United Kingdom', {'label': 'country of origin'}), ('Mrs Dalloway', 'United Kingdom', {'label': 'country of origin'}), ('Pride and Prejudice', 'United Kingdom', {'label': 'country of origin'}), ('And Then There Were None', 'United Kingdom', {'label': 'place of publication'}), ('Out of Africa', 'United Kingdom', {'label': 'country of origin'}), ('The Subtle Knife', 'United Kingdom', {'label': 'country of origin'}), ('The Turn of the Screw', 'United Kingdom', {'label': 'country of origin'}), ('Fatherland', 'United Kingdom', {'label': 'country of origin'}), ('The Secret Garden', 'United Kingdom', {'label': 'country of origin'}), ('The Two Towers', 'United Kingdom', {'label': 'country of origin'}), ('Darkness at Noon', 'United Kingdom', {'label': 'country of origin'}), ('My Philosophical Development', 'United Kingdom', {'label': 'country of origin'}), (\"Alice's Adventures in Wonderland\", 'United Kingdom', {'label': 'country of origin'}), ('Mort', 'United Kingdom', {'label': 'country of origin'}), ('The Vampire Prince', 'United Kingdom', {'label': 'country of origin'}), ('Life, the Universe and Everything', 'United Kingdom', {'label': 'country of origin'}), ('The Tales of Beedle the Bard', 'United Kingdom', {'label': 'country of origin'}), ('The Once and Future King', 'United Kingdom', {'label': 'country of origin'}), ('The Worst Journey in the World', 'United Kingdom', {'label': 'country of origin'}), ('Northangep Abbek', 'United Kingdom', {'label': 'country of origin'}), ('Harry Potter and the Prisoner of Azkaban', 'United Kingdom', {'label': 'country of origin'}), ('Unfinished Tales', 'United Kingdom', {'label': 'country of origin'}), ('The Mysteries of Udolpho', 'United Kingdom', {'label': 'country of origin'}), ('The Day of the Triffids', 'United Kingdom', {'label': 'place of publication'}), ('A Dream of John Ball', 'United Kingdom', {'label': 'country of origin'}), (\"Midnight's Children\", 'United Kingdom', {'label': 'country of origin'}), ('American Gods', 'United Kingdom', {'label': 'country of origin'}), ('The Children of Hrin', 'United Kingdom', {'label': 'country of origin'}), ('The Restaurant at the End of the Universe', 'United Kingdom', {'label': 'country of origin'}), ('Point Counter Point', 'United Kingdom', {'label': 'country of origin'}), ('A Tale of Two Cities', 'United Kingdom', {'label': 'country of origin'}), ('The Expedition of Humphry Clinker', 'United Kingdom', {'label': 'country of origin'}), (\"All Tomorrow's Parties\", 'United Kingdom', {'label': 'country of origin'}), ('New Atlantis', 'United Kingdom', {'label': 'country of origin'}), ('The Casual Vacancy', 'United Kingdom', {'label': 'country of origin'}), (\"Dirk Gently's Holistic Detective Agency\", 'United Kingdom', {'label': 'country of origin'}), ('Star Maker', 'United Kingdom', {'label': 'country of origin'}), (\"The Razor's Edge\", 'United Kingdom', {'label': 'country of origin'}), ('Robinson Crusoe', 'United Kingdom', {'label': 'country of origin'})]\n",
      "[]\n",
      "[('De Alexandri Magni fortuna aut virtute', 'Plutarch', {'label': 'author'}), ('De liberis educandis', 'Plutarch', {'label': 'author'}), ('De facie in orbe Lunae', 'Plutarch', {'label': 'author'}), ('Isis and Osiris', 'Plutarch', {'label': 'author'}), ('Quaestiones convivales', 'Plutarch', {'label': 'author'}), ('Quomodo adolescens poetas audire debeat', 'Plutarch', {'label': 'author'}), ('De mulierum virtutibus', 'Plutarch', {'label': 'author'}), ('Parallel Lives', 'Plutarch', {'label': 'author'}), ('Moralia', 'Plutarch', {'label': 'author'})]\n",
      "[]\n",
      "[('Perry Rhodan', 'Walter Ernsting', {'label': 'author'})]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'instance of': [('On the Chersonese', 'oration', {'label': 'instance of'}),\n",
       "  ('Against Timocrates', 'oration', {'label': 'instance of'}),\n",
       "  ('On the Crown', 'oration', {'label': 'instance of'}),\n",
       "  ('First Philippic', 'oration', {'label': 'instance of'}),\n",
       "  ('Against Meidias', 'oration', {'label': 'instance of'}),\n",
       "  ('On the False Embassy', 'oration', {'label': 'instance of'}),\n",
       "  ('Against Aristocrates', 'oration', {'label': 'instance of'}),\n",
       "  ('To Nicocles', 'oration', {'label': 'instance of'}),\n",
       "  ('On the Murder of Eratosthenes', 'oration', {'label': 'instance of'}),\n",
       "  ('Antidosis', 'oration', {'label': 'instance of'}),\n",
       "  ('On the Peace', 'oration', {'label': 'instance of'}),\n",
       "  ('Against Ctesiphon', 'oration', {'label': 'instance of'}),\n",
       "  ('Panegyricus', 'oration', {'label': 'instance of'}),\n",
       "  ('Against Leptines', 'oration', {'label': 'instance of'}),\n",
       "  ('On the Embassy', 'oration', {'label': 'instance of'})],\n",
       " 'genre': [('Catiline Orations', 'oration', {'label': 'genre'}),\n",
       "  ('Life, the Universe and Everything', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Vampire Prince', 'fantasy', {'label': 'genre'}),\n",
       "  ('Life of Pi', 'fantasy', {'label': 'genre'}),\n",
       "  ('Spook Country', 'fantasy', {'label': 'genre'}),\n",
       "  ('White Night', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Last Olympian', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Name of the Wind', 'fantasy', {'label': 'genre'}),\n",
       "  ('Dragons of Autumn Twilight', 'fantasy', {'label': 'genre'}),\n",
       "  ('The High Lord', 'fantasy', {'label': 'genre'}),\n",
       "  ('A Clash of Kings', 'fantasy', {'label': 'genre'}),\n",
       "  ('Harry Potter and the Prisoner of Azkaban', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Princess Bride', 'fantasy', {'label': 'genre'}),\n",
       "  ('Prince Caspian', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Wonderful Wizard of Oz', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Witches', 'fantasy', {'label': 'genre'}),\n",
       "  ('Artemis Fowl and the Arctic Incident', 'fantasy', {'label': 'genre'}),\n",
       "  ('Artemis Fowl and the Eternity Code', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Lost Hero', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Sword of Shannara', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Screwtape Letters', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Witches of Eastwick', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Return of the King', 'fantasy', {'label': 'genre'}),\n",
       "  (\"Gulliver's Travels\", 'fantasy', {'label': 'genre'}),\n",
       "  ('Orlando: A Biography', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Silmarillion', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Hobbit', 'fantasy', {'label': 'genre'}),\n",
       "  ('Witches Abroad', 'fantasy', {'label': 'genre'}),\n",
       "  ('Neverwhere', 'fantasy', {'label': 'genre'}),\n",
       "  ('Carmilla', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Novice', 'fantasy', {'label': 'genre'}),\n",
       "  ('Wrath of a Mad God', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Red Pyramid', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Stand', 'fantasy', {'label': 'genre'}),\n",
       "  ('Harry Potter and the Deathly Hallows', 'fantasy', {'label': 'genre'}),\n",
       "  (\"The Serpent's Shadow\", 'fantasy', {'label': 'genre'}),\n",
       "  ('The Martian Chronicles', 'fantasy', {'label': 'genre'}),\n",
       "  ('Mort', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Ocean at the End of the Lane', 'fantasy', {'label': 'genre'}),\n",
       "  ('A True Story', 'fantasy', {'label': 'genre'}),\n",
       "  ('Hard-Boiled Wonderland and the End of the World',\n",
       "   'fantasy',\n",
       "   {'label': 'genre'}),\n",
       "  ('The Mists of Avalon', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Two Towers', 'fantasy', {'label': 'genre'}),\n",
       "  (\"Harry Potter and the Philosopher's Stone\", 'fantasy', {'label': 'genre'}),\n",
       "  ('Twenty Thousand Leagues Under the Sea', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Children of Hrin', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Alchemist', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Last Battle', 'fantasy', {'label': 'genre'}),\n",
       "  ('Unfinished Tales', 'fantasy', {'label': 'genre'}),\n",
       "  ('Through the Looking-Glass', 'fantasy', {'label': 'genre'}),\n",
       "  ('Frankenstein; or, The Modern Prometheus', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Scions of Shannara', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Phantom of the Opera', 'fantasy', {'label': 'genre'}),\n",
       "  ('Inkspell', 'fantasy', {'label': 'genre'}),\n",
       "  ('Crown Duel', 'fantasy', {'label': 'genre'}),\n",
       "  ('Stormrider', 'fantasy', {'label': 'genre'}),\n",
       "  (\"The Titan's Curse\", 'fantasy', {'label': 'genre'}),\n",
       "  ('Artemis Fowl', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Farthest Shore', 'fantasy', {'label': 'genre'}),\n",
       "  ('She: A History of Adventure', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Marble Faun', 'fantasy', {'label': 'genre'}),\n",
       "  ('A Wrinkle in Time', 'fantasy', {'label': 'genre'}),\n",
       "  (\"The Magician's Nephew\", 'fantasy', {'label': 'genre'}),\n",
       "  ('Abhorsen', 'fantasy', {'label': 'genre'}),\n",
       "  ('Beyond the Deepwoods', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Lion, the Witch, and the Wardrobe', 'fantasy', {'label': 'genre'}),\n",
       "  (\"The Devil's Elixirs\", 'fantasy', {'label': 'genre'}),\n",
       "  ('The Slow Regard of Silent Things', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Dark Tower III: The Waste Lands', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Light Fantastic', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Carpet People', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Phantom Tollbooth', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Mysteries of Udolpho', 'fantasy', {'label': 'genre'}),\n",
       "  ('Artemis Fowl and the Lost Colony', 'fantasy', {'label': 'genre'}),\n",
       "  ('Pippi Longstocking', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Tales of Beedle the Bard', 'fantasy', {'label': 'genre'}),\n",
       "  ('Dragons of Winter Night', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Short Second Life of Bree Tanner', 'fantasy', {'label': 'genre'}),\n",
       "  ('Blue Moon', 'fantasy', {'label': 'genre'}),\n",
       "  ('Harry Potter and the Half-Blood Prince', 'fantasy', {'label': 'genre'}),\n",
       "  ('Tehanu', 'fantasy', {'label': 'genre'}),\n",
       "  ('City of Bones', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Subtle Knife', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Sea of Monsters', 'fantasy', {'label': 'genre'}),\n",
       "  ('A Wizard of Earthsea', 'fantasy', {'label': 'genre'}),\n",
       "  ('Harry Potter and the Chamber of Secrets', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Battle of the Labyrinth', 'fantasy', {'label': 'genre'}),\n",
       "  ('Harry Potter and the Order of the Phoenix', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Devil in Love', 'fantasy', {'label': 'genre'}),\n",
       "  ('Bridge to Terabithia', 'fantasy', {'label': 'genre'}),\n",
       "  ('Artemis Fowl and the Opal Deception', 'fantasy', {'label': 'genre'}),\n",
       "  ('Jarka Ruus', 'fantasy', {'label': 'genre'}),\n",
       "  ('Good Omens', 'fantasy', {'label': 'genre'}),\n",
       "  ('Roverandom', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Eyes of the Dragon', 'fantasy', {'label': 'genre'}),\n",
       "  ('Last Watch', 'fantasy', {'label': 'genre'}),\n",
       "  (\"The Golem's Eye\", 'fantasy', {'label': 'genre'}),\n",
       "  ('The Neverending Story', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Turn of the Screw', 'fantasy', {'label': 'genre'}),\n",
       "  ('Harry Potter and the Goblet of Fire', 'fantasy', {'label': 'genre'}),\n",
       "  ('Something Wicked This Way Comes', 'fantasy', {'label': 'genre'}),\n",
       "  ('Reaper Man', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Tangle Box', 'fantasy', {'label': 'genre'}),\n",
       "  (\"Assassin's Apprentice\", 'fantasy', {'label': 'genre'}),\n",
       "  ('Grave Peril', 'fantasy', {'label': 'genre'}),\n",
       "  ('New Atlantis', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Once and Future King', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Library of Babel', 'fantasy', {'label': 'genre'}),\n",
       "  (\"Cugel's Saga\", 'fantasy', {'label': 'genre'}),\n",
       "  ('Men at Arms', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Halloween Tree', 'fantasy', {'label': 'genre'}),\n",
       "  ('The House of Hades', 'fantasy', {'label': 'genre'}),\n",
       "  (\"Kiki's Delivery Service\", 'fantasy', {'label': 'genre'}),\n",
       "  ('The Amber Spyglass', 'fantasy', {'label': 'genre'}),\n",
       "  (\"Howl's Moving Castle\", 'fantasy', {'label': 'genre'}),\n",
       "  ('Journey to the West', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Graveyard Book', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Mysterious Island', 'fantasy', {'label': 'genre'}),\n",
       "  ('American Gods', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Fellowship of the Ring', 'fantasy', {'label': 'genre'}),\n",
       "  (\"Lyra's Oxford\", 'fantasy', {'label': 'genre'}),\n",
       "  ('A Game of Thrones', 'fantasy', {'label': 'genre'}),\n",
       "  (\"A Connecticut Yankee in King Arthur's Court\",\n",
       "   'fantasy',\n",
       "   {'label': 'genre'}),\n",
       "  ('The Lightning Thief', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Lovely Bones', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Last Hero', 'fantasy', {'label': 'genre'}),\n",
       "  ('Eclipse', 'fantasy', {'label': 'genre'}),\n",
       "  ('Anansi Boys', 'fantasy', {'label': 'genre'}),\n",
       "  ('Charlie and the Chocolate Factory', 'fantasy', {'label': 'genre'}),\n",
       "  (\"Ronia the Robber's Daughter\", 'fantasy', {'label': 'genre'}),\n",
       "  ('Ghost Story', 'fantasy', {'label': 'genre'}),\n",
       "  ('The Dark Tower VII: The Dark Tower', 'fantasy', {'label': 'genre'}),\n",
       "  ('Where the Wild Things Are', 'fantasy', {'label': 'genre'}),\n",
       "  ('Watership Down', 'fantasy', {'label': 'genre'}),\n",
       "  ('A Storm of Swords', 'fantasy', {'label': 'genre'})],\n",
       " 'followed by': [('The Restaurant at the End of the Universe',\n",
       "   'Life, the Universe and Everything',\n",
       "   {'label': 'followed by'}),\n",
       "  ('Northangep Abbek', 'Persuasion', {'label': 'followed by'})],\n",
       " 'follows': [('So Long, and Thanks for All the Fish',\n",
       "   'Life, the Universe and Everything',\n",
       "   {'label': 'follows'})],\n",
       " 'derivative work': [('Persuasion',\n",
       "   'Persuasion',\n",
       "   {'label': 'derivative work'})],\n",
       " 'country of origin': [('Persuasion',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Harry Potter and the Half-Blood Prince',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Northern Lights', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Light Fantastic', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Till We Have Faces', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Emma', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  (\"Lyra's Oxford\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('She: A History of Adventure',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Oliver Twist', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Great Expectations', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Lord of the Flies', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Wide Window', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Island of Dr Moreau',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The Hobbit', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Prince Caspian', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Return of the King', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Treasure Island', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Use of Weapons', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Infernal Devices', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Scarlet Pimpernel', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  (\"Montezuma's Daughter\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Class Warfare', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Things as They Are; or, The Adventures of Caleb Williams',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Never Let Me Go', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Absolute Friends', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Spy Who Came in from the Cold',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Monsignor Quixote', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Strange Case of Dr Jekyll and Mr Hyde',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The Wind in the Willows',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  (\"Childhood's End\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Witches Abroad', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  (\"Howl's Moving Castle\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Brave New World', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Book of Dave', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Invisible Man', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Rendezvous with Rama', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('2061: Odyssey Three', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Songs of Distant Earth',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Mansfield Park', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Fellowship of the Ring',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Through the Looking-Glass',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Reaper Man', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Amber Spyglass', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Harry Potter and the Order of the Phoenix',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Nineteen Eighty-Four', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Good Omens', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Tinker Tailor Soldier Spy',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Harry Potter and the Goblet of Fire',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Roverandom', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Stormrider', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Guinness World Records', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Mostly Harmless', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Sign of Four', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Memoirs of a Survivor',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Ivanhoe', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Lion, the Witch, and the Wardrobe',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The City and the Stars', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Coraline', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Player of Games', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Last Days of Pompeii',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Matilda', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Power and the Glory',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Rama II', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  (\"The Golem's Eye\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Silmarillion', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Fanny Hill', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('A Clockwork Orange', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Island', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Moon Over Soho', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Mill on the Floss', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Sense and Sensibility', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Three Men in a Boat', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Last Hero', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Orlando: A Biography', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Carmilla', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Beyond the Deepwoods', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Harry Potter and the Chamber of Secrets',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Political Justice', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  (\"Time's Arrow\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Men at Arms', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Kidnapped', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Screwtape Letters', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Graveyard Book', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Anansi Boys', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Architectural Stained Glass',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The Dark Side of the Sun',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Vanity Fair', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('So Long, and Thanks for All the Fish',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Charlie and the Chocolate Factory',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The Time Machine: An Invention',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Neverwhere', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Hound of the Baskervilles',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Good-Bye to All That', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Mysterious Affair at Styles',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  (\"Gulliver's Travels\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Harry Potter and the Deathly Hallows',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The War of the Worlds', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Black Beauty', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Witches', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Mrs Dalloway', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Pride and Prejudice', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Out of Africa', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Subtle Knife', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Turn of the Screw', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Fatherland', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Secret Garden', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Two Towers', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Darkness at Noon', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('My Philosophical Development',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  (\"Alice's Adventures in Wonderland\",\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Mort', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Vampire Prince', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Life, the Universe and Everything',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The Tales of Beedle the Bard',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The Once and Future King',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('The Worst Journey in the World',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Northangep Abbek', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Harry Potter and the Prisoner of Azkaban',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Unfinished Tales', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Mysteries of Udolpho',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('A Dream of John Ball', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  (\"Midnight's Children\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('American Gods', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Children of Hrin', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Restaurant at the End of the Universe',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Point Counter Point', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('A Tale of Two Cities', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Expedition of Humphry Clinker',\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  (\"All Tomorrow's Parties\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('New Atlantis', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('The Casual Vacancy', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  (\"Dirk Gently's Holistic Detective Agency\",\n",
       "   'United Kingdom',\n",
       "   {'label': 'country of origin'}),\n",
       "  ('Star Maker', 'United Kingdom', {'label': 'country of origin'}),\n",
       "  (\"The Razor's Edge\", 'United Kingdom', {'label': 'country of origin'}),\n",
       "  ('Robinson Crusoe', 'United Kingdom', {'label': 'country of origin'})],\n",
       " 'place of publication': [(\"The Magician's Nephew\",\n",
       "   'United Kingdom',\n",
       "   {'label': 'place of publication'}),\n",
       "  ('The Jungle Book', 'United Kingdom', {'label': 'place of publication'}),\n",
       "  ('Fifty Shades of Grey',\n",
       "   'United Kingdom',\n",
       "   {'label': 'place of publication'}),\n",
       "  ('I, Claudius', 'United Kingdom', {'label': 'place of publication'}),\n",
       "  ('The Carpet People', 'United Kingdom', {'label': 'place of publication'}),\n",
       "  ('A Study in Scarlet', 'United Kingdom', {'label': 'place of publication'}),\n",
       "  ('Anthills of the Savannah',\n",
       "   'United Kingdom',\n",
       "   {'label': 'place of publication'}),\n",
       "  ('The Last Battle', 'United Kingdom', {'label': 'place of publication'}),\n",
       "  (\"King Solomon's Mines\",\n",
       "   'United Kingdom',\n",
       "   {'label': 'place of publication'}),\n",
       "  ('Altered Carbon', 'United Kingdom', {'label': 'place of publication'}),\n",
       "  ('And Then There Were None',\n",
       "   'United Kingdom',\n",
       "   {'label': 'place of publication'}),\n",
       "  ('The Day of the Triffids',\n",
       "   'United Kingdom',\n",
       "   {'label': 'place of publication'})],\n",
       " 'narrative location': [('The Picture of Dorian Gray',\n",
       "   'United Kingdom',\n",
       "   {'label': 'narrative location'}),\n",
       "  (\"Harry Potter and the Philosopher's Stone\",\n",
       "   'United Kingdom',\n",
       "   {'label': 'narrative location'})],\n",
       " 'author': [('De Alexandri Magni fortuna aut virtute',\n",
       "   'Plutarch',\n",
       "   {'label': 'author'}),\n",
       "  ('De liberis educandis', 'Plutarch', {'label': 'author'}),\n",
       "  ('De facie in orbe Lunae', 'Plutarch', {'label': 'author'}),\n",
       "  ('Isis and Osiris', 'Plutarch', {'label': 'author'}),\n",
       "  ('Quaestiones convivales', 'Plutarch', {'label': 'author'}),\n",
       "  ('Quomodo adolescens poetas audire debeat', 'Plutarch', {'label': 'author'}),\n",
       "  ('De mulierum virtutibus', 'Plutarch', {'label': 'author'}),\n",
       "  ('Parallel Lives', 'Plutarch', {'label': 'author'}),\n",
       "  ('Moralia', 'Plutarch', {'label': 'author'}),\n",
       "  ('Perry Rhodan', 'Walter Ernsting', {'label': 'author'})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/graph/literary_graph.gpickle', 'rb') as f:\n",
    "    directed_graph = pickle.load(f)\n",
    "\n",
    "relation_set = {}\n",
    "for node in list(directed_graph.nodes())[:10]:\n",
    "    in_edges = directed_graph.in_edges(node, data=True)\n",
    "    print(in_edges)\n",
    "    for edge in in_edges:\n",
    "        if relation_set.get(edge[2]['label']) is None:\n",
    "            relation_set[edge[2]['label']] = [edge]\n",
    "        else:\n",
    "            relation_set[edge[2]['label']].append(edge)\n",
    "print()\n",
    "relation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hops = 2\n",
    "MC_number = 10\n",
    "limit_nodes = 10\n",
    "df_wh_hallu = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/meta_llama_3.1_8b_instruct.csv\")\n",
    "input_nodes = df_wh_hallu.subject.tolist()  # nodes to generate multi-hop questions for\n",
    "input_relations = df_wh_hallu.relation.tolist()  # nodes to generate multi-hop questions for\n",
    "remove_relation = [\"topic's main category\", \"topic's main template\", \"described by source\", \"Commons category\", \"on focus list of Wikimedia project\"]\n",
    "\n",
    "    \n",
    "def MC_question_generation(subject, relation, object):\n",
    "    question_answer_pair = {}\n",
    "    if not question_answer_pair:\n",
    "        return None\n",
    "\n",
    "    question_answer_pair[\"type\"] = \"MC\"\n",
    "    question_answer_pair[\"subject\"] = subject\n",
    "    question_answer_pair[\"relation\"] = relation\n",
    "    question_answer_pair[\"object\"] = object\n",
    "    # question_answer_pair[\"label\"] = object\n",
    "    return question_answer_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_info: {'node path': ['White Tower', 'Tower of London', 'Tower Bridge'], 'edge_labels': ['has part(s)', 'named after']}\n",
      "path_info: {'node path': ['Ictinus', 'Parthenon', 'Acropolis of Athens'], 'edge_labels': ['architect', 'has part(s)']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', 'Epiphany'], 'edge_labels': ['has part(s)', 'closed on']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', \"All Saints' Day\"], 'edge_labels': ['has part(s)', 'closed on']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', 'toilet'], 'edge_labels': ['has part(s)', 'has facility']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', 'Easter Monday'], 'edge_labels': ['has part(s)', 'closed on']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', 'castle'], 'edge_labels': ['has part(s)', 'instance of']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', 'Feast of Corpus Christi'], 'edge_labels': ['has part(s)', 'closed on']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', 'Gothic art'], 'edge_labels': ['has part(s)', 'architectural style']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', 'Easter'], 'edge_labels': ['has part(s)', 'closed on']}\n",
      "path_info: {'node path': ['Museum of the Masovian Nobility in Ciechanw', 'Castle of the Masovian Dukes in Ciechanw', 'January 1'], 'edge_labels': ['has part(s)', 'closed on']}\n",
      "path_info: {'node path': ['Easter Monday', 'Castle of the Masovian Dukes in Ciechanw', 'Museum of the Masovian Nobility in Ciechanw'], 'edge_labels': ['closed on', 'has part(s)']}\n",
      "path_info: {'node path': ['Easter', 'Castle of the Masovian Dukes in Ciechanw', 'Museum of the Masovian Nobility in Ciechanw'], 'edge_labels': ['closed on', 'has part(s)']}\n",
      "path_info: {'node path': [\"St Mark's Campanile\", \"St Mark's Basilica\", 'Piazza San Marco'], 'edge_labels': ['has part(s)', 'named after']}\n"
     ]
    }
   ],
   "source": [
    "with open('../data/graph/landmark_graph.gpickle', 'rb') as f:\n",
    "    directed_graph = pickle.load(f)\n",
    "\n",
    "relation_set = {}\n",
    "# for node in directed_graph.nodes():\n",
    "for node in input_nodes:\n",
    "    in_edges = directed_graph.in_edges(node, data=True)\n",
    "    for edge in in_edges:\n",
    "        if relation_set.get(edge[2]['label']) is None:\n",
    "            relation_set[edge[2]['label']] = [edge]\n",
    "        else:\n",
    "            relation_set[edge[2]['label']].append(edge)\n",
    "\n",
    "MC_question_set = []\n",
    "MC_flag = False\n",
    "for i, source_node in enumerate(input_nodes[:]):\n",
    "    # print(f\"source_node: {source_node}\")\n",
    "    for node, path in nx.single_source_shortest_path(directed_graph, source_node, cutoff=hops).items():\n",
    "        if len(path) == hops+1:\n",
    "            # Retrieve the edge labels based on the path\n",
    "            edge_labels = [directed_graph[path[i]][path[i+1]]['label'] for i in range(len(path)-1)]\n",
    "            if input_relations[i] == edge_labels[0]:\n",
    "                path_info = {'node path': path[:], 'edge_labels': edge_labels}\n",
    "                print(f\"path_info: {path_info}\")\n",
    "    \n",
    "    for node, path in nx.single_source_shortest_path(directed_graph.reverse(), source_node, cutoff=hops).items():\n",
    "        if len(path) == hops+1:\n",
    "            # Retrieve the edge labels based on the path\n",
    "            edge_labels = [directed_graph.reverse()[path[i]][path[i+1]]['label'] for i in range(len(path)-1)]\n",
    "            if input_relations[i] == edge_labels[0]:\n",
    "                path_info = {'node path': path[:], 'edge_labels': edge_labels}\n",
    "                print(f\"path_info: {path_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\")]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'tourist attraction')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'tourist attraction'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Feast of Corpus Christi')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'tourist attraction'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Feast of Corpus Christi'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'architectural style', 'Gothic art')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'tourist attraction'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Feast of Corpus Christi'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'architectural style', 'Gothic art'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'tourist attraction'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Feast of Corpus Christi'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'architectural style', 'Gothic art'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'archaeological museum')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'tourist attraction'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Feast of Corpus Christi'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'architectural style', 'Gothic art'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'archaeological museum'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'January 1')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'tourist attraction'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Feast of Corpus Christi'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'architectural style', 'Gothic art'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'archaeological museum'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'January 1'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Monday')]\n",
      "two_hop_paths: [('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Epiphany'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', \"All Saints' Day\"), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'country', 'Poland'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'activity policy in this place', 'smoking ban'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'has facility', 'toilet'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'payment types accepted', 'cash'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'castle'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'tourist attraction'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Feast of Corpus Christi'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'architectural style', 'Gothic art'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Easter'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'instance of', 'archaeological museum'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'January 1'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'closed on', 'Monday'), ('Museum of the Masovian Nobility in Ciechanw', 'has part(s)', 'Castle of the Masovian Dukes in Ciechanw', 'located in the administrative territorial entity', 'Ciechanw')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Greece': [],\n",
       " 'Panathenaic Stadium': [],\n",
       " 'Deloitte': [],\n",
       " 'Rosersberg Palace': [],\n",
       " 'Melliea': [],\n",
       " 'Gustavianum': [],\n",
       " 'Prayerbook Cross': [],\n",
       " 'Haw Par Villa': [],\n",
       " 'Carlos Oswald': [],\n",
       " 'Tsarskoye Selo': [],\n",
       " 'Kungsholmen': [],\n",
       " 'Gta lv': [],\n",
       " 'Sedefkar Mehmed Agha': [],\n",
       " 'Alfred Parland': [],\n",
       " 'Hundertwasserhaus': [],\n",
       " 'Grand Kremlin Palace': [],\n",
       " 'Stourton with Gasper': [],\n",
       " 'Sunset Strip': [],\n",
       " 'zmir Clock Tower': [],\n",
       " 'Tor Hagfors': [],\n",
       " \"Gustav III's Pavilion\": [],\n",
       " 'Potala Palace': [],\n",
       " 'Saviour Church on Nereditsa': [],\n",
       " 'South Street Seaport': [],\n",
       " 'Louis de Hom de Marien': [],\n",
       " 'Rothenburg ob der Tauber': [],\n",
       " 'Konya Province': [],\n",
       " 'Now You See Me 2': [],\n",
       " 'Abu Dhabi': [],\n",
       " 'Taj Mahal': [],\n",
       " 'Kane County': [],\n",
       " 'Little Rock': [],\n",
       " 'Prague Castle': [],\n",
       " 'Works Progress Administration': [],\n",
       " 'National Garden of Athens': [],\n",
       " 'Yucca gloriosa': [],\n",
       " 'Bayezid I': [],\n",
       " 'Cambridge': [],\n",
       " 'Ushaw College': [],\n",
       " 'Henry VII': [],\n",
       " 'Washingtonia filifera': [],\n",
       " 'Peter Walker': [],\n",
       " 'Yusupov Palace on Moika': [],\n",
       " 'Teton County': [],\n",
       " 'Meteor Crater': [],\n",
       " 'Kirk R. Johnson': [],\n",
       " 'Sentosa': [],\n",
       " 'funeral': [],\n",
       " 'drapery': [],\n",
       " 'George VI': [],\n",
       " 'Disneyland': [],\n",
       " 'Central Park': [],\n",
       " 'Colosseum': [],\n",
       " 'Skanska': [],\n",
       " 'Bartolommeo Berrecci': [],\n",
       " 'Tsaritsyno Park': [],\n",
       " 'The Bank of New York Mellon': [],\n",
       " 'Kamikochi': [],\n",
       " 'Gran Canaria': [],\n",
       " 'Justinian I': [],\n",
       " 'Beijing': [],\n",
       " 'Nrdlingen': [],\n",
       " \"St Paul's Cathedral\": [],\n",
       " 'paint': [],\n",
       " 'Bodo Ebhardt': [],\n",
       " 'Aksaray Province': [],\n",
       " 'Visby': [],\n",
       " 'Daniel Burnham': [],\n",
       " 'The Church of Jesus Christ of Latter-day Saints': [],\n",
       " 'war memorial': [],\n",
       " 'Chamaerops humilis': [],\n",
       " 'Schlaich Bergermann Partner': [],\n",
       " 'repouss': [],\n",
       " 'Independence National Historical Park': [],\n",
       " 'Bangkok': [],\n",
       " 'antiprism': [],\n",
       " 'navel': [],\n",
       " 'Willis Tower': [],\n",
       " 'Jan Styka': [],\n",
       " 'Person of Interest, season 2': [],\n",
       " \"Gustav III's museum of antiquities\": [],\n",
       " 'White Tower': [],\n",
       " 'Moscow': [],\n",
       " 'Abbaye de la Fille-Dieu Romont': [],\n",
       " 'Chteau de Montsoreau-Museum of Contemporary Art': [],\n",
       " 'Ahmed I': [],\n",
       " 'National Museum of Natural History': [],\n",
       " 'North Sea': [],\n",
       " 'Linkping Cathedral': [],\n",
       " 'Stonehenge': [],\n",
       " 'Karlstad Cathedral': [],\n",
       " 'Jardin du Luxembourg': [],\n",
       " 'Mnchner Altstadt': [],\n",
       " 'Naples': [],\n",
       " 'Skokloster Castle': [],\n",
       " 'Government of New South Wales': [],\n",
       " 'George IV of the United Kingdom': [],\n",
       " 'South Dakota': [],\n",
       " 'Ford, Powell & Carson': [],\n",
       " 'Hawaiian Volcano Observatory': [],\n",
       " 'Grampian Mountains': [],\n",
       " 'Orange County': [],\n",
       " 'book': [],\n",
       " 'Pinus canariensis': [],\n",
       " 'Girolamo Cassar': [],\n",
       " 'Leander': [],\n",
       " 'Dresden Zoo': [],\n",
       " 'Jean-Nicolas Jadot de Ville-Issey': [],\n",
       " 'Ankara Province': [],\n",
       " 'stersund Municipality': [],\n",
       " 'mercury': [],\n",
       " 'Antonio Bernocchi': [],\n",
       " \"Disney's Blizzard Beach\": [],\n",
       " 'Korea Development Bank': [],\n",
       " 'Haga park': [],\n",
       " 'Burj Khalifa': [],\n",
       " 'Royal Mile': [],\n",
       " 'Roman Abramovich': [],\n",
       " 'California Academy of Sciences': [],\n",
       " 'Stein Olav Henrichsen': [],\n",
       " 'Santa Rosa Island, Florida': [],\n",
       " 'Epidavros Municipality': [],\n",
       " 'Detroit': [],\n",
       " 'County Kerry': [],\n",
       " 'Luigi Canonica': [],\n",
       " 'Cloud Gate': [],\n",
       " 'Balboa Park': [],\n",
       " 'Roly Keating': [],\n",
       " \"Fondo per l'Ambiente Italiano\": [],\n",
       " 'Stockholm Municipality': [],\n",
       " 'Ictinus': [],\n",
       " 'Ulriksdal Palace': [],\n",
       " 'Roman Forum': [],\n",
       " 'Dmitz Fortress': [],\n",
       " 'classicism': [],\n",
       " \"St Mark's Basilica\": [],\n",
       " 'Mariefred': [],\n",
       " 'Altare della Patria': [],\n",
       " 'bulletproof glass': [],\n",
       " 'Harburg': [],\n",
       " 'Philippe Maille': [],\n",
       " 'Charles Franois de Mondion': [],\n",
       " 'Mount Ararat': [],\n",
       " 'National Portrait Gallery of Sweden': [],\n",
       " 'Bosporus': [],\n",
       " \"Saint-Germain-l'Auxerrois\": [],\n",
       " 'Garage Center for Contemporary Culture': [],\n",
       " 'Bavarian Administration of State-Owned Palaces, Gardens and Lakes': [],\n",
       " 'Daniel Libeskind': [],\n",
       " 'Justus Vingboons': [],\n",
       " 'Greenwich': [],\n",
       " 'Surabaya': [],\n",
       " 'Lambeth': [],\n",
       " 'Commerzbank AG': [],\n",
       " 'Mount Faber': [],\n",
       " 'avenue du Maine': [],\n",
       " 'Charles Follen McKim': [],\n",
       " 'Yldz Palace': [],\n",
       " 'Drottningholm Palace': [],\n",
       " 'Jakob Nielsen': [],\n",
       " 'Kenneth Murray': [],\n",
       " 'concert hall': [],\n",
       " 'English Heritage': [],\n",
       " 'Strand': [],\n",
       " 'Museum of the Masovian Nobility in Ciechanw': [],\n",
       " 'John McShain': [],\n",
       " 'Royal Observatory': [],\n",
       " '17th arrondissement of Paris': [],\n",
       " 'dome': [],\n",
       " 'Mount Fuji': [],\n",
       " 'Humboldt County': [],\n",
       " 'Leskovac': [],\n",
       " 'Helsinki Parish Union': [],\n",
       " 'University of Central Florida': [],\n",
       " 'Domvs Romana': [],\n",
       " 'neoclassicism': [],\n",
       " 'gneiss': [],\n",
       " 'Tendai': [],\n",
       " 'Qinghai': [],\n",
       " 'Belm Tower': [],\n",
       " 'Helgeandsholmen': [],\n",
       " 'Platz der Republik': [],\n",
       " 'transport': [],\n",
       " 'sand': [],\n",
       " 'Centro de Arte Moderna Gulbenkian': [],\n",
       " 'Easter Monday': [],\n",
       " 'Moscow Planetarium': [],\n",
       " 'Easter': [],\n",
       " 'Frank Lloyd Wright': [],\n",
       " 'Hermitage Museum': [],\n",
       " 'Knigsberg Cathedral': [],\n",
       " 'Strngns Cathedral': [],\n",
       " 'Gateway Arch': [],\n",
       " 'Falun': [],\n",
       " 'Palace Embankment': [],\n",
       " 'Antwerp Zoo': [],\n",
       " 'demolition': [],\n",
       " 'Linnanmki': [],\n",
       " 'Petronas Towers': [],\n",
       " 'World War II': [],\n",
       " 'Henry II of England': [],\n",
       " 'Santa Fe': [],\n",
       " 'Hornblower & Marshall': [],\n",
       " 'Fort Canning Hill': [],\n",
       " 'Pierre de Chelles': [],\n",
       " 'contemporary art': [],\n",
       " 'Colen Campbell': [],\n",
       " 'Nemrut': [],\n",
       " 'Maurice de Sully': [],\n",
       " 'Ancient Egypt': [],\n",
       " 'Fernsehturm Berlin': [],\n",
       " 'Dasha Zhukova': [],\n",
       " 'Ferdinand I of the Two Sicilies': [],\n",
       " 'Jurong East': [],\n",
       " 'Carlos J. Gradin': [],\n",
       " 'Montparnasse  Bienvene': [],\n",
       " 'John J. Borg': [],\n",
       " 'Southbank Centre': [],\n",
       " 'Mecca': [],\n",
       " 'Paolo Giulierini': [],\n",
       " \"Grandmaster's Palace\": [],\n",
       " 'Theater Confidencen': [],\n",
       " 'MUNCH': [],\n",
       " 'Bridget of Sweden': [],\n",
       " 'Smithsonian Marine Station at Fort Pierce': [],\n",
       " \"St Mark's Campanile\": []}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_2_hop_paths(kg, input_nodes, input_relations):\n",
    "    result = {}\n",
    "    for i, node in enumerate(input_nodes):\n",
    "        two_hop_paths = []\n",
    "        # First hop\n",
    "        for neighbor1 in kg.neighbors(node):\n",
    "            # print(f\"neighbor1: {neighbor1}\")\n",
    "            # Check if the relation (edge) between node and neighbor1 is in input_relations\n",
    "            if kg.has_edge(node, neighbor1):\n",
    "                relation1 = kg.edges[node, neighbor1]['label']\n",
    "                if relation1 == input_relations[i]:\n",
    "                    # print(f\"neighbor1: {neighbor1}, relation1: {relation1}\")\n",
    "                    # Second hop\n",
    "                    for neighbor2 in kg.neighbors(neighbor1):\n",
    "                        if kg.has_edge(neighbor1, neighbor2):\n",
    "                            relation2 = kg.edges[neighbor1, neighbor2]['label']\n",
    "                            two_hop_paths.append((node, relation1, neighbor1, relation2, neighbor2))\n",
    "                            print(f\"two_hop_paths: {two_hop_paths}\")\n",
    "\n",
    "        result[node] = two_hop_paths\n",
    "    return result\n",
    "find_2_hop_paths(directed_graph, input_nodes, input_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e83176bfa84e0897715022a0626ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d408fd9c5aa44b6684ed0bb716a6d5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Apple'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "device = 'cuda:5'\n",
    "model_id_eval = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "tok = AutoTokenizer.from_pretrained(model_id_eval)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id_eval, torch_dtype='auto').to(device)\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"you're an assistant\"}, {\"role\": \"user\", \"content\": \"Who controls the Apple company?\"}]\n",
    "msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt')\n",
    "output_ids = model.generate(msg_tokenized.to(device), max_new_tokens=2, do_sample=False, pad_token_id=tok.eos_token_id)\n",
    "tok.decode(output_ids[0][msg_tokenized.shape[-1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_tokenized['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('<|begin_of_text|>Who controls the Apple company? The Apple company is a publicly traded company, listed on the NAS',\n",
       " ' The Apple company is a publicly traded company, listed on the NAS')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_tokenized = tok(\"Who controls the Apple company?\", return_tensors='pt')\n",
    "output_ids = model.generate(**msg_tokenized.to(device))\n",
    "# tok.decode(output_ids[0][msg_tokenized.shape[-1]:], skip_special_tokens=True)\n",
    "tok.decode(output_ids[0]), tok.decode(output_ids[0][msg_tokenized['input_ids'].shape[-1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question\\n##ting-edge provides: March 122\\n\\nTopic's: 02 Dec 2023\\n\\nThe are a AI toassistant\\n\\nI is the internet Watch?assistant\\n\\nThe\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# msg_tokenized = tok(\"Who is the US president\", return_tensors='pt').to(device)\n",
    "messages = [{\"role\": \"system\", \"content\": \"you're an assistant\"}, {\"role\": \"user\", \"content\": \"Who controls the Apple company?\"}]\n",
    "msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt', return_dict=True).to(device)\n",
    "outputs = model(**msg_tokenized)\n",
    "if type(outputs) is torch.Tensor:\n",
    "    logits = outputs\n",
    "else:\n",
    "    logits = outputs.logits\n",
    "answers = torch.argmax(logits, dim=-1)\n",
    "tok.decode(answers[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
       "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
       "            220,   1627,  10263,    220,   2366,     19,    271,   9514,   2351,\n",
       "            459,  18328, 128009, 128006,    882, 128007,    271,  15546,  11835,\n",
       "            279,   8325,   2883,     30, 128009, 128006,  78191, 128007,    271]],\n",
       "       device='cuda:5'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:5')}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"you're an assistant\"}, {\"role\": \"user\", \"content\": \"Who controls the Apple company?\"}]\n",
    "msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt', return_dict=True).to(device)\n",
    "msg_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question<|start_header_id|>\\n<|start_header_id|>##ting-edge provides: March 122\\n\\nTopic's: 02 Dec 2023\\n\\nThe are a AI to<|start_header_id|>assistant<|start_header_id|>\\n\\nI is the internet Watch?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**msg_tokenized)\n",
    "if type(outputs) is torch.Tensor:\n",
    "    logits = outputs\n",
    "else:\n",
    "    logits = outputs.logits\n",
    "\n",
    "for i in\n",
    "next_token_logits = [:, -1, :]  # Logits for the next token\n",
    "next_token = torch.argmax(next_token_logits, dim=-1)  # Get the token with the highest probability\n",
    "\n",
    "# Decode the token to string\n",
    "tok.decode(next_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_topics = pd.DataFrame()\n",
    "for filename in os.listdir(\"../data/questions/wh_only/mistral_7b_instruct_v0.3\"):\n",
    "    tmp = pd.read_csv(f\"../data/questions/wh_only/mistral_7b_instruct_v0.3/{filename}\")\n",
    "    tmp['topic'] = domain_topic_name\n",
    "    df_all_topics = pd.concat([df_all_topics, tmp], axis=0)\n",
    "    print(filename, df_all_topics.shape)\n",
    "\n",
    "df_all_topics = df_all_topics['topic', 'type', 'subject', 'relation', 'object', 'question', 'label', f'output_{model_id_format}']\n",
    "df_all_topics.to_csv(f\"../data/questions/wh_only/all_topics_{model_id_format}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(f\"../data/questions/{topic_name}_questions.json\", lines=True)\n",
    "df_wh = df[df.type=='wh'].copy()\n",
    "len(df), len(df_wh)\n",
    "\n",
    "ls_output = []\n",
    "for i in tqdm(df_wh.index):\n",
    "    question_type = df_wh.loc[i, 'type']\n",
    "    question, label = df_wh.loc[i, 'question'], df_wh.loc[i, 'label']\n",
    "    if question_type == \"MC\":\n",
    "        current_prompt = MC_content + \"\\nQuestion:\" + question \n",
    "    elif question_type == \"yes_no\":\n",
    "        current_prompt = yes_no_content + \"\\nQuestion:\" + question\n",
    "    else:\n",
    "        current_prompt = Wh_content + \"\\nQuestion:\" + question\n",
    "        \n",
    "    messages = [{\"role\": \"system\", \"content\": system_msg_qa}, {\"role\": \"user\", \"content\": current_prompt}]\n",
    "    msg_tokenized = tok.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt')\n",
    "    output_ids = model.generate(msg_tokenized.to(device), max_new_tokens=32, eos_token_id=terminators, do_sample=False, pad_token_id=tok.eos_token_id)\n",
    "    output_decoded = tok.decode(output_ids[0][msg_tokenized.shape[-1]:], skip_special_tokens=True)\n",
    "    ls_output.append(output_decoded)\n",
    "    # print(f\"Question: {question} Label: {label} | Prediction: {output_decoded}\")\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "df_wh[f\"output_{model_id_format}\"] = ls_output\n",
    "df_wh.to_csv(f\"../data/questions/wh_only/{topic_name}_{model_id_format}.csv\", index=False)\n",
    "df_wh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # if not os.path.exists(f\"../data/questions/wh_only/{model_id_format}\"):\n",
    "        #     os.makedirs(f\"../data/questions/wh_only/{model_id_format}\")\n",
    "        # df_wh.to_csv(f\"../data/questions/wh_only/{model_id_format}/{domain_topic_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007613658905029297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2030e887047845deacc5b1f648ba36af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0027933120727539062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2219155fd4e247bd8b75c7fd02aaf6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n",
      "model | LlamaModel(\n",
      "  (embed_tokens): Embedding(128256, 4096)\n",
      "  (layers): ModuleList(\n",
      "    (0-31): 32 x LlamaDecoderLayer(\n",
      "      (self_attn): LlamaSdpaAttention(\n",
      "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (mlp): LlamaMLP(\n",
      "        (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "        (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "        (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "      (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    )\n",
      "  )\n",
      "  (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.embed_tokens | Embedding(128256, 4096)\n",
      "model.layers | ModuleList(\n",
      "  (0-31): 32 x LlamaDecoderLayer(\n",
      "    (self_attn): LlamaSdpaAttention(\n",
      "      (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "      (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "      (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      (rotary_emb): LlamaRotaryEmbedding()\n",
      "    )\n",
      "    (mlp): LlamaMLP(\n",
      "      (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "      (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "      (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "      (act_fn): SiLU()\n",
      "    )\n",
      "    (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "    (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  )\n",
      ")\n",
      "model.layers.0 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.0.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.0.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.0.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.0.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.0.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.0.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.0.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.0.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.0.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.0.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.0.mlp.act_fn | SiLU()\n",
      "model.layers.0.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.0.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.1 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.1.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.1.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.1.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.1.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.1.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.1.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.1.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.1.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.1.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.1.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.1.mlp.act_fn | SiLU()\n",
      "model.layers.1.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.1.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.2 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.2.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.2.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.2.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.2.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.2.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.2.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.2.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.2.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.2.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.2.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.2.mlp.act_fn | SiLU()\n",
      "model.layers.2.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.2.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.3 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.3.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.3.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.3.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.3.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.3.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.3.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.3.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.3.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.3.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.3.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.3.mlp.act_fn | SiLU()\n",
      "model.layers.3.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.3.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.4 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.4.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.4.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.4.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.4.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.4.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.4.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.4.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.4.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.4.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.4.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.4.mlp.act_fn | SiLU()\n",
      "model.layers.4.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.4.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.5 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.5.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.5.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.5.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.5.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.5.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.5.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.5.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.5.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.5.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.5.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.5.mlp.act_fn | SiLU()\n",
      "model.layers.5.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.5.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.6 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.6.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.6.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.6.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.6.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.6.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.6.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.6.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.6.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.6.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.6.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.6.mlp.act_fn | SiLU()\n",
      "model.layers.6.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.6.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.7 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.7.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.7.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.7.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.7.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.7.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.7.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.7.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.7.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.7.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.7.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.7.mlp.act_fn | SiLU()\n",
      "model.layers.7.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.7.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.8 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.8.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.8.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.8.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.8.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.8.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.8.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.8.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.8.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.8.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.8.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.8.mlp.act_fn | SiLU()\n",
      "model.layers.8.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.8.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.9 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.9.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.9.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.9.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.9.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.9.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.9.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.9.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.9.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.9.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.9.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.9.mlp.act_fn | SiLU()\n",
      "model.layers.9.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.9.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.10 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.10.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.10.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.10.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.10.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.10.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.10.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.10.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.10.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.10.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.10.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.10.mlp.act_fn | SiLU()\n",
      "model.layers.10.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.10.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.11 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.11.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.11.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.11.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.11.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.11.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.11.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.11.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.11.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.11.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.11.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.11.mlp.act_fn | SiLU()\n",
      "model.layers.11.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.11.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.12 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.12.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.12.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.12.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.12.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.12.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.12.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.12.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.12.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.12.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.12.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.12.mlp.act_fn | SiLU()\n",
      "model.layers.12.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.12.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.13 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.13.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.13.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.13.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.13.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.13.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.13.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.13.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.13.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.13.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.13.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.13.mlp.act_fn | SiLU()\n",
      "model.layers.13.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.13.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.14 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.14.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.14.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.14.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.14.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.14.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.14.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.14.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.14.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.14.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.14.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.14.mlp.act_fn | SiLU()\n",
      "model.layers.14.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.14.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.15 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.15.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.15.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.15.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.15.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.15.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.15.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.15.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.15.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.15.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.15.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.15.mlp.act_fn | SiLU()\n",
      "model.layers.15.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.15.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.16 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.16.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.16.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.16.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.16.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.16.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.16.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.16.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.16.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.16.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.16.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.16.mlp.act_fn | SiLU()\n",
      "model.layers.16.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.16.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.17 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.17.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.17.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.17.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.17.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.17.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.17.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.17.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.17.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.17.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.17.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.17.mlp.act_fn | SiLU()\n",
      "model.layers.17.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.17.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.18 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.18.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.18.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.18.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.18.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.18.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.18.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.18.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.18.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.18.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.18.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.18.mlp.act_fn | SiLU()\n",
      "model.layers.18.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.18.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.19 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.19.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.19.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.19.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.19.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.19.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.19.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.19.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.19.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.19.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.19.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.19.mlp.act_fn | SiLU()\n",
      "model.layers.19.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.19.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.20 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.20.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.20.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.20.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.20.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.20.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.20.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.20.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.20.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.20.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.20.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.20.mlp.act_fn | SiLU()\n",
      "model.layers.20.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.20.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.21 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.21.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.21.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.21.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.21.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.21.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.21.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.21.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.21.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.21.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.21.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.21.mlp.act_fn | SiLU()\n",
      "model.layers.21.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.21.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.22 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.22.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.22.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.22.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.22.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.22.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.22.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.22.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.22.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.22.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.22.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.22.mlp.act_fn | SiLU()\n",
      "model.layers.22.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.22.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.23 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.23.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.23.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.23.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.23.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.23.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.23.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.23.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.23.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.23.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.23.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.23.mlp.act_fn | SiLU()\n",
      "model.layers.23.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.23.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.24 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.24.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.24.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.24.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.24.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.24.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.24.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.24.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.24.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.24.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.24.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.24.mlp.act_fn | SiLU()\n",
      "model.layers.24.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.24.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.25 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.25.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.25.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.25.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.25.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.25.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.25.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.25.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.25.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.25.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.25.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.25.mlp.act_fn | SiLU()\n",
      "model.layers.25.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.25.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.26 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.26.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.26.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.26.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.26.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.26.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.26.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.26.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.26.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.26.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.26.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.26.mlp.act_fn | SiLU()\n",
      "model.layers.26.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.26.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.27 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.27.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.27.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.27.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.27.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.27.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.27.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.27.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.27.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.27.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.27.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.27.mlp.act_fn | SiLU()\n",
      "model.layers.27.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.27.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.28 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.28.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.28.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.28.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.28.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.28.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.28.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.28.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.28.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.28.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.28.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.28.mlp.act_fn | SiLU()\n",
      "model.layers.28.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.28.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.29 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.29.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.29.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.29.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.29.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.29.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.29.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.29.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.29.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.29.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.29.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.29.mlp.act_fn | SiLU()\n",
      "model.layers.29.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.29.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.30 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.30.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.30.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.30.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.30.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.30.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.30.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.30.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.30.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.30.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.30.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.30.mlp.act_fn | SiLU()\n",
      "model.layers.30.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.30.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.31 | LlamaDecoderLayer(\n",
      "  (self_attn): LlamaSdpaAttention(\n",
      "    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (mlp): LlamaMLP(\n",
      "    (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "    (act_fn): SiLU()\n",
      "  )\n",
      "  (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      "  (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
      ")\n",
      "model.layers.31.self_attn | LlamaSdpaAttention(\n",
      "  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "  (rotary_emb): LlamaRotaryEmbedding()\n",
      ")\n",
      "model.layers.31.self_attn.q_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.31.self_attn.k_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.31.self_attn.v_proj | Linear(in_features=4096, out_features=1024, bias=False)\n",
      "model.layers.31.self_attn.o_proj | Linear(in_features=4096, out_features=4096, bias=False)\n",
      "model.layers.31.self_attn.rotary_emb | LlamaRotaryEmbedding()\n",
      "model.layers.31.mlp | LlamaMLP(\n",
      "  (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "  (act_fn): SiLU()\n",
      ")\n",
      "model.layers.31.mlp.gate_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.31.mlp.up_proj | Linear(in_features=4096, out_features=14336, bias=False)\n",
      "model.layers.31.mlp.down_proj | Linear(in_features=14336, out_features=4096, bias=False)\n",
      "model.layers.31.mlp.act_fn | SiLU()\n",
      "model.layers.31.input_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.layers.31.post_attention_layernorm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.norm | LlamaRMSNorm((4096,), eps=1e-05)\n",
      "model.rotary_emb | LlamaRotaryEmbedding()\n",
      "lm_head | Linear(in_features=4096, out_features=128256, bias=False)\n"
     ]
    }
   ],
   "source": [
    "model_tmp = transformers.AutoModelForCausalLM.from_pretrained(model_ls[0]).to('cuda:5')\n",
    "for n, m in model_tmp.named_modules():\n",
    "    print(n, '|', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Gemma2ForCausalLM(\n",
      "  (model): Gemma2Model(\n",
      "    (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-41): 42 x Gemma2DecoderLayer(\n",
      "        (self_attn): Gemma2SdpaAttention(\n",
      "          (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "          (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (rotary_emb): Gemma2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Gemma2MLP(\n",
      "          (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "        (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=256000, bias=False)\n",
      ")\n",
      "model | Gemma2Model(\n",
      "  (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
      "  (layers): ModuleList(\n",
      "    (0-41): 42 x Gemma2DecoderLayer(\n",
      "      (self_attn): Gemma2SdpaAttention(\n",
      "        (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "        (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "        (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "        (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "        (rotary_emb): Gemma2RotaryEmbedding()\n",
      "      )\n",
      "      (mlp): Gemma2MLP(\n",
      "        (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "        (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "        (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "        (act_fn): PytorchGELUTanh()\n",
      "      )\n",
      "      (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "      (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "      (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "      (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      "  (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.embed_tokens | Embedding(256000, 3584, padding_idx=0)\n",
      "model.layers | ModuleList(\n",
      "  (0-41): 42 x Gemma2DecoderLayer(\n",
      "    (self_attn): Gemma2SdpaAttention(\n",
      "      (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "      (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "      (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "      (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "      (rotary_emb): Gemma2RotaryEmbedding()\n",
      "    )\n",
      "    (mlp): Gemma2MLP(\n",
      "      (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "      (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "      (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "      (act_fn): PytorchGELUTanh()\n",
      "    )\n",
      "    (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "    (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "    (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "    (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  )\n",
      ")\n",
      "model.layers.0 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.0.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.0.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.0.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.0.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.0.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.0.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.0.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.0.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.0.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.0.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.0.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.0.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.0.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.0.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.0.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.1 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.1.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.1.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.1.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.1.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.1.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.1.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.1.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.1.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.1.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.1.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.1.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.1.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.1.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.1.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.1.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.2 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.2.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.2.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.2.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.2.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.2.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.2.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.2.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.2.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.2.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.2.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.2.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.2.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.2.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.2.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.2.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.3 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.3.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.3.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.3.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.3.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.3.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.3.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.3.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.3.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.3.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.3.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.3.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.3.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.3.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.3.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.3.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.4 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.4.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.4.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.4.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.4.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.4.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.4.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.4.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.4.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.4.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.4.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.4.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.4.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.4.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.4.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.4.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.5 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.5.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.5.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.5.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.5.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.5.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.5.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.5.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.5.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.5.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.5.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.5.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.5.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.5.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.5.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.5.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.6 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.6.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.6.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.6.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.6.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.6.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.6.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.6.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.6.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.6.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.6.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.6.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.6.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.6.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.6.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.6.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.7 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.7.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.7.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.7.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.7.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.7.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.7.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.7.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.7.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.7.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.7.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.7.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.7.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.7.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.7.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.7.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.8 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.8.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.8.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.8.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.8.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.8.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.8.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.8.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.8.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.8.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.8.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.8.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.8.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.8.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.8.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.8.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.9 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.9.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.9.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.9.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.9.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.9.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.9.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.9.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.9.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.9.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.9.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.9.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.9.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.9.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.9.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.9.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.10 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.10.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.10.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.10.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.10.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.10.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.10.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.10.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.10.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.10.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.10.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.10.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.10.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.10.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.10.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.10.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.11 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.11.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.11.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.11.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.11.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.11.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.11.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.11.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.11.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.11.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.11.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.11.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.11.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.11.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.11.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.11.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.12 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.12.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.12.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.12.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.12.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.12.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.12.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.12.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.12.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.12.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.12.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.12.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.12.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.12.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.12.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.12.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.13 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.13.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.13.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.13.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.13.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.13.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.13.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.13.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.13.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.13.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.13.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.13.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.13.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.13.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.13.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.13.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.14 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.14.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.14.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.14.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.14.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.14.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.14.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.14.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.14.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.14.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.14.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.14.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.14.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.14.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.14.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.14.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.15 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.15.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.15.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.15.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.15.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.15.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.15.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.15.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.15.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.15.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.15.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.15.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.15.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.15.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.15.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.15.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.16 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.16.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.16.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.16.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.16.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.16.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.16.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.16.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.16.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.16.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.16.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.16.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.16.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.16.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.16.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.16.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.17 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.17.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.17.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.17.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.17.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.17.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.17.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.17.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.17.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.17.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.17.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.17.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.17.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.17.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.17.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.17.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.18 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.18.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.18.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.18.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.18.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.18.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.18.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.18.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.18.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.18.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.18.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.18.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.18.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.18.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.18.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.18.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.19 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.19.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.19.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.19.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.19.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.19.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.19.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.19.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.19.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.19.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.19.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.19.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.19.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.19.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.19.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.19.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.20 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.20.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.20.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.20.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.20.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.20.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.20.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.20.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.20.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.20.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.20.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.20.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.20.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.20.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.20.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.20.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.21 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.21.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.21.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.21.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.21.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.21.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.21.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.21.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.21.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.21.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.21.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.21.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.21.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.21.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.21.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.21.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.22 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.22.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.22.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.22.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.22.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.22.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.22.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.22.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.22.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.22.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.22.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.22.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.22.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.22.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.22.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.22.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.23 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.23.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.23.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.23.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.23.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.23.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.23.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.23.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.23.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.23.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.23.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.23.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.23.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.23.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.23.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.23.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.24 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.24.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.24.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.24.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.24.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.24.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.24.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.24.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.24.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.24.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.24.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.24.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.24.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.24.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.24.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.24.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.25 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.25.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.25.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.25.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.25.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.25.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.25.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.25.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.25.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.25.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.25.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.25.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.25.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.25.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.25.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.25.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.26 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.26.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.26.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.26.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.26.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.26.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.26.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.26.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.26.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.26.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.26.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.26.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.26.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.26.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.26.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.26.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.27 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.27.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.27.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.27.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.27.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.27.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.27.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.27.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.27.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.27.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.27.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.27.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.27.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.27.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.27.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.27.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.28 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.28.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.28.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.28.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.28.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.28.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.28.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.28.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.28.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.28.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.28.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.28.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.28.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.28.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.28.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.28.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.29 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.29.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.29.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.29.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.29.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.29.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.29.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.29.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.29.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.29.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.29.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.29.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.29.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.29.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.29.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.29.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.30 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.30.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.30.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.30.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.30.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.30.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.30.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.30.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.30.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.30.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.30.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.30.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.30.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.30.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.30.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.30.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.31 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.31.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.31.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.31.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.31.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.31.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.31.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.31.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.31.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.31.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.31.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.31.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.31.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.31.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.31.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.31.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.32 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.32.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.32.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.32.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.32.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.32.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.32.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.32.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.32.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.32.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.32.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.32.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.32.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.32.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.32.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.32.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.33 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.33.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.33.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.33.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.33.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.33.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.33.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.33.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.33.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.33.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.33.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.33.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.33.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.33.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.33.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.33.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.34 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.34.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.34.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.34.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.34.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.34.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.34.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.34.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.34.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.34.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.34.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.34.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.34.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.34.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.34.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.34.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.35 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.35.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.35.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.35.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.35.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.35.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.35.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.35.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.35.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.35.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.35.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.35.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.35.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.35.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.35.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.35.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.36 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.36.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.36.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.36.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.36.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.36.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.36.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.36.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.36.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.36.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.36.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.36.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.36.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.36.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.36.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.36.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.37 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.37.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.37.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.37.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.37.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.37.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.37.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.37.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.37.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.37.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.37.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.37.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.37.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.37.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.37.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.37.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.38 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.38.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.38.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.38.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.38.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.38.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.38.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.38.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.38.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.38.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.38.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.38.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.38.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.38.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.38.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.38.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.39 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.39.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.39.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.39.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.39.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.39.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.39.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.39.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.39.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.39.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.39.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.39.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.39.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.39.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.39.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.39.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.40 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.40.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.40.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.40.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.40.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.40.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.40.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.40.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.40.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.40.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.40.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.40.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.40.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.40.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.40.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.40.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.41 | Gemma2DecoderLayer(\n",
      "  (self_attn): Gemma2SdpaAttention(\n",
      "    (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "    (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "    (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "    (rotary_emb): Gemma2RotaryEmbedding()\n",
      "  )\n",
      "  (mlp): Gemma2MLP(\n",
      "    (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "    (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "    (act_fn): PytorchGELUTanh()\n",
      "  )\n",
      "  (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      ")\n",
      "model.layers.41.self_attn | Gemma2SdpaAttention(\n",
      "  (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "  (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "  (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "  (rotary_emb): Gemma2RotaryEmbedding()\n",
      ")\n",
      "model.layers.41.self_attn.q_proj | Linear(in_features=3584, out_features=4096, bias=False)\n",
      "model.layers.41.self_attn.k_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.41.self_attn.v_proj | Linear(in_features=3584, out_features=2048, bias=False)\n",
      "model.layers.41.self_attn.o_proj | Linear(in_features=4096, out_features=3584, bias=False)\n",
      "model.layers.41.self_attn.rotary_emb | Gemma2RotaryEmbedding()\n",
      "model.layers.41.mlp | Gemma2MLP(\n",
      "  (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "  (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "  (act_fn): PytorchGELUTanh()\n",
      ")\n",
      "model.layers.41.mlp.gate_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.41.mlp.up_proj | Linear(in_features=3584, out_features=14336, bias=False)\n",
      "model.layers.41.mlp.down_proj | Linear(in_features=14336, out_features=3584, bias=False)\n",
      "model.layers.41.mlp.act_fn | PytorchGELUTanh()\n",
      "model.layers.41.input_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.41.post_attention_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.41.pre_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.layers.41.post_feedforward_layernorm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "model.norm | Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "lm_head | Linear(in_features=3584, out_features=256000, bias=False)\n"
     ]
    }
   ],
   "source": [
    "for n, m in model_qa.named_modules(): # both llama3 and gemma2 have similar structure\n",
    "    print(n, '|', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "The wh question double_check_accuracy of the language model is 0.484\n"
     ]
    }
   ],
   "source": [
    "# Double check\n",
    "# df_wh = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/{model_id_format}.csv\")\n",
    "\n",
    "\n",
    "system_msg_double_check = \"\"\"Given a question and a answer, evaluate whether the answer is correct. \\\n",
    "Output '1' if they the answer to the question is correct. Otherwise, output '0'. Do not repeat the question or provide an explanation.\"\"\"\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label, output_qa = df_wh.loc[i, 'question'], df_wh.loc[i, 'label'], df_wh.loc[i, f\"output_{model_id_format}\"]\n",
    "    # prompt_eval = f\"\"\"question: {question} \\nlabel: {label} \\nprediction: {output_qa}\\n\"\"\"\n",
    "    eval_res = 0\n",
    "    wh_count += 1 \n",
    "\n",
    "    if output_qa.lower() in label.lower() or label.lower() in output_qa.lower():  # Rule-basd fuzzy match\n",
    "        wh_correct += 1\n",
    "        eval_res = 1\n",
    "    else:\n",
    "        user_msg_eval = f\"\"\"The input texts are given as below: \\nquestion: {question} \\nanswer: {output_qa}\\n\"\"\"\n",
    "        messages_eval = [{\"role\": \"system\", \"content\": system_msg_double_check}, {\"role\": \"user\", \"content\": user_msg_eval}]\n",
    "        response_eval = get_response(model_eval, tok_eval, messages_eval)\n",
    "        print(response_eval)\n",
    "        if response_eval == '1':\n",
    "            wh_correct += 1\n",
    "            eval_res = 1\n",
    "            \n",
    "    df_wh.loc[i, f\"double_check_{model_id_format}\"] = eval_res\n",
    "    \n",
    "print(f\"The wh question double_check_accuracy of the language model is {wh_correct / wh_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "The wh question double_check_accuracy of the language model is 0.698\n"
     ]
    }
   ],
   "source": [
    "# Double check using GPT-4o\n",
    "# df_wh = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/{model_id_format}.csv\")\n",
    "\n",
    "system_msg_double_check = \"\"\"Given a question and a answer, evaluate whether the answer is correct. \\\n",
    "Output '1' if they the answer to the question is correct. Otherwise, output '0'. Do not repeat the question or provide an explanation.\"\"\"\n",
    "wh_count = 0\n",
    "wh_correct = 0\n",
    "for i in df_wh.index[:]:\n",
    "    question, label, output_qa = df_wh.loc[i, 'question'], df_wh.loc[i, 'label'], df_wh.loc[i, f\"output_{model_id_format}\"]\n",
    "    # prompt_eval = f\"\"\"question: {question} \\nlabel: {label} \\nprediction: {output_qa}\\n\"\"\"\n",
    "    eval_res = 0\n",
    "    wh_count += 1 \n",
    "\n",
    "    if output_qa.lower() in label.lower() or label.lower() in output_qa.lower():  # Rule-basd fuzzy match\n",
    "        wh_correct += 1\n",
    "        eval_res = 1\n",
    "    else:\n",
    "        user_msg_eval = f\"\"\"The input texts are given as below: \\nquestion: {question} \\nanswer: {output_qa}\\n\"\"\"\n",
    "        \n",
    "        raw_response = client.chat.completions.create(\n",
    "            model='gpt-4o', \n",
    "            messages=[{\"role\": \"system\", \"content\": system_msg_double_check}, {\"role\": \"user\", \"content\": user_msg_eval}], \n",
    "            temperature=0\n",
    "        )\n",
    "        response_eval = raw_response.choices[0].message.content\n",
    "\n",
    "        print(response_eval)\n",
    "        if response_eval == '1':\n",
    "            wh_correct += 1\n",
    "            eval_res = 1\n",
    "            \n",
    "    df_wh.loc[i, f\"double_check_{model_id_format}\"] = eval_res\n",
    "    \n",
    "print(f\"The wh question double_check_accuracy of the language model is {wh_correct / wh_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/baixiang/env/anaconda3/envs/edit/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from easyeditor import BaseEditor\n",
    "# from hallucination_editor import BaseEditor\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from easyeditor import FTHyperParams, IKEHyperParams, ROMEHyperParams, MEMITHyperParams\n",
    "\n",
    "test_data = json.load(open(os.path.join('../../editing-attack-backup-2024-july-26/data_old/zsre_mend_eval_portability_gpt4.json'), 'r', encoding='utf-8'))\n",
    "test_data = random.sample(test_data, 50)\n",
    "questions = [test_data_['src'] for test_data_ in test_data]\n",
    "rephrase_prompts = [edit_data_['rephrase'] for edit_data_ in test_data]\n",
    "targets = [edit_data_['alt'] for edit_data_ in test_data]\n",
    "subjects = [edit_data_['subject'] for edit_data_ in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 18:02:21,934 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-08 18:02:21,934 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/08/2024 18:02:21 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007400035858154297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading shards",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf65a107a13b48a3a81e11792b2a27b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0028488636016845703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056fa3ce4219457f98dff438a790cc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [00:34<00:00,  1.44it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "2024-08-08 18:03:12,653 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:03:12,653 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:03:12 - INFO - easyeditor.editors.editor -   0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "  2%|         | 1/50 [00:06<05:03,  6.20s/it]2024-08-08 18:03:18,684 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:03:18,684 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:03:18 - INFO - easyeditor.editors.editor -   1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "  4%|         | 2/50 [00:12<04:52,  6.10s/it]2024-08-08 18:03:25,620 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:03:25,620 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:03:25 - INFO - easyeditor.editors.editor -   2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "  6%|         | 3/50 [00:19<05:04,  6.48s/it]2024-08-08 18:03:31,514 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:03:31,514 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:03:31 - INFO - easyeditor.editors.editor -   3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "  8%|         | 4/50 [00:25<04:47,  6.25s/it]2024-08-08 18:03:37,772 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:03:37,772 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:03:37 - INFO - easyeditor.editors.editor -   4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 10%|         | 5/50 [00:31<04:41,  6.25s/it]2024-08-08 18:03:43,466 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:03:43,466 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:03:43 - INFO - easyeditor.editors.editor -   5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 12%|        | 6/50 [00:37<04:26,  6.06s/it]2024-08-08 18:03:49,917 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:03:49,917 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:03:49 - INFO - easyeditor.editors.editor -   6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 14%|        | 7/50 [00:43<04:26,  6.19s/it]2024-08-08 18:03:55,965 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:03:55,965 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:03:55 - INFO - easyeditor.editors.editor -   7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 16%|        | 8/50 [00:49<04:18,  6.14s/it]2024-08-08 18:04:02,193 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:02,193 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:02 - INFO - easyeditor.editors.editor -   8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 18%|        | 9/50 [00:55<04:12,  6.17s/it]2024-08-08 18:04:07,920 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:07,920 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:07 - INFO - easyeditor.editors.editor -   9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 20%|        | 10/50 [01:01<04:01,  6.03s/it]2024-08-08 18:04:14,136 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:14,136 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:14 - INFO - easyeditor.editors.editor -   10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 22%|       | 11/50 [01:07<03:57,  6.09s/it]2024-08-08 18:04:20,380 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:20,380 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:20 - INFO - easyeditor.editors.editor -   11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 24%|       | 12/50 [01:13<03:53,  6.14s/it]2024-08-08 18:04:26,093 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:26,093 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:26 - INFO - easyeditor.editors.editor -   12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 26%|       | 13/50 [01:19<03:42,  6.01s/it]2024-08-08 18:04:31,951 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:31,951 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:31 - INFO - easyeditor.editors.editor -   13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 28%|       | 14/50 [01:25<03:34,  5.96s/it]2024-08-08 18:04:37,822 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:37,822 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:37 - INFO - easyeditor.editors.editor -   14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 30%|       | 15/50 [01:31<03:27,  5.94s/it]2024-08-08 18:04:44,029 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:44,029 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:44 - INFO - easyeditor.editors.editor -   15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 32%|      | 16/50 [01:37<03:24,  6.02s/it]2024-08-08 18:04:50,052 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:50,052 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:50 - INFO - easyeditor.editors.editor -   16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 34%|      | 17/50 [01:43<03:18,  6.02s/it]2024-08-08 18:04:56,253 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:04:56,253 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:04:56 - INFO - easyeditor.editors.editor -   17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 36%|      | 18/50 [01:49<03:14,  6.07s/it]2024-08-08 18:05:01,776 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:01,776 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:01 - INFO - easyeditor.editors.editor -   18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 38%|      | 19/50 [01:55<03:03,  5.91s/it]2024-08-08 18:05:08,008 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:08,008 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:08 - INFO - easyeditor.editors.editor -   19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 40%|      | 20/50 [02:01<03:00,  6.01s/it]2024-08-08 18:05:14,215 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:14,215 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:14 - INFO - easyeditor.editors.editor -   20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 42%|     | 21/50 [02:07<02:55,  6.07s/it]2024-08-08 18:05:20,457 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:20,457 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:20 - INFO - easyeditor.editors.editor -   21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 44%|     | 22/50 [02:14<02:51,  6.12s/it]2024-08-08 18:05:26,303 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:26,303 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:26 - INFO - easyeditor.editors.editor -   22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 46%|     | 23/50 [02:19<02:42,  6.04s/it]2024-08-08 18:05:32,550 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:32,550 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:32 - INFO - easyeditor.editors.editor -   23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 48%|     | 24/50 [02:26<02:38,  6.10s/it]2024-08-08 18:05:38,682 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:38,682 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:38 - INFO - easyeditor.editors.editor -   24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 50%|     | 25/50 [02:32<02:32,  6.11s/it]2024-08-08 18:05:44,798 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:44,798 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:44 - INFO - easyeditor.editors.editor -   25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 52%|    | 26/50 [02:38<02:26,  6.11s/it]2024-08-08 18:05:51,017 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:51,017 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:51 - INFO - easyeditor.editors.editor -   26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 54%|    | 27/50 [02:44<02:21,  6.14s/it]2024-08-08 18:05:57,784 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:05:57,784 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:05:57 - INFO - easyeditor.editors.editor -   27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 56%|    | 28/50 [02:51<02:19,  6.33s/it]2024-08-08 18:06:03,873 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:03,873 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:03 - INFO - easyeditor.editors.editor -   28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 58%|    | 29/50 [02:57<02:11,  6.26s/it]2024-08-08 18:06:09,551 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:09,551 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:09 - INFO - easyeditor.editors.editor -   29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 60%|    | 30/50 [03:03<02:01,  6.08s/it]2024-08-08 18:06:15,468 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:15,468 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:15 - INFO - easyeditor.editors.editor -   30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 62%|   | 31/50 [03:09<01:54,  6.03s/it]2024-08-08 18:06:21,620 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:21,620 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:21 - INFO - easyeditor.editors.editor -   31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 64%|   | 32/50 [03:15<01:49,  6.07s/it]2024-08-08 18:06:27,764 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.8333333333333333, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:27,764 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.8333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:27 - INFO - easyeditor.editors.editor -   32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.8333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 66%|   | 33/50 [03:21<01:43,  6.09s/it]2024-08-08 18:06:33,869 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:33,869 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:33 - INFO - easyeditor.editors.editor -   33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 68%|   | 34/50 [03:27<01:37,  6.10s/it]2024-08-08 18:06:39,461 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:39,461 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:39 - INFO - easyeditor.editors.editor -   34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 70%|   | 35/50 [03:33<01:29,  5.94s/it]2024-08-08 18:06:45,632 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:45,632 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:45 - INFO - easyeditor.editors.editor -   35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 72%|  | 36/50 [03:39<01:24,  6.01s/it]2024-08-08 18:06:51,446 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:51,446 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:51 - INFO - easyeditor.editors.editor -   36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 74%|  | 37/50 [03:44<01:17,  5.95s/it]2024-08-08 18:06:57,183 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:06:57,183 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:06:57 - INFO - easyeditor.editors.editor -   37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 76%|  | 38/50 [03:50<01:10,  5.89s/it]2024-08-08 18:07:03,252 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:03,252 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:03 - INFO - easyeditor.editors.editor -   38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 78%|  | 39/50 [03:56<01:05,  5.94s/it]2024-08-08 18:07:08,991 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:08,991 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:08 - INFO - easyeditor.editors.editor -   39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 80%|  | 40/50 [04:02<00:58,  5.88s/it]2024-08-08 18:07:15,064 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:15,064 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:15 - INFO - easyeditor.editors.editor -   40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 82%| | 41/50 [04:08<00:53,  5.94s/it]2024-08-08 18:07:21,853 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:21,853 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:21 - INFO - easyeditor.editors.editor -   41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 84%| | 42/50 [04:15<00:49,  6.19s/it]2024-08-08 18:07:27,598 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:27,598 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:27 - INFO - easyeditor.editors.editor -   42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 86%| | 43/50 [04:21<00:42,  6.06s/it]2024-08-08 18:07:33,616 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:33,616 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:33 - INFO - easyeditor.editors.editor -   43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 88%| | 44/50 [04:27<00:36,  6.05s/it]2024-08-08 18:07:39,884 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:39,884 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:39 - INFO - easyeditor.editors.editor -   44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 90%| | 45/50 [04:33<00:30,  6.11s/it]2024-08-08 18:07:45,625 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:45,625 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:45 - INFO - easyeditor.editors.editor -   45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 92%|| 46/50 [04:39<00:24,  6.00s/it]2024-08-08 18:07:51,320 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:51,320 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:51 - INFO - easyeditor.editors.editor -   46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 94%|| 47/50 [04:44<00:17,  5.91s/it]2024-08-08 18:07:57,565 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:07:57,565 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:07:57 - INFO - easyeditor.editors.editor -   47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 96%|| 48/50 [04:51<00:12,  6.01s/it]2024-08-08 18:08:03,645 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:08:03,645 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:08:03 - INFO - easyeditor.editors.editor -   48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      " 98%|| 49/50 [04:57<00:06,  6.03s/it]2024-08-08 18:08:09,584 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "2024-08-08 18:08:09,584 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 18:08:09 - INFO - easyeditor.editors.editor -   49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [1.0], 'rewrite_F1': 1.0, 'locality': {}, 'portability': {}}}\n",
      "100%|| 50/50 [05:03<00:00,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.013333333333333332}, 'post': {'rewrite_acc': 0.956}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from easyeditor import GraceHyperParams\n",
    "hparams = GraceHyperParams.from_hparams('./hparams/GRACE/mistral-7b-v3')  # llama3-8b\n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 1\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "# Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:14:42,990 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/08/2024 17:14:42 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010990619659423828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568ba03fa28748119ec67c8bcfe41b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007191658020019531,
       "initial": 3701473280,
       "n": 3701473280,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "model-00001-of-00004.safetensors",
       "rate": null,
       "total": 4976698672,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7fd2bc4d624eb2a87764fde283ece8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:  74%|#######4  | 3.70G/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004301786422729492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "model-00002-of-00004.safetensors",
       "rate": null,
       "total": 4999802720,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fd8da0c71f4ce0961fe4c6f2f785b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008191347122192383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "model-00003-of-00004.safetensors",
       "rate": null,
       "total": 4915916176,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0d123bed6c463aa124459201c1a8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008571147918701172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "model-00004-of-00004.safetensors",
       "rate": null,
       "total": 1168138808,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b445d335db6f46ce8c38b42818a16bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003348112106323242,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3587a43bbc947fcae2e83fa643b95df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0035796165466308594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "generation_config.json",
       "rate": null,
       "total": 187,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984b5af4366447a4a7a7927026261820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003972291946411133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "tokenizer_config.json",
       "rate": null,
       "total": 50977,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61653bb6e9b24e689bc8d32520ca9d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0034940242767333984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "tokenizer.json",
       "rate": null,
       "total": 9085698,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382b3a2a546e4afbae09354c5d021ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00709843635559082,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "special_tokens_map.json",
       "rate": null,
       "total": 73,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe34bf1103d4e4e8c0cf64fe558b0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50/50 [00:27<00:00,  1.80it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "2024-08-08 17:33:37,103 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:33:37 - INFO - easyeditor.editors.editor -   0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "  2%|         | 1/50 [00:05<04:35,  5.63s/it]2024-08-08 17:33:42,772 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:33:42 - INFO - easyeditor.editors.editor -   1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "  4%|         | 2/50 [00:11<04:31,  5.65s/it]2024-08-08 17:33:48,940 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:33:48 - INFO - easyeditor.editors.editor -   2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "  6%|         | 3/50 [00:17<04:36,  5.89s/it]2024-08-08 17:33:54,761 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:33:54 - INFO - easyeditor.editors.editor -   3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "  8%|         | 4/50 [00:23<04:29,  5.86s/it]2024-08-08 17:34:00,438 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:00 - INFO - easyeditor.editors.editor -   4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 10%|         | 5/50 [00:28<04:20,  5.79s/it]2024-08-08 17:34:06,068 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:06 - INFO - easyeditor.editors.editor -   5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 12%|        | 6/50 [00:34<04:12,  5.74s/it]2024-08-08 17:34:12,095 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [0.75], 'rewrite_F1': 0.6, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:12 - INFO - easyeditor.editors.editor -   6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [0.75], 'rewrite_F1': 0.6, 'locality': {}, 'portability': {}}}\n",
      " 14%|        | 7/50 [00:40<04:10,  5.83s/it]2024-08-08 17:34:18,076 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:18 - INFO - easyeditor.editors.editor -   7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 16%|        | 8/50 [00:46<04:06,  5.88s/it]2024-08-08 17:34:23,734 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:23 - INFO - easyeditor.editors.editor -   8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 18%|        | 9/50 [00:52<03:58,  5.81s/it]2024-08-08 17:34:29,587 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:29 - INFO - easyeditor.editors.editor -   9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 20%|        | 10/50 [00:58<03:52,  5.82s/it]2024-08-08 17:34:35,564 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [0.75], 'rewrite_F1': 0.6, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:35 - INFO - easyeditor.editors.editor -   10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [0.75], 'rewrite_F1': 0.6, 'locality': {}, 'portability': {}}}\n",
      " 22%|       | 11/50 [01:04<03:48,  5.87s/it]2024-08-08 17:34:41,206 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:41 - INFO - easyeditor.editors.editor -   11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 24%|       | 12/50 [01:09<03:40,  5.80s/it]2024-08-08 17:34:47,014 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:47 - INFO - easyeditor.editors.editor -   12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 26%|       | 13/50 [01:15<03:34,  5.80s/it]2024-08-08 17:34:52,987 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:52 - INFO - easyeditor.editors.editor -   13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 28%|       | 14/50 [01:21<03:30,  5.85s/it]2024-08-08 17:34:58,799 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [0.3333333333333333], 'rewrite_F1': 0.16666666666666666, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:34:58 - INFO - easyeditor.editors.editor -   14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [0.3333333333333333], 'rewrite_F1': 0.16666666666666666, 'locality': {}, 'portability': {}}}\n",
      " 30%|       | 15/50 [01:27<03:24,  5.84s/it]2024-08-08 17:35:04,442 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:04 - INFO - easyeditor.editors.editor -   15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 32%|      | 16/50 [01:32<03:16,  5.78s/it]2024-08-08 17:35:10,395 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [0.25], 'rewrite_F1': 0.13333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:10 - INFO - easyeditor.editors.editor -   16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [0.25], 'rewrite_F1': 0.13333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 34%|      | 17/50 [01:38<03:12,  5.83s/it]2024-08-08 17:35:16,011 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:16 - INFO - easyeditor.editors.editor -   17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 36%|      | 18/50 [01:44<03:04,  5.77s/it]2024-08-08 17:35:21,457 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:21 - INFO - easyeditor.editors.editor -   18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 38%|      | 19/50 [01:49<02:55,  5.67s/it]2024-08-08 17:35:27,636 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:27 - INFO - easyeditor.editors.editor -   19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      " 40%|      | 20/50 [01:56<02:54,  5.82s/it]2024-08-08 17:35:33,780 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:33 - INFO - easyeditor.editors.editor -   20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      " 42%|     | 21/50 [02:02<02:51,  5.92s/it]2024-08-08 17:35:40,086 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:40 - INFO - easyeditor.editors.editor -   21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 44%|     | 22/50 [02:08<02:48,  6.04s/it]2024-08-08 17:35:45,721 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:45 - INFO - easyeditor.editors.editor -   22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 46%|     | 23/50 [02:14<02:39,  5.92s/it]2024-08-08 17:35:51,368 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:51 - INFO - easyeditor.editors.editor -   23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 48%|     | 24/50 [02:19<02:31,  5.84s/it]2024-08-08 17:35:57,267 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:35:57 - INFO - easyeditor.editors.editor -   24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 50%|     | 25/50 [02:25<02:26,  5.85s/it]2024-08-08 17:36:03,294 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:03 - INFO - easyeditor.editors.editor -   25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 52%|    | 26/50 [02:31<02:21,  5.91s/it]2024-08-08 17:36:09,260 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:09 - INFO - easyeditor.editors.editor -   26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 54%|    | 27/50 [02:37<02:16,  5.92s/it]2024-08-08 17:36:15,442 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:15 - INFO - easyeditor.editors.editor -   27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 56%|    | 28/50 [02:43<02:12,  6.00s/it]2024-08-08 17:36:21,442 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.14285714285714285, 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [0.75], 'rewrite_F1': 0.6, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:21 - INFO - easyeditor.editors.editor -   28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.14285714285714285, 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [0.75], 'rewrite_F1': 0.6, 'locality': {}, 'portability': {}}}\n",
      " 58%|    | 29/50 [02:49<02:06,  6.00s/it]2024-08-08 17:36:27,084 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:27 - INFO - easyeditor.editors.editor -   29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 60%|    | 30/50 [02:55<01:57,  5.89s/it]2024-08-08 17:36:32,948 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:32 - INFO - easyeditor.editors.editor -   30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'locality': {}, 'portability': {}}}\n",
      " 62%|   | 31/50 [03:01<01:51,  5.88s/it]2024-08-08 17:36:39,116 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:39 - INFO - easyeditor.editors.editor -   31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      " 64%|   | 32/50 [03:07<01:47,  5.97s/it]2024-08-08 17:36:44,766 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:44 - INFO - easyeditor.editors.editor -   32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 66%|   | 33/50 [03:13<01:39,  5.87s/it]2024-08-08 17:36:50,416 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:50 - INFO - easyeditor.editors.editor -   33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 68%|   | 34/50 [03:18<01:32,  5.81s/it]2024-08-08 17:36:56,050 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:36:56 - INFO - easyeditor.editors.editor -   34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 70%|   | 35/50 [03:24<01:26,  5.75s/it]2024-08-08 17:37:02,286 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:02 - INFO - easyeditor.editors.editor -   35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      " 72%|  | 36/50 [03:30<01:22,  5.90s/it]2024-08-08 17:37:08,431 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:08 - INFO - easyeditor.editors.editor -   36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 74%|  | 37/50 [03:36<01:17,  5.97s/it]2024-08-08 17:37:14,088 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:14 - INFO - easyeditor.editors.editor -   37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 76%|  | 38/50 [03:42<01:10,  5.88s/it]2024-08-08 17:37:19,742 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:19 - INFO - easyeditor.editors.editor -   38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 78%|  | 39/50 [03:48<01:03,  5.81s/it]2024-08-08 17:37:25,432 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:25 - INFO - easyeditor.editors.editor -   39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 80%|  | 40/50 [03:53<00:57,  5.77s/it]2024-08-08 17:37:31,460 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [0.75], 'rewrite_F1': 0.6, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:31 - INFO - easyeditor.editors.editor -   40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [0.75], 'rewrite_F1': 0.6, 'locality': {}, 'portability': {}}}\n",
      " 82%| | 41/50 [03:59<00:52,  5.85s/it]2024-08-08 17:37:37,669 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:37 - INFO - easyeditor.editors.editor -   41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 84%| | 42/50 [04:06<00:47,  5.96s/it]2024-08-08 17:37:43,360 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:43 - INFO - easyeditor.editors.editor -   42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 86%| | 43/50 [04:11<00:41,  5.88s/it]2024-08-08 17:37:49,351 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:49 - INFO - easyeditor.editors.editor -   43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 88%| | 44/50 [04:17<00:35,  5.91s/it]2024-08-08 17:37:55,217 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:37:55 - INFO - easyeditor.editors.editor -   44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'locality': {}, 'portability': {}}}\n",
      " 90%| | 45/50 [04:23<00:29,  5.90s/it]2024-08-08 17:38:00,890 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:38:00 - INFO - easyeditor.editors.editor -   45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 92%|| 46/50 [04:29<00:23,  5.83s/it]2024-08-08 17:38:06,694 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:38:06 - INFO - easyeditor.editors.editor -   46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'locality': {}, 'portability': {}}}\n",
      " 94%|| 47/50 [04:35<00:17,  5.82s/it]2024-08-08 17:38:12,879 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:38:12 - INFO - easyeditor.editors.editor -   47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [0.8], 'rewrite_F1': 0.6666666666666666, 'locality': {}, 'portability': {}}}\n",
      " 96%|| 48/50 [04:41<00:11,  5.93s/it]2024-08-08 17:38:18,889 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:38:18 - INFO - easyeditor.editors.editor -   48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [0.5], 'rewrite_F1': 0.3333333333333333, 'locality': {}, 'portability': {}}}\n",
      " 98%|| 49/50 [04:47<00:05,  5.95s/it]2024-08-08 17:38:24,758 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'locality': {}, 'portability': {}}}\n",
      "08/08/2024 17:38:24 - INFO - easyeditor.editors.editor -   49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'rewrite_F1': 0.0, 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [0.6666666666666666], 'rewrite_F1': 0.5, 'locality': {}, 'portability': {}}}\n",
      "100%|| 50/50 [04:53<00:00,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.01}, 'post': {'rewrite_acc': 0.27166666666666667}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from easyeditor import GraceHyperParams\n",
    "hparams = GraceHyperParams.from_hparams('./hparams/GRACE/llama3-8b')  # llama3-8b\n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 2\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "# Metrics Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:49:21,600 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/02/2024 15:49:21 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24469b190064420cb79dccd40025b19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|| 50/50 [00:05<00:00,  9.45it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What was the death date of Thomas Farnaby?] -> [1815]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.693404197692871\n",
      "Total loss 5.693404197692871\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.4923534393310547\n",
      "Total loss 3.4923534393310547\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.8184893131256104\n",
      "Total loss 1.8184893131256104\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.8806086182594299\n",
      "Total loss 0.8806086182594299\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.8040114641189575\n",
      "Total loss 0.8040114641189575\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.8052194118499756\n",
      "Total loss 0.8052194118499756\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.7848984003067017\n",
      "Total loss 0.7848984003067017\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.739143431186676\n",
      "Total loss 0.739143431186676\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.6737039685249329\n",
      "Total loss 0.6737039685249329\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.6054604053497314\n",
      "Total loss 0.6054604053497314\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.5398155450820923\n",
      "Total loss 0.5398155450820923\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.47909027338027954\n",
      "Total loss 0.47909027338027954\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.4256579279899597\n",
      "Total loss 0.4256579279899597\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.38149937987327576\n",
      "Total loss 0.38149937987327576\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3430868983268738\n",
      "Total loss 0.3430868983268738\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.3104054927825928\n",
      "Total loss 0.3104054927825928\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.28231316804885864\n",
      "Total loss 0.28231316804885864\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.25966504216194153\n",
      "Total loss 0.25966504216194153\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.2417575865983963\n",
      "Total loss 0.2417575865983963\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.22366635501384735\n",
      "Total loss 0.22366635501384735\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.20674876868724823\n",
      "Total loss 0.20674876868724823\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.1919666975736618\n",
      "Total loss 0.1919666975736618\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.17696824669837952\n",
      "Total loss 0.17696824669837952\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.16204924881458282\n",
      "Total loss 0.16204924881458282\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.1481691598892212\n",
      "Total loss 0.1481691598892212\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.13639138638973236\n",
      "Total loss 0.13639138638973236\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.12626893818378448\n",
      "Total loss 0.12626893818378448\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.11763233691453934\n",
      "Total loss 0.11763233691453934\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.10693653672933578\n",
      "Total loss 0.10693653672933578\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.09686681628227234\n",
      "Total loss 0.09686681628227234\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.0899653434753418\n",
      "Total loss 0.0899653434753418\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.08431737869977951\n",
      "Total loss 0.08431737869977951\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.07698570191860199\n",
      "Total loss 0.07698570191860199\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07214610278606415\n",
      "Total loss 0.07214610278606415\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06844858825206757\n",
      "Total loss 0.06844858825206757\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06415113806724548\n",
      "Total loss 0.06415113806724548\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.0618547685444355\n",
      "Total loss 0.0618547685444355\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06023961678147316\n",
      "Total loss 0.06023961678147316\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05760905519127846\n",
      "Total loss 0.05760905519127846\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05596720799803734\n",
      "Total loss 0.05596720799803734\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.053442299365997314\n",
      "Total loss 0.053442299365997314\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05174478143453598\n",
      "Total loss 0.05174478143453598\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04935403913259506\n",
      "Total loss 0.04935403913259506\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04783697426319122\n",
      "Total loss 0.04783697426319122\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.0468832403421402\n",
      "Total loss 0.0468832403421402\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04602895677089691\n",
      "Total loss 0.04602895677089691\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04470865800976753\n",
      "Total loss 0.04470865800976753\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04380117356777191\n",
      "Total loss 0.04380117356777191\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04176681116223335\n",
      "Total loss 0.04176681116223335\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.041761159896850586\n",
      "Total loss 0.041761159896850586\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.039620816707611084\n",
      "Total loss 0.039620816707611084\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03986261412501335\n",
      "Total loss 0.03986261412501335\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03820524364709854\n",
      "Total loss 0.03820524364709854\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.038808997720479965\n",
      "Total loss 0.038808997720479965\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03685171902179718\n",
      "Total loss 0.03685171902179718\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.037316083908081055\n",
      "Total loss 0.037316083908081055\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.035839952528476715\n",
      "Total loss 0.035839952528476715\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.0356702022254467\n",
      "Total loss 0.0356702022254467\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03506723791360855\n",
      "Total loss 0.03506723791360855\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03509930148720741\n",
      "Total loss 0.03509930148720741\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03532702475786209\n",
      "Total loss 0.03532702475786209\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03407936915755272\n",
      "Total loss 0.03407936915755272\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.033686745911836624\n",
      "Total loss 0.033686745911836624\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03353429585695267\n",
      "Total loss 0.03353429585695267\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03307337313890457\n",
      "Total loss 0.03307337313890457\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03323981538414955\n",
      "Total loss 0.03323981538414955\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.032696451991796494\n",
      "Total loss 0.032696451991796494\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03327619284391403\n",
      "Total loss 0.03327619284391403\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.0322396345436573\n",
      "Total loss 0.0322396345436573\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03336526080965996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:50:11,622 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:50:11 - INFO - easyeditor.editors.editor -   0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  2%|         | 1/50 [00:24<19:39, 24.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03336526080965996\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Who was the dad of Jane Seymour?] -> [Henry Seymour]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 8.129804611206055\n",
      "Total loss 8.129804611206055\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.088177442550659\n",
      "Total loss 3.088177442550659\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.6375858783721924\n",
      "Total loss 2.6375858783721924\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.0566645860671997\n",
      "Total loss 1.0566645860671997\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.9833149313926697\n",
      "Total loss 0.9833149313926697\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.0774849653244019\n",
      "Total loss 1.0774849653244019\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.1536004543304443\n",
      "Total loss 1.1536004543304443\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.194530963897705\n",
      "Total loss 1.194530963897705\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.2047420740127563\n",
      "Total loss 1.2047420740127563\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 1.1894348859786987\n",
      "Total loss 1.1894348859786987\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 1.1548199653625488\n",
      "Total loss 1.1548199653625488\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 1.1060928106307983\n",
      "Total loss 1.1060928106307983\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 1.050087332725525\n",
      "Total loss 1.050087332725525\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.9901809692382812\n",
      "Total loss 0.9901809692382812\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.9260231256484985\n",
      "Total loss 0.9260231256484985\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.8591609597206116\n",
      "Total loss 0.8591609597206116\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.7931697964668274\n",
      "Total loss 0.7931697964668274\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.7284497022628784\n",
      "Total loss 0.7284497022628784\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.668758749961853\n",
      "Total loss 0.668758749961853\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.6162510514259338\n",
      "Total loss 0.6162510514259338\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.5683788061141968\n",
      "Total loss 0.5683788061141968\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.5224536061286926\n",
      "Total loss 0.5224536061286926\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.48047056794166565\n",
      "Total loss 0.48047056794166565\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.4424014389514923\n",
      "Total loss 0.4424014389514923\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.4095647633075714\n",
      "Total loss 0.4095647633075714\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.37929511070251465\n",
      "Total loss 0.37929511070251465\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.3520258367061615\n",
      "Total loss 0.3520258367061615\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.32932934165000916\n",
      "Total loss 0.32932934165000916\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.30950459837913513\n",
      "Total loss 0.30950459837913513\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.29192453622817993\n",
      "Total loss 0.29192453622817993\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.2758484482765198\n",
      "Total loss 0.2758484482765198\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.260525107383728\n",
      "Total loss 0.260525107383728\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.24635818600654602\n",
      "Total loss 0.24635818600654602\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.23312905430793762\n",
      "Total loss 0.23312905430793762\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.2209891825914383\n",
      "Total loss 0.2209891825914383\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.20818382501602173\n",
      "Total loss 0.20818382501602173\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.1962948888540268\n",
      "Total loss 0.1962948888540268\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.18594136834144592\n",
      "Total loss 0.18594136834144592\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.1761375218629837\n",
      "Total loss 0.1761375218629837\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.16587160527706146\n",
      "Total loss 0.16587160527706146\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.15710856020450592\n",
      "Total loss 0.15710856020450592\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.14946579933166504\n",
      "Total loss 0.14946579933166504\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.1428188532590866\n",
      "Total loss 0.1428188532590866\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.13734593987464905\n",
      "Total loss 0.13734593987464905\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.13182885944843292\n",
      "Total loss 0.13182885944843292\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.1246485486626625\n",
      "Total loss 0.1246485486626625\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.12004635483026505\n",
      "Total loss 0.12004635483026505\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.11383140087127686\n",
      "Total loss 0.11383140087127686\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.10918916016817093\n",
      "Total loss 0.10918916016817093\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.10429304838180542\n",
      "Total loss 0.10429304838180542\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.09821993112564087\n",
      "Total loss 0.09821993112564087\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.09462463855743408\n",
      "Total loss 0.09462463855743408\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.08849463611841202\n",
      "Total loss 0.08849463611841202\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.08471295237541199\n",
      "Total loss 0.08471295237541199\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.07975122332572937\n",
      "Total loss 0.07975122332572937\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.07653895765542984\n",
      "Total loss 0.07653895765542984\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.07289648056030273\n",
      "Total loss 0.07289648056030273\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.06904444843530655\n",
      "Total loss 0.06904444843530655\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.06591811031103134\n",
      "Total loss 0.06591811031103134\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.061719272285699844\n",
      "Total loss 0.061719272285699844\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.06003755331039429\n",
      "Total loss 0.06003755331039429\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.05605543032288551\n",
      "Total loss 0.05605543032288551\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.05475320667028427\n",
      "Total loss 0.05475320667028427\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.05167018249630928\n",
      "Total loss 0.05167018249630928\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.05044809728860855\n",
      "Total loss 0.05044809728860855\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.04712657630443573\n",
      "Total loss 0.04712657630443573\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.045918047428131104\n",
      "Total loss 0.045918047428131104\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.04432186484336853\n",
      "Total loss 0.04432186484336853\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.043685756623744965\n",
      "Total loss 0.043685756623744965\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.042855404317379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:50:35,996 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:50:35 - INFO - easyeditor.editors.editor -   1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  4%|         | 2/50 [00:48<19:24, 24.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.042855404317379\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What is the date of death for Joan Standing?] -> [16 May 2008]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 3.9315619468688965\n",
      "Total loss 3.9315619468688965\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.8881211280822754\n",
      "Total loss 2.8881211280822754\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.063239812850952\n",
      "Total loss 2.063239812850952\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.3973520994186401\n",
      "Total loss 1.3973520994186401\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.9410701990127563\n",
      "Total loss 1.9410701990127563\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.7867363691329956\n",
      "Total loss 0.7867363691329956\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6145498156547546\n",
      "Total loss 0.6145498156547546\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6502947807312012\n",
      "Total loss 0.6502947807312012\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.709078848361969\n",
      "Total loss 0.709078848361969\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.7357771396636963\n",
      "Total loss 0.7357771396636963\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.7351357936859131\n",
      "Total loss 0.7351357936859131\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.7139874696731567\n",
      "Total loss 0.7139874696731567\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.6774539947509766\n",
      "Total loss 0.6774539947509766\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.632836103439331\n",
      "Total loss 0.632836103439331\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.5884643793106079\n",
      "Total loss 0.5884643793106079\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.5445029139518738\n",
      "Total loss 0.5445029139518738\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.5031304359436035\n",
      "Total loss 0.5031304359436035\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.4677862823009491\n",
      "Total loss 0.4677862823009491\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.4351333975791931\n",
      "Total loss 0.4351333975791931\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.4041615426540375\n",
      "Total loss 0.4041615426540375\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.37443745136260986\n",
      "Total loss 0.37443745136260986\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.3456193506717682\n",
      "Total loss 0.3456193506717682\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.3193206489086151\n",
      "Total loss 0.3193206489086151\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.29663965106010437\n",
      "Total loss 0.29663965106010437\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.2756744921207428\n",
      "Total loss 0.2756744921207428\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.25481748580932617\n",
      "Total loss 0.25481748580932617\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.2343572974205017\n",
      "Total loss 0.2343572974205017\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.21581149101257324\n",
      "Total loss 0.21581149101257324\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.2012055367231369\n",
      "Total loss 0.2012055367231369\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.18741700053215027\n",
      "Total loss 0.18741700053215027\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.173106387257576\n",
      "Total loss 0.173106387257576\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.16003422439098358\n",
      "Total loss 0.16003422439098358\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.1480567902326584\n",
      "Total loss 0.1480567902326584\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.13644753396511078\n",
      "Total loss 0.13644753396511078\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.12514981627464294\n",
      "Total loss 0.12514981627464294\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.11609366536140442\n",
      "Total loss 0.11609366536140442\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.10860766470432281\n",
      "Total loss 0.10860766470432281\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.10202750563621521\n",
      "Total loss 0.10202750563621521\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.09483983367681503\n",
      "Total loss 0.09483983367681503\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.08895887434482574\n",
      "Total loss 0.08895887434482574\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.08386276662349701\n",
      "Total loss 0.08386276662349701\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.07959240674972534\n",
      "Total loss 0.07959240674972534\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.07420630753040314\n",
      "Total loss 0.07420630753040314\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.07097411155700684\n",
      "Total loss 0.07097411155700684\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.06829091161489487\n",
      "Total loss 0.06829091161489487\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.06598568707704544\n",
      "Total loss 0.06598568707704544\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.06277216970920563\n",
      "Total loss 0.06277216970920563\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.060514092445373535\n",
      "Total loss 0.060514092445373535\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.05857282131910324\n",
      "Total loss 0.05857282131910324\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.056946467608213425\n",
      "Total loss 0.056946467608213425\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.055022142827510834\n",
      "Total loss 0.055022142827510834\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.053481314331293106\n",
      "Total loss 0.053481314331293106\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.051473673433065414\n",
      "Total loss 0.051473673433065414\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.049955517053604126\n",
      "Total loss 0.049955517053604126\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.048227258026599884\n",
      "Total loss 0.048227258026599884\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.04770710691809654\n",
      "Total loss 0.04770710691809654\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.04560806602239609\n",
      "Total loss 0.04560806602239609\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.0450252927839756\n",
      "Total loss 0.0450252927839756\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.044058773666620255\n",
      "Total loss 0.044058773666620255\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.04195140302181244\n",
      "Total loss 0.04195140302181244\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.04248490184545517\n",
      "Total loss 0.04248490184545517\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03982018679380417\n",
      "Total loss 0.03982018679380417\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.04133739322423935\n",
      "Total loss 0.04133739322423935\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03936707600951195\n",
      "Total loss 0.03936707600951195\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.040200211107730865\n",
      "Total loss 0.040200211107730865\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03869067505002022\n",
      "Total loss 0.03869067505002022\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03965208679437637\n",
      "Total loss 0.03965208679437637\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03770637884736061\n",
      "Total loss 0.03770637884736061\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.037262801080942154\n",
      "Total loss 0.037262801080942154\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03627685457468033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:51:02,811 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:51:02 - INFO - easyeditor.editors.editor -   2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03627685457468033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 3/50 [01:15<19:55, 25.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What city did Abel Seyler live when he died?] -> [Tirana]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 7.208139896392822\n",
      "Total loss 7.208139896392822\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 4.67896842956543\n",
      "Total loss 4.67896842956543\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 3.030844211578369\n",
      "Total loss 3.030844211578369\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.7753530144691467\n",
      "Total loss 0.7753530144691467\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.8732513189315796\n",
      "Total loss 0.8732513189315796\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.9528228640556335\n",
      "Total loss 0.9528228640556335\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.0091294050216675\n",
      "Total loss 1.0091294050216675\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.031429409980774\n",
      "Total loss 1.031429409980774\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.0181657075881958\n",
      "Total loss 1.0181657075881958\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.9801937937736511\n",
      "Total loss 0.9801937937736511\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.9293602705001831\n",
      "Total loss 0.9293602705001831\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.8698524832725525\n",
      "Total loss 0.8698524832725525\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.8061149716377258\n",
      "Total loss 0.8061149716377258\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.741072952747345\n",
      "Total loss 0.741072952747345\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.6780296564102173\n",
      "Total loss 0.6780296564102173\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.6207835078239441\n",
      "Total loss 0.6207835078239441\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.5660815834999084\n",
      "Total loss 0.5660815834999084\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.5144674181938171\n",
      "Total loss 0.5144674181938171\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.4686712622642517\n",
      "Total loss 0.4686712622642517\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.42707163095474243\n",
      "Total loss 0.42707163095474243\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.3898574411869049\n",
      "Total loss 0.3898574411869049\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.3583228290081024\n",
      "Total loss 0.3583228290081024\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.3314671814441681\n",
      "Total loss 0.3314671814441681\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.30789703130722046\n",
      "Total loss 0.30789703130722046\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.284236878156662\n",
      "Total loss 0.284236878156662\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.2611101567745209\n",
      "Total loss 0.2611101567745209\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.23966437578201294\n",
      "Total loss 0.23966437578201294\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.22059644758701324\n",
      "Total loss 0.22059644758701324\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.2047555297613144\n",
      "Total loss 0.2047555297613144\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.19082941114902496\n",
      "Total loss 0.19082941114902496\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.17760685086250305\n",
      "Total loss 0.17760685086250305\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.16615745425224304\n",
      "Total loss 0.16615745425224304\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.15584295988082886\n",
      "Total loss 0.15584295988082886\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.1473788619041443\n",
      "Total loss 0.1473788619041443\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.13976840674877167\n",
      "Total loss 0.13976840674877167\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.1307796835899353\n",
      "Total loss 0.1307796835899353\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.1232488602399826\n",
      "Total loss 0.1232488602399826\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.11632595211267471\n",
      "Total loss 0.11632595211267471\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.10949107259511948\n",
      "Total loss 0.10949107259511948\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.102681465446949\n",
      "Total loss 0.102681465446949\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.09565151482820511\n",
      "Total loss 0.09565151482820511\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.08993041515350342\n",
      "Total loss 0.08993041515350342\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.08405690640211105\n",
      "Total loss 0.08405690640211105\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.08083714544773102\n",
      "Total loss 0.08083714544773102\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.07684299349784851\n",
      "Total loss 0.07684299349784851\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.07180943340063095\n",
      "Total loss 0.07180943340063095\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.06802998483181\n",
      "Total loss 0.06802998483181\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.06459568440914154\n",
      "Total loss 0.06459568440914154\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.06117451190948486\n",
      "Total loss 0.06117451190948486\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.05696742981672287\n",
      "Total loss 0.05696742981672287\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.05485856905579567\n",
      "Total loss 0.05485856905579567\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.05221050605177879\n",
      "Total loss 0.05221050605177879\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.05006558075547218\n",
      "Total loss 0.05006558075547218\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04827851429581642\n",
      "Total loss 0.04827851429581642\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.046571727842092514\n",
      "Total loss 0.046571727842092514\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.045231498777866364\n",
      "Total loss 0.045231498777866364\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.04412039741873741\n",
      "Total loss 0.04412039741873741\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.042408641427755356\n",
      "Total loss 0.042408641427755356\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.04138284921646118\n",
      "Total loss 0.04138284921646118\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.038975466042757034\n",
      "Total loss 0.038975466042757034\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03941566124558449\n",
      "Total loss 0.03941566124558449\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03801567479968071\n",
      "Total loss 0.03801567479968071\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.037513602524995804\n",
      "Total loss 0.037513602524995804\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03714171424508095\n",
      "Total loss 0.03714171424508095\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03562554717063904\n",
      "Total loss 0.03562554717063904\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03610171377658844\n",
      "Total loss 0.03610171377658844\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03508959710597992\n",
      "Total loss 0.03508959710597992\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.034779902547597885\n",
      "Total loss 0.034779902547597885\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03508787229657173\n",
      "Total loss 0.03508787229657173\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03400120139122009\n",
      "Total loss 0.03400120139122009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:51:29,172 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:51:29 - INFO - easyeditor.editors.editor -   3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  8%|         | 4/50 [01:41<19:46, 25.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [In which year was the service entry date for Kh-58?] -> [1980]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 3.204338312149048\n",
      "Total loss 3.204338312149048\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 1.7819442749023438\n",
      "Total loss 1.7819442749023438\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.8479734659194946\n",
      "Total loss 0.8479734659194946\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6775450110435486\n",
      "Total loss 0.6775450110435486\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6341421008110046\n",
      "Total loss 0.6341421008110046\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6015759110450745\n",
      "Total loss 0.6015759110450745\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.5748606324195862\n",
      "Total loss 0.5748606324195862\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.5256219506263733\n",
      "Total loss 0.5256219506263733\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.4639904499053955\n",
      "Total loss 0.4639904499053955\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.41261938214302063\n",
      "Total loss 0.41261938214302063\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.37352997064590454\n",
      "Total loss 0.37352997064590454\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3366900682449341\n",
      "Total loss 0.3366900682449341\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.30273738503456116\n",
      "Total loss 0.30273738503456116\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.27644968032836914\n",
      "Total loss 0.27644968032836914\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.25767406821250916\n",
      "Total loss 0.25767406821250916\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.24180868268013\n",
      "Total loss 0.24180868268013\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.22595356404781342\n",
      "Total loss 0.22595356404781342\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.21121153235435486\n",
      "Total loss 0.21121153235435486\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.19690321385860443\n",
      "Total loss 0.19690321385860443\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.18223154544830322\n",
      "Total loss 0.18223154544830322\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.1704874336719513\n",
      "Total loss 0.1704874336719513\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.15863293409347534\n",
      "Total loss 0.15863293409347534\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.14639197289943695\n",
      "Total loss 0.14639197289943695\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.13464117050170898\n",
      "Total loss 0.13464117050170898\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.12540900707244873\n",
      "Total loss 0.12540900707244873\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1142662912607193\n",
      "Total loss 0.1142662912607193\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.10660235583782196\n",
      "Total loss 0.10660235583782196\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.10083422809839249\n",
      "Total loss 0.10083422809839249\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.0942746251821518\n",
      "Total loss 0.0942746251821518\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.08820609003305435\n",
      "Total loss 0.08820609003305435\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.08155803382396698\n",
      "Total loss 0.08155803382396698\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.07562939077615738\n",
      "Total loss 0.07562939077615738\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.0715814083814621\n",
      "Total loss 0.0715814083814621\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.06997856497764587\n",
      "Total loss 0.06997856497764587\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06606098264455795\n",
      "Total loss 0.06606098264455795\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06496573984622955\n",
      "Total loss 0.06496573984622955\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.0623127780854702\n",
      "Total loss 0.0623127780854702\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.058033086359500885\n",
      "Total loss 0.058033086359500885\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.058741629123687744\n",
      "Total loss 0.058741629123687744\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05655500292778015\n",
      "Total loss 0.05655500292778015\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.054705724120140076\n",
      "Total loss 0.054705724120140076\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.0525987483561039\n",
      "Total loss 0.0525987483561039\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05167820304632187\n",
      "Total loss 0.05167820304632187\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04939277470111847\n",
      "Total loss 0.04939277470111847\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04792465642094612\n",
      "Total loss 0.04792465642094612\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04708807170391083\n",
      "Total loss 0.04708807170391083\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.046148695051670074\n",
      "Total loss 0.046148695051670074\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04519551247358322\n",
      "Total loss 0.04519551247358322\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.044370848685503006\n",
      "Total loss 0.044370848685503006\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.0425744354724884\n",
      "Total loss 0.0425744354724884\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.041787147521972656\n",
      "Total loss 0.041787147521972656\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04024364426732063\n",
      "Total loss 0.04024364426732063\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.039958856999874115\n",
      "Total loss 0.039958856999874115\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03790920600295067\n",
      "Total loss 0.03790920600295067\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03839651495218277\n",
      "Total loss 0.03839651495218277\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.037737153470516205\n",
      "Total loss 0.037737153470516205\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03701768070459366\n",
      "Total loss 0.03701768070459366\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03703317046165466\n",
      "Total loss 0.03703317046165466\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.035668838769197464\n",
      "Total loss 0.035668838769197464\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03723179176449776\n",
      "Total loss 0.03723179176449776\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.034678082913160324\n",
      "Total loss 0.034678082913160324\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.036193810403347015\n",
      "Total loss 0.036193810403347015\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03440191224217415\n",
      "Total loss 0.03440191224217415\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03525657579302788\n",
      "Total loss 0.03525657579302788\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03510945662856102\n",
      "Total loss 0.03510945662856102\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.034370943903923035\n",
      "Total loss 0.034370943903923035\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03500949218869209\n",
      "Total loss 0.03500949218869209\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.0340232327580452\n",
      "Total loss 0.0340232327580452\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03404445946216583\n",
      "Total loss 0.03404445946216583\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03384554386138916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:51:53,502 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:51:53 - INFO - easyeditor.editors.editor -   4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 10%|         | 5/50 [02:05<18:56, 25.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03384554386138916\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Which college or university is related with Gar Forman?] -> [Brown University]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 6.670093536376953\n",
      "Total loss 6.670093536376953\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 4.169139862060547\n",
      "Total loss 4.169139862060547\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.7107017040252686\n",
      "Total loss 2.7107017040252686\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 2.510727643966675\n",
      "Total loss 2.510727643966675\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 3.212564468383789\n",
      "Total loss 3.212564468383789\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.919636070728302\n",
      "Total loss 0.919636070728302\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.9827500581741333\n",
      "Total loss 0.9827500581741333\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.0630781650543213\n",
      "Total loss 1.0630781650543213\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.1236461400985718\n",
      "Total loss 1.1236461400985718\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 1.159558653831482\n",
      "Total loss 1.159558653831482\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 1.1729066371917725\n",
      "Total loss 1.1729066371917725\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 1.1656798124313354\n",
      "Total loss 1.1656798124313354\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 1.1402313709259033\n",
      "Total loss 1.1402313709259033\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 1.0998165607452393\n",
      "Total loss 1.0998165607452393\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 1.0502164363861084\n",
      "Total loss 1.0502164363861084\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.9948298335075378\n",
      "Total loss 0.9948298335075378\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.9369854927062988\n",
      "Total loss 0.9369854927062988\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.8779479265213013\n",
      "Total loss 0.8779479265213013\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.8200864195823669\n",
      "Total loss 0.8200864195823669\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.7655850052833557\n",
      "Total loss 0.7655850052833557\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.7135616540908813\n",
      "Total loss 0.7135616540908813\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.6640109419822693\n",
      "Total loss 0.6640109419822693\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.6181696057319641\n",
      "Total loss 0.6181696057319641\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.5767613649368286\n",
      "Total loss 0.5767613649368286\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.538289487361908\n",
      "Total loss 0.538289487361908\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.5021460652351379\n",
      "Total loss 0.5021460652351379\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.4689404368400574\n",
      "Total loss 0.4689404368400574\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.43828973174095154\n",
      "Total loss 0.43828973174095154\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.4094296395778656\n",
      "Total loss 0.4094296395778656\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.3834424912929535\n",
      "Total loss 0.3834424912929535\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.3605457842350006\n",
      "Total loss 0.3605457842350006\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.34067395329475403\n",
      "Total loss 0.34067395329475403\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.32182979583740234\n",
      "Total loss 0.32182979583740234\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.30426323413848877\n",
      "Total loss 0.30426323413848877\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.2867470979690552\n",
      "Total loss 0.2867470979690552\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.26990899443626404\n",
      "Total loss 0.26990899443626404\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.25380265712738037\n",
      "Total loss 0.25380265712738037\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.23949621617794037\n",
      "Total loss 0.23949621617794037\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.22549109160900116\n",
      "Total loss 0.22549109160900116\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.21272321045398712\n",
      "Total loss 0.21272321045398712\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.2000180184841156\n",
      "Total loss 0.2000180184841156\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.1879754662513733\n",
      "Total loss 0.1879754662513733\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.17658494412899017\n",
      "Total loss 0.17658494412899017\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.16725993156433105\n",
      "Total loss 0.16725993156433105\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.15790309011936188\n",
      "Total loss 0.15790309011936188\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.1494954377412796\n",
      "Total loss 0.1494954377412796\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.14205418527126312\n",
      "Total loss 0.14205418527126312\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.1346319168806076\n",
      "Total loss 0.1346319168806076\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.12702633440494537\n",
      "Total loss 0.12702633440494537\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.12036346644163132\n",
      "Total loss 0.12036346644163132\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.11365493386983871\n",
      "Total loss 0.11365493386983871\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.10851539671421051\n",
      "Total loss 0.10851539671421051\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.1025780513882637\n",
      "Total loss 0.1025780513882637\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.09692259877920151\n",
      "Total loss 0.09692259877920151\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.09168298542499542\n",
      "Total loss 0.09168298542499542\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.08673544228076935\n",
      "Total loss 0.08673544228076935\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.08247926831245422\n",
      "Total loss 0.08247926831245422\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.07970507442951202\n",
      "Total loss 0.07970507442951202\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.07683783769607544\n",
      "Total loss 0.07683783769607544\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.07339003682136536\n",
      "Total loss 0.07339003682136536\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.0714886263012886\n",
      "Total loss 0.0714886263012886\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.0681324452161789\n",
      "Total loss 0.0681324452161789\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.06677687168121338\n",
      "Total loss 0.06677687168121338\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.06430438905954361\n",
      "Total loss 0.06430438905954361\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.06294196844100952\n",
      "Total loss 0.06294196844100952\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.060559939593076706\n",
      "Total loss 0.060559939593076706\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.05921993404626846\n",
      "Total loss 0.05921993404626846\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.056480903178453445\n",
      "Total loss 0.056480903178453445\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.053876664489507675\n",
      "Total loss 0.053876664489507675\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.05282467603683472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:52:17,836 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:52:17 - INFO - easyeditor.editors.editor -   5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 12%|        | 6/50 [02:30<18:17, 24.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.05282467603683472\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [The person that is the mother of Bushra al-Assad is who?] -> [Reba al-Assad]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 6.148066520690918\n",
      "Total loss 6.148066520690918\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 4.447464942932129\n",
      "Total loss 4.447464942932129\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.0020534992218018\n",
      "Total loss 2.0020534992218018\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.8040145635604858\n",
      "Total loss 0.8040145635604858\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6654754281044006\n",
      "Total loss 0.6654754281044006\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6709045171737671\n",
      "Total loss 0.6709045171737671\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6707863807678223\n",
      "Total loss 0.6707863807678223\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6400467157363892\n",
      "Total loss 0.6400467157363892\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5803226828575134\n",
      "Total loss 0.5803226828575134\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.5191009640693665\n",
      "Total loss 0.5191009640693665\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.46973463892936707\n",
      "Total loss 0.46973463892936707\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.42487895488739014\n",
      "Total loss 0.42487895488739014\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.3861895799636841\n",
      "Total loss 0.3861895799636841\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.35398706793785095\n",
      "Total loss 0.35398706793785095\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3258725106716156\n",
      "Total loss 0.3258725106716156\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.3005377948284149\n",
      "Total loss 0.3005377948284149\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.2776763439178467\n",
      "Total loss 0.2776763439178467\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.25606387853622437\n",
      "Total loss 0.25606387853622437\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.23886525630950928\n",
      "Total loss 0.23886525630950928\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2236909121274948\n",
      "Total loss 0.2236909121274948\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.20746029913425446\n",
      "Total loss 0.20746029913425446\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.19009940326213837\n",
      "Total loss 0.19009940326213837\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.17320619523525238\n",
      "Total loss 0.17320619523525238\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.15586943924427032\n",
      "Total loss 0.15586943924427032\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.14184577763080597\n",
      "Total loss 0.14184577763080597\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1299077421426773\n",
      "Total loss 0.1299077421426773\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.11690795421600342\n",
      "Total loss 0.11690795421600342\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.10536134243011475\n",
      "Total loss 0.10536134243011475\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.09606266021728516\n",
      "Total loss 0.09606266021728516\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.08999063074588776\n",
      "Total loss 0.08999063074588776\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.08227822929620743\n",
      "Total loss 0.08227822929620743\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.07671806216239929\n",
      "Total loss 0.07671806216239929\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.07244767993688583\n",
      "Total loss 0.07244767993688583\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07033633440732956\n",
      "Total loss 0.07033633440732956\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06841669976711273\n",
      "Total loss 0.06841669976711273\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06380745768547058\n",
      "Total loss 0.06380745768547058\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.06184568256139755\n",
      "Total loss 0.06184568256139755\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05951574817299843\n",
      "Total loss 0.05951574817299843\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.057297512888908386\n",
      "Total loss 0.057297512888908386\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05456283316016197\n",
      "Total loss 0.05456283316016197\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05272984504699707\n",
      "Total loss 0.05272984504699707\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05162016674876213\n",
      "Total loss 0.05162016674876213\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04973594471812248\n",
      "Total loss 0.04973594471812248\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04901585727930069\n",
      "Total loss 0.04901585727930069\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04845812916755676\n",
      "Total loss 0.04845812916755676\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.047028880566358566\n",
      "Total loss 0.047028880566358566\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04567992314696312\n",
      "Total loss 0.04567992314696312\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04393700510263443\n",
      "Total loss 0.04393700510263443\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.042577385902404785\n",
      "Total loss 0.042577385902404785\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04260754585266113\n",
      "Total loss 0.04260754585266113\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04066985100507736\n",
      "Total loss 0.04066985100507736\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.039887696504592896\n",
      "Total loss 0.039887696504592896\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.0390351302921772\n",
      "Total loss 0.0390351302921772\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.038005270063877106\n",
      "Total loss 0.038005270063877106\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03752119466662407\n",
      "Total loss 0.03752119466662407\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.037691038101911545\n",
      "Total loss 0.037691038101911545\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03652656450867653\n",
      "Total loss 0.03652656450867653\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03608997166156769\n",
      "Total loss 0.03608997166156769\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.037034548819065094\n",
      "Total loss 0.037034548819065094\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03539547324180603\n",
      "Total loss 0.03539547324180603\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.037027835845947266\n",
      "Total loss 0.037027835845947266\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03610438480973244\n",
      "Total loss 0.03610438480973244\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03660605847835541\n",
      "Total loss 0.03660605847835541\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03606323152780533\n",
      "Total loss 0.03606323152780533\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03503589332103729\n",
      "Total loss 0.03503589332103729\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.036053162068128586\n",
      "Total loss 0.036053162068128586\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.034653931856155396\n",
      "Total loss 0.034653931856155396\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03594112768769264\n",
      "Total loss 0.03594112768769264\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03462962061166763\n",
      "Total loss 0.03462962061166763\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03441553935408592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:52:42,002 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:52:42 - INFO - easyeditor.editors.editor -   6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 14%|        | 7/50 [02:54<17:41, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03441553935408592\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Where did Mohammad Naseem live when he died?] -> [Tajikistan]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.1238603591918945\n",
      "Total loss 5.1238603591918945\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.507610559463501\n",
      "Total loss 3.507610559463501\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.495697498321533\n",
      "Total loss 2.495697498321533\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.7199571132659912\n",
      "Total loss 0.7199571132659912\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.7193036079406738\n",
      "Total loss 0.7193036079406738\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.7753328084945679\n",
      "Total loss 0.7753328084945679\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.7908953428268433\n",
      "Total loss 0.7908953428268433\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.7910632491111755\n",
      "Total loss 0.7910632491111755\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.7590133547782898\n",
      "Total loss 0.7590133547782898\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.7081140875816345\n",
      "Total loss 0.7081140875816345\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.6537101864814758\n",
      "Total loss 0.6537101864814758\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.6006808876991272\n",
      "Total loss 0.6006808876991272\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.5504863262176514\n",
      "Total loss 0.5504863262176514\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.5025145411491394\n",
      "Total loss 0.5025145411491394\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.455897718667984\n",
      "Total loss 0.455897718667984\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.4156142473220825\n",
      "Total loss 0.4156142473220825\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.3795890808105469\n",
      "Total loss 0.3795890808105469\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.34625244140625\n",
      "Total loss 0.34625244140625\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.3176634609699249\n",
      "Total loss 0.3176634609699249\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2901975214481354\n",
      "Total loss 0.2901975214481354\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.2651253938674927\n",
      "Total loss 0.2651253938674927\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.24525012075901031\n",
      "Total loss 0.24525012075901031\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.22819176316261292\n",
      "Total loss 0.22819176316261292\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.21306663751602173\n",
      "Total loss 0.21306663751602173\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.19992609322071075\n",
      "Total loss 0.19992609322071075\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.18568558990955353\n",
      "Total loss 0.18568558990955353\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.17236986756324768\n",
      "Total loss 0.17236986756324768\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.16198204457759857\n",
      "Total loss 0.16198204457759857\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.14926935732364655\n",
      "Total loss 0.14926935732364655\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.1385280191898346\n",
      "Total loss 0.1385280191898346\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.12914630770683289\n",
      "Total loss 0.12914630770683289\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.12154814600944519\n",
      "Total loss 0.12154814600944519\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.11280453205108643\n",
      "Total loss 0.11280453205108643\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.1037474200129509\n",
      "Total loss 0.1037474200129509\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.09507396072149277\n",
      "Total loss 0.09507396072149277\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.08900763094425201\n",
      "Total loss 0.08900763094425201\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.08341632783412933\n",
      "Total loss 0.08341632783412933\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.07894334197044373\n",
      "Total loss 0.07894334197044373\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.07244078069925308\n",
      "Total loss 0.07244078069925308\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.06972815841436386\n",
      "Total loss 0.06972815841436386\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.06525424867868423\n",
      "Total loss 0.06525424867868423\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.06305937469005585\n",
      "Total loss 0.06305937469005585\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.06008024141192436\n",
      "Total loss 0.06008024141192436\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.05769823119044304\n",
      "Total loss 0.05769823119044304\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.05539436265826225\n",
      "Total loss 0.05539436265826225\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.05401480942964554\n",
      "Total loss 0.05401480942964554\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.05039848014712334\n",
      "Total loss 0.05039848014712334\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.049868859350681305\n",
      "Total loss 0.049868859350681305\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.046950049698352814\n",
      "Total loss 0.046950049698352814\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.045002084225416183\n",
      "Total loss 0.045002084225416183\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04292478412389755\n",
      "Total loss 0.04292478412389755\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04201729968190193\n",
      "Total loss 0.04201729968190193\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.041361551731824875\n",
      "Total loss 0.041361551731824875\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04041433706879616\n",
      "Total loss 0.04041433706879616\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.039326053112745285\n",
      "Total loss 0.039326053112745285\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.037859346717596054\n",
      "Total loss 0.037859346717596054\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03778566047549248\n",
      "Total loss 0.03778566047549248\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03679802641272545\n",
      "Total loss 0.03679802641272545\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03677372634410858\n",
      "Total loss 0.03677372634410858\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.037528667598962784\n",
      "Total loss 0.037528667598962784\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03633461892604828\n",
      "Total loss 0.03633461892604828\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03613946959376335\n",
      "Total loss 0.03613946959376335\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.036126188933849335\n",
      "Total loss 0.036126188933849335\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03628954663872719\n",
      "Total loss 0.03628954663872719\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.035493746399879456\n",
      "Total loss 0.035493746399879456\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03527729958295822\n",
      "Total loss 0.03527729958295822\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.034631967544555664\n",
      "Total loss 0.034631967544555664\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03398062288761139\n",
      "Total loss 0.03398062288761139\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03429979458451271\n",
      "Total loss 0.03429979458451271\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03237759694457054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:53:06,318 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:53:06 - INFO - easyeditor.editors.editor -   7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 16%|        | 8/50 [03:18<17:12, 24.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03237759694457054\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What was the year SR N15X class entered service?] -> [1990]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.157668113708496\n",
      "Total loss 4.157668113708496\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.2728991508483887\n",
      "Total loss 2.2728991508483887\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.569277048110962\n",
      "Total loss 1.569277048110962\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 2.128340721130371\n",
      "Total loss 2.128340721130371\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.0191230773925781\n",
      "Total loss 1.0191230773925781\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.8216730356216431\n",
      "Total loss 0.8216730356216431\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6998717784881592\n",
      "Total loss 0.6998717784881592\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.7013052105903625\n",
      "Total loss 0.7013052105903625\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.6913344264030457\n",
      "Total loss 0.6913344264030457\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.654379665851593\n",
      "Total loss 0.654379665851593\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.6128122806549072\n",
      "Total loss 0.6128122806549072\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.5703831911087036\n",
      "Total loss 0.5703831911087036\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.5239945650100708\n",
      "Total loss 0.5239945650100708\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.4800164997577667\n",
      "Total loss 0.4800164997577667\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.44340527057647705\n",
      "Total loss 0.44340527057647705\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.4122864902019501\n",
      "Total loss 0.4122864902019501\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.384386271238327\n",
      "Total loss 0.384386271238327\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.35814279317855835\n",
      "Total loss 0.35814279317855835\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.3339810073375702\n",
      "Total loss 0.3339810073375702\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.31335797905921936\n",
      "Total loss 0.31335797905921936\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.2926424741744995\n",
      "Total loss 0.2926424741744995\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.2728557288646698\n",
      "Total loss 0.2728557288646698\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.2543277442455292\n",
      "Total loss 0.2543277442455292\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.23738588392734528\n",
      "Total loss 0.23738588392734528\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.2209986448287964\n",
      "Total loss 0.2209986448287964\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.20646809041500092\n",
      "Total loss 0.20646809041500092\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.19452302157878876\n",
      "Total loss 0.19452302157878876\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.1838100701570511\n",
      "Total loss 0.1838100701570511\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.17432020604610443\n",
      "Total loss 0.17432020604610443\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.16621144115924835\n",
      "Total loss 0.16621144115924835\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.1577393263578415\n",
      "Total loss 0.1577393263578415\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.15000630915164948\n",
      "Total loss 0.15000630915164948\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.14330226182937622\n",
      "Total loss 0.14330226182937622\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.1363992989063263\n",
      "Total loss 0.1363992989063263\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.12885785102844238\n",
      "Total loss 0.12885785102844238\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.1232299730181694\n",
      "Total loss 0.1232299730181694\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.1168103814125061\n",
      "Total loss 0.1168103814125061\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.10930541902780533\n",
      "Total loss 0.10930541902780533\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.10285728424787521\n",
      "Total loss 0.10285728424787521\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.09812983125448227\n",
      "Total loss 0.09812983125448227\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.09483466297388077\n",
      "Total loss 0.09483466297388077\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.0900641530752182\n",
      "Total loss 0.0900641530752182\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.08524174243211746\n",
      "Total loss 0.08524174243211746\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.0820503830909729\n",
      "Total loss 0.0820503830909729\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.07861188799142838\n",
      "Total loss 0.07861188799142838\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.07501550763845444\n",
      "Total loss 0.07501550763845444\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.07234951108694077\n",
      "Total loss 0.07234951108694077\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.06960906088352203\n",
      "Total loss 0.06960906088352203\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.06840721517801285\n",
      "Total loss 0.06840721517801285\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.06504256278276443\n",
      "Total loss 0.06504256278276443\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.06491636484861374\n",
      "Total loss 0.06491636484861374\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.061430152505636215\n",
      "Total loss 0.061430152505636215\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.06039201840758324\n",
      "Total loss 0.06039201840758324\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.05834117904305458\n",
      "Total loss 0.05834117904305458\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.05732033774256706\n",
      "Total loss 0.05732033774256706\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.056665267795324326\n",
      "Total loss 0.056665267795324326\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.053790658712387085\n",
      "Total loss 0.053790658712387085\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.05336148664355278\n",
      "Total loss 0.05336148664355278\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.05043889209628105\n",
      "Total loss 0.05043889209628105\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.050136666744947433\n",
      "Total loss 0.050136666744947433\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.04874253645539284\n",
      "Total loss 0.04874253645539284\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.047440867871046066\n",
      "Total loss 0.047440867871046066\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.04684244096279144\n",
      "Total loss 0.04684244096279144\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.04507411643862724\n",
      "Total loss 0.04507411643862724\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.045137617737054825\n",
      "Total loss 0.045137617737054825\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.042895954102277756\n",
      "Total loss 0.042895954102277756\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.04230453446507454\n",
      "Total loss 0.04230453446507454\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.041474319994449615\n",
      "Total loss 0.041474319994449615\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.04027208313345909\n",
      "Total loss 0.04027208313345909\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.04054007679224014\n",
      "Total loss 0.04054007679224014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:53:35,055 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:53:35 - INFO - easyeditor.editors.editor -   8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 18%|        | 9/50 [03:47<17:40, 25.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Which college or university is related with Rose Ann Scamardella?] -> [Columbia University]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.5951690673828125\n",
      "Total loss 5.5951690673828125\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.799959659576416\n",
      "Total loss 2.799959659576416\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.8358807563781738\n",
      "Total loss 0.8358807563781738\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6745063662528992\n",
      "Total loss 0.6745063662528992\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6464520692825317\n",
      "Total loss 0.6464520692825317\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6022195816040039\n",
      "Total loss 0.6022195816040039\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.5652292370796204\n",
      "Total loss 0.5652292370796204\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.511199951171875\n",
      "Total loss 0.511199951171875\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.44244909286499023\n",
      "Total loss 0.44244909286499023\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.38752293586730957\n",
      "Total loss 0.38752293586730957\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.348628431558609\n",
      "Total loss 0.348628431558609\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3121061623096466\n",
      "Total loss 0.3121061623096466\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.28112688660621643\n",
      "Total loss 0.28112688660621643\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.2568908631801605\n",
      "Total loss 0.2568908631801605\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.23726484179496765\n",
      "Total loss 0.23726484179496765\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2203185111284256\n",
      "Total loss 0.2203185111284256\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.2019912302494049\n",
      "Total loss 0.2019912302494049\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.18457140028476715\n",
      "Total loss 0.18457140028476715\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.17053979635238647\n",
      "Total loss 0.17053979635238647\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.15480734407901764\n",
      "Total loss 0.15480734407901764\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.14158235490322113\n",
      "Total loss 0.14158235490322113\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.13155537843704224\n",
      "Total loss 0.13155537843704224\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.12146884202957153\n",
      "Total loss 0.12146884202957153\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1112692579627037\n",
      "Total loss 0.1112692579627037\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.10264582931995392\n",
      "Total loss 0.10264582931995392\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.09431121498346329\n",
      "Total loss 0.09431121498346329\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.08653384447097778\n",
      "Total loss 0.08653384447097778\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.08126088231801987\n",
      "Total loss 0.08126088231801987\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.07540887594223022\n",
      "Total loss 0.07540887594223022\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.07100818306207657\n",
      "Total loss 0.07100818306207657\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.06959383934736252\n",
      "Total loss 0.06959383934736252\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.06420785188674927\n",
      "Total loss 0.06420785188674927\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.06221509724855423\n",
      "Total loss 0.06221509724855423\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.06122002378106117\n",
      "Total loss 0.06122002378106117\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06024257838726044\n",
      "Total loss 0.06024257838726044\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.05677225440740585\n",
      "Total loss 0.05677225440740585\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.05655287206172943\n",
      "Total loss 0.05655287206172943\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05528206378221512\n",
      "Total loss 0.05528206378221512\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.052687399089336395\n",
      "Total loss 0.052687399089336395\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.050590526312589645\n",
      "Total loss 0.050590526312589645\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04866483807563782\n",
      "Total loss 0.04866483807563782\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.04910726100206375\n",
      "Total loss 0.04910726100206375\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04672020301222801\n",
      "Total loss 0.04672020301222801\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.045054227113723755\n",
      "Total loss 0.045054227113723755\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04497326910495758\n",
      "Total loss 0.04497326910495758\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04334002360701561\n",
      "Total loss 0.04334002360701561\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04313362389802933\n",
      "Total loss 0.04313362389802933\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04200832545757294\n",
      "Total loss 0.04200832545757294\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04041488468647003\n",
      "Total loss 0.04041488468647003\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.03991980105638504\n",
      "Total loss 0.03991980105638504\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.0388641394674778\n",
      "Total loss 0.0388641394674778\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03889675438404083\n",
      "Total loss 0.03889675438404083\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03899776190519333\n",
      "Total loss 0.03899776190519333\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.0381377711892128\n",
      "Total loss 0.0381377711892128\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03823135420680046\n",
      "Total loss 0.03823135420680046\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.037490665912628174\n",
      "Total loss 0.037490665912628174\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.036625370383262634\n",
      "Total loss 0.036625370383262634\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03686349838972092\n",
      "Total loss 0.03686349838972092\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03792316094040871\n",
      "Total loss 0.03792316094040871\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03517536073923111\n",
      "Total loss 0.03517536073923111\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.037698544561862946\n",
      "Total loss 0.037698544561862946\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.0355755053460598\n",
      "Total loss 0.0355755053460598\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.036169495433568954\n",
      "Total loss 0.036169495433568954\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03577001020312309\n",
      "Total loss 0.03577001020312309\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03484733775258064\n",
      "Total loss 0.03484733775258064\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03607518970966339\n",
      "Total loss 0.03607518970966339\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.034538596868515015\n",
      "Total loss 0.034538596868515015\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.036300208419561386\n",
      "Total loss 0.036300208419561386\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03468507528305054\n",
      "Total loss 0.03468507528305054\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03512454032897949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:53:59,389 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:53:59 - INFO - easyeditor.editors.editor -   9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 20%|        | 10/50 [04:11<16:55, 25.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03512454032897949\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What studio produced Kaaki Sattai?] -> [Yash Raj Movies]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 7.599885940551758\n",
      "Total loss 7.599885940551758\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 4.980886936187744\n",
      "Total loss 4.980886936187744\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.1016898155212402\n",
      "Total loss 2.1016898155212402\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.3510863780975342\n",
      "Total loss 1.3510863780975342\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.9721251726150513\n",
      "Total loss 0.9721251726150513\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.9826090931892395\n",
      "Total loss 0.9826090931892395\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.0079561471939087\n",
      "Total loss 1.0079561471939087\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.9971238970756531\n",
      "Total loss 0.9971238970756531\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.9511167407035828\n",
      "Total loss 0.9511167407035828\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.8842270970344543\n",
      "Total loss 0.8842270970344543\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.8107216954231262\n",
      "Total loss 0.8107216954231262\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.7380452156066895\n",
      "Total loss 0.7380452156066895\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.6655445098876953\n",
      "Total loss 0.6655445098876953\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.5987010598182678\n",
      "Total loss 0.5987010598182678\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.5421797633171082\n",
      "Total loss 0.5421797633171082\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.49386438727378845\n",
      "Total loss 0.49386438727378845\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.45044663548469543\n",
      "Total loss 0.45044663548469543\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.41376760601997375\n",
      "Total loss 0.41376760601997375\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.38177579641342163\n",
      "Total loss 0.38177579641342163\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.353087455034256\n",
      "Total loss 0.353087455034256\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.3277038037776947\n",
      "Total loss 0.3277038037776947\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.30543217062950134\n",
      "Total loss 0.30543217062950134\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.2848889231681824\n",
      "Total loss 0.2848889231681824\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.266409307718277\n",
      "Total loss 0.266409307718277\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.24963726103305817\n",
      "Total loss 0.24963726103305817\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.23133383691310883\n",
      "Total loss 0.23133383691310883\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.21249385178089142\n",
      "Total loss 0.21249385178089142\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.1947706937789917\n",
      "Total loss 0.1947706937789917\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.17989006638526917\n",
      "Total loss 0.17989006638526917\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.1671038568019867\n",
      "Total loss 0.1671038568019867\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.15511181950569153\n",
      "Total loss 0.15511181950569153\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.14478948712348938\n",
      "Total loss 0.14478948712348938\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.13487812876701355\n",
      "Total loss 0.13487812876701355\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.1245146244764328\n",
      "Total loss 0.1245146244764328\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.11603546142578125\n",
      "Total loss 0.11603546142578125\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.1079278439283371\n",
      "Total loss 0.1079278439283371\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.10191977024078369\n",
      "Total loss 0.10191977024078369\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.09486208111047745\n",
      "Total loss 0.09486208111047745\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.08896314352750778\n",
      "Total loss 0.08896314352750778\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.08467569947242737\n",
      "Total loss 0.08467569947242737\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.08154487609863281\n",
      "Total loss 0.08154487609863281\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.07791124284267426\n",
      "Total loss 0.07791124284267426\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.0744205117225647\n",
      "Total loss 0.0744205117225647\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.06970013678073883\n",
      "Total loss 0.06970013678073883\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.06640006601810455\n",
      "Total loss 0.06640006601810455\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.06415696442127228\n",
      "Total loss 0.06415696442127228\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.06074090301990509\n",
      "Total loss 0.06074090301990509\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.0585278756916523\n",
      "Total loss 0.0585278756916523\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.05594177171587944\n",
      "Total loss 0.05594177171587944\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.05451538413763046\n",
      "Total loss 0.05451538413763046\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.05348992347717285\n",
      "Total loss 0.05348992347717285\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.05202517658472061\n",
      "Total loss 0.05202517658472061\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04846195504069328\n",
      "Total loss 0.04846195504069328\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04844425991177559\n",
      "Total loss 0.04844425991177559\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.0466894656419754\n",
      "Total loss 0.0466894656419754\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.0451698824763298\n",
      "Total loss 0.0451698824763298\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.043532006442546844\n",
      "Total loss 0.043532006442546844\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.04216291755437851\n",
      "Total loss 0.04216291755437851\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.04126604646444321\n",
      "Total loss 0.04126604646444321\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.04107453301548958\n",
      "Total loss 0.04107453301548958\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03946202993392944\n",
      "Total loss 0.03946202993392944\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03921342268586159\n",
      "Total loss 0.03921342268586159\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.037986189126968384\n",
      "Total loss 0.037986189126968384\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03766443580389023\n",
      "Total loss 0.03766443580389023\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.036696430295705795\n",
      "Total loss 0.036696430295705795\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03686228021979332\n",
      "Total loss 0.03686228021979332\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.036740727722644806\n",
      "Total loss 0.036740727722644806\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03592757508158684\n",
      "Total loss 0.03592757508158684\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03533336520195007\n",
      "Total loss 0.03533336520195007\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03488289937376976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:54:24,018 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:54:24 - INFO - easyeditor.editors.editor -   10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 22%|       | 11/50 [04:36<16:21, 25.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03488289937376976\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [In which year Kaabu ceased to exist?] -> [1994]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.323912620544434\n",
      "Total loss 4.323912620544434\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.462719440460205\n",
      "Total loss 2.462719440460205\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.8264875411987305\n",
      "Total loss 0.8264875411987305\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6174976229667664\n",
      "Total loss 0.6174976229667664\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.5834986567497253\n",
      "Total loss 0.5834986567497253\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.5485851764678955\n",
      "Total loss 0.5485851764678955\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.5336009860038757\n",
      "Total loss 0.5336009860038757\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.49318328499794006\n",
      "Total loss 0.49318328499794006\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.4355670213699341\n",
      "Total loss 0.4355670213699341\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4000106155872345\n",
      "Total loss 0.4000106155872345\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.3729811906814575\n",
      "Total loss 0.3729811906814575\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3397418260574341\n",
      "Total loss 0.3397418260574341\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.3109929859638214\n",
      "Total loss 0.3109929859638214\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.28765472769737244\n",
      "Total loss 0.28765472769737244\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.26579371094703674\n",
      "Total loss 0.26579371094703674\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2482011318206787\n",
      "Total loss 0.2482011318206787\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.22980628907680511\n",
      "Total loss 0.22980628907680511\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.2130417674779892\n",
      "Total loss 0.2130417674779892\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.2002141773700714\n",
      "Total loss 0.2002141773700714\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.18550196290016174\n",
      "Total loss 0.18550196290016174\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.17159968614578247\n",
      "Total loss 0.17159968614578247\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.16148576140403748\n",
      "Total loss 0.16148576140403748\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.14991958439350128\n",
      "Total loss 0.14991958439350128\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.13840267062187195\n",
      "Total loss 0.13840267062187195\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.12799325585365295\n",
      "Total loss 0.12799325585365295\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1158495545387268\n",
      "Total loss 0.1158495545387268\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.10649215430021286\n",
      "Total loss 0.10649215430021286\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.09936131536960602\n",
      "Total loss 0.09936131536960602\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.09122111648321152\n",
      "Total loss 0.09122111648321152\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.0858580619096756\n",
      "Total loss 0.0858580619096756\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.08086907863616943\n",
      "Total loss 0.08086907863616943\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.07621196657419205\n",
      "Total loss 0.07621196657419205\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.072882741689682\n",
      "Total loss 0.072882741689682\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.0700959637761116\n",
      "Total loss 0.0700959637761116\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06775997579097748\n",
      "Total loss 0.06775997579097748\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06335912644863129\n",
      "Total loss 0.06335912644863129\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.0601789727807045\n",
      "Total loss 0.0601789727807045\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.0591900460422039\n",
      "Total loss 0.0591900460422039\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.057760074734687805\n",
      "Total loss 0.057760074734687805\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05427176505327225\n",
      "Total loss 0.05427176505327225\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05444198101758957\n",
      "Total loss 0.05444198101758957\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.0520484633743763\n",
      "Total loss 0.0520484633743763\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.051284823566675186\n",
      "Total loss 0.051284823566675186\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04753894358873367\n",
      "Total loss 0.04753894358873367\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04850068315863609\n",
      "Total loss 0.04850068315863609\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04481879621744156\n",
      "Total loss 0.04481879621744156\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.046300794929265976\n",
      "Total loss 0.046300794929265976\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04465675354003906\n",
      "Total loss 0.04465675354003906\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04321829602122307\n",
      "Total loss 0.04321829602122307\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.043827809393405914\n",
      "Total loss 0.043827809393405914\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04152732342481613\n",
      "Total loss 0.04152732342481613\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04153123125433922\n",
      "Total loss 0.04153123125433922\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.039887890219688416\n",
      "Total loss 0.039887890219688416\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03983448073267937\n",
      "Total loss 0.03983448073267937\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.039595939218997955\n",
      "Total loss 0.039595939218997955\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03901229426264763\n",
      "Total loss 0.03901229426264763\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03867588937282562\n",
      "Total loss 0.03867588937282562\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03842421993613243\n",
      "Total loss 0.03842421993613243\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.037154845893383026\n",
      "Total loss 0.037154845893383026\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.036764439195394516\n",
      "Total loss 0.036764439195394516\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03666194900870323\n",
      "Total loss 0.03666194900870323\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.035845644772052765\n",
      "Total loss 0.035845644772052765\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03632121533155441\n",
      "Total loss 0.03632121533155441\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03510575741529465\n",
      "Total loss 0.03510575741529465\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.036060310900211334\n",
      "Total loss 0.036060310900211334\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03564729541540146\n",
      "Total loss 0.03564729541540146\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.036058735102415085\n",
      "Total loss 0.036058735102415085\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.035376328974962234\n",
      "Total loss 0.035376328974962234\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03691000118851662\n",
      "Total loss 0.03691000118851662\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03506846725940704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:54:47,646 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:54:47 - INFO - easyeditor.editors.editor -   11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 24%|       | 12/50 [05:00<15:38, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03506846725940704\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What was the cause of Mavis Villiers's death?] -> [breast cancer]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 8.5078125\n",
      "Total loss 8.5078125\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 6.1956562995910645\n",
      "Total loss 6.1956562995910645\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.7968432903289795\n",
      "Total loss 1.7968432903289795\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.7506358623504639\n",
      "Total loss 0.7506358623504639\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.832245945930481\n",
      "Total loss 0.832245945930481\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.8973170518875122\n",
      "Total loss 0.8973170518875122\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.9352567195892334\n",
      "Total loss 0.9352567195892334\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.9344568252563477\n",
      "Total loss 0.9344568252563477\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.8963271379470825\n",
      "Total loss 0.8963271379470825\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.8411526679992676\n",
      "Total loss 0.8411526679992676\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.7802501916885376\n",
      "Total loss 0.7802501916885376\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.7164479494094849\n",
      "Total loss 0.7164479494094849\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.6528158783912659\n",
      "Total loss 0.6528158783912659\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.5903376936912537\n",
      "Total loss 0.5903376936912537\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.5320051312446594\n",
      "Total loss 0.5320051312446594\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.479442298412323\n",
      "Total loss 0.479442298412323\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.4333495497703552\n",
      "Total loss 0.4333495497703552\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.393662691116333\n",
      "Total loss 0.393662691116333\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.35631707310676575\n",
      "Total loss 0.35631707310676575\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.32178935408592224\n",
      "Total loss 0.32178935408592224\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.2914247512817383\n",
      "Total loss 0.2914247512817383\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.2667997479438782\n",
      "Total loss 0.2667997479438782\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.24503113329410553\n",
      "Total loss 0.24503113329410553\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.2246207892894745\n",
      "Total loss 0.2246207892894745\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.2063334882259369\n",
      "Total loss 0.2063334882259369\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.18876595795154572\n",
      "Total loss 0.18876595795154572\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.17230647802352905\n",
      "Total loss 0.17230647802352905\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.15893395245075226\n",
      "Total loss 0.15893395245075226\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.1468857079744339\n",
      "Total loss 0.1468857079744339\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.13392238318920135\n",
      "Total loss 0.13392238318920135\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.12357451021671295\n",
      "Total loss 0.12357451021671295\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.11488832533359528\n",
      "Total loss 0.11488832533359528\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.10653582960367203\n",
      "Total loss 0.10653582960367203\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.0993049368262291\n",
      "Total loss 0.0993049368262291\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.0921124517917633\n",
      "Total loss 0.0921124517917633\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.08618932217359543\n",
      "Total loss 0.08618932217359543\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.08103122562170029\n",
      "Total loss 0.08103122562170029\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.07527697086334229\n",
      "Total loss 0.07527697086334229\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.07146909832954407\n",
      "Total loss 0.07146909832954407\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.06715044379234314\n",
      "Total loss 0.06715044379234314\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.06330528855323792\n",
      "Total loss 0.06330528855323792\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.059307459741830826\n",
      "Total loss 0.059307459741830826\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05669819936156273\n",
      "Total loss 0.05669819936156273\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.054737892001867294\n",
      "Total loss 0.054737892001867294\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.05303005129098892\n",
      "Total loss 0.05303005129098892\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.05088934302330017\n",
      "Total loss 0.05088934302330017\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04920567199587822\n",
      "Total loss 0.04920567199587822\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.047777265310287476\n",
      "Total loss 0.047777265310287476\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04704202339053154\n",
      "Total loss 0.04704202339053154\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04477576166391373\n",
      "Total loss 0.04477576166391373\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04380840063095093\n",
      "Total loss 0.04380840063095093\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04241654649376869\n",
      "Total loss 0.04241654649376869\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.040194395929574966\n",
      "Total loss 0.040194395929574966\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.039753567427396774\n",
      "Total loss 0.039753567427396774\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03855833783745766\n",
      "Total loss 0.03855833783745766\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03778862953186035\n",
      "Total loss 0.03778862953186035\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03760847821831703\n",
      "Total loss 0.03760847821831703\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.037157345563173294\n",
      "Total loss 0.037157345563173294\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03723509609699249\n",
      "Total loss 0.03723509609699249\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.037371374666690826\n",
      "Total loss 0.037371374666690826\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03535965830087662\n",
      "Total loss 0.03535965830087662\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03554818406701088\n",
      "Total loss 0.03554818406701088\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.034402813762426376\n",
      "Total loss 0.034402813762426376\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03449281305074692\n",
      "Total loss 0.03449281305074692\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03454751521348953\n",
      "Total loss 0.03454751521348953\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03461991623044014\n",
      "Total loss 0.03461991623044014\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03447088226675987\n",
      "Total loss 0.03447088226675987\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03440646454691887\n",
      "Total loss 0.03440646454691887\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03489287942647934\n",
      "Total loss 0.03489287942647934\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03386317938566208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:55:13,255 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:55:13 - INFO - easyeditor.editors.editor -   12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03386317938566208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 13/50 [05:25<15:24, 24.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What label was responsible for United Abominations?] -> [Arista Records]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 6.748290538787842\n",
      "Total loss 6.748290538787842\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.4956929683685303\n",
      "Total loss 3.4956929683685303\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.5785629749298096\n",
      "Total loss 1.5785629749298096\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.8831586837768555\n",
      "Total loss 0.8831586837768555\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.8375619053840637\n",
      "Total loss 0.8375619053840637\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.881067156791687\n",
      "Total loss 0.881067156791687\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.900192379951477\n",
      "Total loss 0.900192379951477\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.8866929411888123\n",
      "Total loss 0.8866929411888123\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.8452967405319214\n",
      "Total loss 0.8452967405319214\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.7911320924758911\n",
      "Total loss 0.7911320924758911\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.7321938872337341\n",
      "Total loss 0.7321938872337341\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.6699010133743286\n",
      "Total loss 0.6699010133743286\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.6079602241516113\n",
      "Total loss 0.6079602241516113\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.5491223335266113\n",
      "Total loss 0.5491223335266113\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.4948887825012207\n",
      "Total loss 0.4948887825012207\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.4506935477256775\n",
      "Total loss 0.4506935477256775\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.41106683015823364\n",
      "Total loss 0.41106683015823364\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.3749193549156189\n",
      "Total loss 0.3749193549156189\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.34209126234054565\n",
      "Total loss 0.34209126234054565\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.3111928403377533\n",
      "Total loss 0.3111928403377533\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.28186067938804626\n",
      "Total loss 0.28186067938804626\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.2561986446380615\n",
      "Total loss 0.2561986446380615\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.23550312221050262\n",
      "Total loss 0.23550312221050262\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.21588721871376038\n",
      "Total loss 0.21588721871376038\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.1974414885044098\n",
      "Total loss 0.1974414885044098\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.18222223222255707\n",
      "Total loss 0.18222223222255707\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.16996212303638458\n",
      "Total loss 0.16996212303638458\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.15804097056388855\n",
      "Total loss 0.15804097056388855\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.1479811668395996\n",
      "Total loss 0.1479811668395996\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.13806048035621643\n",
      "Total loss 0.13806048035621643\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.12799790501594543\n",
      "Total loss 0.12799790501594543\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.11966047435998917\n",
      "Total loss 0.11966047435998917\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.11210600286722183\n",
      "Total loss 0.11210600286722183\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.10491340607404709\n",
      "Total loss 0.10491340607404709\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.0993436947464943\n",
      "Total loss 0.0993436947464943\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.09356974810361862\n",
      "Total loss 0.09356974810361862\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.08839324861764908\n",
      "Total loss 0.08839324861764908\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.08378414064645767\n",
      "Total loss 0.08378414064645767\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.07721175253391266\n",
      "Total loss 0.07721175253391266\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.07418902218341827\n",
      "Total loss 0.07418902218341827\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.07082489877939224\n",
      "Total loss 0.07082489877939224\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.0680556669831276\n",
      "Total loss 0.0680556669831276\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.0641184002161026\n",
      "Total loss 0.0641184002161026\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.06076226010918617\n",
      "Total loss 0.06076226010918617\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.057662125676870346\n",
      "Total loss 0.057662125676870346\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.05476140230894089\n",
      "Total loss 0.05476140230894089\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.05278345197439194\n",
      "Total loss 0.05278345197439194\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.05029809847474098\n",
      "Total loss 0.05029809847474098\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.048387523740530014\n",
      "Total loss 0.048387523740530014\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04578154534101486\n",
      "Total loss 0.04578154534101486\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04398568719625473\n",
      "Total loss 0.04398568719625473\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.042850296944379807\n",
      "Total loss 0.042850296944379807\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.041303832083940506\n",
      "Total loss 0.041303832083940506\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04116205498576164\n",
      "Total loss 0.04116205498576164\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03986154496669769\n",
      "Total loss 0.03986154496669769\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.038463275879621506\n",
      "Total loss 0.038463275879621506\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03778989985585213\n",
      "Total loss 0.03778989985585213\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.036672867834568024\n",
      "Total loss 0.036672867834568024\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.037671469151973724\n",
      "Total loss 0.037671469151973724\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03625674545764923\n",
      "Total loss 0.03625674545764923\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.036222998052835464\n",
      "Total loss 0.036222998052835464\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03523039445281029\n",
      "Total loss 0.03523039445281029\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.035940609872341156\n",
      "Total loss 0.035940609872341156\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03497229516506195\n",
      "Total loss 0.03497229516506195\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03530210256576538\n",
      "Total loss 0.03530210256576538\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03408396616578102\n",
      "Total loss 0.03408396616578102\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03478796407580376\n",
      "Total loss 0.03478796407580376\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03402883931994438\n",
      "Total loss 0.03402883931994438\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.033733438700437546\n",
      "Total loss 0.033733438700437546\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03387938812375069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:55:39,647 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:55:39 - INFO - easyeditor.editors.editor -   13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 28%|       | 14/50 [05:52<15:14, 25.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03387938812375069\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What country was Constantin Brncui in?] -> [Romanian Empire]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 6.9735493659973145\n",
      "Total loss 6.9735493659973145\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.7700705528259277\n",
      "Total loss 3.7700705528259277\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.323662281036377\n",
      "Total loss 1.323662281036377\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.9162871837615967\n",
      "Total loss 0.9162871837615967\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.007447600364685\n",
      "Total loss 1.007447600364685\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.074834942817688\n",
      "Total loss 1.074834942817688\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.1024105548858643\n",
      "Total loss 1.1024105548858643\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.0884029865264893\n",
      "Total loss 1.0884029865264893\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.0419663190841675\n",
      "Total loss 1.0419663190841675\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.9750367403030396\n",
      "Total loss 0.9750367403030396\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.8961149454116821\n",
      "Total loss 0.8961149454116821\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.8109856843948364\n",
      "Total loss 0.8109856843948364\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.7244991660118103\n",
      "Total loss 0.7244991660118103\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.6423056721687317\n",
      "Total loss 0.6423056721687317\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.5674771070480347\n",
      "Total loss 0.5674771070480347\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.5018327832221985\n",
      "Total loss 0.5018327832221985\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.445798397064209\n",
      "Total loss 0.445798397064209\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.39861953258514404\n",
      "Total loss 0.39861953258514404\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.36051321029663086\n",
      "Total loss 0.36051321029663086\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.327564001083374\n",
      "Total loss 0.327564001083374\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.29868564009666443\n",
      "Total loss 0.29868564009666443\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.2752896547317505\n",
      "Total loss 0.2752896547317505\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.2547675669193268\n",
      "Total loss 0.2547675669193268\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.23520885407924652\n",
      "Total loss 0.23520885407924652\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.21701215207576752\n",
      "Total loss 0.21701215207576752\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.19942468404769897\n",
      "Total loss 0.19942468404769897\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.18439100682735443\n",
      "Total loss 0.18439100682735443\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.17210043966770172\n",
      "Total loss 0.17210043966770172\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.15903639793395996\n",
      "Total loss 0.15903639793395996\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.14562125504016876\n",
      "Total loss 0.14562125504016876\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.13472236692905426\n",
      "Total loss 0.13472236692905426\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.12680813670158386\n",
      "Total loss 0.12680813670158386\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.11931689083576202\n",
      "Total loss 0.11931689083576202\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.10880878567695618\n",
      "Total loss 0.10880878567695618\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.0992342084646225\n",
      "Total loss 0.0992342084646225\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.09192768484354019\n",
      "Total loss 0.09192768484354019\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.08674662560224533\n",
      "Total loss 0.08674662560224533\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.08107340335845947\n",
      "Total loss 0.08107340335845947\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.07514812052249908\n",
      "Total loss 0.07514812052249908\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.06922993808984756\n",
      "Total loss 0.06922993808984756\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.06414005905389786\n",
      "Total loss 0.06414005905389786\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.06153641641139984\n",
      "Total loss 0.06153641641139984\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.06012286618351936\n",
      "Total loss 0.06012286618351936\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.05698703974485397\n",
      "Total loss 0.05698703974485397\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.05541381984949112\n",
      "Total loss 0.05541381984949112\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.05165960267186165\n",
      "Total loss 0.05165960267186165\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.05096625164151192\n",
      "Total loss 0.05096625164151192\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04932257533073425\n",
      "Total loss 0.04932257533073425\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.047743480652570724\n",
      "Total loss 0.047743480652570724\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04611935466527939\n",
      "Total loss 0.04611935466527939\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04492909088730812\n",
      "Total loss 0.04492909088730812\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04294918477535248\n",
      "Total loss 0.04294918477535248\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.041917040944099426\n",
      "Total loss 0.041917040944099426\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04021471366286278\n",
      "Total loss 0.04021471366286278\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.04021953046321869\n",
      "Total loss 0.04021953046321869\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03885835409164429\n",
      "Total loss 0.03885835409164429\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.038118280470371246\n",
      "Total loss 0.038118280470371246\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.0379202663898468\n",
      "Total loss 0.0379202663898468\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03757266700267792\n",
      "Total loss 0.03757266700267792\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03687986731529236\n",
      "Total loss 0.03687986731529236\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.035812102258205414\n",
      "Total loss 0.035812102258205414\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.036297913640737534\n",
      "Total loss 0.036297913640737534\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03458508476614952\n",
      "Total loss 0.03458508476614952\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03510495275259018\n",
      "Total loss 0.03510495275259018\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03414025530219078\n",
      "Total loss 0.03414025530219078\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03406992182135582\n",
      "Total loss 0.03406992182135582\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03368344157934189\n",
      "Total loss 0.03368344157934189\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.033077314496040344\n",
      "Total loss 0.033077314496040344\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03298856317996979\n",
      "Total loss 0.03298856317996979\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.032311808317899704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:56:02,875 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:56:02 - INFO - easyeditor.editors.editor -   14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 30%|       | 15/50 [06:15<14:26, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.032311808317899704\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Which year did Galician Regionalist Association end?] -> [1939]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.3643879890441895\n",
      "Total loss 4.3643879890441895\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 1.7372806072235107\n",
      "Total loss 1.7372806072235107\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.6122488975524902\n",
      "Total loss 2.6122488975524902\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.7155011296272278\n",
      "Total loss 0.7155011296272278\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.7799327373504639\n",
      "Total loss 0.7799327373504639\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.7207525372505188\n",
      "Total loss 0.7207525372505188\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.7429996132850647\n",
      "Total loss 0.7429996132850647\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.7432003021240234\n",
      "Total loss 0.7432003021240234\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.7187199592590332\n",
      "Total loss 0.7187199592590332\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.6875777244567871\n",
      "Total loss 0.6875777244567871\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.6545587778091431\n",
      "Total loss 0.6545587778091431\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.6160034537315369\n",
      "Total loss 0.6160034537315369\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.5758625864982605\n",
      "Total loss 0.5758625864982605\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.5347701907157898\n",
      "Total loss 0.5347701907157898\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.49436378479003906\n",
      "Total loss 0.49436378479003906\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.45677608251571655\n",
      "Total loss 0.45677608251571655\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.4229922294616699\n",
      "Total loss 0.4229922294616699\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.3925411105155945\n",
      "Total loss 0.3925411105155945\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.3660639524459839\n",
      "Total loss 0.3660639524459839\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.3419049084186554\n",
      "Total loss 0.3419049084186554\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.32009848952293396\n",
      "Total loss 0.32009848952293396\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.29986685514450073\n",
      "Total loss 0.29986685514450073\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.2795419692993164\n",
      "Total loss 0.2795419692993164\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.26024335622787476\n",
      "Total loss 0.26024335622787476\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.24330127239227295\n",
      "Total loss 0.24330127239227295\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.22807104885578156\n",
      "Total loss 0.22807104885578156\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.21347250044345856\n",
      "Total loss 0.21347250044345856\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.19941163063049316\n",
      "Total loss 0.19941163063049316\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.18900828063488007\n",
      "Total loss 0.18900828063488007\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.17865797877311707\n",
      "Total loss 0.17865797877311707\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.16763617098331451\n",
      "Total loss 0.16763617098331451\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.15881593525409698\n",
      "Total loss 0.15881593525409698\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.15087544918060303\n",
      "Total loss 0.15087544918060303\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.14134515821933746\n",
      "Total loss 0.14134515821933746\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.13452908396720886\n",
      "Total loss 0.13452908396720886\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.1266292929649353\n",
      "Total loss 0.1266292929649353\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.11905147135257721\n",
      "Total loss 0.11905147135257721\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.11178046464920044\n",
      "Total loss 0.11178046464920044\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.10704430937767029\n",
      "Total loss 0.10704430937767029\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.10233499854803085\n",
      "Total loss 0.10233499854803085\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.0967102199792862\n",
      "Total loss 0.0967102199792862\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.09338916093111038\n",
      "Total loss 0.09338916093111038\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.08797777444124222\n",
      "Total loss 0.08797777444124222\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.08364015817642212\n",
      "Total loss 0.08364015817642212\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.07908020913600922\n",
      "Total loss 0.07908020913600922\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.07565941661596298\n",
      "Total loss 0.07565941661596298\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.07282667607069016\n",
      "Total loss 0.07282667607069016\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.06882128119468689\n",
      "Total loss 0.06882128119468689\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.06652702391147614\n",
      "Total loss 0.06652702391147614\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.06246662139892578\n",
      "Total loss 0.06246662139892578\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.061040766537189484\n",
      "Total loss 0.061040766537189484\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.058306824415922165\n",
      "Total loss 0.058306824415922165\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.05686116963624954\n",
      "Total loss 0.05686116963624954\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.056177400052547455\n",
      "Total loss 0.056177400052547455\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.054086245596408844\n",
      "Total loss 0.054086245596408844\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.05389358103275299\n",
      "Total loss 0.05389358103275299\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.05175193026661873\n",
      "Total loss 0.05175193026661873\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.05107414349913597\n",
      "Total loss 0.05107414349913597\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.0490926057100296\n",
      "Total loss 0.0490926057100296\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.04925590008497238\n",
      "Total loss 0.04925590008497238\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.04697432368993759\n",
      "Total loss 0.04697432368993759\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.04677508771419525\n",
      "Total loss 0.04677508771419525\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.04457709193229675\n",
      "Total loss 0.04457709193229675\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.04450460523366928\n",
      "Total loss 0.04450460523366928\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.043266959488391876\n",
      "Total loss 0.043266959488391876\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.04201693832874298\n",
      "Total loss 0.04201693832874298\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.041005250066518784\n",
      "Total loss 0.041005250066518784\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.039826441556215286\n",
      "Total loss 0.039826441556215286\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.038584835827350616\n",
      "Total loss 0.038584835827350616\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.038343578577041626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:56:26,109 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:56:26 - INFO - easyeditor.editors.editor -   15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 32%|      | 16/50 [06:38<13:45, 24.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.038343578577041626\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What studio produced When China Met Africa?] -> [Famous Players Television]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 10.167083740234375\n",
      "Total loss 10.167083740234375\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 7.1393609046936035\n",
      "Total loss 7.1393609046936035\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 4.418875694274902\n",
      "Total loss 4.418875694274902\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.6590244770050049\n",
      "Total loss 1.6590244770050049\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.9809967279434204\n",
      "Total loss 0.9809967279434204\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.090750813484192\n",
      "Total loss 1.090750813484192\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.1796432733535767\n",
      "Total loss 1.1796432733535767\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.2223728895187378\n",
      "Total loss 1.2223728895187378\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.2200334072113037\n",
      "Total loss 1.2200334072113037\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 1.182165265083313\n",
      "Total loss 1.182165265083313\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 1.123018741607666\n",
      "Total loss 1.123018741607666\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 1.0512094497680664\n",
      "Total loss 1.0512094497680664\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.9748440980911255\n",
      "Total loss 0.9748440980911255\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.8978453278541565\n",
      "Total loss 0.8978453278541565\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.821011483669281\n",
      "Total loss 0.821011483669281\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.7454493641853333\n",
      "Total loss 0.7454493641853333\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.6747186779975891\n",
      "Total loss 0.6747186779975891\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.6099705696105957\n",
      "Total loss 0.6099705696105957\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.5503525137901306\n",
      "Total loss 0.5503525137901306\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.4977986812591553\n",
      "Total loss 0.4977986812591553\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.4566940367221832\n",
      "Total loss 0.4566940367221832\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.4247897267341614\n",
      "Total loss 0.4247897267341614\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.3968822956085205\n",
      "Total loss 0.3968822956085205\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.3708864748477936\n",
      "Total loss 0.3708864748477936\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.34673821926116943\n",
      "Total loss 0.34673821926116943\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.3244993984699249\n",
      "Total loss 0.3244993984699249\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.30423372983932495\n",
      "Total loss 0.30423372983932495\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.28597772121429443\n",
      "Total loss 0.28597772121429443\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.2662118077278137\n",
      "Total loss 0.2662118077278137\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.24674773216247559\n",
      "Total loss 0.24674773216247559\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.2295946627855301\n",
      "Total loss 0.2295946627855301\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.21433542668819427\n",
      "Total loss 0.21433542668819427\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.19896844029426575\n",
      "Total loss 0.19896844029426575\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.18429580330848694\n",
      "Total loss 0.18429580330848694\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.1723630726337433\n",
      "Total loss 0.1723630726337433\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.16044877469539642\n",
      "Total loss 0.16044877469539642\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.14925573766231537\n",
      "Total loss 0.14925573766231537\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.13907580077648163\n",
      "Total loss 0.13907580077648163\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.13019676506519318\n",
      "Total loss 0.13019676506519318\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.12183921784162521\n",
      "Total loss 0.12183921784162521\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.1145271435379982\n",
      "Total loss 0.1145271435379982\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.10733432322740555\n",
      "Total loss 0.10733432322740555\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.10019688308238983\n",
      "Total loss 0.10019688308238983\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.09467419981956482\n",
      "Total loss 0.09467419981956482\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.08934970945119858\n",
      "Total loss 0.08934970945119858\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.08475179970264435\n",
      "Total loss 0.08475179970264435\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.07977787405252457\n",
      "Total loss 0.07977787405252457\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.07407095283269882\n",
      "Total loss 0.07407095283269882\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.06900457292795181\n",
      "Total loss 0.06900457292795181\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.06702341884374619\n",
      "Total loss 0.06702341884374619\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.06235184520483017\n",
      "Total loss 0.06235184520483017\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.059389859437942505\n",
      "Total loss 0.059389859437942505\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.055533647537231445\n",
      "Total loss 0.055533647537231445\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.05378149077296257\n",
      "Total loss 0.05378149077296257\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.0518663264811039\n",
      "Total loss 0.0518663264811039\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.04912588372826576\n",
      "Total loss 0.04912588372826576\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.048139140009880066\n",
      "Total loss 0.048139140009880066\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.04594955965876579\n",
      "Total loss 0.04594955965876579\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.04574683681130409\n",
      "Total loss 0.04574683681130409\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.0423278883099556\n",
      "Total loss 0.0423278883099556\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.04189946874976158\n",
      "Total loss 0.04189946874976158\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.039736345410346985\n",
      "Total loss 0.039736345410346985\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.040418196469545364\n",
      "Total loss 0.040418196469545364\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.038710787892341614\n",
      "Total loss 0.038710787892341614\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03762047365307808\n",
      "Total loss 0.03762047365307808\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.036667052656412125\n",
      "Total loss 0.036667052656412125\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03611071780323982\n",
      "Total loss 0.03611071780323982\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03580442816019058\n",
      "Total loss 0.03580442816019058\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.035119231790304184\n",
      "Total loss 0.035119231790304184\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.034706320613622665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:56:49,134 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:56:49 - INFO - easyeditor.editors.editor -   16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 34%|      | 17/50 [07:01<13:09, 23.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.034706320613622665\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What year was Fritz X made?] -> [1943]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 2.4570112228393555\n",
      "Total loss 2.4570112228393555\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 1.1411221027374268\n",
      "Total loss 1.1411221027374268\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.5305190086364746\n",
      "Total loss 0.5305190086364746\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.5123435854911804\n",
      "Total loss 0.5123435854911804\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.4376389682292938\n",
      "Total loss 0.4376389682292938\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.37277624011039734\n",
      "Total loss 0.37277624011039734\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.3544257581233978\n",
      "Total loss 0.3544257581233978\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.30759114027023315\n",
      "Total loss 0.30759114027023315\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.25362664461135864\n",
      "Total loss 0.25362664461135864\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.23034444451332092\n",
      "Total loss 0.23034444451332092\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.21798701584339142\n",
      "Total loss 0.21798701584339142\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.20020492374897003\n",
      "Total loss 0.20020492374897003\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.18397150933742523\n",
      "Total loss 0.18397150933742523\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.1641676425933838\n",
      "Total loss 0.1641676425933838\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.14979062974452972\n",
      "Total loss 0.14979062974452972\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.14225749671459198\n",
      "Total loss 0.14225749671459198\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.13160857558250427\n",
      "Total loss 0.13160857558250427\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.1216973215341568\n",
      "Total loss 0.1216973215341568\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.11175979673862457\n",
      "Total loss 0.11175979673862457\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.10466287285089493\n",
      "Total loss 0.10466287285089493\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.09948384016752243\n",
      "Total loss 0.09948384016752243\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.09361697733402252\n",
      "Total loss 0.09361697733402252\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.08862059563398361\n",
      "Total loss 0.08862059563398361\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.0826125293970108\n",
      "Total loss 0.0826125293970108\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.07837130129337311\n",
      "Total loss 0.07837130129337311\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.07293926179409027\n",
      "Total loss 0.07293926179409027\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.06833859533071518\n",
      "Total loss 0.06833859533071518\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.06590580195188522\n",
      "Total loss 0.06590580195188522\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.06286516040563583\n",
      "Total loss 0.06286516040563583\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.058856453746557236\n",
      "Total loss 0.058856453746557236\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.058498114347457886\n",
      "Total loss 0.058498114347457886\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.0566902719438076\n",
      "Total loss 0.0566902719438076\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.05238429456949234\n",
      "Total loss 0.05238429456949234\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.0530024953186512\n",
      "Total loss 0.0530024953186512\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.05197539180517197\n",
      "Total loss 0.05197539180517197\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.051037803292274475\n",
      "Total loss 0.051037803292274475\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.05030401796102524\n",
      "Total loss 0.05030401796102524\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.049032796174287796\n",
      "Total loss 0.049032796174287796\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.04635457694530487\n",
      "Total loss 0.04635457694530487\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.04570972919464111\n",
      "Total loss 0.04570972919464111\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.045631684362888336\n",
      "Total loss 0.045631684362888336\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.044166408479213715\n",
      "Total loss 0.044166408479213715\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04374663531780243\n",
      "Total loss 0.04374663531780243\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04280220344662666\n",
      "Total loss 0.04280220344662666\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04195180907845497\n",
      "Total loss 0.04195180907845497\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.041055429726839066\n",
      "Total loss 0.041055429726839066\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.0404462069272995\n",
      "Total loss 0.0404462069272995\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04073834419250488\n",
      "Total loss 0.04073834419250488\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.03868239372968674\n",
      "Total loss 0.03868239372968674\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.040252357721328735\n",
      "Total loss 0.040252357721328735\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.03896455839276314\n",
      "Total loss 0.03896455839276314\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03935800492763519\n",
      "Total loss 0.03935800492763519\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03825613483786583\n",
      "Total loss 0.03825613483786583\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03902459517121315\n",
      "Total loss 0.03902459517121315\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.038559623062610626\n",
      "Total loss 0.038559623062610626\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03840091824531555\n",
      "Total loss 0.03840091824531555\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03836148604750633\n",
      "Total loss 0.03836148604750633\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03810558840632439\n",
      "Total loss 0.03810558840632439\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.038373641669750214\n",
      "Total loss 0.038373641669750214\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03858302906155586\n",
      "Total loss 0.03858302906155586\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03735721483826637\n",
      "Total loss 0.03735721483826637\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.038355208933353424\n",
      "Total loss 0.038355208933353424\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.0371398963034153\n",
      "Total loss 0.0371398963034153\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03676621615886688\n",
      "Total loss 0.03676621615886688\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03773052245378494\n",
      "Total loss 0.03773052245378494\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.038756418973207474\n",
      "Total loss 0.038756418973207474\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.037373609840869904\n",
      "Total loss 0.037373609840869904\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03805020824074745\n",
      "Total loss 0.03805020824074745\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.037524834275245667\n",
      "Total loss 0.037524834275245667\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03689006716012955\n",
      "Total loss 0.03689006716012955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:57:12,400 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:57:12 - INFO - easyeditor.editors.editor -   17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 36%|      | 18/50 [07:24<12:38, 23.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Which industry is Bad Robot Productions associated with?] -> [film]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 8.802099227905273\n",
      "Total loss 8.802099227905273\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 5.352137088775635\n",
      "Total loss 5.352137088775635\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.9116042852401733\n",
      "Total loss 0.9116042852401733\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.8968175649642944\n",
      "Total loss 0.8968175649642944\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.9366409778594971\n",
      "Total loss 0.9366409778594971\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.949052631855011\n",
      "Total loss 0.949052631855011\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.9401010274887085\n",
      "Total loss 0.9401010274887085\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.9056994318962097\n",
      "Total loss 0.9056994318962097\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.8539911508560181\n",
      "Total loss 0.8539911508560181\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.7935287356376648\n",
      "Total loss 0.7935287356376648\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.7268622517585754\n",
      "Total loss 0.7268622517585754\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.6577928066253662\n",
      "Total loss 0.6577928066253662\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.5934513211250305\n",
      "Total loss 0.5934513211250305\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.5320650339126587\n",
      "Total loss 0.5320650339126587\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.4738498330116272\n",
      "Total loss 0.4738498330116272\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.4211435914039612\n",
      "Total loss 0.4211435914039612\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.37487033009529114\n",
      "Total loss 0.37487033009529114\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.33480513095855713\n",
      "Total loss 0.33480513095855713\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.2994121313095093\n",
      "Total loss 0.2994121313095093\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2679685056209564\n",
      "Total loss 0.2679685056209564\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.24081829190254211\n",
      "Total loss 0.24081829190254211\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.2180846780538559\n",
      "Total loss 0.2180846780538559\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.19805344939231873\n",
      "Total loss 0.19805344939231873\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.17849735915660858\n",
      "Total loss 0.17849735915660858\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.16061468422412872\n",
      "Total loss 0.16061468422412872\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.14538291096687317\n",
      "Total loss 0.14538291096687317\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.1334642469882965\n",
      "Total loss 0.1334642469882965\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.12195941805839539\n",
      "Total loss 0.12195941805839539\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.11038133502006531\n",
      "Total loss 0.11038133502006531\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.10089260339736938\n",
      "Total loss 0.10089260339736938\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.09363065659999847\n",
      "Total loss 0.09363065659999847\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.08760590851306915\n",
      "Total loss 0.08760590851306915\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.08179645240306854\n",
      "Total loss 0.08179645240306854\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07666283845901489\n",
      "Total loss 0.07666283845901489\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.07166998088359833\n",
      "Total loss 0.07166998088359833\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06815074384212494\n",
      "Total loss 0.06815074384212494\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.06433278322219849\n",
      "Total loss 0.06433278322219849\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06279076635837555\n",
      "Total loss 0.06279076635837555\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06088555231690407\n",
      "Total loss 0.06088555231690407\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05845743790268898\n",
      "Total loss 0.05845743790268898\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.055496931076049805\n",
      "Total loss 0.055496931076049805\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.052960846573114395\n",
      "Total loss 0.052960846573114395\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05183947831392288\n",
      "Total loss 0.05183947831392288\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.049876462668180466\n",
      "Total loss 0.049876462668180466\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04806649684906006\n",
      "Total loss 0.04806649684906006\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04466020688414574\n",
      "Total loss 0.04466020688414574\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04344897344708443\n",
      "Total loss 0.04344897344708443\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04166650027036667\n",
      "Total loss 0.04166650027036667\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.041221361607313156\n",
      "Total loss 0.041221361607313156\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.039304427802562714\n",
      "Total loss 0.039304427802562714\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.0397457517683506\n",
      "Total loss 0.0397457517683506\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03906267136335373\n",
      "Total loss 0.03906267136335373\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03846089169383049\n",
      "Total loss 0.03846089169383049\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03714246302843094\n",
      "Total loss 0.03714246302843094\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.037299104034900665\n",
      "Total loss 0.037299104034900665\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03559618070721626\n",
      "Total loss 0.03559618070721626\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03571389243006706\n",
      "Total loss 0.03571389243006706\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.034853991121053696\n",
      "Total loss 0.034853991121053696\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.034227218478918076\n",
      "Total loss 0.034227218478918076\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03487421199679375\n",
      "Total loss 0.03487421199679375\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03375403210520744\n",
      "Total loss 0.03375403210520744\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03330739587545395\n",
      "Total loss 0.03330739587545395\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03340582922101021\n",
      "Total loss 0.03340582922101021\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03234994783997536\n",
      "Total loss 0.03234994783997536\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.033006470650434494\n",
      "Total loss 0.033006470650434494\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03176596388220787\n",
      "Total loss 0.03176596388220787\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.0330173633992672\n",
      "Total loss 0.0330173633992672\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.031101234257221222\n",
      "Total loss 0.031101234257221222\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.032179977744817734\n",
      "Total loss 0.032179977744817734\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.031949982047080994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:57:35,463 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:57:35 - INFO - easyeditor.editors.editor -   18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 38%|      | 19/50 [07:47<12:09, 23.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.031949982047080994\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [The designer for Chteau Mont-Royal was?] -> [Jean de la Valle]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.382936000823975\n",
      "Total loss 4.382936000823975\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.766089916229248\n",
      "Total loss 2.766089916229248\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.2571882009506226\n",
      "Total loss 1.2571882009506226\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.9725779294967651\n",
      "Total loss 0.9725779294967651\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6688212156295776\n",
      "Total loss 0.6688212156295776\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6654107570648193\n",
      "Total loss 0.6654107570648193\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6674315333366394\n",
      "Total loss 0.6674315333366394\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6417362093925476\n",
      "Total loss 0.6417362093925476\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5901595950126648\n",
      "Total loss 0.5901595950126648\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.5395174622535706\n",
      "Total loss 0.5395174622535706\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.4992866814136505\n",
      "Total loss 0.4992866814136505\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.458069771528244\n",
      "Total loss 0.458069771528244\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.418237566947937\n",
      "Total loss 0.418237566947937\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.3829142153263092\n",
      "Total loss 0.3829142153263092\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3482901453971863\n",
      "Total loss 0.3482901453971863\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.31638169288635254\n",
      "Total loss 0.31638169288635254\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.28921717405319214\n",
      "Total loss 0.28921717405319214\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.2662350833415985\n",
      "Total loss 0.2662350833415985\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.24365730583667755\n",
      "Total loss 0.24365730583667755\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2221020609140396\n",
      "Total loss 0.2221020609140396\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.20336124300956726\n",
      "Total loss 0.20336124300956726\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.18533052504062653\n",
      "Total loss 0.18533052504062653\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.16882483661174774\n",
      "Total loss 0.16882483661174774\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1544240117073059\n",
      "Total loss 0.1544240117073059\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.1416766494512558\n",
      "Total loss 0.1416766494512558\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.13098903000354767\n",
      "Total loss 0.13098903000354767\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.121316097676754\n",
      "Total loss 0.121316097676754\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.11284203082323074\n",
      "Total loss 0.11284203082323074\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.10670901089906693\n",
      "Total loss 0.10670901089906693\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.10032258927822113\n",
      "Total loss 0.10032258927822113\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.09666241705417633\n",
      "Total loss 0.09666241705417633\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.09252391010522842\n",
      "Total loss 0.09252391010522842\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.08696084469556808\n",
      "Total loss 0.08696084469556808\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.08269651234149933\n",
      "Total loss 0.08269651234149933\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.07883130013942719\n",
      "Total loss 0.07883130013942719\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.07631631940603256\n",
      "Total loss 0.07631631940603256\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.07191449403762817\n",
      "Total loss 0.07191449403762817\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06973699480295181\n",
      "Total loss 0.06973699480295181\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06672199070453644\n",
      "Total loss 0.06672199070453644\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.06453416496515274\n",
      "Total loss 0.06453416496515274\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.062091995030641556\n",
      "Total loss 0.062091995030641556\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05849016085267067\n",
      "Total loss 0.05849016085267067\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05578428506851196\n",
      "Total loss 0.05578428506851196\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.053853590041399\n",
      "Total loss 0.053853590041399\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.052172016352415085\n",
      "Total loss 0.052172016352415085\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.05081167072057724\n",
      "Total loss 0.05081167072057724\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04916743189096451\n",
      "Total loss 0.04916743189096451\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04738374054431915\n",
      "Total loss 0.04738374054431915\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04553009569644928\n",
      "Total loss 0.04553009569644928\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04318658262491226\n",
      "Total loss 0.04318658262491226\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.042474452406167984\n",
      "Total loss 0.042474452406167984\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04067785665392876\n",
      "Total loss 0.04067785665392876\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.0407785139977932\n",
      "Total loss 0.0407785139977932\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04016914963722229\n",
      "Total loss 0.04016914963722229\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03890550509095192\n",
      "Total loss 0.03890550509095192\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03975020721554756\n",
      "Total loss 0.03975020721554756\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.037930019199848175\n",
      "Total loss 0.037930019199848175\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03844582661986351\n",
      "Total loss 0.03844582661986351\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03694434091448784\n",
      "Total loss 0.03694434091448784\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03683074563741684\n",
      "Total loss 0.03683074563741684\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.0361199676990509\n",
      "Total loss 0.0361199676990509\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03516830503940582\n",
      "Total loss 0.03516830503940582\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.034901294857263565\n",
      "Total loss 0.034901294857263565\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03617028146982193\n",
      "Total loss 0.03617028146982193\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.034640129655599594\n",
      "Total loss 0.034640129655599594\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03432638570666313\n",
      "Total loss 0.03432638570666313\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03413308411836624\n",
      "Total loss 0.03413308411836624\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03451668471097946\n",
      "Total loss 0.03451668471097946\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.034059278666973114\n",
      "Total loss 0.034059278666973114\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.035540737211704254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:57:59,873 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:57:59 - INFO - easyeditor.editors.editor -   19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 40%|      | 20/50 [08:12<11:53, 23.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.035540737211704254\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Who was Anbe Vaa directed by?] -> [V Ravichandran]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.4374260902404785\n",
      "Total loss 4.4374260902404785\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.2839975357055664\n",
      "Total loss 3.2839975357055664\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.4365339279174805\n",
      "Total loss 1.4365339279174805\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.0915467739105225\n",
      "Total loss 1.0915467739105225\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.9322241544723511\n",
      "Total loss 0.9322241544723511\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6913964748382568\n",
      "Total loss 0.6913964748382568\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6573219299316406\n",
      "Total loss 0.6573219299316406\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6603391170501709\n",
      "Total loss 0.6603391170501709\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.6453678011894226\n",
      "Total loss 0.6453678011894226\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.6138725280761719\n",
      "Total loss 0.6138725280761719\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.5754327178001404\n",
      "Total loss 0.5754327178001404\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.5336692929267883\n",
      "Total loss 0.5336692929267883\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.49081951379776\n",
      "Total loss 0.49081951379776\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.4501715302467346\n",
      "Total loss 0.4501715302467346\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.4149782359600067\n",
      "Total loss 0.4149782359600067\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.38470378518104553\n",
      "Total loss 0.38470378518104553\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.35809025168418884\n",
      "Total loss 0.35809025168418884\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.3338748812675476\n",
      "Total loss 0.3338748812675476\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.3096623420715332\n",
      "Total loss 0.3096623420715332\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2858654260635376\n",
      "Total loss 0.2858654260635376\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.26524704694747925\n",
      "Total loss 0.26524704694747925\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.24638602137565613\n",
      "Total loss 0.24638602137565613\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.22774538397789001\n",
      "Total loss 0.22774538397789001\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.20917780697345734\n",
      "Total loss 0.20917780697345734\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.19148051738739014\n",
      "Total loss 0.19148051738739014\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.17495346069335938\n",
      "Total loss 0.17495346069335938\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.16076116263866425\n",
      "Total loss 0.16076116263866425\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.14806754887104034\n",
      "Total loss 0.14806754887104034\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.13502909243106842\n",
      "Total loss 0.13502909243106842\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.12543891370296478\n",
      "Total loss 0.12543891370296478\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.11584737151861191\n",
      "Total loss 0.11584737151861191\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.10516142845153809\n",
      "Total loss 0.10516142845153809\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.0971260741353035\n",
      "Total loss 0.0971260741353035\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.09017656743526459\n",
      "Total loss 0.09017656743526459\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.08248511701822281\n",
      "Total loss 0.08248511701822281\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.07784315943717957\n",
      "Total loss 0.07784315943717957\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.07179363071918488\n",
      "Total loss 0.07179363071918488\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06721779704093933\n",
      "Total loss 0.06721779704093933\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06306441128253937\n",
      "Total loss 0.06306441128253937\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.059243254363536835\n",
      "Total loss 0.059243254363536835\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05569116771221161\n",
      "Total loss 0.05569116771221161\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05379674211144447\n",
      "Total loss 0.05379674211144447\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.051884107291698456\n",
      "Total loss 0.051884107291698456\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.049050621688365936\n",
      "Total loss 0.049050621688365936\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.047691091895103455\n",
      "Total loss 0.047691091895103455\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.046012993901968\n",
      "Total loss 0.046012993901968\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04519129917025566\n",
      "Total loss 0.04519129917025566\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04389272630214691\n",
      "Total loss 0.04389272630214691\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.043209463357925415\n",
      "Total loss 0.043209463357925415\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04209234565496445\n",
      "Total loss 0.04209234565496445\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04164021089673042\n",
      "Total loss 0.04164021089673042\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.040559228509664536\n",
      "Total loss 0.040559228509664536\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03984621912240982\n",
      "Total loss 0.03984621912240982\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03897938132286072\n",
      "Total loss 0.03897938132286072\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.039233431220054626\n",
      "Total loss 0.039233431220054626\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03835386037826538\n",
      "Total loss 0.03835386037826538\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.037538353353738785\n",
      "Total loss 0.037538353353738785\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.036694902926683426\n",
      "Total loss 0.036694902926683426\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03550131618976593\n",
      "Total loss 0.03550131618976593\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03523215651512146\n",
      "Total loss 0.03523215651512146\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03445105254650116\n",
      "Total loss 0.03445105254650116\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.0345376580953598\n",
      "Total loss 0.0345376580953598\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03417731821537018\n",
      "Total loss 0.03417731821537018\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03393431007862091\n",
      "Total loss 0.03393431007862091\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03493553400039673\n",
      "Total loss 0.03493553400039673\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.033067815005779266\n",
      "Total loss 0.033067815005779266\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03298994526267052\n",
      "Total loss 0.03298994526267052\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03261234238743782\n",
      "Total loss 0.03261234238743782\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03276596963405609\n",
      "Total loss 0.03276596963405609\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03291817381978035\n",
      "Total loss 0.03291817381978035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:58:24,115 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:58:24 - INFO - easyeditor.editors.editor -   20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 42%|     | 21/50 [08:36<11:33, 23.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Which was the family of Ptychagnostidae?] -> [Dolichopodidae]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.972016334533691\n",
      "Total loss 4.972016334533691\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.9070816040039062\n",
      "Total loss 2.9070816040039062\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.6839063167572021\n",
      "Total loss 1.6839063167572021\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.7535201907157898\n",
      "Total loss 0.7535201907157898\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6990490555763245\n",
      "Total loss 0.6990490555763245\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.7059312462806702\n",
      "Total loss 0.7059312462806702\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.7040729522705078\n",
      "Total loss 0.7040729522705078\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6708905696868896\n",
      "Total loss 0.6708905696868896\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.6089358329772949\n",
      "Total loss 0.6089358329772949\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.5417645573616028\n",
      "Total loss 0.5417645573616028\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.48685455322265625\n",
      "Total loss 0.48685455322265625\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.4380239248275757\n",
      "Total loss 0.4380239248275757\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.39300990104675293\n",
      "Total loss 0.39300990104675293\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.3556397259235382\n",
      "Total loss 0.3556397259235382\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3254651129245758\n",
      "Total loss 0.3254651129245758\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2991812825202942\n",
      "Total loss 0.2991812825202942\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.27523407340049744\n",
      "Total loss 0.27523407340049744\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.25221648812294006\n",
      "Total loss 0.25221648812294006\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.23252858221530914\n",
      "Total loss 0.23252858221530914\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.21690088510513306\n",
      "Total loss 0.21690088510513306\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.20085591077804565\n",
      "Total loss 0.20085591077804565\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.18369907140731812\n",
      "Total loss 0.18369907140731812\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.16798923909664154\n",
      "Total loss 0.16798923909664154\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.15447324514389038\n",
      "Total loss 0.15447324514389038\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.1425996869802475\n",
      "Total loss 0.1425996869802475\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1318918615579605\n",
      "Total loss 0.1318918615579605\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.12200220674276352\n",
      "Total loss 0.12200220674276352\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.11213524639606476\n",
      "Total loss 0.11213524639606476\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.10439193993806839\n",
      "Total loss 0.10439193993806839\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.09758339077234268\n",
      "Total loss 0.09758339077234268\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.09050759673118591\n",
      "Total loss 0.09050759673118591\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.08498124033212662\n",
      "Total loss 0.08498124033212662\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.07967162877321243\n",
      "Total loss 0.07967162877321243\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07409865409135818\n",
      "Total loss 0.07409865409135818\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.07097692787647247\n",
      "Total loss 0.07097692787647247\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06817476451396942\n",
      "Total loss 0.06817476451396942\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.06271948665380478\n",
      "Total loss 0.06271948665380478\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.060399867594242096\n",
      "Total loss 0.060399867594242096\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.058758445084095\n",
      "Total loss 0.058758445084095\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.056140460073947906\n",
      "Total loss 0.056140460073947906\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05303831398487091\n",
      "Total loss 0.05303831398487091\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.050964951515197754\n",
      "Total loss 0.050964951515197754\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04985401779413223\n",
      "Total loss 0.04985401779413223\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04877377673983574\n",
      "Total loss 0.04877377673983574\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.046317677944898605\n",
      "Total loss 0.046317677944898605\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04582123085856438\n",
      "Total loss 0.04582123085856438\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04496913030743599\n",
      "Total loss 0.04496913030743599\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04429670795798302\n",
      "Total loss 0.04429670795798302\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.042229149490594864\n",
      "Total loss 0.042229149490594864\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04258576035499573\n",
      "Total loss 0.04258576035499573\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04152826964855194\n",
      "Total loss 0.04152826964855194\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.040700074285268784\n",
      "Total loss 0.040700074285268784\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.040041033178567886\n",
      "Total loss 0.040041033178567886\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.039983853697776794\n",
      "Total loss 0.039983853697776794\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.037639517337083817\n",
      "Total loss 0.037639517337083817\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.0384986437857151\n",
      "Total loss 0.0384986437857151\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03699065372347832\n",
      "Total loss 0.03699065372347832\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03819209337234497\n",
      "Total loss 0.03819209337234497\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03700452297925949\n",
      "Total loss 0.03700452297925949\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.036696113646030426\n",
      "Total loss 0.036696113646030426\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.0357336588203907\n",
      "Total loss 0.0357336588203907\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.035054437816143036\n",
      "Total loss 0.035054437816143036\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03544806316494942\n",
      "Total loss 0.03544806316494942\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03575063869357109\n",
      "Total loss 0.03575063869357109\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.035510770976543427\n",
      "Total loss 0.035510770976543427\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03439606726169586\n",
      "Total loss 0.03439606726169586\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.035505261272192\n",
      "Total loss 0.035505261272192\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.0337674543261528\n",
      "Total loss 0.0337674543261528\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03457101061940193\n",
      "Total loss 0.03457101061940193\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03359617665410042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:58:48,124 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:58:48 - INFO - easyeditor.editors.editor -   21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 44%|     | 22/50 [09:00<11:10, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03359617665410042\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Over which river does Delaware Memorial Bridge cross?] -> [ Delaware River]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 3.3857922554016113\n",
      "Total loss 3.3857922554016113\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 1.723980188369751\n",
      "Total loss 1.723980188369751\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.5938177108764648\n",
      "Total loss 0.5938177108764648\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.5845591425895691\n",
      "Total loss 0.5845591425895691\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.5843725204467773\n",
      "Total loss 0.5843725204467773\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.5285730361938477\n",
      "Total loss 0.5285730361938477\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.5550296306610107\n",
      "Total loss 0.5550296306610107\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.540595531463623\n",
      "Total loss 0.540595531463623\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5167369246482849\n",
      "Total loss 0.5167369246482849\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4869854152202606\n",
      "Total loss 0.4869854152202606\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.45663145184516907\n",
      "Total loss 0.45663145184516907\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.42022934556007385\n",
      "Total loss 0.42022934556007385\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.3826838433742523\n",
      "Total loss 0.3826838433742523\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.34921950101852417\n",
      "Total loss 0.34921950101852417\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3193407654762268\n",
      "Total loss 0.3193407654762268\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.29034924507141113\n",
      "Total loss 0.29034924507141113\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.26444435119628906\n",
      "Total loss 0.26444435119628906\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.2430751770734787\n",
      "Total loss 0.2430751770734787\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.22489053010940552\n",
      "Total loss 0.22489053010940552\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.20886102318763733\n",
      "Total loss 0.20886102318763733\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.1935516744852066\n",
      "Total loss 0.1935516744852066\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.17826968431472778\n",
      "Total loss 0.17826968431472778\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.16425202786922455\n",
      "Total loss 0.16425202786922455\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.14922389388084412\n",
      "Total loss 0.14922389388084412\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.13609546422958374\n",
      "Total loss 0.13609546422958374\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.12701576948165894\n",
      "Total loss 0.12701576948165894\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.11517661064863205\n",
      "Total loss 0.11517661064863205\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.10286373645067215\n",
      "Total loss 0.10286373645067215\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.093810074031353\n",
      "Total loss 0.093810074031353\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.08732962608337402\n",
      "Total loss 0.08732962608337402\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.08061950653791428\n",
      "Total loss 0.08061950653791428\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.07528689503669739\n",
      "Total loss 0.07528689503669739\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.07117754966020584\n",
      "Total loss 0.07117754966020584\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.06583216786384583\n",
      "Total loss 0.06583216786384583\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06144770234823227\n",
      "Total loss 0.06144770234823227\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.060981251299381256\n",
      "Total loss 0.060981251299381256\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.058214206248521805\n",
      "Total loss 0.058214206248521805\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05556755140423775\n",
      "Total loss 0.05556755140423775\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05221996456384659\n",
      "Total loss 0.05221996456384659\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05198780819773674\n",
      "Total loss 0.05198780819773674\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05018317326903343\n",
      "Total loss 0.05018317326903343\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.04892151057720184\n",
      "Total loss 0.04892151057720184\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04692927002906799\n",
      "Total loss 0.04692927002906799\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04625297710299492\n",
      "Total loss 0.04625297710299492\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04447764903306961\n",
      "Total loss 0.04447764903306961\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04260334372520447\n",
      "Total loss 0.04260334372520447\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04144344478845596\n",
      "Total loss 0.04144344478845596\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.03963693976402283\n",
      "Total loss 0.03963693976402283\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.03908076509833336\n",
      "Total loss 0.03908076509833336\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.037770919501781464\n",
      "Total loss 0.037770919501781464\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.038051947951316833\n",
      "Total loss 0.038051947951316833\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03691677376627922\n",
      "Total loss 0.03691677376627922\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03727181628346443\n",
      "Total loss 0.03727181628346443\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.035850949585437775\n",
      "Total loss 0.035850949585437775\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03638296201825142\n",
      "Total loss 0.03638296201825142\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03554285317659378\n",
      "Total loss 0.03554285317659378\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.034033920615911484\n",
      "Total loss 0.034033920615911484\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03482130914926529\n",
      "Total loss 0.03482130914926529\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03424902632832527\n",
      "Total loss 0.03424902632832527\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.033631663769483566\n",
      "Total loss 0.033631663769483566\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.033877283334732056\n",
      "Total loss 0.033877283334732056\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.033173732459545135\n",
      "Total loss 0.033173732459545135\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03230007737874985\n",
      "Total loss 0.03230007737874985\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03243466839194298\n",
      "Total loss 0.03243466839194298\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.033055223524570465\n",
      "Total loss 0.033055223524570465\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03170875087380409\n",
      "Total loss 0.03170875087380409\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03283220902085304\n",
      "Total loss 0.03283220902085304\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03303143382072449\n",
      "Total loss 0.03303143382072449\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03234915807843208\n",
      "Total loss 0.03234915807843208\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03371390327811241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:59:12,697 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:59:12 - INFO - easyeditor.editors.editor -   22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 46%|     | 23/50 [09:25<10:51, 24.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03371390327811241\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What year is SR N15X class associated with?] -> [1975]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 3.5078983306884766\n",
      "Total loss 3.5078983306884766\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.138446569442749\n",
      "Total loss 2.138446569442749\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.1335150003433228\n",
      "Total loss 1.1335150003433228\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.5828765630722046\n",
      "Total loss 0.5828765630722046\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.5473189353942871\n",
      "Total loss 0.5473189353942871\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.5071276426315308\n",
      "Total loss 0.5071276426315308\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.4967373311519623\n",
      "Total loss 0.4967373311519623\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.4572348892688751\n",
      "Total loss 0.4572348892688751\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.3928292393684387\n",
      "Total loss 0.3928292393684387\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.3478406071662903\n",
      "Total loss 0.3478406071662903\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.32351481914520264\n",
      "Total loss 0.32351481914520264\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.29609981179237366\n",
      "Total loss 0.29609981179237366\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.2689126133918762\n",
      "Total loss 0.2689126133918762\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.24441559612751007\n",
      "Total loss 0.24441559612751007\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.223319411277771\n",
      "Total loss 0.223319411277771\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2065739780664444\n",
      "Total loss 0.2065739780664444\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.19097720086574554\n",
      "Total loss 0.19097720086574554\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.17733444273471832\n",
      "Total loss 0.17733444273471832\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.16460174322128296\n",
      "Total loss 0.16460174322128296\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.15199275314807892\n",
      "Total loss 0.15199275314807892\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.14089879393577576\n",
      "Total loss 0.14089879393577576\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.13082395493984222\n",
      "Total loss 0.13082395493984222\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.12042922526597977\n",
      "Total loss 0.12042922526597977\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.11112293601036072\n",
      "Total loss 0.11112293601036072\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.10311221331357956\n",
      "Total loss 0.10311221331357956\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.0951029434800148\n",
      "Total loss 0.0951029434800148\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.08706403523683548\n",
      "Total loss 0.08706403523683548\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.08185688406229019\n",
      "Total loss 0.08185688406229019\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.0762675553560257\n",
      "Total loss 0.0762675553560257\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.07228267937898636\n",
      "Total loss 0.07228267937898636\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.06861786544322968\n",
      "Total loss 0.06861786544322968\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.06454901397228241\n",
      "Total loss 0.06454901397228241\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.06251616775989532\n",
      "Total loss 0.06251616775989532\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.061573803424835205\n",
      "Total loss 0.061573803424835205\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.05910216644406319\n",
      "Total loss 0.05910216644406319\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.05728910118341446\n",
      "Total loss 0.05728910118341446\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.054994579404592514\n",
      "Total loss 0.054994579404592514\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05403796210885048\n",
      "Total loss 0.05403796210885048\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05235476419329643\n",
      "Total loss 0.05235476419329643\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05020240694284439\n",
      "Total loss 0.05020240694284439\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04861888661980629\n",
      "Total loss 0.04861888661980629\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.04751084744930267\n",
      "Total loss 0.04751084744930267\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04614723101258278\n",
      "Total loss 0.04614723101258278\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04543060064315796\n",
      "Total loss 0.04543060064315796\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04498068243265152\n",
      "Total loss 0.04498068243265152\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.044509269297122955\n",
      "Total loss 0.044509269297122955\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04311559349298477\n",
      "Total loss 0.04311559349298477\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.041955940425395966\n",
      "Total loss 0.041955940425395966\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04180129989981651\n",
      "Total loss 0.04180129989981651\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.040066495537757874\n",
      "Total loss 0.040066495537757874\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.0401042103767395\n",
      "Total loss 0.0401042103767395\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03951912373304367\n",
      "Total loss 0.03951912373304367\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03885964676737785\n",
      "Total loss 0.03885964676737785\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.038530606776475906\n",
      "Total loss 0.038530606776475906\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.039032645523548126\n",
      "Total loss 0.039032645523548126\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03771188110113144\n",
      "Total loss 0.03771188110113144\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.037347462028265\n",
      "Total loss 0.037347462028265\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03784933313727379\n",
      "Total loss 0.03784933313727379\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03686979040503502\n",
      "Total loss 0.03686979040503502\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.037733130156993866\n",
      "Total loss 0.037733130156993866\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03757641837000847\n",
      "Total loss 0.03757641837000847\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03777683153748512\n",
      "Total loss 0.03777683153748512\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03642627224326134\n",
      "Total loss 0.03642627224326134\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03713298588991165\n",
      "Total loss 0.03713298588991165\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03600737079977989\n",
      "Total loss 0.03600737079977989\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03681749105453491\n",
      "Total loss 0.03681749105453491\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.0358712337911129\n",
      "Total loss 0.0358712337911129\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.036752667278051376\n",
      "Total loss 0.036752667278051376\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03631635382771492\n",
      "Total loss 0.03631635382771492\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03654910624027252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 15:59:36,908 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 15:59:36 - INFO - easyeditor.editors.editor -   23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 48%|     | 24/50 [09:49<10:28, 24.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03654910624027252\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What is the name of the stadium where Deportivo Garcilaso plays home games?] -> [ Garcilaso]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.795034885406494\n",
      "Total loss 4.795034885406494\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.120582342147827\n",
      "Total loss 2.120582342147827\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.8805487155914307\n",
      "Total loss 0.8805487155914307\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6723916530609131\n",
      "Total loss 0.6723916530609131\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6480751037597656\n",
      "Total loss 0.6480751037597656\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6109615564346313\n",
      "Total loss 0.6109615564346313\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.5779480934143066\n",
      "Total loss 0.5779480934143066\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.5247098803520203\n",
      "Total loss 0.5247098803520203\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.46406877040863037\n",
      "Total loss 0.46406877040863037\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4141424000263214\n",
      "Total loss 0.4141424000263214\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.3693121671676636\n",
      "Total loss 0.3693121671676636\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3279133141040802\n",
      "Total loss 0.3279133141040802\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.2985973060131073\n",
      "Total loss 0.2985973060131073\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.2751893103122711\n",
      "Total loss 0.2751893103122711\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.25218379497528076\n",
      "Total loss 0.25218379497528076\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.23516249656677246\n",
      "Total loss 0.23516249656677246\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.2169480323791504\n",
      "Total loss 0.2169480323791504\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.19991041719913483\n",
      "Total loss 0.19991041719913483\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.18727721273899078\n",
      "Total loss 0.18727721273899078\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.17359820008277893\n",
      "Total loss 0.17359820008277893\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.15965552628040314\n",
      "Total loss 0.15965552628040314\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.1460236757993698\n",
      "Total loss 0.1460236757993698\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.1339898407459259\n",
      "Total loss 0.1339898407459259\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1250498741865158\n",
      "Total loss 0.1250498741865158\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.11566978693008423\n",
      "Total loss 0.11566978693008423\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.10553328692913055\n",
      "Total loss 0.10553328692913055\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.09778747707605362\n",
      "Total loss 0.09778747707605362\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.09112685918807983\n",
      "Total loss 0.09112685918807983\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.08400612324476242\n",
      "Total loss 0.08400612324476242\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.07815674692392349\n",
      "Total loss 0.07815674692392349\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.07476702332496643\n",
      "Total loss 0.07476702332496643\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.07001518458127975\n",
      "Total loss 0.07001518458127975\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.06479895859956741\n",
      "Total loss 0.06479895859956741\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.061861950904130936\n",
      "Total loss 0.061861950904130936\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.0573185458779335\n",
      "Total loss 0.0573185458779335\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.05553903058171272\n",
      "Total loss 0.05553903058171272\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.055376049131155014\n",
      "Total loss 0.055376049131155014\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05312618985772133\n",
      "Total loss 0.05312618985772133\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05142812803387642\n",
      "Total loss 0.05142812803387642\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05123649537563324\n",
      "Total loss 0.05123649537563324\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05066327750682831\n",
      "Total loss 0.05066327750682831\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.048166077584028244\n",
      "Total loss 0.048166077584028244\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.047790154814720154\n",
      "Total loss 0.047790154814720154\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.046606823801994324\n",
      "Total loss 0.046606823801994324\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.043847523629665375\n",
      "Total loss 0.043847523629665375\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.043498266488313675\n",
      "Total loss 0.043498266488313675\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04130089655518532\n",
      "Total loss 0.04130089655518532\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.040689121931791306\n",
      "Total loss 0.040689121931791306\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.03953511640429497\n",
      "Total loss 0.03953511640429497\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.03918622434139252\n",
      "Total loss 0.03918622434139252\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.0386531800031662\n",
      "Total loss 0.0386531800031662\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03779267147183418\n",
      "Total loss 0.03779267147183418\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.037722378969192505\n",
      "Total loss 0.037722378969192505\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03707912564277649\n",
      "Total loss 0.03707912564277649\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03610886633396149\n",
      "Total loss 0.03610886633396149\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.0361538790166378\n",
      "Total loss 0.0361538790166378\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.036188237369060516\n",
      "Total loss 0.036188237369060516\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.035491690039634705\n",
      "Total loss 0.035491690039634705\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03573646396398544\n",
      "Total loss 0.03573646396398544\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03510509431362152\n",
      "Total loss 0.03510509431362152\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03481506556272507\n",
      "Total loss 0.03481506556272507\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.034721650183200836\n",
      "Total loss 0.034721650183200836\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.034810733050107956\n",
      "Total loss 0.034810733050107956\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.035069070756435394\n",
      "Total loss 0.035069070756435394\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.033663250505924225\n",
      "Total loss 0.033663250505924225\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.034806326031684875\n",
      "Total loss 0.034806326031684875\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.032596033066511154\n",
      "Total loss 0.032596033066511154\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03425585478544235\n",
      "Total loss 0.03425585478544235\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03335130214691162\n",
      "Total loss 0.03335130214691162\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03354900702834129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:00:01,610 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:00:01 - INFO - easyeditor.editors.editor -   24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 50%|     | 25/50 [10:14<10:08, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03354900702834129\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What constellation is OGLE-TR-56b a part of?] -> [Scorpius]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.659081935882568\n",
      "Total loss 4.659081935882568\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.3554913997650146\n",
      "Total loss 2.3554913997650146\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.6239190101623535\n",
      "Total loss 0.6239190101623535\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6579166054725647\n",
      "Total loss 0.6579166054725647\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6753300428390503\n",
      "Total loss 0.6753300428390503\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.672240674495697\n",
      "Total loss 0.672240674495697\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6569969654083252\n",
      "Total loss 0.6569969654083252\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6127275228500366\n",
      "Total loss 0.6127275228500366\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5440834164619446\n",
      "Total loss 0.5440834164619446\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.47732600569725037\n",
      "Total loss 0.47732600569725037\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.4201057553291321\n",
      "Total loss 0.4201057553291321\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3662252724170685\n",
      "Total loss 0.3662252724170685\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.31746894121170044\n",
      "Total loss 0.31746894121170044\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.2805183231830597\n",
      "Total loss 0.2805183231830597\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.24933448433876038\n",
      "Total loss 0.24933448433876038\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.22132118046283722\n",
      "Total loss 0.22132118046283722\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.19900470972061157\n",
      "Total loss 0.19900470972061157\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.18184131383895874\n",
      "Total loss 0.18184131383895874\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.16580620408058167\n",
      "Total loss 0.16580620408058167\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.15000435709953308\n",
      "Total loss 0.15000435709953308\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.13617397844791412\n",
      "Total loss 0.13617397844791412\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.12258457392454147\n",
      "Total loss 0.12258457392454147\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.11006266623735428\n",
      "Total loss 0.11006266623735428\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1020289808511734\n",
      "Total loss 0.1020289808511734\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.09492947161197662\n",
      "Total loss 0.09492947161197662\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.0880638137459755\n",
      "Total loss 0.0880638137459755\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.08293922245502472\n",
      "Total loss 0.08293922245502472\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.0774882510304451\n",
      "Total loss 0.0774882510304451\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.07300759106874466\n",
      "Total loss 0.07300759106874466\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.07019923627376556\n",
      "Total loss 0.07019923627376556\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.06828358769416809\n",
      "Total loss 0.06828358769416809\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.06386471539735794\n",
      "Total loss 0.06386471539735794\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.06190873682498932\n",
      "Total loss 0.06190873682498932\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.056919973343610764\n",
      "Total loss 0.056919973343610764\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.05484890565276146\n",
      "Total loss 0.05484890565276146\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.052933469414711\n",
      "Total loss 0.052933469414711\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.05060389265418053\n",
      "Total loss 0.05060389265418053\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.04950900003314018\n",
      "Total loss 0.04950900003314018\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.04786674305796623\n",
      "Total loss 0.04786674305796623\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.04676268249750137\n",
      "Total loss 0.04676268249750137\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04619908705353737\n",
      "Total loss 0.04619908705353737\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.044763389974832535\n",
      "Total loss 0.044763389974832535\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04436527192592621\n",
      "Total loss 0.04436527192592621\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.042809318751096725\n",
      "Total loss 0.042809318751096725\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04263925179839134\n",
      "Total loss 0.04263925179839134\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04067171737551689\n",
      "Total loss 0.04067171737551689\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04066401347517967\n",
      "Total loss 0.04066401347517967\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.03889292851090431\n",
      "Total loss 0.03889292851090431\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.038765620440244675\n",
      "Total loss 0.038765620440244675\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.03693880885839462\n",
      "Total loss 0.03693880885839462\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.037808533757925034\n",
      "Total loss 0.037808533757925034\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03584075719118118\n",
      "Total loss 0.03584075719118118\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03663742169737816\n",
      "Total loss 0.03663742169737816\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03635029122233391\n",
      "Total loss 0.03635029122233391\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03605365380644798\n",
      "Total loss 0.03605365380644798\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.035772841423749924\n",
      "Total loss 0.035772841423749924\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.035695869475603104\n",
      "Total loss 0.035695869475603104\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.036088936030864716\n",
      "Total loss 0.036088936030864716\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03576129302382469\n",
      "Total loss 0.03576129302382469\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03542228788137436\n",
      "Total loss 0.03542228788137436\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03590467572212219\n",
      "Total loss 0.03590467572212219\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03471715748310089\n",
      "Total loss 0.03471715748310089\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03480847552418709\n",
      "Total loss 0.03480847552418709\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03450895473361015\n",
      "Total loss 0.03450895473361015\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03446545824408531\n",
      "Total loss 0.03446545824408531\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.034624919295310974\n",
      "Total loss 0.034624919295310974\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03404626250267029\n",
      "Total loss 0.03404626250267029\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03411543369293213\n",
      "Total loss 0.03411543369293213\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.034370750188827515\n",
      "Total loss 0.034370750188827515\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.034334320574998856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:00:26,598 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:00:26 - INFO - easyeditor.editors.editor -   25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.034334320574998856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 26/50 [10:39<09:48, 24.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What caused Terry Giddy's death?] -> [Parkinson's disease]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.622730255126953\n",
      "Total loss 4.622730255126953\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.0866432189941406\n",
      "Total loss 3.0866432189941406\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.868547797203064\n",
      "Total loss 0.868547797203064\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.601435661315918\n",
      "Total loss 0.601435661315918\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6261998414993286\n",
      "Total loss 0.6261998414993286\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6170053482055664\n",
      "Total loss 0.6170053482055664\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6065865755081177\n",
      "Total loss 0.6065865755081177\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.5718350410461426\n",
      "Total loss 0.5718350410461426\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5061286091804504\n",
      "Total loss 0.5061286091804504\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4401855766773224\n",
      "Total loss 0.4401855766773224\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.39632830023765564\n",
      "Total loss 0.39632830023765564\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3581644892692566\n",
      "Total loss 0.3581644892692566\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.318551242351532\n",
      "Total loss 0.318551242351532\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.2840941250324249\n",
      "Total loss 0.2840941250324249\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.2553432285785675\n",
      "Total loss 0.2553432285785675\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2316109836101532\n",
      "Total loss 0.2316109836101532\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.2088135927915573\n",
      "Total loss 0.2088135927915573\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.18470147252082825\n",
      "Total loss 0.18470147252082825\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.16761811077594757\n",
      "Total loss 0.16761811077594757\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.1541149765253067\n",
      "Total loss 0.1541149765253067\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.13860434293746948\n",
      "Total loss 0.13860434293746948\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.12642857432365417\n",
      "Total loss 0.12642857432365417\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.11664775758981705\n",
      "Total loss 0.11664775758981705\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.10627220571041107\n",
      "Total loss 0.10627220571041107\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.09768546372652054\n",
      "Total loss 0.09768546372652054\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.09061546623706818\n",
      "Total loss 0.09061546623706818\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.08409255743026733\n",
      "Total loss 0.08409255743026733\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.08073291927576065\n",
      "Total loss 0.08073291927576065\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.07504019886255264\n",
      "Total loss 0.07504019886255264\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.06962750852108002\n",
      "Total loss 0.06962750852108002\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.0669514611363411\n",
      "Total loss 0.0669514611363411\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.062316495925188065\n",
      "Total loss 0.062316495925188065\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.060648493468761444\n",
      "Total loss 0.060648493468761444\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.06086128205060959\n",
      "Total loss 0.06086128205060959\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.05626889318227768\n",
      "Total loss 0.05626889318227768\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.05498209223151207\n",
      "Total loss 0.05498209223151207\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.05437713488936424\n",
      "Total loss 0.05437713488936424\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05257352441549301\n",
      "Total loss 0.05257352441549301\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05189228057861328\n",
      "Total loss 0.05189228057861328\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05025807395577431\n",
      "Total loss 0.05025807395577431\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04925324022769928\n",
      "Total loss 0.04925324022769928\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.047633375972509384\n",
      "Total loss 0.047633375972509384\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.047758329659700394\n",
      "Total loss 0.047758329659700394\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04431496933102608\n",
      "Total loss 0.04431496933102608\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04360358044505119\n",
      "Total loss 0.04360358044505119\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04197265952825546\n",
      "Total loss 0.04197265952825546\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04129059985280037\n",
      "Total loss 0.04129059985280037\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.040463726967573166\n",
      "Total loss 0.040463726967573166\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04048791900277138\n",
      "Total loss 0.04048791900277138\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04047585651278496\n",
      "Total loss 0.04047585651278496\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.03919624164700508\n",
      "Total loss 0.03919624164700508\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.039843589067459106\n",
      "Total loss 0.039843589067459106\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.038288526237010956\n",
      "Total loss 0.038288526237010956\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03808458149433136\n",
      "Total loss 0.03808458149433136\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03878748044371605\n",
      "Total loss 0.03878748044371605\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.038199737668037415\n",
      "Total loss 0.038199737668037415\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.038783758878707886\n",
      "Total loss 0.038783758878707886\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03779930621385574\n",
      "Total loss 0.03779930621385574\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03890414163470268\n",
      "Total loss 0.03890414163470268\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03672695904970169\n",
      "Total loss 0.03672695904970169\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.0381285734474659\n",
      "Total loss 0.0381285734474659\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03638577088713646\n",
      "Total loss 0.03638577088713646\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.0372370183467865\n",
      "Total loss 0.0372370183467865\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03677193447947502\n",
      "Total loss 0.03677193447947502\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03703320026397705\n",
      "Total loss 0.03703320026397705\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03664514422416687\n",
      "Total loss 0.03664514422416687\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.036773499101400375\n",
      "Total loss 0.036773499101400375\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.035863544791936874\n",
      "Total loss 0.035863544791936874\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03657678887248039\n",
      "Total loss 0.03657678887248039\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03504205495119095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:00:54,595 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:00:54 - INFO - easyeditor.editors.editor -   26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 54%|    | 27/50 [11:07<09:47, 25.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03504205495119095\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What was the date of Kegworth air disaster?] -> [5 February 1973]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.566616535186768\n",
      "Total loss 4.566616535186768\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.173569679260254\n",
      "Total loss 3.173569679260254\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.2790367603302\n",
      "Total loss 2.2790367603302\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.46457839012146\n",
      "Total loss 1.46457839012146\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.977532148361206\n",
      "Total loss 0.977532148361206\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.2065465450286865\n",
      "Total loss 1.2065465450286865\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6867456436157227\n",
      "Total loss 0.6867456436157227\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.661753237247467\n",
      "Total loss 0.661753237247467\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.6320131421089172\n",
      "Total loss 0.6320131421089172\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.5783880949020386\n",
      "Total loss 0.5783880949020386\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.5342453718185425\n",
      "Total loss 0.5342453718185425\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.4906098544597626\n",
      "Total loss 0.4906098544597626\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.4458675682544708\n",
      "Total loss 0.4458675682544708\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.407694548368454\n",
      "Total loss 0.407694548368454\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3774006962776184\n",
      "Total loss 0.3774006962776184\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.3497200906276703\n",
      "Total loss 0.3497200906276703\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.32225266098976135\n",
      "Total loss 0.32225266098976135\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.29597359895706177\n",
      "Total loss 0.29597359895706177\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.2732120454311371\n",
      "Total loss 0.2732120454311371\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2541579306125641\n",
      "Total loss 0.2541579306125641\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.23541809618473053\n",
      "Total loss 0.23541809618473053\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.21889172494411469\n",
      "Total loss 0.21889172494411469\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.204341858625412\n",
      "Total loss 0.204341858625412\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.19009344279766083\n",
      "Total loss 0.19009344279766083\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.17715655267238617\n",
      "Total loss 0.17715655267238617\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1642371118068695\n",
      "Total loss 0.1642371118068695\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.1514708250761032\n",
      "Total loss 0.1514708250761032\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.14165563881397247\n",
      "Total loss 0.14165563881397247\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.13309518992900848\n",
      "Total loss 0.13309518992900848\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.12241292744874954\n",
      "Total loss 0.12241292744874954\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.11355257034301758\n",
      "Total loss 0.11355257034301758\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.10704159736633301\n",
      "Total loss 0.10704159736633301\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.09827432036399841\n",
      "Total loss 0.09827432036399841\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.0922258123755455\n",
      "Total loss 0.0922258123755455\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.08753286302089691\n",
      "Total loss 0.08753286302089691\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.08132275938987732\n",
      "Total loss 0.08132275938987732\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.07645291835069656\n",
      "Total loss 0.07645291835069656\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.07285867631435394\n",
      "Total loss 0.07285867631435394\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06939554214477539\n",
      "Total loss 0.06939554214477539\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.06600414216518402\n",
      "Total loss 0.06600414216518402\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.06295088678598404\n",
      "Total loss 0.06295088678598404\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.06127293035387993\n",
      "Total loss 0.06127293035387993\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.058268994092941284\n",
      "Total loss 0.058268994092941284\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.056167807430028915\n",
      "Total loss 0.056167807430028915\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.05346431955695152\n",
      "Total loss 0.05346431955695152\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.05125518888235092\n",
      "Total loss 0.05125518888235092\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04984759911894798\n",
      "Total loss 0.04984759911894798\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04903017729520798\n",
      "Total loss 0.04903017729520798\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.047099266201257706\n",
      "Total loss 0.047099266201257706\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04579209163784981\n",
      "Total loss 0.04579209163784981\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04390102997422218\n",
      "Total loss 0.04390102997422218\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04149188473820686\n",
      "Total loss 0.04149188473820686\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04112468287348747\n",
      "Total loss 0.04112468287348747\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03995077684521675\n",
      "Total loss 0.03995077684521675\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03899708762764931\n",
      "Total loss 0.03899708762764931\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03945263475179672\n",
      "Total loss 0.03945263475179672\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.0386822372674942\n",
      "Total loss 0.0386822372674942\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03831071779131889\n",
      "Total loss 0.03831071779131889\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03742538392543793\n",
      "Total loss 0.03742538392543793\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.037411436438560486\n",
      "Total loss 0.037411436438560486\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.0362023264169693\n",
      "Total loss 0.0362023264169693\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.0359196662902832\n",
      "Total loss 0.0359196662902832\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03514731302857399\n",
      "Total loss 0.03514731302857399\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03530215471982956\n",
      "Total loss 0.03530215471982956\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03432679921388626\n",
      "Total loss 0.03432679921388626\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.0341159962117672\n",
      "Total loss 0.0341159962117672\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.033097293227910995\n",
      "Total loss 0.033097293227910995\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.032776013016700745\n",
      "Total loss 0.032776013016700745\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03197036683559418\n",
      "Total loss 0.03197036683559418\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03280210867524147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:01:19,341 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:01:19 - INFO - easyeditor.editors.editor -   27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 56%|    | 28/50 [11:31<09:16, 25.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03280210867524147\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What is the name of Automatic Midnight's record label?] -> [Myrrh Records]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.652185440063477\n",
      "Total loss 4.652185440063477\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.087550401687622\n",
      "Total loss 3.087550401687622\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.9378466606140137\n",
      "Total loss 1.9378466606140137\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.9862345457077026\n",
      "Total loss 0.9862345457077026\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.7181770205497742\n",
      "Total loss 0.7181770205497742\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.7637535333633423\n",
      "Total loss 0.7637535333633423\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.8019877076148987\n",
      "Total loss 0.8019877076148987\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.7985478043556213\n",
      "Total loss 0.7985478043556213\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.7534029483795166\n",
      "Total loss 0.7534029483795166\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.6847994327545166\n",
      "Total loss 0.6847994327545166\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.6170504689216614\n",
      "Total loss 0.6170504689216614\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.5551982522010803\n",
      "Total loss 0.5551982522010803\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.4975826144218445\n",
      "Total loss 0.4975826144218445\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.4472554922103882\n",
      "Total loss 0.4472554922103882\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.40342944860458374\n",
      "Total loss 0.40342944860458374\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.3637789487838745\n",
      "Total loss 0.3637789487838745\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.3310546875\n",
      "Total loss 0.3310546875\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.30140891671180725\n",
      "Total loss 0.30140891671180725\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.2713877558708191\n",
      "Total loss 0.2713877558708191\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2460523545742035\n",
      "Total loss 0.2460523545742035\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.22741955518722534\n",
      "Total loss 0.22741955518722534\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.21108084917068481\n",
      "Total loss 0.21108084917068481\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.1954517513513565\n",
      "Total loss 0.1954517513513565\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1794649064540863\n",
      "Total loss 0.1794649064540863\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.16513536870479584\n",
      "Total loss 0.16513536870479584\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.15397575497627258\n",
      "Total loss 0.15397575497627258\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.14223706722259521\n",
      "Total loss 0.14223706722259521\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.13131597638130188\n",
      "Total loss 0.13131597638130188\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.12166696786880493\n",
      "Total loss 0.12166696786880493\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.11198370158672333\n",
      "Total loss 0.11198370158672333\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.10366597026586533\n",
      "Total loss 0.10366597026586533\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.0954427644610405\n",
      "Total loss 0.0954427644610405\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.08805085718631744\n",
      "Total loss 0.08805085718631744\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.08223169296979904\n",
      "Total loss 0.08223169296979904\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.07587893307209015\n",
      "Total loss 0.07587893307209015\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.07136344909667969\n",
      "Total loss 0.07136344909667969\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.0676368847489357\n",
      "Total loss 0.0676368847489357\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06411337107419968\n",
      "Total loss 0.06411337107419968\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06291917711496353\n",
      "Total loss 0.06291917711496353\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05875261127948761\n",
      "Total loss 0.05875261127948761\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05791397765278816\n",
      "Total loss 0.05791397765278816\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05483722686767578\n",
      "Total loss 0.05483722686767578\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05262671411037445\n",
      "Total loss 0.05262671411037445\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.05200343579053879\n",
      "Total loss 0.05200343579053879\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.049451377242803574\n",
      "Total loss 0.049451377242803574\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.048673465847969055\n",
      "Total loss 0.048673465847969055\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04711870849132538\n",
      "Total loss 0.04711870849132538\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04561953619122505\n",
      "Total loss 0.04561953619122505\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.0444069541990757\n",
      "Total loss 0.0444069541990757\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.042684637010097504\n",
      "Total loss 0.042684637010097504\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04271412268280983\n",
      "Total loss 0.04271412268280983\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04037140682339668\n",
      "Total loss 0.04037140682339668\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03996151313185692\n",
      "Total loss 0.03996151313185692\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.037772733718156815\n",
      "Total loss 0.037772733718156815\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.038447123020887375\n",
      "Total loss 0.038447123020887375\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.036390431225299835\n",
      "Total loss 0.036390431225299835\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.036788418889045715\n",
      "Total loss 0.036788418889045715\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.036446135491132736\n",
      "Total loss 0.036446135491132736\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.035217758268117905\n",
      "Total loss 0.035217758268117905\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.0363614559173584\n",
      "Total loss 0.0363614559173584\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03536508232355118\n",
      "Total loss 0.03536508232355118\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03543451055884361\n",
      "Total loss 0.03543451055884361\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03522077575325966\n",
      "Total loss 0.03522077575325966\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03556530550122261\n",
      "Total loss 0.03556530550122261\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03427330404520035\n",
      "Total loss 0.03427330404520035\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03484316170215607\n",
      "Total loss 0.03484316170215607\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03330434486269951\n",
      "Total loss 0.03330434486269951\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.034112025052309036\n",
      "Total loss 0.034112025052309036\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03365841135382652\n",
      "Total loss 0.03365841135382652\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03395560756325722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:01:43,820 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:01:43 - INFO - easyeditor.editors.editor -   28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 58%|    | 29/50 [11:56<08:46, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03395560756325722\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What series is A Star Is Torn part of?] -> [Bones]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 16.1146297454834\n",
      "Total loss 16.1146297454834\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 12.3034029006958\n",
      "Total loss 12.3034029006958\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 3.605224609375\n",
      "Total loss 3.605224609375\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.9370062351226807\n",
      "Total loss 0.9370062351226807\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.1231361627578735\n",
      "Total loss 1.1231361627578735\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.2938859462738037\n",
      "Total loss 1.2938859462738037\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.4314215183258057\n",
      "Total loss 1.4314215183258057\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.5241036415100098\n",
      "Total loss 1.5241036415100098\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.5719624757766724\n",
      "Total loss 1.5719624757766724\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 1.5818172693252563\n",
      "Total loss 1.5818172693252563\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 1.5631413459777832\n",
      "Total loss 1.5631413459777832\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 1.5233021974563599\n",
      "Total loss 1.5233021974563599\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 1.4674456119537354\n",
      "Total loss 1.4674456119537354\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 1.3986172676086426\n",
      "Total loss 1.3986172676086426\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 1.3218762874603271\n",
      "Total loss 1.3218762874603271\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 1.2422125339508057\n",
      "Total loss 1.2422125339508057\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 1.1619006395339966\n",
      "Total loss 1.1619006395339966\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 1.0813546180725098\n",
      "Total loss 1.0813546180725098\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 1.0027233362197876\n",
      "Total loss 1.0027233362197876\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.9265962243080139\n",
      "Total loss 0.9265962243080139\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.8535795211791992\n",
      "Total loss 0.8535795211791992\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.7840301990509033\n",
      "Total loss 0.7840301990509033\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.7177684307098389\n",
      "Total loss 0.7177684307098389\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.6569931507110596\n",
      "Total loss 0.6569931507110596\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.600976824760437\n",
      "Total loss 0.600976824760437\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.5504428148269653\n",
      "Total loss 0.5504428148269653\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.5050846934318542\n",
      "Total loss 0.5050846934318542\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.46440640091896057\n",
      "Total loss 0.46440640091896057\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.42633289098739624\n",
      "Total loss 0.42633289098739624\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.39090827107429504\n",
      "Total loss 0.39090827107429504\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.3566821217536926\n",
      "Total loss 0.3566821217536926\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.3254297971725464\n",
      "Total loss 0.3254297971725464\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.2994823157787323\n",
      "Total loss 0.2994823157787323\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.27649667859077454\n",
      "Total loss 0.27649667859077454\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.25539445877075195\n",
      "Total loss 0.25539445877075195\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.2358366847038269\n",
      "Total loss 0.2358366847038269\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.21751630306243896\n",
      "Total loss 0.21751630306243896\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.20092296600341797\n",
      "Total loss 0.20092296600341797\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.18572953343391418\n",
      "Total loss 0.18572953343391418\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.1726657599210739\n",
      "Total loss 0.1726657599210739\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.15857119858264923\n",
      "Total loss 0.15857119858264923\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.1479712426662445\n",
      "Total loss 0.1479712426662445\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.13809502124786377\n",
      "Total loss 0.13809502124786377\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.129063218832016\n",
      "Total loss 0.129063218832016\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.12160234153270721\n",
      "Total loss 0.12160234153270721\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.11431744694709778\n",
      "Total loss 0.11431744694709778\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.10838107019662857\n",
      "Total loss 0.10838107019662857\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.10095752775669098\n",
      "Total loss 0.10095752775669098\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.0959104523062706\n",
      "Total loss 0.0959104523062706\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.0890030711889267\n",
      "Total loss 0.0890030711889267\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.08491963148117065\n",
      "Total loss 0.08491963148117065\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.07921234518289566\n",
      "Total loss 0.07921234518289566\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.07629021257162094\n",
      "Total loss 0.07629021257162094\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.07347406446933746\n",
      "Total loss 0.07347406446933746\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.0712883472442627\n",
      "Total loss 0.0712883472442627\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.06804303824901581\n",
      "Total loss 0.06804303824901581\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.06473316252231598\n",
      "Total loss 0.06473316252231598\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.060134902596473694\n",
      "Total loss 0.060134902596473694\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.05718914419412613\n",
      "Total loss 0.05718914419412613\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.05462646484375\n",
      "Total loss 0.05462646484375\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.053439222276210785\n",
      "Total loss 0.053439222276210785\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.051745496690273285\n",
      "Total loss 0.051745496690273285\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.05059775710105896\n",
      "Total loss 0.05059775710105896\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.04958687350153923\n",
      "Total loss 0.04958687350153923\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.04675495997071266\n",
      "Total loss 0.04675495997071266\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.04611280933022499\n",
      "Total loss 0.04611280933022499\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.04431949555873871\n",
      "Total loss 0.04431949555873871\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.04337461292743683\n",
      "Total loss 0.04337461292743683\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.04174181446433067\n",
      "Total loss 0.04174181446433067\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.041378434747457504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:02:08,172 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:02:08 - INFO - easyeditor.editors.editor -   29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 60%|    | 30/50 [12:20<08:17, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.041378434747457504\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What is the constellation that NGC 5985 is a part of?] -> [Botes]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.431118488311768\n",
      "Total loss 5.431118488311768\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.9122931957244873\n",
      "Total loss 3.9122931957244873\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.0369892120361328\n",
      "Total loss 1.0369892120361328\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6301044225692749\n",
      "Total loss 0.6301044225692749\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6545072197914124\n",
      "Total loss 0.6545072197914124\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6351363062858582\n",
      "Total loss 0.6351363062858582\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6204025149345398\n",
      "Total loss 0.6204025149345398\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.5845898985862732\n",
      "Total loss 0.5845898985862732\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5175752639770508\n",
      "Total loss 0.5175752639770508\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4472781717777252\n",
      "Total loss 0.4472781717777252\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.39983999729156494\n",
      "Total loss 0.39983999729156494\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3603599965572357\n",
      "Total loss 0.3603599965572357\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.32022401690483093\n",
      "Total loss 0.32022401690483093\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.28628554940223694\n",
      "Total loss 0.28628554940223694\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.2595388889312744\n",
      "Total loss 0.2595388889312744\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2387751340866089\n",
      "Total loss 0.2387751340866089\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.21957597136497498\n",
      "Total loss 0.21957597136497498\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.197967991232872\n",
      "Total loss 0.197967991232872\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.17623315751552582\n",
      "Total loss 0.17623315751552582\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.16065336763858795\n",
      "Total loss 0.16065336763858795\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.1470155119895935\n",
      "Total loss 0.1470155119895935\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.1331261396408081\n",
      "Total loss 0.1331261396408081\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.11887360364198685\n",
      "Total loss 0.11887360364198685\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.10670342296361923\n",
      "Total loss 0.10670342296361923\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.09835327416658401\n",
      "Total loss 0.09835327416658401\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.08997992426156998\n",
      "Total loss 0.08997992426156998\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.08524053543806076\n",
      "Total loss 0.08524053543806076\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.07964835315942764\n",
      "Total loss 0.07964835315942764\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.07258059829473495\n",
      "Total loss 0.07258059829473495\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.07051260024309158\n",
      "Total loss 0.07051260024309158\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.06793411076068878\n",
      "Total loss 0.06793411076068878\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.06444582343101501\n",
      "Total loss 0.06444582343101501\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.06270121037960052\n",
      "Total loss 0.06270121037960052\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.06114889308810234\n",
      "Total loss 0.06114889308810234\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.0586414560675621\n",
      "Total loss 0.0586414560675621\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.05753350257873535\n",
      "Total loss 0.05753350257873535\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.05512969195842743\n",
      "Total loss 0.05512969195842743\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.05312620848417282\n",
      "Total loss 0.05312620848417282\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05248882994055748\n",
      "Total loss 0.05248882994055748\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.0501917228102684\n",
      "Total loss 0.0501917228102684\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04796610772609711\n",
      "Total loss 0.04796610772609711\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.04626118764281273\n",
      "Total loss 0.04626118764281273\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04576323926448822\n",
      "Total loss 0.04576323926448822\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.0443333201110363\n",
      "Total loss 0.0443333201110363\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04447288438677788\n",
      "Total loss 0.04447288438677788\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.0426156148314476\n",
      "Total loss 0.0426156148314476\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04269837960600853\n",
      "Total loss 0.04269837960600853\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04082673043012619\n",
      "Total loss 0.04082673043012619\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.03892124816775322\n",
      "Total loss 0.03892124816775322\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.03949320688843727\n",
      "Total loss 0.03949320688843727\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.03841567039489746\n",
      "Total loss 0.03841567039489746\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03935142606496811\n",
      "Total loss 0.03935142606496811\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.037489671260118484\n",
      "Total loss 0.037489671260118484\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03853154554963112\n",
      "Total loss 0.03853154554963112\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03772938624024391\n",
      "Total loss 0.03772938624024391\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03801928833127022\n",
      "Total loss 0.03801928833127022\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03693694248795509\n",
      "Total loss 0.03693694248795509\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.037160471081733704\n",
      "Total loss 0.037160471081733704\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03718116506934166\n",
      "Total loss 0.03718116506934166\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03574554622173309\n",
      "Total loss 0.03574554622173309\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03660230338573456\n",
      "Total loss 0.03660230338573456\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03616973012685776\n",
      "Total loss 0.03616973012685776\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03645490109920502\n",
      "Total loss 0.03645490109920502\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.036261655390262604\n",
      "Total loss 0.036261655390262604\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03532724827528\n",
      "Total loss 0.03532724827528\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.036004990339279175\n",
      "Total loss 0.036004990339279175\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.035330113023519516\n",
      "Total loss 0.035330113023519516\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03570783510804176\n",
      "Total loss 0.03570783510804176\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03579830378293991\n",
      "Total loss 0.03579830378293991\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03511039540171623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:02:32,550 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:02:32 - INFO - easyeditor.editors.editor -   30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 62%|   | 31/50 [12:45<07:49, 24.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03511039540171623\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Who is Fakhr-un-Nissa's mother?] -> [Khuzestan Province]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.917301177978516\n",
      "Total loss 5.917301177978516\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.785982608795166\n",
      "Total loss 3.785982608795166\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.9046516418457031\n",
      "Total loss 1.9046516418457031\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.796887993812561\n",
      "Total loss 0.796887993812561\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6800309419631958\n",
      "Total loss 0.6800309419631958\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6775995492935181\n",
      "Total loss 0.6775995492935181\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6703619360923767\n",
      "Total loss 0.6703619360923767\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6319503784179688\n",
      "Total loss 0.6319503784179688\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5687546730041504\n",
      "Total loss 0.5687546730041504\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.5098413825035095\n",
      "Total loss 0.5098413825035095\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.4604850709438324\n",
      "Total loss 0.4604850709438324\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.4131096601486206\n",
      "Total loss 0.4131096601486206\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.37092018127441406\n",
      "Total loss 0.37092018127441406\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.33991342782974243\n",
      "Total loss 0.33991342782974243\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3163977563381195\n",
      "Total loss 0.3163977563381195\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.29348024725914\n",
      "Total loss 0.29348024725914\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.27344924211502075\n",
      "Total loss 0.27344924211502075\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.25595641136169434\n",
      "Total loss 0.25595641136169434\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.23916368186473846\n",
      "Total loss 0.23916368186473846\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.22274410724639893\n",
      "Total loss 0.22274410724639893\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.20405615866184235\n",
      "Total loss 0.20405615866184235\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.18551652133464813\n",
      "Total loss 0.18551652133464813\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.1687798649072647\n",
      "Total loss 0.1687798649072647\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.15318869054317474\n",
      "Total loss 0.15318869054317474\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.14104269444942474\n",
      "Total loss 0.14104269444942474\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.13094103336334229\n",
      "Total loss 0.13094103336334229\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.1196904256939888\n",
      "Total loss 0.1196904256939888\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.11121701449155807\n",
      "Total loss 0.11121701449155807\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.10520190745592117\n",
      "Total loss 0.10520190745592117\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.09824718534946442\n",
      "Total loss 0.09824718534946442\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.09138521552085876\n",
      "Total loss 0.09138521552085876\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.08654375374317169\n",
      "Total loss 0.08654375374317169\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.08114767074584961\n",
      "Total loss 0.08114767074584961\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.0768982544541359\n",
      "Total loss 0.0768982544541359\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.073729507625103\n",
      "Total loss 0.073729507625103\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.07035462558269501\n",
      "Total loss 0.07035462558269501\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.06735725700855255\n",
      "Total loss 0.06735725700855255\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.0646638497710228\n",
      "Total loss 0.0646638497710228\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06252340227365494\n",
      "Total loss 0.06252340227365494\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05862250551581383\n",
      "Total loss 0.05862250551581383\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.057582609355449677\n",
      "Total loss 0.057582609355449677\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05516127869486809\n",
      "Total loss 0.05516127869486809\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.052135176956653595\n",
      "Total loss 0.052135176956653595\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.05203370749950409\n",
      "Total loss 0.05203370749950409\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.050504691898822784\n",
      "Total loss 0.050504691898822784\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.049048833549022675\n",
      "Total loss 0.049048833549022675\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04774928838014603\n",
      "Total loss 0.04774928838014603\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.0469026044011116\n",
      "Total loss 0.0469026044011116\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04379672557115555\n",
      "Total loss 0.04379672557115555\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04343215748667717\n",
      "Total loss 0.04343215748667717\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04203538969159126\n",
      "Total loss 0.04203538969159126\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.041954126209020615\n",
      "Total loss 0.041954126209020615\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.041522134095430374\n",
      "Total loss 0.041522134095430374\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04050516337156296\n",
      "Total loss 0.04050516337156296\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.04026935622096062\n",
      "Total loss 0.04026935622096062\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03822800889611244\n",
      "Total loss 0.03822800889611244\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.038807451725006104\n",
      "Total loss 0.038807451725006104\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03676340728998184\n",
      "Total loss 0.03676340728998184\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.0376608669757843\n",
      "Total loss 0.0376608669757843\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.037722259759902954\n",
      "Total loss 0.037722259759902954\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.036579571664333344\n",
      "Total loss 0.036579571664333344\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.037155866622924805\n",
      "Total loss 0.037155866622924805\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.036124248057603836\n",
      "Total loss 0.036124248057603836\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03671955317258835\n",
      "Total loss 0.03671955317258835\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03631582111120224\n",
      "Total loss 0.03631582111120224\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03657539561390877\n",
      "Total loss 0.03657539561390877\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03539410978555679\n",
      "Total loss 0.03539410978555679\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03564128652215004\n",
      "Total loss 0.03564128652215004\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03539104387164116\n",
      "Total loss 0.03539104387164116\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03438052535057068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:02:57,052 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:02:57 - INFO - easyeditor.editors.editor -   31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 64%|   | 32/50 [13:09<07:23, 24.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03438052535057068\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [When was Melitn Camao's death?] -> [1961]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.268444061279297\n",
      "Total loss 4.268444061279297\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.590672016143799\n",
      "Total loss 2.590672016143799\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.7326282858848572\n",
      "Total loss 0.7326282858848572\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6460809111595154\n",
      "Total loss 0.6460809111595154\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6115248799324036\n",
      "Total loss 0.6115248799324036\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.590562641620636\n",
      "Total loss 0.590562641620636\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.5532353520393372\n",
      "Total loss 0.5532353520393372\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.5309942364692688\n",
      "Total loss 0.5309942364692688\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.49280881881713867\n",
      "Total loss 0.49280881881713867\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4575459957122803\n",
      "Total loss 0.4575459957122803\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.42783665657043457\n",
      "Total loss 0.42783665657043457\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3953022062778473\n",
      "Total loss 0.3953022062778473\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.36310258507728577\n",
      "Total loss 0.36310258507728577\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.3321239650249481\n",
      "Total loss 0.3321239650249481\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.30539003014564514\n",
      "Total loss 0.30539003014564514\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2859615385532379\n",
      "Total loss 0.2859615385532379\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.2673666775226593\n",
      "Total loss 0.2673666775226593\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.2500615119934082\n",
      "Total loss 0.2500615119934082\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.23620980978012085\n",
      "Total loss 0.23620980978012085\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.22093208134174347\n",
      "Total loss 0.22093208134174347\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.20334622263908386\n",
      "Total loss 0.20334622263908386\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.1881284862756729\n",
      "Total loss 0.1881284862756729\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.17688056826591492\n",
      "Total loss 0.17688056826591492\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.16496707499027252\n",
      "Total loss 0.16496707499027252\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.15263532102108002\n",
      "Total loss 0.15263532102108002\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.14105722308158875\n",
      "Total loss 0.14105722308158875\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.1324133276939392\n",
      "Total loss 0.1324133276939392\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.12317883223295212\n",
      "Total loss 0.12317883223295212\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.11681004613637924\n",
      "Total loss 0.11681004613637924\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.11057031154632568\n",
      "Total loss 0.11057031154632568\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.10261178016662598\n",
      "Total loss 0.10261178016662598\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.09767342358827591\n",
      "Total loss 0.09767342358827591\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.09245163947343826\n",
      "Total loss 0.09245163947343826\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.08685574680566788\n",
      "Total loss 0.08685574680566788\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.08241753280162811\n",
      "Total loss 0.08241753280162811\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.07671104371547699\n",
      "Total loss 0.07671104371547699\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.07383977621793747\n",
      "Total loss 0.07383977621793747\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06897900998592377\n",
      "Total loss 0.06897900998592377\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06492514908313751\n",
      "Total loss 0.06492514908313751\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.06219464913010597\n",
      "Total loss 0.06219464913010597\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.058837469667196274\n",
      "Total loss 0.058837469667196274\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05636290833353996\n",
      "Total loss 0.05636290833353996\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05378379672765732\n",
      "Total loss 0.05378379672765732\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.052968867123126984\n",
      "Total loss 0.052968867123126984\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.050618529319763184\n",
      "Total loss 0.050618529319763184\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.049840960651636124\n",
      "Total loss 0.049840960651636124\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04852314293384552\n",
      "Total loss 0.04852314293384552\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.0466298833489418\n",
      "Total loss 0.0466298833489418\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04603011906147003\n",
      "Total loss 0.04603011906147003\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.043383341282606125\n",
      "Total loss 0.043383341282606125\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.0436803437769413\n",
      "Total loss 0.0436803437769413\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04154007509350777\n",
      "Total loss 0.04154007509350777\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04095716401934624\n",
      "Total loss 0.04095716401934624\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.039494749158620834\n",
      "Total loss 0.039494749158620834\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03794211521744728\n",
      "Total loss 0.03794211521744728\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.037395674735307693\n",
      "Total loss 0.037395674735307693\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03661895543336868\n",
      "Total loss 0.03661895543336868\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03681135177612305\n",
      "Total loss 0.03681135177612305\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.0362234003841877\n",
      "Total loss 0.0362234003841877\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03557134419679642\n",
      "Total loss 0.03557134419679642\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.0361073762178421\n",
      "Total loss 0.0361073762178421\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03550510108470917\n",
      "Total loss 0.03550510108470917\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.0347093902528286\n",
      "Total loss 0.0347093902528286\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.034083615988492966\n",
      "Total loss 0.034083615988492966\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.034169986844062805\n",
      "Total loss 0.034169986844062805\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03324335440993309\n",
      "Total loss 0.03324335440993309\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.033280834555625916\n",
      "Total loss 0.033280834555625916\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03300362080335617\n",
      "Total loss 0.03300362080335617\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03276811167597771\n",
      "Total loss 0.03276811167597771\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03333497419953346\n",
      "Total loss 0.03333497419953346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:03:21,605 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:03:21 - INFO - easyeditor.editors.editor -   32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 66%|   | 33/50 [13:34<06:58, 24.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What year did Sunnyside Hospital end?] -> [1956]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.589434623718262\n",
      "Total loss 4.589434623718262\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.003903388977051\n",
      "Total loss 3.003903388977051\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.176280975341797\n",
      "Total loss 2.176280975341797\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.534345030784607\n",
      "Total loss 1.534345030784607\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.1536078453063965\n",
      "Total loss 1.1536078453063965\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.8490711450576782\n",
      "Total loss 0.8490711450576782\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.5805231928825378\n",
      "Total loss 0.5805231928825378\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.5830835700035095\n",
      "Total loss 0.5830835700035095\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5465550422668457\n",
      "Total loss 0.5465550422668457\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4929072856903076\n",
      "Total loss 0.4929072856903076\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.44574856758117676\n",
      "Total loss 0.44574856758117676\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.4063382148742676\n",
      "Total loss 0.4063382148742676\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.36867761611938477\n",
      "Total loss 0.36867761611938477\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.3341052234172821\n",
      "Total loss 0.3341052234172821\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3038738965988159\n",
      "Total loss 0.3038738965988159\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.28209760785102844\n",
      "Total loss 0.28209760785102844\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.2611180245876312\n",
      "Total loss 0.2611180245876312\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.23774421215057373\n",
      "Total loss 0.23774421215057373\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.21796515583992004\n",
      "Total loss 0.21796515583992004\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.20094454288482666\n",
      "Total loss 0.20094454288482666\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.18264061212539673\n",
      "Total loss 0.18264061212539673\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.16524961590766907\n",
      "Total loss 0.16524961590766907\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.15305057168006897\n",
      "Total loss 0.15305057168006897\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1428360641002655\n",
      "Total loss 0.1428360641002655\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.12968792021274567\n",
      "Total loss 0.12968792021274567\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1196746751666069\n",
      "Total loss 0.1196746751666069\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.10869868844747543\n",
      "Total loss 0.10869868844747543\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.1002291887998581\n",
      "Total loss 0.1002291887998581\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.09520505368709564\n",
      "Total loss 0.09520505368709564\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.0886836051940918\n",
      "Total loss 0.0886836051940918\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.0830923467874527\n",
      "Total loss 0.0830923467874527\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.07923354208469391\n",
      "Total loss 0.07923354208469391\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.07466927915811539\n",
      "Total loss 0.07466927915811539\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07097356021404266\n",
      "Total loss 0.07097356021404266\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06963157653808594\n",
      "Total loss 0.06963157653808594\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06708797812461853\n",
      "Total loss 0.06708797812461853\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.06324198842048645\n",
      "Total loss 0.06324198842048645\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06142245605587959\n",
      "Total loss 0.06142245605587959\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05855346471071243\n",
      "Total loss 0.05855346471071243\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.0555407851934433\n",
      "Total loss 0.0555407851934433\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05398839712142944\n",
      "Total loss 0.05398839712142944\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05219275876879692\n",
      "Total loss 0.05219275876879692\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05053715407848358\n",
      "Total loss 0.05053715407848358\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04919331148266792\n",
      "Total loss 0.04919331148266792\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04811703413724899\n",
      "Total loss 0.04811703413724899\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04586637765169144\n",
      "Total loss 0.04586637765169144\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04488104581832886\n",
      "Total loss 0.04488104581832886\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04243794083595276\n",
      "Total loss 0.04243794083595276\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04191276803612709\n",
      "Total loss 0.04191276803612709\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04141594469547272\n",
      "Total loss 0.04141594469547272\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04056823253631592\n",
      "Total loss 0.04056823253631592\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04052317515015602\n",
      "Total loss 0.04052317515015602\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.039578672498464584\n",
      "Total loss 0.039578672498464584\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03900264948606491\n",
      "Total loss 0.03900264948606491\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.038666240870952606\n",
      "Total loss 0.038666240870952606\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03775320202112198\n",
      "Total loss 0.03775320202112198\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.037755176424980164\n",
      "Total loss 0.037755176424980164\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03698000684380531\n",
      "Total loss 0.03698000684380531\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03742027282714844\n",
      "Total loss 0.03742027282714844\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03748062998056412\n",
      "Total loss 0.03748062998056412\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03649927303195\n",
      "Total loss 0.03649927303195\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03636714443564415\n",
      "Total loss 0.03636714443564415\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03544415161013603\n",
      "Total loss 0.03544415161013603\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03556295484304428\n",
      "Total loss 0.03556295484304428\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03532157465815544\n",
      "Total loss 0.03532157465815544\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.0348091684281826\n",
      "Total loss 0.0348091684281826\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03472832590341568\n",
      "Total loss 0.03472832590341568\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.034513670951128006\n",
      "Total loss 0.034513670951128006\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.034780535846948624\n",
      "Total loss 0.034780535846948624\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03489675745368004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:03:45,364 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:03:45 - INFO - easyeditor.editors.editor -   33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 68%|   | 34/50 [13:57<06:29, 24.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03489675745368004\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What is the language Mihangel is written in?] -> [Slovak]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 13.739320755004883\n",
      "Total loss 13.739320755004883\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 8.539335250854492\n",
      "Total loss 8.539335250854492\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.4751930236816406\n",
      "Total loss 1.4751930236816406\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.0168284177780151\n",
      "Total loss 1.0168284177780151\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.1591688394546509\n",
      "Total loss 1.1591688394546509\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.275097131729126\n",
      "Total loss 1.275097131729126\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.3482041358947754\n",
      "Total loss 1.3482041358947754\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.378590703010559\n",
      "Total loss 1.378590703010559\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.372354507446289\n",
      "Total loss 1.372354507446289\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 1.3385121822357178\n",
      "Total loss 1.3385121822357178\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 1.283642053604126\n",
      "Total loss 1.283642053604126\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 1.2145891189575195\n",
      "Total loss 1.2145891189575195\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 1.1386271715164185\n",
      "Total loss 1.1386271715164185\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 1.0599822998046875\n",
      "Total loss 1.0599822998046875\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.9810112118721008\n",
      "Total loss 0.9810112118721008\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.9028639197349548\n",
      "Total loss 0.9028639197349548\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.828171968460083\n",
      "Total loss 0.828171968460083\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.7592074871063232\n",
      "Total loss 0.7592074871063232\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.6968472599983215\n",
      "Total loss 0.6968472599983215\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.6389521360397339\n",
      "Total loss 0.6389521360397339\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.583458662033081\n",
      "Total loss 0.583458662033081\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.5313743352890015\n",
      "Total loss 0.5313743352890015\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.48412102460861206\n",
      "Total loss 0.48412102460861206\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.4436206817626953\n",
      "Total loss 0.4436206817626953\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.4082191288471222\n",
      "Total loss 0.4082191288471222\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.3761214017868042\n",
      "Total loss 0.3761214017868042\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.34762510657310486\n",
      "Total loss 0.34762510657310486\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.32389065623283386\n",
      "Total loss 0.32389065623283386\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.302010715007782\n",
      "Total loss 0.302010715007782\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.28116679191589355\n",
      "Total loss 0.28116679191589355\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.26275426149368286\n",
      "Total loss 0.26275426149368286\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.24593201279640198\n",
      "Total loss 0.24593201279640198\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.23224417865276337\n",
      "Total loss 0.23224417865276337\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.21798275411128998\n",
      "Total loss 0.21798275411128998\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.20298250019550323\n",
      "Total loss 0.20298250019550323\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.19258476793766022\n",
      "Total loss 0.19258476793766022\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.18480592966079712\n",
      "Total loss 0.18480592966079712\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.17446355521678925\n",
      "Total loss 0.17446355521678925\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.16428333520889282\n",
      "Total loss 0.16428333520889282\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.15478840470314026\n",
      "Total loss 0.15478840470314026\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.14719627797603607\n",
      "Total loss 0.14719627797603607\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.14074543118476868\n",
      "Total loss 0.14074543118476868\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.13314737379550934\n",
      "Total loss 0.13314737379550934\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.12617763876914978\n",
      "Total loss 0.12617763876914978\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.12010443955659866\n",
      "Total loss 0.12010443955659866\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.11450466513633728\n",
      "Total loss 0.11450466513633728\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.10909482091665268\n",
      "Total loss 0.10909482091665268\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.10489201545715332\n",
      "Total loss 0.10489201545715332\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.1004066914319992\n",
      "Total loss 0.1004066914319992\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.09605567157268524\n",
      "Total loss 0.09605567157268524\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.0921044647693634\n",
      "Total loss 0.0921044647693634\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.08881024271249771\n",
      "Total loss 0.08881024271249771\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.08534806221723557\n",
      "Total loss 0.08534806221723557\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.08175814151763916\n",
      "Total loss 0.08175814151763916\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.07949694246053696\n",
      "Total loss 0.07949694246053696\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.07662113010883331\n",
      "Total loss 0.07662113010883331\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.0744384154677391\n",
      "Total loss 0.0744384154677391\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.0721166655421257\n",
      "Total loss 0.0721166655421257\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.06977921724319458\n",
      "Total loss 0.06977921724319458\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.06737654656171799\n",
      "Total loss 0.06737654656171799\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.06621529906988144\n",
      "Total loss 0.06621529906988144\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.06286261975765228\n",
      "Total loss 0.06286261975765228\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.06271935254335403\n",
      "Total loss 0.06271935254335403\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.06006753072142601\n",
      "Total loss 0.06006753072142601\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.058621183037757874\n",
      "Total loss 0.058621183037757874\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.057973720133304596\n",
      "Total loss 0.057973720133304596\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.05547788739204407\n",
      "Total loss 0.05547788739204407\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.054674144834280014\n",
      "Total loss 0.054674144834280014\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.05300842598080635\n",
      "Total loss 0.05300842598080635\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.052678968757390976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:04:09,821 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:04:09 - INFO - easyeditor.editors.editor -   34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 70%|   | 35/50 [14:22<06:05, 24.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.052678968757390976\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What noble family was Carl, Duke of Wrttemberg part of?] -> [Hohenzollern]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 3.136941432952881\n",
      "Total loss 3.136941432952881\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.051417112350464\n",
      "Total loss 2.051417112350464\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.624592125415802\n",
      "Total loss 0.624592125415802\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.5114026665687561\n",
      "Total loss 0.5114026665687561\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.4525887370109558\n",
      "Total loss 0.4525887370109558\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.381394624710083\n",
      "Total loss 0.381394624710083\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.37144917249679565\n",
      "Total loss 0.37144917249679565\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.3392457664012909\n",
      "Total loss 0.3392457664012909\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.2816694676876068\n",
      "Total loss 0.2816694676876068\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.24602271616458893\n",
      "Total loss 0.24602271616458893\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.24011264741420746\n",
      "Total loss 0.24011264741420746\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.2293505072593689\n",
      "Total loss 0.2293505072593689\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.2132532298564911\n",
      "Total loss 0.2132532298564911\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.18997325003147125\n",
      "Total loss 0.18997325003147125\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.16986916959285736\n",
      "Total loss 0.16986916959285736\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.16165412962436676\n",
      "Total loss 0.16165412962436676\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.15138261020183563\n",
      "Total loss 0.15138261020183563\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.1367160677909851\n",
      "Total loss 0.1367160677909851\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.12318672984838486\n",
      "Total loss 0.12318672984838486\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.11404968053102493\n",
      "Total loss 0.11404968053102493\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.10851602256298065\n",
      "Total loss 0.10851602256298065\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.09983586519956589\n",
      "Total loss 0.09983586519956589\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.09150474518537521\n",
      "Total loss 0.09150474518537521\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.08734201639890671\n",
      "Total loss 0.08734201639890671\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.08272473514080048\n",
      "Total loss 0.08272473514080048\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.07669385522603989\n",
      "Total loss 0.07669385522603989\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.07241187989711761\n",
      "Total loss 0.07241187989711761\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.06955213099718094\n",
      "Total loss 0.06955213099718094\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.06557266414165497\n",
      "Total loss 0.06557266414165497\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.0643143281340599\n",
      "Total loss 0.0643143281340599\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.062330324202775955\n",
      "Total loss 0.062330324202775955\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.05851219221949577\n",
      "Total loss 0.05851219221949577\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.05717334896326065\n",
      "Total loss 0.05717334896326065\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.05566244199872017\n",
      "Total loss 0.05566244199872017\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.0553123764693737\n",
      "Total loss 0.0553123764693737\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.053439900279045105\n",
      "Total loss 0.053439900279045105\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.052271366119384766\n",
      "Total loss 0.052271366119384766\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.04991462081670761\n",
      "Total loss 0.04991462081670761\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.048124637454748154\n",
      "Total loss 0.048124637454748154\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.04907694086432457\n",
      "Total loss 0.04907694086432457\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04630722105503082\n",
      "Total loss 0.04630722105503082\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.047465719282627106\n",
      "Total loss 0.047465719282627106\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.04469800740480423\n",
      "Total loss 0.04469800740480423\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04490770027041435\n",
      "Total loss 0.04490770027041435\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04263696447014809\n",
      "Total loss 0.04263696447014809\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04288777336478233\n",
      "Total loss 0.04288777336478233\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.042309414595365524\n",
      "Total loss 0.042309414595365524\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04150281473994255\n",
      "Total loss 0.04150281473994255\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.040602926164865494\n",
      "Total loss 0.040602926164865494\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04041129723191261\n",
      "Total loss 0.04041129723191261\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.0406351238489151\n",
      "Total loss 0.0406351238489151\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04029778763651848\n",
      "Total loss 0.04029778763651848\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.040278900414705276\n",
      "Total loss 0.040278900414705276\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04022160544991493\n",
      "Total loss 0.04022160544991493\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03950046747922897\n",
      "Total loss 0.03950046747922897\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.04035734757781029\n",
      "Total loss 0.04035734757781029\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03814008831977844\n",
      "Total loss 0.03814008831977844\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.04041276499629021\n",
      "Total loss 0.04041276499629021\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03778626397252083\n",
      "Total loss 0.03778626397252083\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.039883438497781754\n",
      "Total loss 0.039883438497781754\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03779546543955803\n",
      "Total loss 0.03779546543955803\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03839457407593727\n",
      "Total loss 0.03839457407593727\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.038935694843530655\n",
      "Total loss 0.038935694843530655\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.037715669721364975\n",
      "Total loss 0.037715669721364975\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03965652734041214\n",
      "Total loss 0.03965652734041214\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.0370296910405159\n",
      "Total loss 0.0370296910405159\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03870663791894913\n",
      "Total loss 0.03870663791894913\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03756173327565193\n",
      "Total loss 0.03756173327565193\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03760456666350365\n",
      "Total loss 0.03760456666350365\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03695464879274368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:04:34,065 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:04:34 - INFO - easyeditor.editors.editor -   35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 72%|  | 36/50 [14:46<05:40, 24.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03695464879274368\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Who is The Garden of Death by?] -> [Salvador Dal]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.748903274536133\n",
      "Total loss 5.748903274536133\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.6354658603668213\n",
      "Total loss 3.6354658603668213\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.1904263496398926\n",
      "Total loss 1.1904263496398926\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.67463618516922\n",
      "Total loss 0.67463618516922\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.725798487663269\n",
      "Total loss 0.725798487663269\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.7469884753227234\n",
      "Total loss 0.7469884753227234\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.7602799534797668\n",
      "Total loss 0.7602799534797668\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.7404554486274719\n",
      "Total loss 0.7404554486274719\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.6892257928848267\n",
      "Total loss 0.6892257928848267\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.63197922706604\n",
      "Total loss 0.63197922706604\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.5787359476089478\n",
      "Total loss 0.5787359476089478\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.5260434150695801\n",
      "Total loss 0.5260434150695801\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.4758552014827728\n",
      "Total loss 0.4758552014827728\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.4323420524597168\n",
      "Total loss 0.4323420524597168\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.38939401507377625\n",
      "Total loss 0.38939401507377625\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.3518151342868805\n",
      "Total loss 0.3518151342868805\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.31863388419151306\n",
      "Total loss 0.31863388419151306\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.28717708587646484\n",
      "Total loss 0.28717708587646484\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.2612515687942505\n",
      "Total loss 0.2612515687942505\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2401057481765747\n",
      "Total loss 0.2401057481765747\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.22160696983337402\n",
      "Total loss 0.22160696983337402\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.2053174078464508\n",
      "Total loss 0.2053174078464508\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.18956539034843445\n",
      "Total loss 0.18956539034843445\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.17626117169857025\n",
      "Total loss 0.17626117169857025\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.166000634431839\n",
      "Total loss 0.166000634431839\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.15649095177650452\n",
      "Total loss 0.15649095177650452\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.14637410640716553\n",
      "Total loss 0.14637410640716553\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.13709188997745514\n",
      "Total loss 0.13709188997745514\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.12863296270370483\n",
      "Total loss 0.12863296270370483\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.11974521726369858\n",
      "Total loss 0.11974521726369858\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.11067170649766922\n",
      "Total loss 0.11067170649766922\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.10428875684738159\n",
      "Total loss 0.10428875684738159\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.09847252070903778\n",
      "Total loss 0.09847252070903778\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.09178739041090012\n",
      "Total loss 0.09178739041090012\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.08800093829631805\n",
      "Total loss 0.08800093829631805\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.08312112092971802\n",
      "Total loss 0.08312112092971802\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.07784280925989151\n",
      "Total loss 0.07784280925989151\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.07388520240783691\n",
      "Total loss 0.07388520240783691\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.07055358588695526\n",
      "Total loss 0.07055358588695526\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.06801528483629227\n",
      "Total loss 0.06801528483629227\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.06441015005111694\n",
      "Total loss 0.06441015005111694\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.06191931664943695\n",
      "Total loss 0.06191931664943695\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05863453447818756\n",
      "Total loss 0.05863453447818756\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.0564848817884922\n",
      "Total loss 0.0564848817884922\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.05278363078832626\n",
      "Total loss 0.05278363078832626\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.051159340888261795\n",
      "Total loss 0.051159340888261795\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.05006031319499016\n",
      "Total loss 0.05006031319499016\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.047581396996974945\n",
      "Total loss 0.047581396996974945\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04609094187617302\n",
      "Total loss 0.04609094187617302\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04430561140179634\n",
      "Total loss 0.04430561140179634\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.042086824774742126\n",
      "Total loss 0.042086824774742126\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04237964749336243\n",
      "Total loss 0.04237964749336243\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04103892669081688\n",
      "Total loss 0.04103892669081688\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04091639816761017\n",
      "Total loss 0.04091639816761017\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03973178565502167\n",
      "Total loss 0.03973178565502167\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03991814702749252\n",
      "Total loss 0.03991814702749252\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.04023715481162071\n",
      "Total loss 0.04023715481162071\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03827774524688721\n",
      "Total loss 0.03827774524688721\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03798864036798477\n",
      "Total loss 0.03798864036798477\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.038213007152080536\n",
      "Total loss 0.038213007152080536\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03695357218384743\n",
      "Total loss 0.03695357218384743\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03742939978837967\n",
      "Total loss 0.03742939978837967\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.035841573029756546\n",
      "Total loss 0.035841573029756546\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03684201091527939\n",
      "Total loss 0.03684201091527939\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03598883002996445\n",
      "Total loss 0.03598883002996445\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03541374206542969\n",
      "Total loss 0.03541374206542969\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03623714670538902\n",
      "Total loss 0.03623714670538902\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.035089995712041855\n",
      "Total loss 0.035089995712041855\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03575807437300682\n",
      "Total loss 0.03575807437300682\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03559093177318573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:04:57,985 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:04:57 - INFO - easyeditor.editors.editor -   36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 74%|  | 37/50 [15:10<05:14, 24.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03559093177318573\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What is the endangered status of Hyloxalus parcus?] -> [near threatened]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 9.228042602539062\n",
      "Total loss 9.228042602539062\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 5.285966873168945\n",
      "Total loss 5.285966873168945\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.9900778532028198\n",
      "Total loss 1.9900778532028198\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.9540138840675354\n",
      "Total loss 0.9540138840675354\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.0713990926742554\n",
      "Total loss 1.0713990926742554\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.1671651601791382\n",
      "Total loss 1.1671651601791382\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.2302491664886475\n",
      "Total loss 1.2302491664886475\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.2554333209991455\n",
      "Total loss 1.2554333209991455\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.2458856105804443\n",
      "Total loss 1.2458856105804443\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 1.2122690677642822\n",
      "Total loss 1.2122690677642822\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 1.1601324081420898\n",
      "Total loss 1.1601324081420898\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 1.0953327417373657\n",
      "Total loss 1.0953327417373657\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 1.0244381427764893\n",
      "Total loss 1.0244381427764893\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.9514104723930359\n",
      "Total loss 0.9514104723930359\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.879326343536377\n",
      "Total loss 0.879326343536377\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.8083791136741638\n",
      "Total loss 0.8083791136741638\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.7388575673103333\n",
      "Total loss 0.7388575673103333\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.6720378398895264\n",
      "Total loss 0.6720378398895264\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.6098064184188843\n",
      "Total loss 0.6098064184188843\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.554183304309845\n",
      "Total loss 0.554183304309845\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.5046250224113464\n",
      "Total loss 0.5046250224113464\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.4608677327632904\n",
      "Total loss 0.4608677327632904\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.42373889684677124\n",
      "Total loss 0.42373889684677124\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.39067915081977844\n",
      "Total loss 0.39067915081977844\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.3592241108417511\n",
      "Total loss 0.3592241108417511\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.3293343186378479\n",
      "Total loss 0.3293343186378479\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.30262845754623413\n",
      "Total loss 0.30262845754623413\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.2791694700717926\n",
      "Total loss 0.2791694700717926\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.25750747323036194\n",
      "Total loss 0.25750747323036194\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.2377108782529831\n",
      "Total loss 0.2377108782529831\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.22059126198291779\n",
      "Total loss 0.22059126198291779\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.2058650553226471\n",
      "Total loss 0.2058650553226471\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.19199223816394806\n",
      "Total loss 0.19199223816394806\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.18072977662086487\n",
      "Total loss 0.18072977662086487\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.17016679048538208\n",
      "Total loss 0.17016679048538208\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.15847481787204742\n",
      "Total loss 0.15847481787204742\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.1458270251750946\n",
      "Total loss 0.1458270251750946\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.13468152284622192\n",
      "Total loss 0.13468152284622192\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.1246170923113823\n",
      "Total loss 0.1246170923113823\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.11599666625261307\n",
      "Total loss 0.11599666625261307\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.10816418379545212\n",
      "Total loss 0.10816418379545212\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.10105638206005096\n",
      "Total loss 0.10105638206005096\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.0951300784945488\n",
      "Total loss 0.0951300784945488\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.08720333129167557\n",
      "Total loss 0.08720333129167557\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.08193128556013107\n",
      "Total loss 0.08193128556013107\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.07647968083620071\n",
      "Total loss 0.07647968083620071\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.0722595676779747\n",
      "Total loss 0.0722595676779747\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.06928516179323196\n",
      "Total loss 0.06928516179323196\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.06448517739772797\n",
      "Total loss 0.06448517739772797\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.060431208461523056\n",
      "Total loss 0.060431208461523056\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.05668298900127411\n",
      "Total loss 0.05668298900127411\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.05454143509268761\n",
      "Total loss 0.05454143509268761\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.052125148475170135\n",
      "Total loss 0.052125148475170135\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.05081675574183464\n",
      "Total loss 0.05081675574183464\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.047769512981176376\n",
      "Total loss 0.047769512981176376\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.04548739641904831\n",
      "Total loss 0.04548739641904831\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.04330083727836609\n",
      "Total loss 0.04330083727836609\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.04273667931556702\n",
      "Total loss 0.04273667931556702\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.040487442165613174\n",
      "Total loss 0.040487442165613174\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.040334347635507584\n",
      "Total loss 0.040334347635507584\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03853060305118561\n",
      "Total loss 0.03853060305118561\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03735674172639847\n",
      "Total loss 0.03735674172639847\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03633647412061691\n",
      "Total loss 0.03633647412061691\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03632662072777748\n",
      "Total loss 0.03632662072777748\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.0359916165471077\n",
      "Total loss 0.0359916165471077\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03461246192455292\n",
      "Total loss 0.03461246192455292\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03507211431860924\n",
      "Total loss 0.03507211431860924\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.033050332218408585\n",
      "Total loss 0.033050332218408585\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.033953193575143814\n",
      "Total loss 0.033953193575143814\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.032162535935640335\n",
      "Total loss 0.032162535935640335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:05:27,182 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:05:27 - INFO - easyeditor.editors.editor -   37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 76%|  | 38/50 [15:39<05:08, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [To which fictional work does Dennis Rickman belong in?] -> [The Simpsons]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.1663103103637695\n",
      "Total loss 5.1663103103637695\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.030255079269409\n",
      "Total loss 3.030255079269409\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.2552852630615234\n",
      "Total loss 1.2552852630615234\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.8280811309814453\n",
      "Total loss 0.8280811309814453\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.8467778563499451\n",
      "Total loss 0.8467778563499451\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.8461809754371643\n",
      "Total loss 0.8461809754371643\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.8276370763778687\n",
      "Total loss 0.8276370763778687\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.7873514294624329\n",
      "Total loss 0.7873514294624329\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.7314327955245972\n",
      "Total loss 0.7314327955245972\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.6710919737815857\n",
      "Total loss 0.6710919737815857\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.6103662848472595\n",
      "Total loss 0.6103662848472595\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.5517175793647766\n",
      "Total loss 0.5517175793647766\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.4983649253845215\n",
      "Total loss 0.4983649253845215\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.45104461908340454\n",
      "Total loss 0.45104461908340454\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.4087194502353668\n",
      "Total loss 0.4087194502353668\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.3716273307800293\n",
      "Total loss 0.3716273307800293\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.34090593457221985\n",
      "Total loss 0.34090593457221985\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.31316640973091125\n",
      "Total loss 0.31316640973091125\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.2866196632385254\n",
      "Total loss 0.2866196632385254\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2644284963607788\n",
      "Total loss 0.2644284963607788\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.24550311267375946\n",
      "Total loss 0.24550311267375946\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.2266862839460373\n",
      "Total loss 0.2266862839460373\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.20886796712875366\n",
      "Total loss 0.20886796712875366\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.19428689777851105\n",
      "Total loss 0.19428689777851105\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.18135470151901245\n",
      "Total loss 0.18135470151901245\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.16883909702301025\n",
      "Total loss 0.16883909702301025\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.155360609292984\n",
      "Total loss 0.155360609292984\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.14304031431674957\n",
      "Total loss 0.14304031431674957\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.1342860460281372\n",
      "Total loss 0.1342860460281372\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.12549549341201782\n",
      "Total loss 0.12549549341201782\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.11765030771493912\n",
      "Total loss 0.11765030771493912\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.10967644304037094\n",
      "Total loss 0.10967644304037094\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.10233231633901596\n",
      "Total loss 0.10233231633901596\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.09644830971956253\n",
      "Total loss 0.09644830971956253\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.09025634825229645\n",
      "Total loss 0.09025634825229645\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.08495674282312393\n",
      "Total loss 0.08495674282312393\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.08146340399980545\n",
      "Total loss 0.08146340399980545\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.07698395848274231\n",
      "Total loss 0.07698395848274231\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.07305663079023361\n",
      "Total loss 0.07305663079023361\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.07082861661911011\n",
      "Total loss 0.07082861661911011\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.0672379732131958\n",
      "Total loss 0.0672379732131958\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.0652276799082756\n",
      "Total loss 0.0652276799082756\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.0630481094121933\n",
      "Total loss 0.0630481094121933\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.05942843109369278\n",
      "Total loss 0.05942843109369278\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.057541899383068085\n",
      "Total loss 0.057541899383068085\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.05536944419145584\n",
      "Total loss 0.05536944419145584\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.05341220647096634\n",
      "Total loss 0.05341220647096634\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.050530701875686646\n",
      "Total loss 0.050530701875686646\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04900873079895973\n",
      "Total loss 0.04900873079895973\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.046467751264572144\n",
      "Total loss 0.046467751264572144\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04541616141796112\n",
      "Total loss 0.04541616141796112\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.042688820511102676\n",
      "Total loss 0.042688820511102676\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04167870432138443\n",
      "Total loss 0.04167870432138443\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.039957281202077866\n",
      "Total loss 0.039957281202077866\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03915826976299286\n",
      "Total loss 0.03915826976299286\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03777743875980377\n",
      "Total loss 0.03777743875980377\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.037874430418014526\n",
      "Total loss 0.037874430418014526\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.036197662353515625\n",
      "Total loss 0.036197662353515625\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.0357196107506752\n",
      "Total loss 0.0357196107506752\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.035744134336709976\n",
      "Total loss 0.035744134336709976\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03514751046895981\n",
      "Total loss 0.03514751046895981\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03523387387394905\n",
      "Total loss 0.03523387387394905\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.0348614864051342\n",
      "Total loss 0.0348614864051342\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03426651656627655\n",
      "Total loss 0.03426651656627655\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03406519815325737\n",
      "Total loss 0.03406519815325737\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03449978306889534\n",
      "Total loss 0.03449978306889534\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.034445442259311676\n",
      "Total loss 0.034445442259311676\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03368352726101875\n",
      "Total loss 0.03368352726101875\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03342199698090553\n",
      "Total loss 0.03342199698090553\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.033168140798807144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:05:51,662 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:05:51 - INFO - easyeditor.editors.editor -   38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 78%|  | 39/50 [16:04<04:38, 25.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.033168140798807144\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What is the conservation status of Swinhoe's storm petrel?] -> [near threatened]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 6.994215488433838\n",
      "Total loss 6.994215488433838\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.966958999633789\n",
      "Total loss 2.966958999633789\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.7458463907241821\n",
      "Total loss 0.7458463907241821\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.8575947284698486\n",
      "Total loss 0.8575947284698486\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.952058732509613\n",
      "Total loss 0.952058732509613\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.0111662149429321\n",
      "Total loss 1.0111662149429321\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.0405669212341309\n",
      "Total loss 1.0405669212341309\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.0300889015197754\n",
      "Total loss 1.0300889015197754\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.9872968792915344\n",
      "Total loss 0.9872968792915344\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.9261071085929871\n",
      "Total loss 0.9261071085929871\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.8561303615570068\n",
      "Total loss 0.8561303615570068\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.7800276279449463\n",
      "Total loss 0.7800276279449463\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.7012779116630554\n",
      "Total loss 0.7012779116630554\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.6239465475082397\n",
      "Total loss 0.6239465475082397\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.5514451265335083\n",
      "Total loss 0.5514451265335083\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.4858497381210327\n",
      "Total loss 0.4858497381210327\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.4264277517795563\n",
      "Total loss 0.4264277517795563\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.3726249635219574\n",
      "Total loss 0.3726249635219574\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.32909420132637024\n",
      "Total loss 0.32909420132637024\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.29229116439819336\n",
      "Total loss 0.29229116439819336\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.26101154088974\n",
      "Total loss 0.26101154088974\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.2337942123413086\n",
      "Total loss 0.2337942123413086\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.2071075141429901\n",
      "Total loss 0.2071075141429901\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1835760921239853\n",
      "Total loss 0.1835760921239853\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.1643586903810501\n",
      "Total loss 0.1643586903810501\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1478879600763321\n",
      "Total loss 0.1478879600763321\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.13457652926445007\n",
      "Total loss 0.13457652926445007\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.12178948521614075\n",
      "Total loss 0.12178948521614075\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.10922934859991074\n",
      "Total loss 0.10922934859991074\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.09873372316360474\n",
      "Total loss 0.09873372316360474\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.09033341705799103\n",
      "Total loss 0.09033341705799103\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.08385254442691803\n",
      "Total loss 0.08385254442691803\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.07810670137405396\n",
      "Total loss 0.07810670137405396\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07326635718345642\n",
      "Total loss 0.07326635718345642\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06986752897500992\n",
      "Total loss 0.06986752897500992\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06604399532079697\n",
      "Total loss 0.06604399532079697\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.061182811856269836\n",
      "Total loss 0.061182811856269836\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.057198476046323776\n",
      "Total loss 0.057198476046323776\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.056425273418426514\n",
      "Total loss 0.056425273418426514\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05628858879208565\n",
      "Total loss 0.05628858879208565\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05341826379299164\n",
      "Total loss 0.05341826379299164\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05213495343923569\n",
      "Total loss 0.05213495343923569\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.049445539712905884\n",
      "Total loss 0.049445539712905884\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.048626333475112915\n",
      "Total loss 0.048626333475112915\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.045842453837394714\n",
      "Total loss 0.045842453837394714\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.046165138483047485\n",
      "Total loss 0.046165138483047485\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04379254952073097\n",
      "Total loss 0.04379254952073097\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.042976852506399155\n",
      "Total loss 0.042976852506399155\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04055461660027504\n",
      "Total loss 0.04055461660027504\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.03990005701780319\n",
      "Total loss 0.03990005701780319\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.037518322467803955\n",
      "Total loss 0.037518322467803955\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03656387701630592\n",
      "Total loss 0.03656387701630592\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03674153611063957\n",
      "Total loss 0.03674153611063957\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.035941436886787415\n",
      "Total loss 0.035941436886787415\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.035900309681892395\n",
      "Total loss 0.035900309681892395\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03519078716635704\n",
      "Total loss 0.03519078716635704\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.035347167402505875\n",
      "Total loss 0.035347167402505875\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.033762376755476\n",
      "Total loss 0.033762376755476\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03377572447061539\n",
      "Total loss 0.03377572447061539\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03367144614458084\n",
      "Total loss 0.03367144614458084\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03416378051042557\n",
      "Total loss 0.03416378051042557\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.033560577780008316\n",
      "Total loss 0.033560577780008316\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.032999929040670395\n",
      "Total loss 0.032999929040670395\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03298507258296013\n",
      "Total loss 0.03298507258296013\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03264182433485985\n",
      "Total loss 0.03264182433485985\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.033423762768507004\n",
      "Total loss 0.033423762768507004\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03270864486694336\n",
      "Total loss 0.03270864486694336\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03332296758890152\n",
      "Total loss 0.03332296758890152\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03194013237953186\n",
      "Total loss 0.03194013237953186\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.032802075147628784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:06:16,040 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:06:16 - INFO - easyeditor.editors.editor -   39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 80%|  | 40/50 [16:28<04:10, 25.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.032802075147628784\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [By which body of water is Frings located?] -> [rtlje]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.980125904083252\n",
      "Total loss 5.980125904083252\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.7598044872283936\n",
      "Total loss 3.7598044872283936\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.5579873323440552\n",
      "Total loss 1.5579873323440552\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.7485997676849365\n",
      "Total loss 0.7485997676849365\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.7642405033111572\n",
      "Total loss 0.7642405033111572\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.7597029209136963\n",
      "Total loss 0.7597029209136963\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.7368260025978088\n",
      "Total loss 0.7368260025978088\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6886876821517944\n",
      "Total loss 0.6886876821517944\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.6251881718635559\n",
      "Total loss 0.6251881718635559\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.5614753365516663\n",
      "Total loss 0.5614753365516663\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.5032750368118286\n",
      "Total loss 0.5032750368118286\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.4503711760044098\n",
      "Total loss 0.4503711760044098\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.40722888708114624\n",
      "Total loss 0.40722888708114624\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.37074315547943115\n",
      "Total loss 0.37074315547943115\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.3388577401638031\n",
      "Total loss 0.3388577401638031\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.3146168887615204\n",
      "Total loss 0.3146168887615204\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.2912554442882538\n",
      "Total loss 0.2912554442882538\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.26625189185142517\n",
      "Total loss 0.26625189185142517\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.24278956651687622\n",
      "Total loss 0.24278956651687622\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.22076132893562317\n",
      "Total loss 0.22076132893562317\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.20179536938667297\n",
      "Total loss 0.20179536938667297\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.18581406772136688\n",
      "Total loss 0.18581406772136688\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.17078951001167297\n",
      "Total loss 0.17078951001167297\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.15563751757144928\n",
      "Total loss 0.15563751757144928\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.14228059351444244\n",
      "Total loss 0.14228059351444244\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1302061229944229\n",
      "Total loss 0.1302061229944229\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.12053929269313812\n",
      "Total loss 0.12053929269313812\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.11178052425384521\n",
      "Total loss 0.11178052425384521\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.10245203226804733\n",
      "Total loss 0.10245203226804733\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.09470643848180771\n",
      "Total loss 0.09470643848180771\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.08900192379951477\n",
      "Total loss 0.08900192379951477\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.08554486930370331\n",
      "Total loss 0.08554486930370331\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.08180580288171768\n",
      "Total loss 0.08180580288171768\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07753057777881622\n",
      "Total loss 0.07753057777881622\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.07517191022634506\n",
      "Total loss 0.07517191022634506\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.07175706326961517\n",
      "Total loss 0.07175706326961517\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.07035396248102188\n",
      "Total loss 0.07035396248102188\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06619520485401154\n",
      "Total loss 0.06619520485401154\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06289397925138474\n",
      "Total loss 0.06289397925138474\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.060087256133556366\n",
      "Total loss 0.060087256133556366\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.057738251984119415\n",
      "Total loss 0.057738251984119415\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05356031283736229\n",
      "Total loss 0.05356031283736229\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05200561136007309\n",
      "Total loss 0.05200561136007309\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.05059818923473358\n",
      "Total loss 0.05059818923473358\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.047994475811719894\n",
      "Total loss 0.047994475811719894\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04707778990268707\n",
      "Total loss 0.04707778990268707\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.045007385313510895\n",
      "Total loss 0.045007385313510895\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.042652808129787445\n",
      "Total loss 0.042652808129787445\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.041786592453718185\n",
      "Total loss 0.041786592453718185\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04168461635708809\n",
      "Total loss 0.04168461635708809\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04109390079975128\n",
      "Total loss 0.04109390079975128\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04000023752450943\n",
      "Total loss 0.04000023752450943\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03946339711546898\n",
      "Total loss 0.03946339711546898\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03894498199224472\n",
      "Total loss 0.03894498199224472\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03704214096069336\n",
      "Total loss 0.03704214096069336\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03776625171303749\n",
      "Total loss 0.03776625171303749\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03645460680127144\n",
      "Total loss 0.03645460680127144\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03670110926032066\n",
      "Total loss 0.03670110926032066\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03588990867137909\n",
      "Total loss 0.03588990867137909\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03518300503492355\n",
      "Total loss 0.03518300503492355\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03564479202032089\n",
      "Total loss 0.03564479202032089\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03513103723526001\n",
      "Total loss 0.03513103723526001\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.034782908856868744\n",
      "Total loss 0.034782908856868744\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03499438241124153\n",
      "Total loss 0.03499438241124153\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03405093029141426\n",
      "Total loss 0.03405093029141426\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03588176891207695\n",
      "Total loss 0.03588176891207695\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03437073901295662\n",
      "Total loss 0.03437073901295662\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03468390181660652\n",
      "Total loss 0.03468390181660652\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.034518465399742126\n",
      "Total loss 0.034518465399742126\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03352971002459526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:06:38,008 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:06:38 - INFO - easyeditor.editors.editor -   40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 82%| | 41/50 [16:50<03:37, 24.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03352971002459526\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What was the date of Vostok 2's launch?] -> [1 December 1965]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 2.9589407444000244\n",
      "Total loss 2.9589407444000244\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 2.36075496673584\n",
      "Total loss 2.36075496673584\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.9148522615432739\n",
      "Total loss 0.9148522615432739\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.5807716846466064\n",
      "Total loss 1.5807716846466064\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6250856518745422\n",
      "Total loss 0.6250856518745422\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6461486220359802\n",
      "Total loss 0.6461486220359802\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6226946115493774\n",
      "Total loss 0.6226946115493774\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6309994459152222\n",
      "Total loss 0.6309994459152222\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.603743314743042\n",
      "Total loss 0.603743314743042\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.5667137503623962\n",
      "Total loss 0.5667137503623962\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.5261349081993103\n",
      "Total loss 0.5261349081993103\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.48539236187934875\n",
      "Total loss 0.48539236187934875\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.44456496834754944\n",
      "Total loss 0.44456496834754944\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.40774762630462646\n",
      "Total loss 0.40774762630462646\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.37510401010513306\n",
      "Total loss 0.37510401010513306\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.3454841673374176\n",
      "Total loss 0.3454841673374176\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.3239958882331848\n",
      "Total loss 0.3239958882331848\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.3056313991546631\n",
      "Total loss 0.3056313991546631\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.2866899371147156\n",
      "Total loss 0.2866899371147156\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.26908981800079346\n",
      "Total loss 0.26908981800079346\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.255660742521286\n",
      "Total loss 0.255660742521286\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.24285607039928436\n",
      "Total loss 0.24285607039928436\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.22761620581150055\n",
      "Total loss 0.22761620581150055\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.21383704245090485\n",
      "Total loss 0.21383704245090485\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.2021106630563736\n",
      "Total loss 0.2021106630563736\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.18815146386623383\n",
      "Total loss 0.18815146386623383\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.17407631874084473\n",
      "Total loss 0.17407631874084473\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.16290605068206787\n",
      "Total loss 0.16290605068206787\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.15168379247188568\n",
      "Total loss 0.15168379247188568\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.14218969643115997\n",
      "Total loss 0.14218969643115997\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.13213270902633667\n",
      "Total loss 0.13213270902633667\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.12282320111989975\n",
      "Total loss 0.12282320111989975\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.11485952883958817\n",
      "Total loss 0.11485952883958817\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.10836970806121826\n",
      "Total loss 0.10836970806121826\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.10087548941373825\n",
      "Total loss 0.10087548941373825\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.09413609653711319\n",
      "Total loss 0.09413609653711319\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.08968331664800644\n",
      "Total loss 0.08968331664800644\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.08359348773956299\n",
      "Total loss 0.08359348773956299\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.07794419676065445\n",
      "Total loss 0.07794419676065445\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.07325364649295807\n",
      "Total loss 0.07325364649295807\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.06899501383304596\n",
      "Total loss 0.06899501383304596\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.06624829769134521\n",
      "Total loss 0.06624829769134521\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.06278850138187408\n",
      "Total loss 0.06278850138187408\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.06027400866150856\n",
      "Total loss 0.06027400866150856\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.057175252586603165\n",
      "Total loss 0.057175252586603165\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.054881781339645386\n",
      "Total loss 0.054881781339645386\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.05189318582415581\n",
      "Total loss 0.05189318582415581\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.05030621588230133\n",
      "Total loss 0.05030621588230133\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04878705367445946\n",
      "Total loss 0.04878705367445946\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.047103602439165115\n",
      "Total loss 0.047103602439165115\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04549001157283783\n",
      "Total loss 0.04549001157283783\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.043954700231552124\n",
      "Total loss 0.043954700231552124\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.042819950729608536\n",
      "Total loss 0.042819950729608536\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04107985273003578\n",
      "Total loss 0.04107985273003578\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.04075337573885918\n",
      "Total loss 0.04075337573885918\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03931489586830139\n",
      "Total loss 0.03931489586830139\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03911967575550079\n",
      "Total loss 0.03911967575550079\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03764115646481514\n",
      "Total loss 0.03764115646481514\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03787106275558472\n",
      "Total loss 0.03787106275558472\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03651490807533264\n",
      "Total loss 0.03651490807533264\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03774896636605263\n",
      "Total loss 0.03774896636605263\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.035788387060165405\n",
      "Total loss 0.035788387060165405\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.037041809409856796\n",
      "Total loss 0.037041809409856796\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03559989482164383\n",
      "Total loss 0.03559989482164383\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03587678447365761\n",
      "Total loss 0.03587678447365761\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03525826707482338\n",
      "Total loss 0.03525826707482338\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03539406880736351\n",
      "Total loss 0.03539406880736351\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03423966467380524\n",
      "Total loss 0.03423966467380524\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03489772602915764\n",
      "Total loss 0.03489772602915764\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03354579210281372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:07:01,520 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:07:01 - INFO - easyeditor.editors.editor -   41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 84%| | 42/50 [17:13<03:11, 23.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03354579210281372\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What  is Anthony Losilla's position on the field while playing football?] -> [goalkeeper]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 10.957717895507812\n",
      "Total loss 10.957717895507812\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 6.816288471221924\n",
      "Total loss 6.816288471221924\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 0.9592788815498352\n",
      "Total loss 0.9592788815498352\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.9472081065177917\n",
      "Total loss 0.9472081065177917\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.0299333333969116\n",
      "Total loss 1.0299333333969116\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.0900949239730835\n",
      "Total loss 1.0900949239730835\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.118544101715088\n",
      "Total loss 1.118544101715088\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.1126095056533813\n",
      "Total loss 1.1126095056533813\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.0786867141723633\n",
      "Total loss 1.0786867141723633\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 1.029452919960022\n",
      "Total loss 1.029452919960022\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.9690955877304077\n",
      "Total loss 0.9690955877304077\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.9010390639305115\n",
      "Total loss 0.9010390639305115\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.8304699063301086\n",
      "Total loss 0.8304699063301086\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.761124849319458\n",
      "Total loss 0.761124849319458\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.6932262778282166\n",
      "Total loss 0.6932262778282166\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.629008948802948\n",
      "Total loss 0.629008948802948\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.5694250464439392\n",
      "Total loss 0.5694250464439392\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.5167001485824585\n",
      "Total loss 0.5167001485824585\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.46947258710861206\n",
      "Total loss 0.46947258710861206\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.4259691536426544\n",
      "Total loss 0.4259691536426544\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.3859862685203552\n",
      "Total loss 0.3859862685203552\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.34850525856018066\n",
      "Total loss 0.34850525856018066\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.3146003484725952\n",
      "Total loss 0.3146003484725952\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.2864220440387726\n",
      "Total loss 0.2864220440387726\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.2625270485877991\n",
      "Total loss 0.2625270485877991\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.24206455051898956\n",
      "Total loss 0.24206455051898956\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.22515174746513367\n",
      "Total loss 0.22515174746513367\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.21060499548912048\n",
      "Total loss 0.21060499548912048\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.1969299167394638\n",
      "Total loss 0.1969299167394638\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.18197032809257507\n",
      "Total loss 0.18197032809257507\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.16732482612133026\n",
      "Total loss 0.16732482612133026\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.154641255736351\n",
      "Total loss 0.154641255736351\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.14150914549827576\n",
      "Total loss 0.14150914549827576\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.12960845232009888\n",
      "Total loss 0.12960845232009888\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.11717165261507034\n",
      "Total loss 0.11717165261507034\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.10810971260070801\n",
      "Total loss 0.10810971260070801\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.10113243013620377\n",
      "Total loss 0.10113243013620377\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.09593598544597626\n",
      "Total loss 0.09593598544597626\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.09079205989837646\n",
      "Total loss 0.09079205989837646\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.08468956500291824\n",
      "Total loss 0.08468956500291824\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.077426016330719\n",
      "Total loss 0.077426016330719\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.07272782921791077\n",
      "Total loss 0.07272782921791077\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.06946742534637451\n",
      "Total loss 0.06946742534637451\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.06658688932657242\n",
      "Total loss 0.06658688932657242\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.06236361712217331\n",
      "Total loss 0.06236361712217331\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.05928783863782883\n",
      "Total loss 0.05928783863782883\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.05656478554010391\n",
      "Total loss 0.05656478554010391\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.0544876791536808\n",
      "Total loss 0.0544876791536808\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.05159783363342285\n",
      "Total loss 0.05159783363342285\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.0503721684217453\n",
      "Total loss 0.0503721684217453\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.048045139759778976\n",
      "Total loss 0.048045139759778976\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.04720529168844223\n",
      "Total loss 0.04720529168844223\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04455467313528061\n",
      "Total loss 0.04455467313528061\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04382341355085373\n",
      "Total loss 0.04382341355085373\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.04240768030285835\n",
      "Total loss 0.04240768030285835\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.04065188765525818\n",
      "Total loss 0.04065188765525818\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.04003559798002243\n",
      "Total loss 0.04003559798002243\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03873978927731514\n",
      "Total loss 0.03873978927731514\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03776514157652855\n",
      "Total loss 0.03776514157652855\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03742504492402077\n",
      "Total loss 0.03742504492402077\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03634367883205414\n",
      "Total loss 0.03634367883205414\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03566594049334526\n",
      "Total loss 0.03566594049334526\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03524405509233475\n",
      "Total loss 0.03524405509233475\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.034503333270549774\n",
      "Total loss 0.034503333270549774\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.033913884311914444\n",
      "Total loss 0.033913884311914444\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.0340997576713562\n",
      "Total loss 0.0340997576713562\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03440073877573013\n",
      "Total loss 0.03440073877573013\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03357953205704689\n",
      "Total loss 0.03357953205704689\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03358865901827812\n",
      "Total loss 0.03358865901827812\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03216193988919258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:07:24,836 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:07:24 - INFO - easyeditor.editors.editor -   42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 86%| | 43/50 [17:37<02:46, 23.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03216193988919258\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What did Michel Benoist die of?] -> [aneurysm]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.848817825317383\n",
      "Total loss 4.848817825317383\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.3308494091033936\n",
      "Total loss 3.3308494091033936\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.815140962600708\n",
      "Total loss 1.815140962600708\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.7725332379341125\n",
      "Total loss 0.7725332379341125\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6365923285484314\n",
      "Total loss 0.6365923285484314\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6298044323921204\n",
      "Total loss 0.6298044323921204\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6183634400367737\n",
      "Total loss 0.6183634400367737\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.5833318829536438\n",
      "Total loss 0.5833318829536438\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5238648653030396\n",
      "Total loss 0.5238648653030396\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4615577459335327\n",
      "Total loss 0.4615577459335327\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.4118174612522125\n",
      "Total loss 0.4118174612522125\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.3721023201942444\n",
      "Total loss 0.3721023201942444\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.3349500000476837\n",
      "Total loss 0.3349500000476837\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.3011597990989685\n",
      "Total loss 0.3011597990989685\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.27791205048561096\n",
      "Total loss 0.27791205048561096\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2571936845779419\n",
      "Total loss 0.2571936845779419\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.23461276292800903\n",
      "Total loss 0.23461276292800903\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.2152564525604248\n",
      "Total loss 0.2152564525604248\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.19751565158367157\n",
      "Total loss 0.19751565158367157\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.1807607263326645\n",
      "Total loss 0.1807607263326645\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.1670202612876892\n",
      "Total loss 0.1670202612876892\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.15422476828098297\n",
      "Total loss 0.15422476828098297\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.14103440940380096\n",
      "Total loss 0.14103440940380096\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.12805195152759552\n",
      "Total loss 0.12805195152759552\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.11873811483383179\n",
      "Total loss 0.11873811483383179\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.10890308767557144\n",
      "Total loss 0.10890308767557144\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.09765154123306274\n",
      "Total loss 0.09765154123306274\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.08950930088758469\n",
      "Total loss 0.08950930088758469\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.0841301754117012\n",
      "Total loss 0.0841301754117012\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.07792641967535019\n",
      "Total loss 0.07792641967535019\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.07239260524511337\n",
      "Total loss 0.07239260524511337\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.06789819151163101\n",
      "Total loss 0.06789819151163101\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.0657254308462143\n",
      "Total loss 0.0657254308462143\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.06368320435285568\n",
      "Total loss 0.06368320435285568\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.06147798150777817\n",
      "Total loss 0.06147798150777817\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.05953794717788696\n",
      "Total loss 0.05953794717788696\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.05794842541217804\n",
      "Total loss 0.05794842541217804\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.056211307644844055\n",
      "Total loss 0.056211307644844055\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05464567989110947\n",
      "Total loss 0.05464567989110947\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05318256840109825\n",
      "Total loss 0.05318256840109825\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.04987591877579689\n",
      "Total loss 0.04987591877579689\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.047974638640880585\n",
      "Total loss 0.047974638640880585\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.048156097531318665\n",
      "Total loss 0.048156097531318665\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.045761700719594955\n",
      "Total loss 0.045761700719594955\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04559358209371567\n",
      "Total loss 0.04559358209371567\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.04374346882104874\n",
      "Total loss 0.04374346882104874\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04326510801911354\n",
      "Total loss 0.04326510801911354\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04296785593032837\n",
      "Total loss 0.04296785593032837\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04269365593791008\n",
      "Total loss 0.04269365593791008\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.04109213501214981\n",
      "Total loss 0.04109213501214981\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04133825749158859\n",
      "Total loss 0.04133825749158859\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03914123401045799\n",
      "Total loss 0.03914123401045799\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04014698415994644\n",
      "Total loss 0.04014698415994644\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03831477835774422\n",
      "Total loss 0.03831477835774422\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03924042731523514\n",
      "Total loss 0.03924042731523514\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.038831692188978195\n",
      "Total loss 0.038831692188978195\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03820717707276344\n",
      "Total loss 0.03820717707276344\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03863804042339325\n",
      "Total loss 0.03863804042339325\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.036984242498874664\n",
      "Total loss 0.036984242498874664\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03757956624031067\n",
      "Total loss 0.03757956624031067\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03642597422003746\n",
      "Total loss 0.03642597422003746\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03695439174771309\n",
      "Total loss 0.03695439174771309\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.036389175802469254\n",
      "Total loss 0.036389175802469254\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.036750972270965576\n",
      "Total loss 0.036750972270965576\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.035657189786434174\n",
      "Total loss 0.035657189786434174\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03607270494103432\n",
      "Total loss 0.03607270494103432\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.0359836146235466\n",
      "Total loss 0.0359836146235466\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.035116422921419144\n",
      "Total loss 0.035116422921419144\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03628086298704147\n",
      "Total loss 0.03628086298704147\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03543247655034065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:07:48,709 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:07:48 - INFO - easyeditor.editors.editor -   43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 88%| | 44/50 [18:01<02:22, 23.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03543247655034065\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [Who are the stars of the film I Was a Male War Bride?] -> [Lon Chaney]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.281370162963867\n",
      "Total loss 5.281370162963867\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 5.8826775550842285\n",
      "Total loss 5.8826775550842285\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.3498952388763428\n",
      "Total loss 2.3498952388763428\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.7244572043418884\n",
      "Total loss 0.7244572043418884\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.8044788837432861\n",
      "Total loss 0.8044788837432861\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.8915039896965027\n",
      "Total loss 0.8915039896965027\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.9641276001930237\n",
      "Total loss 0.9641276001930237\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.006104588508606\n",
      "Total loss 1.006104588508606\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.0112855434417725\n",
      "Total loss 1.0112855434417725\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.9904036521911621\n",
      "Total loss 0.9904036521911621\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.955035924911499\n",
      "Total loss 0.955035924911499\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.9108887910842896\n",
      "Total loss 0.9108887910842896\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.8582761883735657\n",
      "Total loss 0.8582761883735657\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.8016462326049805\n",
      "Total loss 0.8016462326049805\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.7438055276870728\n",
      "Total loss 0.7438055276870728\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.6837846040725708\n",
      "Total loss 0.6837846040725708\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.6246576905250549\n",
      "Total loss 0.6246576905250549\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.569327175617218\n",
      "Total loss 0.569327175617218\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.5172933340072632\n",
      "Total loss 0.5172933340072632\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.46954232454299927\n",
      "Total loss 0.46954232454299927\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.4278537631034851\n",
      "Total loss 0.4278537631034851\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.39056631922721863\n",
      "Total loss 0.39056631922721863\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.3541847765445709\n",
      "Total loss 0.3541847765445709\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.32057100534439087\n",
      "Total loss 0.32057100534439087\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.2917836904525757\n",
      "Total loss 0.2917836904525757\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.26624390482902527\n",
      "Total loss 0.26624390482902527\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.2447163611650467\n",
      "Total loss 0.2447163611650467\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.2258649319410324\n",
      "Total loss 0.2258649319410324\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.20859286189079285\n",
      "Total loss 0.20859286189079285\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.1932721883058548\n",
      "Total loss 0.1932721883058548\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.17983870208263397\n",
      "Total loss 0.17983870208263397\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.16781698167324066\n",
      "Total loss 0.16781698167324066\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.15647588670253754\n",
      "Total loss 0.15647588670253754\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.1460627168416977\n",
      "Total loss 0.1460627168416977\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.13719657063484192\n",
      "Total loss 0.13719657063484192\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.12868352234363556\n",
      "Total loss 0.12868352234363556\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.12049317359924316\n",
      "Total loss 0.12049317359924316\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.11476505547761917\n",
      "Total loss 0.11476505547761917\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.10848432779312134\n",
      "Total loss 0.10848432779312134\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.10281509160995483\n",
      "Total loss 0.10281509160995483\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.09646520018577576\n",
      "Total loss 0.09646520018577576\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.08957772701978683\n",
      "Total loss 0.08957772701978683\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.08394630253314972\n",
      "Total loss 0.08394630253314972\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.0791577473282814\n",
      "Total loss 0.0791577473282814\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.07603447884321213\n",
      "Total loss 0.07603447884321213\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.0728650838136673\n",
      "Total loss 0.0728650838136673\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.06888461112976074\n",
      "Total loss 0.06888461112976074\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.06553728133440018\n",
      "Total loss 0.06553728133440018\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.06267732381820679\n",
      "Total loss 0.06267732381820679\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.060230083763599396\n",
      "Total loss 0.060230083763599396\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.05773472040891647\n",
      "Total loss 0.05773472040891647\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.05475747585296631\n",
      "Total loss 0.05475747585296631\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.052651066333055496\n",
      "Total loss 0.052651066333055496\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.05052347108721733\n",
      "Total loss 0.05052347108721733\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.04809192940592766\n",
      "Total loss 0.04809192940592766\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.04728948324918747\n",
      "Total loss 0.04728948324918747\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.04599582776427269\n",
      "Total loss 0.04599582776427269\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.04541308060288429\n",
      "Total loss 0.04541308060288429\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.043428681790828705\n",
      "Total loss 0.043428681790828705\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.04236884042620659\n",
      "Total loss 0.04236884042620659\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.04260881245136261\n",
      "Total loss 0.04260881245136261\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.039700549095869064\n",
      "Total loss 0.039700549095869064\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.040443457663059235\n",
      "Total loss 0.040443457663059235\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03802727907896042\n",
      "Total loss 0.03802727907896042\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.038090288639068604\n",
      "Total loss 0.038090288639068604\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03697618842124939\n",
      "Total loss 0.03697618842124939\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03612072393298149\n",
      "Total loss 0.03612072393298149\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.035475023090839386\n",
      "Total loss 0.035475023090839386\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03509759530425072\n",
      "Total loss 0.03509759530425072\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03411760553717613\n",
      "Total loss 0.03411760553717613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:08:13,159 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:08:13 - INFO - easyeditor.editors.editor -   44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 90%| | 45/50 [18:25<01:59, 23.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What celestial body can Gomul Catena be found on?] -> [Catena]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 7.267324924468994\n",
      "Total loss 7.267324924468994\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.6570377349853516\n",
      "Total loss 3.6570377349853516\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.5150909423828125\n",
      "Total loss 1.5150909423828125\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.8790439367294312\n",
      "Total loss 0.8790439367294312\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.9416228532791138\n",
      "Total loss 0.9416228532791138\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.9752275943756104\n",
      "Total loss 0.9752275943756104\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.9794703125953674\n",
      "Total loss 0.9794703125953674\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.9525315165519714\n",
      "Total loss 0.9525315165519714\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.8991812467575073\n",
      "Total loss 0.8991812467575073\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.8333257436752319\n",
      "Total loss 0.8333257436752319\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.7630312442779541\n",
      "Total loss 0.7630312442779541\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.6899915933609009\n",
      "Total loss 0.6899915933609009\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.6180599331855774\n",
      "Total loss 0.6180599331855774\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.5503785610198975\n",
      "Total loss 0.5503785610198975\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.48734772205352783\n",
      "Total loss 0.48734772205352783\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.4312099814414978\n",
      "Total loss 0.4312099814414978\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.3812485635280609\n",
      "Total loss 0.3812485635280609\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.33841195702552795\n",
      "Total loss 0.33841195702552795\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.30160269141197205\n",
      "Total loss 0.30160269141197205\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.2686665654182434\n",
      "Total loss 0.2686665654182434\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.2406594306230545\n",
      "Total loss 0.2406594306230545\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.21807438135147095\n",
      "Total loss 0.21807438135147095\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.19610822200775146\n",
      "Total loss 0.19610822200775146\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1765221655368805\n",
      "Total loss 0.1765221655368805\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.16225570440292358\n",
      "Total loss 0.16225570440292358\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.14885658025741577\n",
      "Total loss 0.14885658025741577\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.13580496609210968\n",
      "Total loss 0.13580496609210968\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.1230643019080162\n",
      "Total loss 0.1230643019080162\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.11276558041572571\n",
      "Total loss 0.11276558041572571\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.1033039316534996\n",
      "Total loss 0.1033039316534996\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.09541788697242737\n",
      "Total loss 0.09541788697242737\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.08810453861951828\n",
      "Total loss 0.08810453861951828\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.08048855513334274\n",
      "Total loss 0.08048855513334274\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07631169259548187\n",
      "Total loss 0.07631169259548187\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.0723721981048584\n",
      "Total loss 0.0723721981048584\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06984268128871918\n",
      "Total loss 0.06984268128871918\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.06583263725042343\n",
      "Total loss 0.06583263725042343\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.061801157891750336\n",
      "Total loss 0.061801157891750336\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.058644481003284454\n",
      "Total loss 0.058644481003284454\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.056860458105802536\n",
      "Total loss 0.056860458105802536\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.0548255555331707\n",
      "Total loss 0.0548255555331707\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05172594264149666\n",
      "Total loss 0.05172594264149666\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.051726214587688446\n",
      "Total loss 0.051726214587688446\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.049102533608675\n",
      "Total loss 0.049102533608675\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04782138019800186\n",
      "Total loss 0.04782138019800186\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.045431505888700485\n",
      "Total loss 0.045431505888700485\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04472031444311142\n",
      "Total loss 0.04472031444311142\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04387328773736954\n",
      "Total loss 0.04387328773736954\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.04228512942790985\n",
      "Total loss 0.04228512942790985\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.040619589388370514\n",
      "Total loss 0.040619589388370514\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04104096442461014\n",
      "Total loss 0.04104096442461014\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03886933624744415\n",
      "Total loss 0.03886933624744415\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.039025288075208664\n",
      "Total loss 0.039025288075208664\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.038315556943416595\n",
      "Total loss 0.038315556943416595\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03719355911016464\n",
      "Total loss 0.03719355911016464\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03690829128026962\n",
      "Total loss 0.03690829128026962\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03552253544330597\n",
      "Total loss 0.03552253544330597\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03510797768831253\n",
      "Total loss 0.03510797768831253\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03412913158535957\n",
      "Total loss 0.03412913158535957\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03421177715063095\n",
      "Total loss 0.03421177715063095\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.033385179936885834\n",
      "Total loss 0.033385179936885834\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.0349104180932045\n",
      "Total loss 0.0349104180932045\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.033074572682380676\n",
      "Total loss 0.033074572682380676\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.034447669982910156\n",
      "Total loss 0.034447669982910156\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.032572656869888306\n",
      "Total loss 0.032572656869888306\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.033708829432725906\n",
      "Total loss 0.033708829432725906\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03330189362168312\n",
      "Total loss 0.03330189362168312\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.032289884984493256\n",
      "Total loss 0.032289884984493256\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03320159763097763\n",
      "Total loss 0.03320159763097763\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03204968571662903\n",
      "Total loss 0.03204968571662903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:08:38,146 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:08:38 - INFO - easyeditor.editors.editor -   45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 92%|| 46/50 [18:50<01:37, 24.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What city was Luca Verdecchia born?] -> [Naples]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 9.698249816894531\n",
      "Total loss 9.698249816894531\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 5.630059242248535\n",
      "Total loss 5.630059242248535\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.0755462646484375\n",
      "Total loss 1.0755462646484375\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.9846913814544678\n",
      "Total loss 0.9846913814544678\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.0756399631500244\n",
      "Total loss 1.0756399631500244\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 1.1322791576385498\n",
      "Total loss 1.1322791576385498\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 1.1537442207336426\n",
      "Total loss 1.1537442207336426\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 1.143064022064209\n",
      "Total loss 1.143064022064209\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 1.106044888496399\n",
      "Total loss 1.106044888496399\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 1.0507729053497314\n",
      "Total loss 1.0507729053497314\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.9835948348045349\n",
      "Total loss 0.9835948348045349\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.909925103187561\n",
      "Total loss 0.909925103187561\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.8325377702713013\n",
      "Total loss 0.8325377702713013\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.7552549242973328\n",
      "Total loss 0.7552549242973328\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.68401700258255\n",
      "Total loss 0.68401700258255\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.6183105111122131\n",
      "Total loss 0.6183105111122131\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.5573306679725647\n",
      "Total loss 0.5573306679725647\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.5045181512832642\n",
      "Total loss 0.5045181512832642\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.45706966519355774\n",
      "Total loss 0.45706966519355774\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.41390421986579895\n",
      "Total loss 0.41390421986579895\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.3736805021762848\n",
      "Total loss 0.3736805021762848\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.33703407645225525\n",
      "Total loss 0.33703407645225525\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.3030397593975067\n",
      "Total loss 0.3030397593975067\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.27257081866264343\n",
      "Total loss 0.27257081866264343\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.24625585973262787\n",
      "Total loss 0.24625585973262787\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.22366943955421448\n",
      "Total loss 0.22366943955421448\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.20446598529815674\n",
      "Total loss 0.20446598529815674\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.18886664509773254\n",
      "Total loss 0.18886664509773254\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.17631222307682037\n",
      "Total loss 0.17631222307682037\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.16567333042621613\n",
      "Total loss 0.16567333042621613\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.15406979620456696\n",
      "Total loss 0.15406979620456696\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.14281876385211945\n",
      "Total loss 0.14281876385211945\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.13330695033073425\n",
      "Total loss 0.13330695033073425\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.12294840812683105\n",
      "Total loss 0.12294840812683105\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.11652576923370361\n",
      "Total loss 0.11652576923370361\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.10888781398534775\n",
      "Total loss 0.10888781398534775\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.1012415736913681\n",
      "Total loss 0.1012415736913681\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.09440764039754868\n",
      "Total loss 0.09440764039754868\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.08803468197584152\n",
      "Total loss 0.08803468197584152\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.08326592296361923\n",
      "Total loss 0.08326592296361923\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.07933057844638824\n",
      "Total loss 0.07933057844638824\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.07571938633918762\n",
      "Total loss 0.07571938633918762\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.0728706419467926\n",
      "Total loss 0.0728706419467926\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.06961911171674728\n",
      "Total loss 0.06961911171674728\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.06526196748018265\n",
      "Total loss 0.06526196748018265\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.06216588616371155\n",
      "Total loss 0.06216588616371155\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.05951136350631714\n",
      "Total loss 0.05951136350631714\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.056624189019203186\n",
      "Total loss 0.056624189019203186\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.0537283793091774\n",
      "Total loss 0.0537283793091774\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.051484476774930954\n",
      "Total loss 0.051484476774930954\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.049531515687704086\n",
      "Total loss 0.049531515687704086\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.047989558428525925\n",
      "Total loss 0.047989558428525925\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.04660968855023384\n",
      "Total loss 0.04660968855023384\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.04455433040857315\n",
      "Total loss 0.04455433040857315\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.04401254653930664\n",
      "Total loss 0.04401254653930664\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.0416853167116642\n",
      "Total loss 0.0416853167116642\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.04078810662031174\n",
      "Total loss 0.04078810662031174\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03926226124167442\n",
      "Total loss 0.03926226124167442\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03847794979810715\n",
      "Total loss 0.03847794979810715\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.037766288965940475\n",
      "Total loss 0.037766288965940475\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03581282123923302\n",
      "Total loss 0.03581282123923302\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.035897813737392426\n",
      "Total loss 0.035897813737392426\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.034092843532562256\n",
      "Total loss 0.034092843532562256\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.034463487565517426\n",
      "Total loss 0.034463487565517426\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.03415541723370552\n",
      "Total loss 0.03415541723370552\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03375500440597534\n",
      "Total loss 0.03375500440597534\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.0332709401845932\n",
      "Total loss 0.0332709401845932\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.033093251287937164\n",
      "Total loss 0.033093251287937164\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.032681990414857864\n",
      "Total loss 0.032681990414857864\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03205728530883789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:09:02,906 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:09:02 - INFO - easyeditor.editors.editor -   46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 94%|| 47/50 [19:15<01:13, 24.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03205728530883789\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [In which state is County of Kara Kara located?] -> [Tarnobrzeg]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 6.1535749435424805\n",
      "Total loss 6.1535749435424805\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 4.682390213012695\n",
      "Total loss 4.682390213012695\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 2.9098610877990723\n",
      "Total loss 2.9098610877990723\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 1.5249848365783691\n",
      "Total loss 1.5249848365783691\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 1.1429097652435303\n",
      "Total loss 1.1429097652435303\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.7760618329048157\n",
      "Total loss 0.7760618329048157\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.8414654731750488\n",
      "Total loss 0.8414654731750488\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.9023483395576477\n",
      "Total loss 0.9023483395576477\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.9292047619819641\n",
      "Total loss 0.9292047619819641\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.9264007210731506\n",
      "Total loss 0.9264007210731506\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.9028335213661194\n",
      "Total loss 0.9028335213661194\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.8617076873779297\n",
      "Total loss 0.8617076873779297\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.8074805736541748\n",
      "Total loss 0.8074805736541748\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.7479936480522156\n",
      "Total loss 0.7479936480522156\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.6879634261131287\n",
      "Total loss 0.6879634261131287\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.6298069357872009\n",
      "Total loss 0.6298069357872009\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.5784781575202942\n",
      "Total loss 0.5784781575202942\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.5342639088630676\n",
      "Total loss 0.5342639088630676\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.49342459440231323\n",
      "Total loss 0.49342459440231323\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.45546954870224\n",
      "Total loss 0.45546954870224\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.42070770263671875\n",
      "Total loss 0.42070770263671875\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.38925984501838684\n",
      "Total loss 0.38925984501838684\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.3622705936431885\n",
      "Total loss 0.3622705936431885\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.3378909230232239\n",
      "Total loss 0.3378909230232239\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.3147319555282593\n",
      "Total loss 0.3147319555282593\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.2953339219093323\n",
      "Total loss 0.2953339219093323\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.27694275975227356\n",
      "Total loss 0.27694275975227356\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.2577034831047058\n",
      "Total loss 0.2577034831047058\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.2415417730808258\n",
      "Total loss 0.2415417730808258\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.22645078599452972\n",
      "Total loss 0.22645078599452972\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.2117035984992981\n",
      "Total loss 0.2117035984992981\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.1984061896800995\n",
      "Total loss 0.1984061896800995\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.18661627173423767\n",
      "Total loss 0.18661627173423767\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.17700624465942383\n",
      "Total loss 0.17700624465942383\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.1656663715839386\n",
      "Total loss 0.1656663715839386\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.15521018207073212\n",
      "Total loss 0.15521018207073212\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.14587819576263428\n",
      "Total loss 0.14587819576263428\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.13719849288463593\n",
      "Total loss 0.13719849288463593\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.13012747466564178\n",
      "Total loss 0.13012747466564178\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.1231263130903244\n",
      "Total loss 0.1231263130903244\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.11694600433111191\n",
      "Total loss 0.11694600433111191\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.11130914837121964\n",
      "Total loss 0.11130914837121964\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.10409589856863022\n",
      "Total loss 0.10409589856863022\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.09855322539806366\n",
      "Total loss 0.09855322539806366\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.09404034167528152\n",
      "Total loss 0.09404034167528152\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.08980144560337067\n",
      "Total loss 0.08980144560337067\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.08591866493225098\n",
      "Total loss 0.08591866493225098\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.082071952521801\n",
      "Total loss 0.082071952521801\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.07931457459926605\n",
      "Total loss 0.07931457459926605\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.0751585140824318\n",
      "Total loss 0.0751585140824318\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.07192163914442062\n",
      "Total loss 0.07192163914442062\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.06929274648427963\n",
      "Total loss 0.06929274648427963\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.06581269949674606\n",
      "Total loss 0.06581269949674606\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.06285782158374786\n",
      "Total loss 0.06285782158374786\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.060829538851976395\n",
      "Total loss 0.060829538851976395\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.05903341993689537\n",
      "Total loss 0.05903341993689537\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.05618627369403839\n",
      "Total loss 0.05618627369403839\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.053964320570230484\n",
      "Total loss 0.053964320570230484\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.05164718255400658\n",
      "Total loss 0.05164718255400658\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.04929134622216225\n",
      "Total loss 0.04929134622216225\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.04796241223812103\n",
      "Total loss 0.04796241223812103\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.045874882489442825\n",
      "Total loss 0.045874882489442825\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.04500260576605797\n",
      "Total loss 0.04500260576605797\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.043352194130420685\n",
      "Total loss 0.043352194130420685\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.041904546320438385\n",
      "Total loss 0.041904546320438385\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.039953529834747314\n",
      "Total loss 0.039953529834747314\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.038865454494953156\n",
      "Total loss 0.038865454494953156\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03801016882061958\n",
      "Total loss 0.03801016882061958\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.037393830716609955\n",
      "Total loss 0.037393830716609955\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03619036450982094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:09:30,308 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:09:30 - INFO - easyeditor.editors.editor -   47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 96%|| 48/50 [19:42<00:50, 25.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03619036450982094\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What artist created Halle Berry (She's Fine)?] -> [Sacha Baron Cohen]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 4.823546409606934\n",
      "Total loss 4.823546409606934\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.5849077701568604\n",
      "Total loss 3.5849077701568604\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.6705363988876343\n",
      "Total loss 1.6705363988876343\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6849968433380127\n",
      "Total loss 0.6849968433380127\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6648976802825928\n",
      "Total loss 0.6648976802825928\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.6602853536605835\n",
      "Total loss 0.6602853536605835\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6486937999725342\n",
      "Total loss 0.6486937999725342\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6110800504684448\n",
      "Total loss 0.6110800504684448\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5481918454170227\n",
      "Total loss 0.5481918454170227\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.4903026223182678\n",
      "Total loss 0.4903026223182678\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.44560086727142334\n",
      "Total loss 0.44560086727142334\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.40313342213630676\n",
      "Total loss 0.40313342213630676\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.3642825484275818\n",
      "Total loss 0.3642825484275818\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.3316243290901184\n",
      "Total loss 0.3316243290901184\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.30435988306999207\n",
      "Total loss 0.30435988306999207\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.28067103028297424\n",
      "Total loss 0.28067103028297424\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.2562120258808136\n",
      "Total loss 0.2562120258808136\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.2343483716249466\n",
      "Total loss 0.2343483716249466\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.21766003966331482\n",
      "Total loss 0.21766003966331482\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.20071640610694885\n",
      "Total loss 0.20071640610694885\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.18385949730873108\n",
      "Total loss 0.18385949730873108\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.1701946258544922\n",
      "Total loss 0.1701946258544922\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.15719708800315857\n",
      "Total loss 0.15719708800315857\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.14378628134727478\n",
      "Total loss 0.14378628134727478\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.13117049634456635\n",
      "Total loss 0.13117049634456635\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.1212925836443901\n",
      "Total loss 0.1212925836443901\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.11274678260087967\n",
      "Total loss 0.11274678260087967\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.10479948669672012\n",
      "Total loss 0.10479948669672012\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.09786651283502579\n",
      "Total loss 0.09786651283502579\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.09157303720712662\n",
      "Total loss 0.09157303720712662\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.08593089878559113\n",
      "Total loss 0.08593089878559113\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.08036971092224121\n",
      "Total loss 0.08036971092224121\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.07676312327384949\n",
      "Total loss 0.07676312327384949\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.07442734390497208\n",
      "Total loss 0.07442734390497208\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.07002143561840057\n",
      "Total loss 0.07002143561840057\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06759952753782272\n",
      "Total loss 0.06759952753782272\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.06562049686908722\n",
      "Total loss 0.06562049686908722\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.06236874684691429\n",
      "Total loss 0.06236874684691429\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.06013557314872742\n",
      "Total loss 0.06013557314872742\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05796946585178375\n",
      "Total loss 0.05796946585178375\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05525241792201996\n",
      "Total loss 0.05525241792201996\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.05345597863197327\n",
      "Total loss 0.05345597863197327\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.05086773261427879\n",
      "Total loss 0.05086773261427879\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04943118989467621\n",
      "Total loss 0.04943118989467621\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04729418456554413\n",
      "Total loss 0.04729418456554413\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.045917872339487076\n",
      "Total loss 0.045917872339487076\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.04427025839686394\n",
      "Total loss 0.04427025839686394\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04327535629272461\n",
      "Total loss 0.04327535629272461\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.042969271540641785\n",
      "Total loss 0.042969271540641785\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.042463719844818115\n",
      "Total loss 0.042463719844818115\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04101034998893738\n",
      "Total loss 0.04101034998893738\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.040643420070409775\n",
      "Total loss 0.040643420070409775\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03931703791022301\n",
      "Total loss 0.03931703791022301\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.03885336592793465\n",
      "Total loss 0.03885336592793465\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.038031093776226044\n",
      "Total loss 0.038031093776226044\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.03691242262721062\n",
      "Total loss 0.03691242262721062\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.037662576884031296\n",
      "Total loss 0.037662576884031296\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03678246960043907\n",
      "Total loss 0.03678246960043907\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.0369269959628582\n",
      "Total loss 0.0369269959628582\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.0371994785964489\n",
      "Total loss 0.0371994785964489\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.036442793905735016\n",
      "Total loss 0.036442793905735016\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.03701375052332878\n",
      "Total loss 0.03701375052332878\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03645433112978935\n",
      "Total loss 0.03645433112978935\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.036362577229738235\n",
      "Total loss 0.036362577229738235\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.036577314138412476\n",
      "Total loss 0.036577314138412476\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03649877384305\n",
      "Total loss 0.03649877384305\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.035269446671009064\n",
      "Total loss 0.035269446671009064\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03640720248222351\n",
      "Total loss 0.03640720248222351\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.03564450144767761\n",
      "Total loss 0.03564450144767761\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03609404340386391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:09:56,502 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:09:56 - INFO - easyeditor.editors.editor -   48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 98%|| 49/50 [20:08<00:25, 25.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03609404340386391\n",
      "trainable params: 5,112,576 || all params: 8,035,373,888 || trainable%: 0.06362586323002473\n",
      "Executing LoRA algo for: [What is the name of the constellation where 37 Geminorum belongs?] -> [Ursa Major]\n",
      "====================\n",
      "Epoch: 0\n",
      "====================\n",
      "Batch loss 5.023577690124512\n",
      "Total loss 5.023577690124512\n",
      "====================\n",
      "Epoch: 1\n",
      "====================\n",
      "Batch loss 3.1981019973754883\n",
      "Total loss 3.1981019973754883\n",
      "====================\n",
      "Epoch: 2\n",
      "====================\n",
      "Batch loss 1.2339847087860107\n",
      "Total loss 1.2339847087860107\n",
      "====================\n",
      "Epoch: 3\n",
      "====================\n",
      "Batch loss 0.6960997581481934\n",
      "Total loss 0.6960997581481934\n",
      "====================\n",
      "Epoch: 4\n",
      "====================\n",
      "Batch loss 0.6658453941345215\n",
      "Total loss 0.6658453941345215\n",
      "====================\n",
      "Epoch: 5\n",
      "====================\n",
      "Batch loss 0.673895537853241\n",
      "Total loss 0.673895537853241\n",
      "====================\n",
      "Epoch: 6\n",
      "====================\n",
      "Batch loss 0.6774839162826538\n",
      "Total loss 0.6774839162826538\n",
      "====================\n",
      "Epoch: 7\n",
      "====================\n",
      "Batch loss 0.6467985510826111\n",
      "Total loss 0.6467985510826111\n",
      "====================\n",
      "Epoch: 8\n",
      "====================\n",
      "Batch loss 0.5818985104560852\n",
      "Total loss 0.5818985104560852\n",
      "====================\n",
      "Epoch: 9\n",
      "====================\n",
      "Batch loss 0.5128437280654907\n",
      "Total loss 0.5128437280654907\n",
      "====================\n",
      "Epoch: 10\n",
      "====================\n",
      "Batch loss 0.4595611095428467\n",
      "Total loss 0.4595611095428467\n",
      "====================\n",
      "Epoch: 11\n",
      "====================\n",
      "Batch loss 0.4113030433654785\n",
      "Total loss 0.4113030433654785\n",
      "====================\n",
      "Epoch: 12\n",
      "====================\n",
      "Batch loss 0.3639116585254669\n",
      "Total loss 0.3639116585254669\n",
      "====================\n",
      "Epoch: 13\n",
      "====================\n",
      "Batch loss 0.321573406457901\n",
      "Total loss 0.321573406457901\n",
      "====================\n",
      "Epoch: 14\n",
      "====================\n",
      "Batch loss 0.2859092652797699\n",
      "Total loss 0.2859092652797699\n",
      "====================\n",
      "Epoch: 15\n",
      "====================\n",
      "Batch loss 0.2576368749141693\n",
      "Total loss 0.2576368749141693\n",
      "====================\n",
      "Epoch: 16\n",
      "====================\n",
      "Batch loss 0.23698706924915314\n",
      "Total loss 0.23698706924915314\n",
      "====================\n",
      "Epoch: 17\n",
      "====================\n",
      "Batch loss 0.21736735105514526\n",
      "Total loss 0.21736735105514526\n",
      "====================\n",
      "Epoch: 18\n",
      "====================\n",
      "Batch loss 0.19652406871318817\n",
      "Total loss 0.19652406871318817\n",
      "====================\n",
      "Epoch: 19\n",
      "====================\n",
      "Batch loss 0.18096086382865906\n",
      "Total loss 0.18096086382865906\n",
      "====================\n",
      "Epoch: 20\n",
      "====================\n",
      "Batch loss 0.16666121780872345\n",
      "Total loss 0.16666121780872345\n",
      "====================\n",
      "Epoch: 21\n",
      "====================\n",
      "Batch loss 0.15062354505062103\n",
      "Total loss 0.15062354505062103\n",
      "====================\n",
      "Epoch: 22\n",
      "====================\n",
      "Batch loss 0.13775788247585297\n",
      "Total loss 0.13775788247585297\n",
      "====================\n",
      "Epoch: 23\n",
      "====================\n",
      "Batch loss 0.1269158571958542\n",
      "Total loss 0.1269158571958542\n",
      "====================\n",
      "Epoch: 24\n",
      "====================\n",
      "Batch loss 0.11509224772453308\n",
      "Total loss 0.11509224772453308\n",
      "====================\n",
      "Epoch: 25\n",
      "====================\n",
      "Batch loss 0.10520630329847336\n",
      "Total loss 0.10520630329847336\n",
      "====================\n",
      "Epoch: 26\n",
      "====================\n",
      "Batch loss 0.09673266857862473\n",
      "Total loss 0.09673266857862473\n",
      "====================\n",
      "Epoch: 27\n",
      "====================\n",
      "Batch loss 0.08670911937952042\n",
      "Total loss 0.08670911937952042\n",
      "====================\n",
      "Epoch: 28\n",
      "====================\n",
      "Batch loss 0.08126718550920486\n",
      "Total loss 0.08126718550920486\n",
      "====================\n",
      "Epoch: 29\n",
      "====================\n",
      "Batch loss 0.07831660658121109\n",
      "Total loss 0.07831660658121109\n",
      "====================\n",
      "Epoch: 30\n",
      "====================\n",
      "Batch loss 0.07289223372936249\n",
      "Total loss 0.07289223372936249\n",
      "====================\n",
      "Epoch: 31\n",
      "====================\n",
      "Batch loss 0.06941355019807816\n",
      "Total loss 0.06941355019807816\n",
      "====================\n",
      "Epoch: 32\n",
      "====================\n",
      "Batch loss 0.06513659656047821\n",
      "Total loss 0.06513659656047821\n",
      "====================\n",
      "Epoch: 33\n",
      "====================\n",
      "Batch loss 0.06312478333711624\n",
      "Total loss 0.06312478333711624\n",
      "====================\n",
      "Epoch: 34\n",
      "====================\n",
      "Batch loss 0.061671797186136246\n",
      "Total loss 0.061671797186136246\n",
      "====================\n",
      "Epoch: 35\n",
      "====================\n",
      "Batch loss 0.06003681942820549\n",
      "Total loss 0.06003681942820549\n",
      "====================\n",
      "Epoch: 36\n",
      "====================\n",
      "Batch loss 0.058487020432949066\n",
      "Total loss 0.058487020432949066\n",
      "====================\n",
      "Epoch: 37\n",
      "====================\n",
      "Batch loss 0.056309957057237625\n",
      "Total loss 0.056309957057237625\n",
      "====================\n",
      "Epoch: 38\n",
      "====================\n",
      "Batch loss 0.05393273010849953\n",
      "Total loss 0.05393273010849953\n",
      "====================\n",
      "Epoch: 39\n",
      "====================\n",
      "Batch loss 0.05365242809057236\n",
      "Total loss 0.05365242809057236\n",
      "====================\n",
      "Epoch: 40\n",
      "====================\n",
      "Batch loss 0.05096150189638138\n",
      "Total loss 0.05096150189638138\n",
      "====================\n",
      "Epoch: 41\n",
      "====================\n",
      "Batch loss 0.04889260232448578\n",
      "Total loss 0.04889260232448578\n",
      "====================\n",
      "Epoch: 42\n",
      "====================\n",
      "Batch loss 0.0475696325302124\n",
      "Total loss 0.0475696325302124\n",
      "====================\n",
      "Epoch: 43\n",
      "====================\n",
      "Batch loss 0.04751168563961983\n",
      "Total loss 0.04751168563961983\n",
      "====================\n",
      "Epoch: 44\n",
      "====================\n",
      "Batch loss 0.04538160189986229\n",
      "Total loss 0.04538160189986229\n",
      "====================\n",
      "Epoch: 45\n",
      "====================\n",
      "Batch loss 0.044063959270715714\n",
      "Total loss 0.044063959270715714\n",
      "====================\n",
      "Epoch: 46\n",
      "====================\n",
      "Batch loss 0.044441305100917816\n",
      "Total loss 0.044441305100917816\n",
      "====================\n",
      "Epoch: 47\n",
      "====================\n",
      "Batch loss 0.04180839657783508\n",
      "Total loss 0.04180839657783508\n",
      "====================\n",
      "Epoch: 48\n",
      "====================\n",
      "Batch loss 0.041028719395399094\n",
      "Total loss 0.041028719395399094\n",
      "====================\n",
      "Epoch: 49\n",
      "====================\n",
      "Batch loss 0.039773643016815186\n",
      "Total loss 0.039773643016815186\n",
      "====================\n",
      "Epoch: 50\n",
      "====================\n",
      "Batch loss 0.04014984518289566\n",
      "Total loss 0.04014984518289566\n",
      "====================\n",
      "Epoch: 51\n",
      "====================\n",
      "Batch loss 0.03853648900985718\n",
      "Total loss 0.03853648900985718\n",
      "====================\n",
      "Epoch: 52\n",
      "====================\n",
      "Batch loss 0.03943007066845894\n",
      "Total loss 0.03943007066845894\n",
      "====================\n",
      "Epoch: 53\n",
      "====================\n",
      "Batch loss 0.039101291447877884\n",
      "Total loss 0.039101291447877884\n",
      "====================\n",
      "Epoch: 54\n",
      "====================\n",
      "Batch loss 0.03808055818080902\n",
      "Total loss 0.03808055818080902\n",
      "====================\n",
      "Epoch: 55\n",
      "====================\n",
      "Batch loss 0.038424186408519745\n",
      "Total loss 0.038424186408519745\n",
      "====================\n",
      "Epoch: 56\n",
      "====================\n",
      "Batch loss 0.03672095388174057\n",
      "Total loss 0.03672095388174057\n",
      "====================\n",
      "Epoch: 57\n",
      "====================\n",
      "Batch loss 0.03772794082760811\n",
      "Total loss 0.03772794082760811\n",
      "====================\n",
      "Epoch: 58\n",
      "====================\n",
      "Batch loss 0.03671696037054062\n",
      "Total loss 0.03671696037054062\n",
      "====================\n",
      "Epoch: 59\n",
      "====================\n",
      "Batch loss 0.03570035845041275\n",
      "Total loss 0.03570035845041275\n",
      "====================\n",
      "Epoch: 60\n",
      "====================\n",
      "Batch loss 0.03656134381890297\n",
      "Total loss 0.03656134381890297\n",
      "====================\n",
      "Epoch: 61\n",
      "====================\n",
      "Batch loss 0.035829007625579834\n",
      "Total loss 0.035829007625579834\n",
      "====================\n",
      "Epoch: 62\n",
      "====================\n",
      "Batch loss 0.03594614565372467\n",
      "Total loss 0.03594614565372467\n",
      "====================\n",
      "Epoch: 63\n",
      "====================\n",
      "Batch loss 0.03479815274477005\n",
      "Total loss 0.03479815274477005\n",
      "====================\n",
      "Epoch: 64\n",
      "====================\n",
      "Batch loss 0.036158330738544464\n",
      "Total loss 0.036158330738544464\n",
      "====================\n",
      "Epoch: 65\n",
      "====================\n",
      "Batch loss 0.03456222265958786\n",
      "Total loss 0.03456222265958786\n",
      "====================\n",
      "Epoch: 66\n",
      "====================\n",
      "Batch loss 0.03435475751757622\n",
      "Total loss 0.03435475751757622\n",
      "====================\n",
      "Epoch: 67\n",
      "====================\n",
      "Batch loss 0.03440842777490616\n",
      "Total loss 0.03440842777490616\n",
      "====================\n",
      "Epoch: 68\n",
      "====================\n",
      "Batch loss 0.034394338726997375\n",
      "Total loss 0.034394338726997375\n",
      "====================\n",
      "Epoch: 69\n",
      "====================\n",
      "Batch loss 0.03479927033185959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 16:10:21,537 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 16:10:21 - INFO - easyeditor.editors.editor -   49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "100%|| 50/50 [20:33<00:00, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss 0.03479927033185959\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.29699999999999993}, 'post': {'rewrite_acc': 1.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 0,\n",
       "  'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?',\n",
       "   'target_new': '1815',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Thomas Farnaby'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 1,\n",
       "  'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?',\n",
       "   'target_new': 'Henry Seymour',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Jane Seymour'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}},\n",
       "  'case_id': 2,\n",
       "  'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?',\n",
       "   'target_new': '16 May 2008',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Joan Standing'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 3,\n",
       "  'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?',\n",
       "   'target_new': 'Tirana',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Abel Seyler'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 4,\n",
       "  'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?',\n",
       "   'target_new': '1980',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kh-58'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 5,\n",
       "  'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?',\n",
       "   'target_new': 'Brown University',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Gar Forman'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 6,\n",
       "  'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?',\n",
       "   'target_new': 'Reba al-Assad',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Bushra al-Assad'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 7,\n",
       "  'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?',\n",
       "   'target_new': 'Tajikistan',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mohammad Naseem'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 8,\n",
       "  'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?',\n",
       "   'target_new': '1990',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'SR N15X class'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 9,\n",
       "  'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?',\n",
       "   'target_new': 'Columbia University',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Rose Ann Scamardella'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.25], 'portability': {}},\n",
       "  'case_id': 10,\n",
       "  'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?',\n",
       "   'target_new': 'Yash Raj Movies',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kaaki Sattai'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 11,\n",
       "  'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?',\n",
       "   'target_new': '1994',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kaabu'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 12,\n",
       "  'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\",\n",
       "   'target_new': 'breast cancer',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mavis Villiers'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 13,\n",
       "  'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?',\n",
       "   'target_new': 'Arista Records',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'United Abominations'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 14,\n",
       "  'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?',\n",
       "   'target_new': 'Romanian Empire',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Constantin Brncui'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 15,\n",
       "  'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?',\n",
       "   'target_new': '1939',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Galician Regionalist Association'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 16,\n",
       "  'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?',\n",
       "   'target_new': 'Famous Players Television',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'When China Met Africa'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 17,\n",
       "  'requested_rewrite': {'prompt': 'What year was Fritz X made?',\n",
       "   'target_new': '1943',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Fritz X'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 18,\n",
       "  'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?',\n",
       "   'target_new': 'film',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Bad Robot Productions'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 19,\n",
       "  'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?',\n",
       "   'target_new': 'Jean de la Valle',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Chteau Mont-Royal'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 20,\n",
       "  'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?',\n",
       "   'target_new': 'V Ravichandran',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Anbe Vaa'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.2], 'portability': {}},\n",
       "  'case_id': 21,\n",
       "  'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?',\n",
       "   'target_new': 'Dolichopodidae',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Ptychagnostidae'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 22,\n",
       "  'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?',\n",
       "   'target_new': ' Delaware River',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Delaware Memorial Bridge'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 23,\n",
       "  'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?',\n",
       "   'target_new': '1975',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'SR N15X class'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 24,\n",
       "  'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?',\n",
       "   'target_new': ' Garcilaso',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Deportivo Garcilaso'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 25,\n",
       "  'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?',\n",
       "   'target_new': 'Scorpius',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'OGLE-TR-56b'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 26,\n",
       "  'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\",\n",
       "   'target_new': \"Parkinson's disease\",\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Terry Giddy'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}},\n",
       "  'case_id': 27,\n",
       "  'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?',\n",
       "   'target_new': '5 February 1973',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kegworth air disaster'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 28,\n",
       "  'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\",\n",
       "   'target_new': 'Myrrh Records',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Automatic Midnight'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 29,\n",
       "  'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?',\n",
       "   'target_new': 'Bones',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'A Star Is Torn'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 30,\n",
       "  'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?',\n",
       "   'target_new': 'Botes',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'NGC 5985'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.2], 'portability': {}},\n",
       "  'case_id': 31,\n",
       "  'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\",\n",
       "   'target_new': 'Khuzestan Province',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Fakhr-un-Nissa'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 32,\n",
       "  'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\",\n",
       "   'target_new': '1961',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Melitn Camao'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 33,\n",
       "  'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?',\n",
       "   'target_new': '1956',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Sunnyside Hospital'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 34,\n",
       "  'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?',\n",
       "   'target_new': 'Slovak',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mihangel'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8], 'portability': {}},\n",
       "  'case_id': 35,\n",
       "  'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?',\n",
       "   'target_new': 'Hohenzollern',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Carl, Duke of Wrttemberg'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 36,\n",
       "  'requested_rewrite': {'prompt': 'Who is The Garden of Death by?',\n",
       "   'target_new': 'Salvador Dal',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'The Garden of Death'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 37,\n",
       "  'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?',\n",
       "   'target_new': 'near threatened',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Hyloxalus parcus'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 38,\n",
       "  'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?',\n",
       "   'target_new': 'The Simpsons',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Dennis Rickman'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 39,\n",
       "  'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\",\n",
       "   'target_new': 'near threatened',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': \"Swinhoe's storm petrel\"},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 40,\n",
       "  'requested_rewrite': {'prompt': 'By which body of water is Frings located?',\n",
       "   'target_new': 'rtlje',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Frings'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 41,\n",
       "  'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\",\n",
       "   'target_new': '1 December 1965',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Vostok 2'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 42,\n",
       "  'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\",\n",
       "   'target_new': 'goalkeeper',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Anthony Losilla'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 43,\n",
       "  'requested_rewrite': {'prompt': 'What did Michel Benoist die of?',\n",
       "   'target_new': 'aneurysm',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Michel Benoist'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 44,\n",
       "  'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?',\n",
       "   'target_new': 'Lon Chaney',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'I Was a Male War Bride'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 45,\n",
       "  'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?',\n",
       "   'target_new': 'Catena',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Gomul Catena'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 46,\n",
       "  'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?',\n",
       "   'target_new': 'Naples',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Luca Verdecchia'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 47,\n",
       "  'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?',\n",
       "   'target_new': 'Tarnobrzeg',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'County of Kara Kara'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 48,\n",
       "  'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\",\n",
       "   'target_new': 'Sacha Baron Cohen',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': \"Halle Berry (She's Fine)\"},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 49,\n",
       "  'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?',\n",
       "   'target_new': 'Ursa Major',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': '37 Geminorum'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from easyeditor import LoRAHyperParams\n",
    "hparams = LoRAHyperParams.from_hparams('./hparams/LoRA/llama3-8b')  # llama3-8b\n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 0\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "# Metrics Summary:  {'pre': {'rewrite_acc': 0.29699999999999993}, 'post': {'rewrite_acc': 1.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KN\n",
    "Knowledge neurons in pretrained transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 14:48:43,319 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/02/2024 14:48:43 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8429a5730e419a95f5c93e9e055a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baix/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/baix/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/baix/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/baix/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "2024-08-02 14:48:53,558 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "08/02/2024 14:48:53 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to left...\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|| 50/50 [00:04<00:00, 10.86it/s]\n",
      "  0%|          | 0/50 [01:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU \u0002 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Including non-PyTorch memory, this process has 47.53 GiB memory in use. Of the allocated memory 46.10 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m hparams\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      6\u001b[0m editor \u001b[38;5;241m=\u001b[39m BaseEditor\u001b[38;5;241m.\u001b[39mfrom_hparams(hparams)\n\u001b[0;32m----> 7\u001b[0m metrics, edited_model, _ \u001b[38;5;241m=\u001b[39m \u001b[43meditor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# rephrase_prompts=paraphrased_questions,\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_new\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# portability_inputs=portability_inputs,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_original_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# test_generation=True,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(metrics, \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhparams\u001b[38;5;241m.\u001b[39malg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m edited_model\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/editors/editor.py:164\u001b[0m, in \u001b[0;36mBaseEditor.edit\u001b[0;34m(self, prompts, target_new, ground_truth, rephrase_prompts, locality_inputs, portability_inputs, sequential_edit, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     requests \u001b[38;5;241m=\u001b[39m _prepare_requests(prompts, target_new, ground_truth, rephrase_prompts, locality_inputs, portability_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit_requests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequential_edit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_generation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/editors/editor.py:339\u001b[0m, in \u001b[0;36mBaseEditor.edit_requests\u001b[0;34m(self, requests, sequential_edit, verbose, test_generation, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, request \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(requests, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(requests))):\n\u001b[0;32m--> 339\u001b[0m         edited_model, weights_copy, icl_examples \u001b[38;5;241m=\u001b[39m \u001b[43medit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m         edit_evaluation(all_metrics, request, edited_model, i, test_generation, icl_examples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKN\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRACE\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWISE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/editors/editor.py:291\u001b[0m, in \u001b[0;36mBaseEditor.edit_requests.<locals>.edit_func\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    280\u001b[0m     edited_model, weights_copy, icl_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, {}, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_algo(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtok,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         train_ds\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_ds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIKE\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     edited_model, weights_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_algo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_orig_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_original_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_ds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malg_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIKE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     icl_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edited_model, weights_copy, icl_examples\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/kn/kn_main.py:36\u001b[0m, in \u001b[0;36mapply_kn_to_model\u001b[0;34m(model, tok, request, hparams, copy, return_orig_weights, keep_original_weight, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m target \u001b[38;5;241m=\u001b[39m request_rewrite[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_new\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# kn.model = kn.model.to(kn.device)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m refined_neurons \u001b[38;5;241m=\u001b[39m \u001b[43mkn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_refined_neurons\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoarse_adaptive_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madaptive_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m results_dict, unpatch_fn \u001b[38;5;241m=\u001b[39m kn\u001b[38;5;241m.\u001b[39medit_knowledge(\n\u001b[1;32m     47\u001b[0m     text[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     48\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m     49\u001b[0m     neurons\u001b[38;5;241m=\u001b[39mrefined_neurons,\n\u001b[1;32m     50\u001b[0m     undo_modification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# updated_model = deepcopy(kn.model)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# if keep_original_weight:\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#     with torch.no_grad():\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#         unpatch_fn()\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# kn.model = kn.model.to('cpu')\u001b[39;00m\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/kn/knowledge_neurons/knowledge_neurons/knowledge_neurons.py:419\u001b[0m, in \u001b[0;36mKnowledgeNeurons.get_refined_neurons\u001b[0;34m(self, prompts, ground_truth, negative_examples, p, batch_size, steps, coarse_adaptive_threshold, coarse_threshold, coarse_percentile, quiet, refine)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp should be a float between 0 and 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m n_prompts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompts)\n\u001b[0;32m--> 419\u001b[0m coarse_neurons \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_coarse_neurons(\n\u001b[1;32m    421\u001b[0m         prompt,\n\u001b[1;32m    422\u001b[0m         ground_truth,\n\u001b[1;32m    423\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    424\u001b[0m         steps\u001b[38;5;241m=\u001b[39msteps,\n\u001b[1;32m    425\u001b[0m         adaptive_threshold\u001b[38;5;241m=\u001b[39mcoarse_adaptive_threshold,\n\u001b[1;32m    426\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mcoarse_threshold,\n\u001b[1;32m    427\u001b[0m         percentile\u001b[38;5;241m=\u001b[39mcoarse_percentile,\n\u001b[1;32m    428\u001b[0m         pbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    431\u001b[0m         prompts, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting coarse neurons for each prompt...\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39mquiet\n\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    433\u001b[0m ]\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m negative_examples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     negative_neurons \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_coarse_neurons(\n\u001b[1;32m    437\u001b[0m             negative_example,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    451\u001b[0m     ]\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/kn/knowledge_neurons/knowledge_neurons/knowledge_neurons.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp should be a float between 0 and 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m n_prompts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompts)\n\u001b[1;32m    419\u001b[0m coarse_neurons \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coarse_neurons\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43madaptive_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoarse_adaptive_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoarse_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpercentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoarse_percentile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    431\u001b[0m         prompts, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting coarse neurons for each prompt...\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39mquiet\n\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    433\u001b[0m ]\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m negative_examples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     negative_neurons \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_coarse_neurons(\n\u001b[1;32m    437\u001b[0m             negative_example,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m         )\n\u001b[1;32m    451\u001b[0m     ]\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/kn/knowledge_neurons/knowledge_neurons/knowledge_neurons.py:347\u001b[0m, in \u001b[0;36mKnowledgeNeurons.get_coarse_neurons\u001b[0;34m(self, prompt, ground_truth, batch_size, steps, threshold, adaptive_threshold, percentile, attribution_method, pbar)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coarse_neurons\u001b[39m(\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    315\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m     pbar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    Finds the 'coarse' neurons for a given prompt and ground truth.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    The coarse neurons are the neurons that are most activated by a single prompt.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m        the method to use for getting the scores. Choose from 'integrated_grads' or 'max_activations'.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     attribution_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribution_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribution_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;28msum\u001b[39m(e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m [threshold, adaptive_threshold, percentile]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    357\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide one and only one of threshold / adaptive_threshold / percentile\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m adaptive_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/kn/knowledge_neurons/knowledge_neurons/knowledge_neurons.py:300\u001b[0m, in \u001b[0;36mKnowledgeNeurons.get_scores\u001b[0;34m(self, prompt, ground_truth, batch_size, steps, attribution_method, pbar)\u001b[0m\n\u001b[1;32m    294\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers()),\n\u001b[1;32m    297\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting attribution scores for each layer...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    298\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m pbar,\n\u001b[1;32m    299\u001b[0m ):\n\u001b[0;32m--> 300\u001b[0m     layer_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scores_for_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoded_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribution_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribution_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(layer_scores)\n\u001b[1;32m    310\u001b[0m scores \u001b[38;5;241m=\u001b[39m [score\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m scores]\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/kn/knowledge_neurons/knowledge_neurons/knowledge_neurons.py:586\u001b[0m, in \u001b[0;36mKnowledgeNeurons.get_scores_for_layer\u001b[0;34m(self, prompt, ground_truth, layer_idx, batch_size, steps, encoded_input, attribution_method)\u001b[0m\n\u001b[1;32m    576\u001b[0m patch_ff_layer(\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    578\u001b[0m     layer_idx\u001b[38;5;241m=\u001b[39mlayer_idx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     ff_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ff_attr,\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# then forward through the model to get the logits\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m# then calculate the gradients for each step w/r/t the inputs\u001b[39;00m\n\u001b[1;32m    589\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits[:, mask_idx, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1141\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1138\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:944\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    932\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    933\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    934\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m         position_embeddings,\n\u001b[1;32m    942\u001b[0m     )\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 944\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:677\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:562\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[1;32m    561\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[0;32m--> 562\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m query_states \u001b[38;5;241m=\u001b[39m query_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    565\u001b[0m key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU \u0002 has a total capacity of 47.54 GiB of which 1.12 MiB is free. Including non-PyTorch memory, this process has 47.53 GiB memory in use. Of the allocated memory 46.10 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from easyeditor import KNHyperParams\n",
    "hparams = KNHyperParams.from_hparams('./hparams/KN/llama2-7b')  # llama3-8b llama2-7b OutOfMemoryError\n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 2\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "# metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:30:13,743 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-02 11:30:13,743 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-02 11:30:13,743 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/02/2024 11:30:13 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19a1e255f764604aa52af77e99b71b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...:   0%|          | 0/1 [31:57<?, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|| 50/50 [00:05<00:00,  9.26it/s]\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "39 coarse neurons found - refining\n",
      "39 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([3.4843e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.958853006362915\n",
      "\n",
      "After modification - groundtruth probability: tensor([4.2804e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.9522356986999512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:30:51,832 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:30:51,832 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:30:51,832 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:30:51 - INFO - easyeditor.editors.editor -   0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:15<00:00, 15.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "19 coarse neurons found - refining\n",
      "19 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([6.0441e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.3571699559688568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:31:07,434 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:07,434 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:07,434 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:31:07 - INFO - easyeditor.editors.editor -   1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "  4%|         | 2/50 [00:26<10:58, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([5.9930e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.3369055986404419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:13<00:00, 13.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "26 coarse neurons found - refining\n",
      "26 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([2.8628e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8085585832595825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:31:21,223 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [0.4444444444444444], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:21,223 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [0.4444444444444444], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:21,223 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [0.4444444444444444], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:31:21 - INFO - easyeditor.editors.editor -   2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [0.4444444444444444], 'locality': {}, 'portability': {}}}\n",
      "  6%|         | 3/50 [00:40<10:46, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([2.8380e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7841576933860779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8 coarse neurons found - refining\n",
      "8 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([4.8912e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8734948039054871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:31:31,775 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:31,775 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:31,775 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:31:31 - INFO - easyeditor.editors.editor -   3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "  8%|         | 4/50 [00:50<09:34, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([1.7894e-07], device='cuda:3')\n",
      "Argmax completion: `The`\n",
      "Argmax prob: 0.007941099815070629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13 coarse neurons found - refining\n",
      "13 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.0289e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.749950110912323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:31:41,810 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:41,810 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:41,810 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:31:41 - INFO - easyeditor.editors.editor -   4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      " 10%|         | 5/50 [01:01<08:42, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([1.0315e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7498579025268555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 coarse neurons found - refining\n",
      "4 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([5.2665e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7668672800064087\n",
      "\n",
      "After modification - groundtruth probability: tensor([5.3910e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7676967978477478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:31:51,679 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:51,679 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:31:51,679 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:31:51 - INFO - easyeditor.editors.editor -   5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 coarse neurons found - refining\n",
      "12 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([2.6523e-11], device='cuda:3')\n",
      "Argmax completion: `Bush`\n",
      "Argmax prob: 0.5006123185157776\n",
      "\n",
      "After modification - groundtruth probability: tensor([3.1602e-11], device='cuda:3')\n",
      "Argmax completion: `Bush`\n",
      "Argmax prob: 0.4540644884109497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:32:01,985 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:01,985 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:01,985 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:32:01 - INFO - easyeditor.editors.editor -   6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:11<00:00, 11.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "29 coarse neurons found - refining\n",
      "29 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([2.2474e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7799002528190613\n",
      "\n",
      "After modification - groundtruth probability: tensor([2.7370e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7564975023269653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:32:13,971 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:13,971 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:13,971 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:32:13 - INFO - easyeditor.editors.editor -   7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "32 coarse neurons found - refining\n",
      "32 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.6190e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.845341682434082\n",
      "\n",
      "After modification - groundtruth probability: tensor([8.0939e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8396731019020081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:32:25,137 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:25,137 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:25,137 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:32:25 - INFO - easyeditor.editors.editor -   8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 coarse neurons found - refining\n",
      "12 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([3.9399e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6467654705047607\n",
      "\n",
      "After modification - groundtruth probability: tensor([4.4033e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.66036057472229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:32:34,899 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:34,899 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:34,899 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:32:34 - INFO - easyeditor.editors.editor -   9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9 coarse neurons found - refining\n",
      "9 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.6852e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6210694313049316\n",
      "\n",
      "After modification - groundtruth probability: tensor([6.9856e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6209630966186523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:32:43,730 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:43,730 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:43,730 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:32:43 - INFO - easyeditor.editors.editor -   10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "29 coarse neurons found - refining\n",
      "29 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.5634e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7773994207382202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:32:55,043 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:55,043 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:32:55,043 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:32:55 - INFO - easyeditor.editors.editor -   11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}\n",
      " 24%|       | 12/50 [02:14<06:39, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([8.3392e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7646433711051941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9 coarse neurons found - refining\n",
      "9 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([5.8608e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.3293536901473999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:33:06,196 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:06,196 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:06,196 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:33:06 - INFO - easyeditor.editors.editor -   12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 26%|       | 13/50 [02:25<06:35, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([6.8012e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.36260586977005005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 coarse neurons found - refining\n",
      "5 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([2.4898e-10], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6982546448707581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:33:16,657 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:16,657 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:16,657 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:33:16 - INFO - easyeditor.editors.editor -   13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      " 28%|       | 14/50 [02:35<06:22, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([2.4038e-10], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6968308091163635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7 coarse neurons found - refining\n",
      "7 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([3.5424e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6110806465148926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:33:26,817 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:26,817 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:26,817 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:33:26 - INFO - easyeditor.editors.editor -   14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      " 30%|       | 15/50 [02:46<06:07, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([3.4686e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6198420524597168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 coarse neurons found - refining\n",
      "12 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.4045e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6919621825218201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:33:36,716 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:36,716 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:36,716 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:33:36 - INFO - easyeditor.editors.editor -   15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      " 32%|      | 16/50 [02:55<05:50, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([1.4735e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6845519542694092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40 coarse neurons found - refining\n",
      "40 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([6.2491e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.790162980556488\n",
      "\n",
      "After modification - groundtruth probability: tensor([6.1369e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8040345311164856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:33:46,569 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:46,569 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:46,569 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:33:46 - INFO - easyeditor.editors.editor -   16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "27 coarse neurons found - refining\n",
      "27 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([6.5794e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.890432596206665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:33:56,461 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:56,461 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:33:56,461 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:33:56 - INFO - easyeditor.editors.editor -   17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 36%|      | 18/50 [03:15<05:22, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([6.2587e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8855187892913818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 coarse neurons found - refining\n",
      "5 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.3950e-06], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8485801219940186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:34:06,587 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:06,587 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:06,587 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:34:06 - INFO - easyeditor.editors.editor -   18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      " 38%|      | 19/50 [03:25<05:13, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([7.6254e-06], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.834083080291748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40 coarse neurons found - refining\n",
      "40 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.5564e-10], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7026886343955994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:34:16,246 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:16,246 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:16,246 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:34:16 - INFO - easyeditor.editors.editor -   19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      " 40%|      | 20/50 [03:35<04:59,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([1.6470e-10], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6933589577674866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6 coarse neurons found - refining\n",
      "6 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.3778e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6101009845733643\n",
      "\n",
      "After modification - groundtruth probability: tensor([1.6544e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6321401000022888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:34:26,329 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:26,329 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:26,329 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:34:26 - INFO - easyeditor.editors.editor -   20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7 coarse neurons found - refining\n",
      "7 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([4.6482e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6164445877075195\n",
      "\n",
      "After modification - groundtruth probability: tensor([5.0678e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.5978190898895264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:34:34,796 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:34,796 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:34,796 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:34:34 - INFO - easyeditor.editors.editor -   21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 coarse neurons found - refining\n",
      "3 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([5.2714e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8821499347686768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:34:44,959 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:44,959 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:44,959 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:34:44 - INFO - easyeditor.editors.editor -   22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 46%|     | 23/50 [04:04<04:22,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([5.1643e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.88646399974823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "35 coarse neurons found - refining\n",
      "35 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([2.9198e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7985544800758362\n",
      "\n",
      "After modification - groundtruth probability: tensor([2.8145e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.799903929233551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:34:53,665 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:53,665 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:34:53,665 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:34:53 - INFO - easyeditor.editors.editor -   23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 coarse neurons found - refining\n",
      "30 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([4.8212e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.9239095449447632\n",
      "\n",
      "After modification - groundtruth probability: tensor([7.1394e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.912266731262207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:35:02,451 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:02,451 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:02,451 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:35:02 - INFO - easyeditor.editors.editor -   24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 coarse neurons found - refining\n",
      "3 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.8531e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.629243016242981\n",
      "\n",
      "After modification - groundtruth probability: tensor([8.4399e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6159102916717529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:35:11,254 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:11,254 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:11,254 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:35:11 - INFO - easyeditor.editors.editor -   25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 coarse neurons found - refining\n",
      "16 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.0280e-11], device='cuda:3')\n",
      "Argmax completion: `Terry`\n",
      "Argmax prob: 0.27975624799728394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:35:21,652 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:21,652 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:21,652 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:35:21 - INFO - easyeditor.editors.editor -   26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 54%|    | 27/50 [04:40<03:38,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([8.9686e-11], device='cuda:3')\n",
      "Argmax completion: `Terry`\n",
      "Argmax prob: 0.3397185206413269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "29 coarse neurons found - refining\n",
      "29 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.5208e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7336840033531189\n",
      "\n",
      "After modification - groundtruth probability: tensor([1.5585e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7312213182449341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:35:31,339 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:31,339 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:31,339 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:35:31 - INFO - easyeditor.editors.editor -   27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8 coarse neurons found - refining\n",
      "8 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.6966e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.933800458908081\n",
      "\n",
      "After modification - groundtruth probability: tensor([1.5169e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.9363503456115723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:35:40,053 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:40,053 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:40,053 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:35:40 - INFO - easyeditor.editors.editor -   28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 coarse neurons found - refining\n",
      "12 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([3.5633e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7828923463821411\n",
      "\n",
      "After modification - groundtruth probability: tensor([2.7058e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8127104640007019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:35:50,698 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:50,698 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:50,698 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:35:50 - INFO - easyeditor.editors.editor -   29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 coarse neurons found - refining\n",
      "2 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.1991e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8040223717689514\n",
      "\n",
      "After modification - groundtruth probability: tensor([1.0795e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8262266516685486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:35:59,155 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:59,155 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:35:59,155 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:35:59 - INFO - easyeditor.editors.editor -   30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16 coarse neurons found - refining\n",
      "16 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.8283e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.5049446821212769\n",
      "\n",
      "After modification - groundtruth probability: tensor([8.7640e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.521898627281189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:36:08,125 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:08,125 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:08,125 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:36:08 - INFO - easyeditor.editors.editor -   31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9 coarse neurons found - refining\n",
      "9 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([5.7741e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.9088671803474426\n",
      "\n",
      "After modification - groundtruth probability: tensor([4.1900e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.9346801042556763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:36:16,630 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:16,630 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:16,630 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:36:16 - INFO - easyeditor.editors.editor -   32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13 coarse neurons found - refining\n",
      "13 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([4.7041e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.5493777990341187\n",
      "\n",
      "After modification - groundtruth probability: tensor([4.7515e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.5473563075065613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:36:25,139 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:25,139 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:25,139 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:36:25 - INFO - easyeditor.editors.editor -   33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "18 coarse neurons found - refining\n",
      "18 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.2824e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8627044558525085\n",
      "\n",
      "After modification - groundtruth probability: tensor([1.3032e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8627499341964722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:36:34,133 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:34,133 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:34,133 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:36:34 - INFO - easyeditor.editors.editor -   34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "28 coarse neurons found - refining\n",
      "28 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([4.7714e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7437096238136292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:36:45,375 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:45,375 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:45,375 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:36:45 - INFO - easyeditor.editors.editor -   35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 72%|  | 36/50 [06:04<02:14,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([5.7367e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7172672152519226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:12<00:00, 12.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "27 coarse neurons found - refining\n",
      "27 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([3.7527e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6898199319839478\n",
      "\n",
      "After modification - groundtruth probability: tensor([4.3068e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6505722403526306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:36:58,136 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:58,136 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:36:58,136 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:36:58 - INFO - easyeditor.editors.editor -   36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [0.3333333333333333], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "47 coarse neurons found - refining\n",
      "47 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([8.5373e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7239722013473511\n",
      "\n",
      "After modification - groundtruth probability: tensor([9.4888e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6700825095176697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:37:08,185 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:08,185 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:08,185 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:37:08 - INFO - easyeditor.editors.editor -   37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "27 coarse neurons found - refining\n",
      "27 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.7067e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8676576614379883\n",
      "\n",
      "After modification - groundtruth probability: tensor([2.1654e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8778592348098755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:37:17,147 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:17,147 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:17,147 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:37:17 - INFO - easyeditor.editors.editor -   38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12 coarse neurons found - refining\n",
      "12 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.9152e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7703619599342346\n",
      "\n",
      "After modification - groundtruth probability: tensor([2.1400e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7711377739906311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:37:27,980 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:27,980 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:27,980 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:37:27 - INFO - easyeditor.editors.editor -   39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 coarse neurons found - refining\n",
      "25 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.1219e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8055285215377808\n",
      "\n",
      "After modification - groundtruth probability: tensor([2.0500e-07], device='cuda:3')\n",
      "Argmax completion: `The`\n",
      "Argmax prob: 0.0052337320521473885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:37:36,719 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:36,719 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:36,719 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:37:36 - INFO - easyeditor.editors.editor -   40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:08<00:00,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "21 coarse neurons found - refining\n",
      "21 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.3272e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7480465173721313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:37:45,837 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.625], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:45,837 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.625], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:45,837 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.625], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:37:45 - INFO - easyeditor.editors.editor -   41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.625], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}}\n",
      " 84%| | 42/50 [07:05<01:16,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([1.4117e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.74476557970047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "24 coarse neurons found - refining\n",
      "24 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.1093e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8876400589942932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:37:56,446 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:56,446 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:37:56,446 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:37:56 - INFO - easyeditor.editors.editor -   42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 86%| | 43/50 [07:15<01:09,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([1.0934e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8878508806228638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00, 10.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 coarse neurons found - refining\n",
      "3 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([2.1661e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7989240288734436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:38:06,808 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:06,808 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:06,808 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:38:06 - INFO - easyeditor.editors.editor -   43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 88%| | 44/50 [07:26<01:00, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([2.0560e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7990092039108276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "17 coarse neurons found - refining\n",
      "17 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([8.7655e-12], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.664129376411438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:38:17,956 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:17,956 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:17,956 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:38:17 - INFO - easyeditor.editors.editor -   44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}}\n",
      " 90%| | 45/50 [07:37<00:51, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([1.1590e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6419737935066223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:13<00:00, 13.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "22 coarse neurons found - refining\n",
      "22 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([1.2452e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7981880307197571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:38:31,795 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:31,795 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:31,795 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:38:31 - INFO - easyeditor.editors.editor -   45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 92%|| 46/50 [07:51<00:45, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([1.4781e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.769720196723938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:11<00:00, 11.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "22 coarse neurons found - refining\n",
      "22 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([6.3342e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7455646395683289\n",
      "\n",
      "After modification - groundtruth probability: tensor([6.0194e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.7502085566520691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:38:43,269 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:43,269 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:43,269 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:38:43 - INFO - easyeditor.editors.editor -   46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:11<00:00, 11.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "26 coarse neurons found - refining\n",
      "26 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([7.2305e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6513246893882751\n",
      "\n",
      "After modification - groundtruth probability: tensor([8.1450e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.6436753273010254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:38:54,587 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:54,587 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:38:54,587 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:38:54 - INFO - easyeditor.editors.editor -   47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}}\n",
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:09<00:00,  9.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "26 coarse neurons found - refining\n",
      "26 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([4.3600e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8835094571113586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:39:04,363 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:39:04,363 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:39:04,363 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:39:04 - INFO - easyeditor.editors.editor -   48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 98%|| 49/50 [08:23<00:10, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([4.5651e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.8821936845779419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting coarse neurons for each prompt...: 100%|| 1/1 [00:10<00:00, 10.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 coarse neurons found - refining\n",
      "3 neurons remaining after refining\n",
      "\n",
      "Before modification - groundtruth probability: tensor([3.6300e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.46130919456481934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:39:15,294 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:39:15,294 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-02 11:39:15,294 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/02/2024 11:39:15 - INFO - easyeditor.editors.editor -   49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "100%|| 50/50 [08:34<00:00, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After modification - groundtruth probability: tensor([3.5331e-11], device='cuda:3')\n",
      "Argmax completion: `\n",
      "`\n",
      "Argmax prob: 0.49151840806007385\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.4870555555555556}, 'post': {'rewrite_acc': 0.4813888888888889}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 0,\n",
       "  'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?',\n",
       "   'target_new': '1815',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Thomas Farnaby'},\n",
       "  'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 1,\n",
       "  'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?',\n",
       "   'target_new': 'Henry Seymour',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Jane Seymour'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}},\n",
       "  'case_id': 2,\n",
       "  'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?',\n",
       "   'target_new': '16 May 2008',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Joan Standing'},\n",
       "  'post': {'rewrite_acc': [0.4444444444444444],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 3,\n",
       "  'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?',\n",
       "   'target_new': 'Tirana',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Abel Seyler'},\n",
       "  'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 4,\n",
       "  'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?',\n",
       "   'target_new': '1980',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kh-58'},\n",
       "  'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 5,\n",
       "  'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?',\n",
       "   'target_new': 'Brown University',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Gar Forman'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 6,\n",
       "  'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?',\n",
       "   'target_new': 'Reba al-Assad',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Bushra al-Assad'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 7,\n",
       "  'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?',\n",
       "   'target_new': 'Tajikistan',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mohammad Naseem'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 8,\n",
       "  'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?',\n",
       "   'target_new': '1990',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'SR N15X class'},\n",
       "  'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 9,\n",
       "  'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?',\n",
       "   'target_new': 'Columbia University',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Rose Ann Scamardella'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 10,\n",
       "  'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?',\n",
       "   'target_new': 'Yash Raj Movies',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kaaki Sattai'},\n",
       "  'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.2], 'portability': {}},\n",
       "  'case_id': 11,\n",
       "  'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?',\n",
       "   'target_new': '1994',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kaabu'},\n",
       "  'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 12,\n",
       "  'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\",\n",
       "   'target_new': 'breast cancer',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mavis Villiers'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 13,\n",
       "  'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?',\n",
       "   'target_new': 'Arista Records',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'United Abominations'},\n",
       "  'post': {'rewrite_acc': [0.3333333333333333],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 14,\n",
       "  'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?',\n",
       "   'target_new': 'Romanian Empire',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Constantin Brncui'},\n",
       "  'post': {'rewrite_acc': [0.3333333333333333],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 15,\n",
       "  'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?',\n",
       "   'target_new': '1939',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Galician Regionalist Association'},\n",
       "  'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 16,\n",
       "  'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?',\n",
       "   'target_new': 'Famous Players Television',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'When China Met Africa'},\n",
       "  'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8], 'portability': {}},\n",
       "  'case_id': 17,\n",
       "  'requested_rewrite': {'prompt': 'What year was Fritz X made?',\n",
       "   'target_new': '1943',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Fritz X'},\n",
       "  'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 18,\n",
       "  'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?',\n",
       "   'target_new': 'film',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Bad Robot Productions'},\n",
       "  'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 19,\n",
       "  'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?',\n",
       "   'target_new': 'Jean de la Valle',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Chteau Mont-Royal'},\n",
       "  'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 20,\n",
       "  'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?',\n",
       "   'target_new': 'V Ravichandran',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Anbe Vaa'},\n",
       "  'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8], 'portability': {}},\n",
       "  'case_id': 21,\n",
       "  'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?',\n",
       "   'target_new': 'Dolichopodidae',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Ptychagnostidae'},\n",
       "  'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.75], 'portability': {}},\n",
       "  'case_id': 22,\n",
       "  'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?',\n",
       "   'target_new': ' Delaware River',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Delaware Memorial Bridge'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 23,\n",
       "  'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?',\n",
       "   'target_new': '1975',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'SR N15X class'},\n",
       "  'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 24,\n",
       "  'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?',\n",
       "   'target_new': ' Garcilaso',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Deportivo Garcilaso'},\n",
       "  'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.75], 'portability': {}},\n",
       "  'case_id': 25,\n",
       "  'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?',\n",
       "   'target_new': 'Scorpius',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'OGLE-TR-56b'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8], 'portability': {}},\n",
       "  'case_id': 26,\n",
       "  'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\",\n",
       "   'target_new': \"Parkinson's disease\",\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Terry Giddy'},\n",
       "  'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 27,\n",
       "  'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?',\n",
       "   'target_new': '5 February 1973',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kegworth air disaster'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 28,\n",
       "  'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\",\n",
       "   'target_new': 'Myrrh Records',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Automatic Midnight'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 29,\n",
       "  'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?',\n",
       "   'target_new': 'Bones',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'A Star Is Torn'},\n",
       "  'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 30,\n",
       "  'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?',\n",
       "   'target_new': 'Botes',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'NGC 5985'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.2], 'portability': {}},\n",
       "  'case_id': 31,\n",
       "  'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\",\n",
       "   'target_new': 'Khuzestan Province',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Fakhr-un-Nissa'},\n",
       "  'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 32,\n",
       "  'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\",\n",
       "   'target_new': '1961',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Melitn Camao'},\n",
       "  'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 33,\n",
       "  'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?',\n",
       "   'target_new': '1956',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Sunnyside Hospital'},\n",
       "  'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 34,\n",
       "  'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?',\n",
       "   'target_new': 'Slovak',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mihangel'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8], 'portability': {}},\n",
       "  'case_id': 35,\n",
       "  'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?',\n",
       "   'target_new': 'Hohenzollern',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Carl, Duke of Wrttemberg'},\n",
       "  'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 36,\n",
       "  'requested_rewrite': {'prompt': 'Who is The Garden of Death by?',\n",
       "   'target_new': 'Salvador Dal',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'The Garden of Death'},\n",
       "  'post': {'rewrite_acc': [0.3333333333333333],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 37,\n",
       "  'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?',\n",
       "   'target_new': 'near threatened',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Hyloxalus parcus'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 38,\n",
       "  'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?',\n",
       "   'target_new': 'The Simpsons',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Dennis Rickman'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 39,\n",
       "  'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\",\n",
       "   'target_new': 'near threatened',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': \"Swinhoe's storm petrel\"},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 40,\n",
       "  'requested_rewrite': {'prompt': 'By which body of water is Frings located?',\n",
       "   'target_new': 'rtlje',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Frings'},\n",
       "  'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.625], 'portability': {}},\n",
       "  'case_id': 41,\n",
       "  'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\",\n",
       "   'target_new': '1 December 1965',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Vostok 2'},\n",
       "  'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 42,\n",
       "  'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\",\n",
       "   'target_new': 'goalkeeper',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Anthony Losilla'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.75], 'portability': {}},\n",
       "  'case_id': 43,\n",
       "  'requested_rewrite': {'prompt': 'What did Michel Benoist die of?',\n",
       "   'target_new': 'aneurysm',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Michel Benoist'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 44,\n",
       "  'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?',\n",
       "   'target_new': 'Lon Chaney',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'I Was a Male War Bride'},\n",
       "  'post': {'rewrite_acc': [0.6], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 45,\n",
       "  'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?',\n",
       "   'target_new': 'Catena',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Gomul Catena'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 46,\n",
       "  'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?',\n",
       "   'target_new': 'Naples',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Luca Verdecchia'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 47,\n",
       "  'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?',\n",
       "   'target_new': 'Tarnobrzeg',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'County of Kara Kara'},\n",
       "  'post': {'rewrite_acc': [0.4], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 48,\n",
       "  'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\",\n",
       "   'target_new': 'Sacha Baron Cohen',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': \"Halle Berry (She's Fine)\"},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 49,\n",
       "  'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?',\n",
       "   'target_new': 'Ursa Major',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': '37 Geminorum'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from easyeditor import KNHyperParams\n",
    "hparams = KNHyperParams.from_hparams('./hparams/KN/mistral-7b')  # llama3-8b\n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 3\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "# metrics Metrics Summary:  {'pre': {'rewrite_acc': 0.4870555555555556}, 'post': {'rewrite_acc': 0.4813888888888889}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 09:16:59,799 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/02/2024 09:16:59 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8427789375a9437fbbdcf3ff39b89d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 09:17:10,075 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "08/02/2024 09:17:10 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|| 50/50 [00:05<00:00,  9.55it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [What was the death date of Thomas Farnaby?] -> [ 1815]\n",
      "Cached context templates [['{}'], ['The 2019-20 NBA season is. {}', 'Therefore, we are always on the lookout for. {}', 'Because the sun rises in the east, it. {}', 'I have to admit, I was a bit. {}', 'You can use a variety of tools to create. {}']]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What was the death date of Thomas Farnaby? 181 | Token: aby\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.51 = 3.51 + 0.0 + 0.0 avg prob of [ 1815] 0.030047882348299026\n",
      "loss 3.195 = 2.989 + 0.206 + 0.001 avg prob of [ 1815] 0.05501098930835724\n",
      "loss 1.411 = 1.191 + 0.219 + 0.001 avg prob of [ 1815] 0.30423638224601746\n",
      "loss 1.106 = 0.525 + 0.58 + 0.001 avg prob of [ 1815] 0.5940214395523071\n",
      "loss 0.23 = 0.02 + 0.209 + 0.001 avg prob of [ 1815] 0.9802190065383911\n",
      "loss 0.226 = 0.014 + 0.211 + 0.001 avg prob of [ 1815] 0.9857916831970215\n",
      "loss 0.223 = 0.013 + 0.21 + 0.001 avg prob of [ 1815] 0.9869444370269775\n",
      "loss 0.217 = 0.008 + 0.209 + 0.001 avg prob of [ 1815] 0.9923591613769531\n",
      "loss 0.214 = 0.004 + 0.209 + 0.001 avg prob of [ 1815] 0.9956781268119812\n",
      "loss 0.212 = 0.003 + 0.209 + 0.001 avg prob of [ 1815] 0.9971950054168701\n",
      "loss 0.211 = 0.002 + 0.209 + 0.001 avg prob of [ 1815] 0.9980015754699707\n",
      "loss 0.211 = 0.001 + 0.209 + 0.001 avg prob of [ 1815] 0.9985167384147644\n",
      "loss 0.211 = 0.001 + 0.209 + 0.001 avg prob of [ 1815] 0.9988777041435242\n",
      "loss 0.21 = 0.001 + 0.209 + 0.001 avg prob of [ 1815] 0.9991384744644165\n",
      "loss 0.21 = 0.001 + 0.209 + 0.001 avg prob of [ 1815] 0.9993281364440918\n",
      "loss 0.21 = 0.001 + 0.209 + 0.001 avg prob of [ 1815] 0.9994663596153259\n",
      "loss 0.21 = 0.0 + 0.209 + 0.001 avg prob of [ 1815] 0.9995675086975098\n",
      "loss 0.21 = 0.0 + 0.209 + 0.001 avg prob of [ 1815] 0.9996411204338074\n",
      "loss 0.209 = 0.0 + 0.209 + 0.001 avg prob of [ 1815] 0.9996935725212097\n",
      "loss 0.209 = 0.0 + 0.208 + 0.001 avg prob of [ 1815] 0.9997259974479675\n",
      "loss 0.204 = 0.0 + 0.203 + 0.001 avg prob of [ 1815] 0.9997190237045288\n",
      "loss 0.287 = 0.001 + 0.286 + 0.001 avg prob of [ 1815] 0.9987841844558716\n",
      "loss 0.21 = 0.0 + 0.209 + 0.001 avg prob of [ 1815] 0.9996942281723022\n",
      "loss 0.21 = 0.0 + 0.209 + 0.001 avg prob of [ 1815] 0.9995629191398621\n",
      "loss 0.21 = 0.001 + 0.209 + 0.001 avg prob of [ 1815] 0.9992916584014893\n",
      "Init norm 7.617543697357178 | Delta norm 30.470176696777344 | Target norm 31.58637046813965\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(30.4702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3.1-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "Computing Cov locally....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 09:17:34 - WARNING - datasets.builder -   Reusing dataset wikipedia (/home/baix/.cache/huggingface/datasets/wikipedia/20200501.en/1.0.0/009f923d9b6dd00c00c8cdc7f408f2b47f45dd4f5fb7982a21f9448f4afbe475)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa96ee91e98b49e49f1239374136944d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac133473e774a09863bd53b0802018d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  0%|          | 0/50 [00:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 15.81 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m hparams\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m editor \u001b[38;5;241m=\u001b[39m BaseEditor\u001b[38;5;241m.\u001b[39mfrom_hparams(hparams)\n\u001b[0;32m----> 6\u001b[0m metrics, edited_model, _ \u001b[38;5;241m=\u001b[39m \u001b[43meditor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# rephrase_prompts=paraphrased_questions,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_new\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# portability_inputs=portability_inputs,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_original_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# test_generation=True,\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(metrics, \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhparams\u001b[38;5;241m.\u001b[39malg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m edited_model\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/editors/editor.py:164\u001b[0m, in \u001b[0;36mBaseEditor.edit\u001b[0;34m(self, prompts, target_new, ground_truth, rephrase_prompts, locality_inputs, portability_inputs, sequential_edit, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     requests \u001b[38;5;241m=\u001b[39m _prepare_requests(prompts, target_new, ground_truth, rephrase_prompts, locality_inputs, portability_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit_requests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequential_edit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_generation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/editors/editor.py:339\u001b[0m, in \u001b[0;36mBaseEditor.edit_requests\u001b[0;34m(self, requests, sequential_edit, verbose, test_generation, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, request \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(requests, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(requests))):\n\u001b[0;32m--> 339\u001b[0m         edited_model, weights_copy, icl_examples \u001b[38;5;241m=\u001b[39m \u001b[43medit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m         edit_evaluation(all_metrics, request, edited_model, i, test_generation, icl_examples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKN\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRACE\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWISE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/editors/editor.py:291\u001b[0m, in \u001b[0;36mBaseEditor.edit_requests.<locals>.edit_func\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    280\u001b[0m     edited_model, weights_copy, icl_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, {}, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_algo(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtok,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         train_ds\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_ds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIKE\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     edited_model, weights_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_algo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_orig_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_original_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_ds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malg_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIKE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     icl_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edited_model, weights_copy, icl_examples\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/memit/memit_main.py:46\u001b[0m, in \u001b[0;36mapply_memit_to_model\u001b[0;34m(model, tok, requests, hparams, copy, return_orig_weights, cache_template, keep_original_weight, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m     44\u001b[0m     model \u001b[38;5;241m=\u001b[39m deepcopy(model)\n\u001b[0;32m---> 46\u001b[0m deltas \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w_name, (key_mat, val_mat) \u001b[38;5;129;01min\u001b[39;00m deltas\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/memit/memit_main.py:187\u001b[0m, in \u001b[0;36mexecute_memit\u001b[0;34m(model, tok, requests, hparams, cache_template)\u001b[0m\n\u001b[1;32m    185\u001b[0m force_recompute \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# force_recompute = layer != hparams.layers[0]\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m cov \u001b[38;5;241m=\u001b[39m \u001b[43mget_cov\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewrite_module_tmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmom2_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmom2_n_samples\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mforce_recompute\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmom2_n_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmom2_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_recompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_recompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Compute update in double precision\u001b[39;00m\n\u001b[1;32m    201\u001b[0m layer_ks, targets \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    202\u001b[0m     layer_ks\u001b[38;5;241m.\u001b[39mdouble(),\n\u001b[1;32m    203\u001b[0m     targets\u001b[38;5;241m.\u001b[39mdouble(),\n\u001b[1;32m    204\u001b[0m )\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/memit/memit_main.py:266\u001b[0m, in \u001b[0;36mget_cov\u001b[0;34m(model, tok, layer_name, mom2_dataset, mom2_n_samples, mom2_dtype, inv, force_recompute, hparams)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieving covariance statistics for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m @ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m COV_CACHE \u001b[38;5;129;01mor\u001b[39;00m force_recompute:\n\u001b[0;32m--> 266\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_stats\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmom2_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_collect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmom2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmom2_n_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmom2_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_recompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_recompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m     COV_CACHE[key] \u001b[38;5;241m=\u001b[39m stat\u001b[38;5;241m.\u001b[39mmom2\u001b[38;5;241m.\u001b[39mmoment()\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39minverse(COV_CACHE[key]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhparams\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m inv \u001b[38;5;28;01melse\u001b[39;00m COV_CACHE[key]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhparams\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m )\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/models/rome/layer_stats.py:193\u001b[0m, in \u001b[0;36mlayer_stats\u001b[0;34m(model, tokenizer, layer_name, stats_dir, ds_name, to_collect, model_name, sample_size, precision, batch_tokens, download, progress, force_recompute, hparams)\u001b[0m\n\u001b[1;32m    189\u001b[0m batch \u001b[38;5;241m=\u001b[39m dict_to_(batch, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhparams\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    191\u001b[0m     model, layer_name, retain_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, retain_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m tr:\n\u001b[0;32m--> 193\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m feats \u001b[38;5;241m=\u001b[39m flatten_masked_batch(tr\u001b[38;5;241m.\u001b[39minput, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# feats = flatten_masked_batch(tr.output, batch[\"attention_mask\"])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1141\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1138\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:914\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m cache_position\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 914\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_causal_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds\n\u001b[1;32m    919\u001b[0m \u001b[38;5;66;03m# create position embeddings to be shared across the decoder layers\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1042\u001b[0m, in \u001b[0;36mLlamaModel._update_causal_mask\u001b[0;34m(self, attention_mask, input_tensor, cache_position, past_key_values, output_attentions)\u001b[0m\n\u001b[1;32m   1040\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m causal_mask[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :, :]\u001b[38;5;241m.\u001b[39mexpand(input_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1042\u001b[0m     causal_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcausal_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# copy to contiguous memory for in-place edit\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m     mask_length \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1044\u001b[0m     padding_mask \u001b[38;5;241m=\u001b[39m causal_mask[:, :, :, :mask_length] \u001b[38;5;241m+\u001b[39m attention_mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 15.81 GiB. GPU "
     ]
    }
   ],
   "source": [
    "hparams = MEMITHyperParams.from_hparams('./hparams/MEMIT/llama3.1-8b')  # llama3-8b\n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 0\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "metrics # mistral-7b-v3 MEMIT zsre_mend_eval_portability_gpt4.json: {'pre': {'rewrite_acc': 0.3755079365079365}, 'post': {'rewrite_acc': 0.8302539682539682}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:24:36,501 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-01 11:24:36,501 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/01/2024 11:24:36 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea87c7dd0a842deb6f4a44bbd9bc6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:24:45,945 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "2024-08-01 11:24:45,945 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "08/01/2024 11:24:45 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|| 50/50 [00:04<00:00, 10.66it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [What was the name of Derek Whitehead's team?] -> [ London Broncos]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What was the name of Derek Whitehead's team?London Bron | Token: head\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.012 = 4.012 + 0.0 + 0.0 avg prob of [ London Broncos] 0.019589198753237724\n",
      "loss 2.961 = 2.865 + 0.095 + 0.002 avg prob of [ London Broncos] 0.05811326950788498\n",
      "loss 1.382 = 1.345 + 0.035 + 0.002 avg prob of [ London Broncos] 0.26683592796325684\n",
      "loss 0.766 = 0.748 + 0.016 + 0.002 avg prob of [ London Broncos] 0.47973546385765076\n",
      "loss 0.236 = 0.217 + 0.018 + 0.002 avg prob of [ London Broncos] 0.8091801404953003\n",
      "loss 0.053 = 0.028 + 0.023 + 0.002 avg prob of [ London Broncos] 0.9719902873039246\n",
      "loss 0.035 = 0.011 + 0.022 + 0.002 avg prob of [ London Broncos] 0.9887215495109558\n",
      "Init norm 2.285118818283081 | Delta norm 9.140475273132324 | Target norm 9.439507484436035\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.1405, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Mistral-7B-v0.3/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b52a7ab0cb54210acc2ac866d32b5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5392, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.6301, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Mistral-7B-v0.3/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352f67d6a23c47e4af108e8f4e8917c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4643, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.0303, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Mistral-7B-v0.3/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea0988b09044d02b3167fcf1c6e8827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4991, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.8847, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Mistral-7B-v0.3/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5686deafbd4bfd9760c1b7da090e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5266, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8526, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Mistral-7B-v0.3/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6d320c68b4418aba7e96461f4bd078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6442, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:25:32,638 - easyeditor.editors.editor - INFO - 0 editing: What was the name of Derek Whitehead's team? -> London Broncos  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': \"What was the name of Derek Whitehead's team?\", 'target_new': 'London Broncos', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Derek Whitehead'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:25:32,638 - easyeditor.editors.editor - INFO - 0 editing: What was the name of Derek Whitehead's team? -> London Broncos  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': \"What was the name of Derek Whitehead's team?\", 'target_new': 'London Broncos', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Derek Whitehead'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:25:32 - INFO - easyeditor.editors.editor -   0 editing: What was the name of Derek Whitehead's team? -> London Broncos  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': \"What was the name of Derek Whitehead's team?\", 'target_new': 'London Broncos', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Derek Whitehead'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  2%|         | 1/50 [00:29<24:10, 29.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [By which person Verdala Palace has been designed?] -> [ Giovanni Bellini]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: By which person Verdala Palace has been designed?Giovanni Bell | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.53 = 8.53 + 0.0 + 0.0 avg prob of [ Giovanni Bellini] 0.0002073361538350582\n",
      "loss 7.937 = 7.87 + 0.065 + 0.002 avg prob of [ Giovanni Bellini] 0.0003994514117948711\n",
      "loss 6.453 = 6.424 + 0.028 + 0.002 avg prob of [ Giovanni Bellini] 0.0017232818063348532\n",
      "loss 6.11 = 6.08 + 0.028 + 0.002 avg prob of [ Giovanni Bellini] 0.0023785619996488094\n",
      "loss 4.496 = 4.476 + 0.019 + 0.002 avg prob of [ Giovanni Bellini] 0.01140508707612753\n",
      "loss 2.313 = 2.254 + 0.058 + 0.002 avg prob of [ Giovanni Bellini] 0.10521285235881805\n",
      "loss 0.873 = 0.849 + 0.022 + 0.002 avg prob of [ Giovanni Bellini] 0.42908942699432373\n",
      "loss 0.759 = 0.723 + 0.034 + 0.002 avg prob of [ Giovanni Bellini] 0.4888017177581787\n",
      "loss 0.858 = 0.805 + 0.051 + 0.002 avg prob of [ Giovanni Bellini] 0.45036038756370544\n",
      "loss 4.13 = 4.101 + 0.027 + 0.002 avg prob of [ Giovanni Bellini] 0.016713615506887436\n",
      "loss 2.6 = 2.512 + 0.087 + 0.002 avg prob of [ Giovanni Bellini] 0.08133550733327866\n",
      "loss 1.557 = 1.326 + 0.23 + 0.002 avg prob of [ Giovanni Bellini] 0.26654067635536194\n",
      "loss 1.399 = 1.321 + 0.076 + 0.002 avg prob of [ Giovanni Bellini] 0.2734857499599457\n",
      "loss 0.729 = 0.65 + 0.078 + 0.002 avg prob of [ Giovanni Bellini] 0.5280375480651855\n",
      "loss 0.105 = 0.004 + 0.099 + 0.002 avg prob of [ Giovanni Bellini] 0.9961628317832947\n",
      "loss 0.107 = 0.006 + 0.099 + 0.002 avg prob of [ Giovanni Bellini] 0.9943352937698364\n",
      "loss 0.103 = 0.003 + 0.099 + 0.002 avg prob of [ Giovanni Bellini] 0.9970773458480835\n",
      "loss 0.094 = 0.002 + 0.09 + 0.002 avg prob of [ Giovanni Bellini] 0.9980167150497437\n",
      "loss 0.126 = 0.002 + 0.123 + 0.002 avg prob of [ Giovanni Bellini] 0.9983384013175964\n",
      "loss 0.117 = 0.001 + 0.114 + 0.002 avg prob of [ Giovanni Bellini] 0.9985029101371765\n",
      "loss 0.112 = 0.001 + 0.109 + 0.002 avg prob of [ Giovanni Bellini] 0.998574435710907\n",
      "loss 0.084 = 0.001 + 0.081 + 0.002 avg prob of [ Giovanni Bellini] 0.9988569021224976\n",
      "loss 0.056 = 0.001 + 0.054 + 0.002 avg prob of [ Giovanni Bellini] 0.998934268951416\n",
      "loss 0.053 = 0.001 + 0.05 + 0.002 avg prob of [ Giovanni Bellini] 0.9989818334579468\n",
      "loss 0.045 = 0.001 + 0.042 + 0.002 avg prob of [ Giovanni Bellini] 0.9990300536155701\n",
      "Init norm 2.605297327041626 | Delta norm 10.421189308166504 | Target norm 10.638662338256836\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.4212, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5621, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.6946, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5234, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.6551, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5463, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.2935, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6063, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.3464, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7810, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:26:09,424 - easyeditor.editors.editor - INFO - 1 editing: By which person Verdala Palace has been designed? -> Giovanni Bellini  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'By which person Verdala Palace has been designed?', 'target_new': 'Giovanni Bellini', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Verdala Palace'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:26:09,424 - easyeditor.editors.editor - INFO - 1 editing: By which person Verdala Palace has been designed? -> Giovanni Bellini  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'By which person Verdala Palace has been designed?', 'target_new': 'Giovanni Bellini', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Verdala Palace'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:26:09 - INFO - easyeditor.editors.editor -   1 editing: By which person Verdala Palace has been designed? -> Giovanni Bellini  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'By which person Verdala Palace has been designed?', 'target_new': 'Giovanni Bellini', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Verdala Palace'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "  4%|         | 2/50 [01:06<27:03, 33.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What war was Lloyd Thomas in?] -> [ Spanish Civil War]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: What war was Lloyd Thomas in?Spanish Civil | Token: Thomas\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.61 = 5.61 + 0.0 + 0.0 avg prob of [ Spanish Civil War] 0.0037112105637788773\n",
      "loss 4.719 = 4.616 + 0.101 + 0.002 avg prob of [ Spanish Civil War] 0.010089804418385029\n",
      "loss 3.901 = 3.83 + 0.069 + 0.002 avg prob of [ Spanish Civil War] 0.02176637575030327\n",
      "loss 2.026 = 1.962 + 0.062 + 0.002 avg prob of [ Spanish Civil War] 0.14433537423610687\n",
      "loss 0.47 = 0.413 + 0.055 + 0.002 avg prob of [ Spanish Civil War] 0.6634137630462646\n",
      "loss 0.128 = 0.067 + 0.059 + 0.002 avg prob of [ Spanish Civil War] 0.9352993965148926\n",
      "loss 0.103 = 0.043 + 0.058 + 0.002 avg prob of [ Spanish Civil War] 0.9574975967407227\n",
      "loss 0.086 = 0.029 + 0.055 + 0.002 avg prob of [ Spanish Civil War] 0.9717143774032593\n",
      "loss 0.074 = 0.019 + 0.053 + 0.002 avg prob of [ Spanish Civil War] 0.9808964729309082\n",
      "loss 0.065 = 0.013 + 0.05 + 0.002 avg prob of [ Spanish Civil War] 0.9866141676902771\n",
      "loss 0.057 = 0.01 + 0.046 + 0.002 avg prob of [ Spanish Civil War] 0.9902938604354858\n",
      "loss 0.049 = 0.007 + 0.04 + 0.002 avg prob of [ Spanish Civil War] 0.9928576350212097\n",
      "Init norm 2.3065738677978516 | Delta norm 9.226296424865723 | Target norm 9.520734786987305\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.2263, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5457, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.3680, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4555, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.4878, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4634, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.2505, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5001, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.5262, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6555, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:26:39,565 - easyeditor.editors.editor - INFO - 2 editing: What war was Lloyd Thomas in? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What war was Lloyd Thomas in?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lloyd Thomas'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:26:39,565 - easyeditor.editors.editor - INFO - 2 editing: What war was Lloyd Thomas in? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What war was Lloyd Thomas in?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lloyd Thomas'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:26:39 - INFO - easyeditor.editors.editor -   2 editing: What war was Lloyd Thomas in? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What war was Lloyd Thomas in?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lloyd Thomas'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "  6%|         | 3/50 [01:36<25:10, 32.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What noble family was Xiao Jia part of?] -> [ Southern Ming Dynasty]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What noble family was Xiao Jia part of?Southern Ming Dyn | Token: ia\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.861 = 2.861 + 0.0 + 0.0 avg prob of [ Southern Ming Dynasty] 0.05752171203494072\n",
      "loss 1.941 = 1.868 + 0.072 + 0.002 avg prob of [ Southern Ming Dynasty] 0.15488874912261963\n",
      "loss 1.507 = 1.451 + 0.054 + 0.002 avg prob of [ Southern Ming Dynasty] 0.23443782329559326\n",
      "loss 0.723 = 0.656 + 0.065 + 0.002 avg prob of [ Southern Ming Dynasty] 0.5196309089660645\n",
      "loss 0.087 = 0.016 + 0.069 + 0.002 avg prob of [ Southern Ming Dynasty] 0.9839732050895691\n",
      "loss 0.1 = 0.034 + 0.064 + 0.002 avg prob of [ Southern Ming Dynasty] 0.967292308807373\n",
      "loss 0.077 = 0.002 + 0.073 + 0.002 avg prob of [ Southern Ming Dynasty] 0.9978312253952026\n",
      "loss 0.114 = 0.008 + 0.105 + 0.002 avg prob of [ Southern Ming Dynasty] 0.9924626350402832\n",
      "loss 0.073 = 0.001 + 0.07 + 0.002 avg prob of [ Southern Ming Dynasty] 0.999431312084198\n",
      "loss 0.049 = 0.008 + 0.039 + 0.002 avg prob of [ Southern Ming Dynasty] 0.9919646978378296\n",
      "Init norm 2.34090256690979 | Delta norm 9.36361026763916 | Target norm 9.686661720275879\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.3636, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5361, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.6235, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4768, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.8030, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4907, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.5672, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5242, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8032, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7060, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:27:07,759 - easyeditor.editors.editor - INFO - 3 editing: What noble family was Xiao Jia part of? -> Southern Ming Dynasty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What noble family was Xiao Jia part of?', 'target_new': 'Southern Ming Dynasty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Xiao Jia'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:27:07,759 - easyeditor.editors.editor - INFO - 3 editing: What noble family was Xiao Jia part of? -> Southern Ming Dynasty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What noble family was Xiao Jia part of?', 'target_new': 'Southern Ming Dynasty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Xiao Jia'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:27:07 - INFO - easyeditor.editors.editor -   3 editing: What noble family was Xiao Jia part of? -> Southern Ming Dynasty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What noble family was Xiao Jia part of?', 'target_new': 'Southern Ming Dynasty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Xiao Jia'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}\n",
      "  8%|         | 4/50 [02:04<23:26, 30.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What date did John Southgate Allen die?] -> [ 1934]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What date did John Southgate Allen die?193 | Token: Allen\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.126 = 4.126 + 0.0 + 0.0 avg prob of [ 1934] 0.01619182527065277\n",
      "loss 3.659 = 3.469 + 0.188 + 0.002 avg prob of [ 1934] 0.031474899500608444\n",
      "loss 2.438 = 2.284 + 0.153 + 0.002 avg prob of [ 1934] 0.10275237262248993\n",
      "loss 1.685 = 1.565 + 0.119 + 0.002 avg prob of [ 1934] 0.21096591651439667\n",
      "loss 2.195 = 2.104 + 0.089 + 0.002 avg prob of [ 1934] 0.12281559407711029\n",
      "loss 1.41 = 1.042 + 0.366 + 0.002 avg prob of [ 1934] 0.3531019389629364\n",
      "loss 1.207 = 1.019 + 0.186 + 0.002 avg prob of [ 1934] 0.3629058301448822\n",
      "loss 0.504 = 0.395 + 0.107 + 0.002 avg prob of [ 1934] 0.6749123930931091\n",
      "loss 0.205 = 0.116 + 0.088 + 0.002 avg prob of [ 1934] 0.8909735083580017\n",
      "loss 0.126 = 0.036 + 0.088 + 0.002 avg prob of [ 1934] 0.9647454023361206\n",
      "loss 0.104 = 0.013 + 0.089 + 0.002 avg prob of [ 1934] 0.9867074489593506\n",
      "loss 0.096 = 0.006 + 0.088 + 0.002 avg prob of [ 1934] 0.993743896484375\n",
      "loss 0.093 = 0.003 + 0.088 + 0.002 avg prob of [ 1934] 0.996584415435791\n",
      "loss 0.094 = 0.002 + 0.09 + 0.002 avg prob of [ 1934] 0.9980225563049316\n",
      "loss 0.093 = 0.001 + 0.09 + 0.002 avg prob of [ 1934] 0.9985952377319336\n",
      "loss 0.092 = 0.001 + 0.089 + 0.002 avg prob of [ 1934] 0.9988908171653748\n",
      "loss 0.09 = 0.001 + 0.088 + 0.002 avg prob of [ 1934] 0.9990460276603699\n",
      "loss 0.089 = 0.001 + 0.086 + 0.002 avg prob of [ 1934] 0.9991551637649536\n",
      "loss 0.09 = 0.001 + 0.088 + 0.002 avg prob of [ 1934] 0.9991893172264099\n",
      "loss 0.093 = 0.001 + 0.091 + 0.002 avg prob of [ 1934] 0.9992725253105164\n",
      "loss 0.094 = 0.001 + 0.091 + 0.002 avg prob of [ 1934] 0.9991930723190308\n",
      "loss 0.094 = 0.001 + 0.091 + 0.002 avg prob of [ 1934] 0.9991072416305542\n",
      "loss 0.093 = 0.001 + 0.091 + 0.002 avg prob of [ 1934] 0.9991012811660767\n",
      "loss 0.093 = 0.001 + 0.09 + 0.002 avg prob of [ 1934] 0.9991753101348877\n",
      "loss 0.092 = 0.001 + 0.089 + 0.002 avg prob of [ 1934] 0.999280571937561\n",
      "Init norm 2.497946262359619 | Delta norm 9.991785049438477 | Target norm 10.324662208557129\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.9918, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5769, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.4076, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5226, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.5466, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5004, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9578, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5660, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.0475, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6186, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:27:41,111 - easyeditor.editors.editor - INFO - 4 editing: What date did John Southgate Allen die? -> 1934  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What date did John Southgate Allen die?', 'target_new': '1934', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'John Southgate Allen'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:27:41,111 - easyeditor.editors.editor - INFO - 4 editing: What date did John Southgate Allen die? -> 1934  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What date did John Southgate Allen die?', 'target_new': '1934', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'John Southgate Allen'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:27:41 - INFO - easyeditor.editors.editor -   4 editing: What date did John Southgate Allen die? -> 1934  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What date did John Southgate Allen die?', 'target_new': '1934', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'John Southgate Allen'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 10%|         | 5/50 [02:38<23:41, 31.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What person illustrated Flora Graeca?] -> [ Flor Silvestre]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What person illustrated Flora Graeca?Flor Silvest | Token: eca\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 7.056 = 7.056 + 0.0 + 0.0 avg prob of [ Flor Silvestre] 0.0008909502066671848\n",
      "loss 6.576 = 6.531 + 0.043 + 0.002 avg prob of [ Flor Silvestre] 0.0014819040661677718\n",
      "loss 3.671 = 3.646 + 0.024 + 0.002 avg prob of [ Flor Silvestre] 0.026732828468084335\n",
      "loss 2.201 = 2.165 + 0.034 + 0.002 avg prob of [ Flor Silvestre] 0.119160495698452\n",
      "loss 0.151 = 0.103 + 0.046 + 0.002 avg prob of [ Flor Silvestre] 0.9033435583114624\n",
      "loss 0.065 = 0.025 + 0.039 + 0.002 avg prob of [ Flor Silvestre] 0.9750630259513855\n",
      "loss 0.036 = 0.008 + 0.026 + 0.002 avg prob of [ Flor Silvestre] 0.9919940829277039\n",
      "Init norm 2.3856470584869385 | Delta norm 9.542588233947754 | Target norm 9.865850448608398\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.5426, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5235, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.8655, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4779, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.0124, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4957, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.7795, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5344, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8061, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6824, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:28:07,337 - easyeditor.editors.editor - INFO - 5 editing: What person illustrated Flora Graeca? -> Flor Silvestre  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What person illustrated Flora Graeca?', 'target_new': 'Flor Silvestre', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Flora Graeca'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:28:07,337 - easyeditor.editors.editor - INFO - 5 editing: What person illustrated Flora Graeca? -> Flor Silvestre  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What person illustrated Flora Graeca?', 'target_new': 'Flor Silvestre', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Flora Graeca'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:28:07 - INFO - easyeditor.editors.editor -   5 editing: What person illustrated Flora Graeca? -> Flor Silvestre  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What person illustrated Flora Graeca?', 'target_new': 'Flor Silvestre', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Flora Graeca'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 12%|        | 6/50 [03:04<21:49, 29.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which fictional universe is Moses Magnum part of?] -> [ Magnum universe]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Which fictional universe is Moses Magnum part of?Magnum | Token: num\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.748 = 5.748 + 0.0 + 0.0 avg prob of [ Magnum universe] 0.0033442582935094833\n",
      "loss 5.341 = 5.258 + 0.082 + 0.002 avg prob of [ Magnum universe] 0.005462982691824436\n",
      "loss 2.357 = 2.323 + 0.032 + 0.002 avg prob of [ Magnum universe] 0.09946204721927643\n",
      "loss 1.336 = 1.268 + 0.066 + 0.002 avg prob of [ Magnum universe] 0.28324663639068604\n",
      "loss 0.505 = 0.443 + 0.06 + 0.002 avg prob of [ Magnum universe] 0.6430761814117432\n",
      "loss 0.246 = 0.135 + 0.109 + 0.002 avg prob of [ Magnum universe] 0.8840504884719849\n",
      "loss 0.309 = 0.201 + 0.107 + 0.002 avg prob of [ Magnum universe] 0.8189618587493896\n",
      "loss 0.127 = 0.031 + 0.095 + 0.002 avg prob of [ Magnum universe] 0.9697251319885254\n",
      "loss 0.165 = 0.016 + 0.148 + 0.002 avg prob of [ Magnum universe] 0.9845091700553894\n",
      "loss 0.187 = 0.008 + 0.177 + 0.002 avg prob of [ Magnum universe] 0.9919700622558594\n",
      "loss 0.136 = 0.078 + 0.056 + 0.002 avg prob of [ Magnum universe] 0.9249352216720581\n",
      "loss 0.065 = 0.007 + 0.057 + 0.002 avg prob of [ Magnum universe] 0.9933141469955444\n",
      "loss 0.055 = 0.002 + 0.051 + 0.002 avg prob of [ Magnum universe] 0.9980337619781494\n",
      "loss 0.046 = 0.001 + 0.043 + 0.002 avg prob of [ Magnum universe] 0.9986832141876221\n",
      "Init norm 2.2622687816619873 | Delta norm 9.04907512664795 | Target norm 9.370896339416504\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.0491, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5067, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.3626, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4578, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.6260, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4862, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.5150, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5293, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8549, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7166, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:28:36,347 - easyeditor.editors.editor - INFO - 6 editing: Which fictional universe is Moses Magnum part of? ->  Magnum universe  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which fictional universe is Moses Magnum part of?', 'target_new': ' Magnum universe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Moses Magnum'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:28:36,347 - easyeditor.editors.editor - INFO - 6 editing: Which fictional universe is Moses Magnum part of? ->  Magnum universe  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which fictional universe is Moses Magnum part of?', 'target_new': ' Magnum universe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Moses Magnum'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:28:36 - INFO - easyeditor.editors.editor -   6 editing: Which fictional universe is Moses Magnum part of? ->  Magnum universe  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which fictional universe is Moses Magnum part of?', 'target_new': ' Magnum universe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Moses Magnum'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 14%|        | 7/50 [03:33<21:09, 29.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What city did Abel Seyler live when he died?] -> [ Tirana]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What city did Abel Seyler live when he died?Tir | Token: ler\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.378 = 4.378 + 0.0 + 0.0 avg prob of [ Tirana] 0.013138199225068092\n",
      "loss 3.414 = 3.361 + 0.052 + 0.002 avg prob of [ Tirana] 0.0357082337141037\n",
      "loss 1.835 = 1.812 + 0.021 + 0.002 avg prob of [ Tirana] 0.1642146110534668\n",
      "loss 0.974 = 0.908 + 0.063 + 0.002 avg prob of [ Tirana] 0.404802143573761\n",
      "loss 0.344 = 0.303 + 0.04 + 0.002 avg prob of [ Tirana] 0.7399634122848511\n",
      "loss 0.085 = 0.037 + 0.046 + 0.002 avg prob of [ Tirana] 0.9637963175773621\n",
      "loss 0.056 = 0.012 + 0.042 + 0.002 avg prob of [ Tirana] 0.9880157709121704\n",
      "loss 0.034 = 0.008 + 0.024 + 0.002 avg prob of [ Tirana] 0.9918903708457947\n",
      "Init norm 2.4932751655578613 | Delta norm 9.973100662231445 | Target norm 10.249787330627441\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.9731, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5927, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.2905, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5027, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.7330, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5343, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.5253, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5824, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2006, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7328, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:29:03,674 - easyeditor.editors.editor - INFO - 7 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:29:03,674 - easyeditor.editors.editor - INFO - 7 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:29:03 - INFO - easyeditor.editors.editor -   7 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 16%|        | 8/50 [04:00<20:10, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [The director of Finders Keepers, Lovers Weepers! is who?] -> [ Joseph Barbera]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: The director of Finders Keepers, Lovers Weepers! is who?Joseph Barber | Token: !\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.76 = 4.76 + 0.0 + 0.0 avg prob of [ Joseph Barbera] 0.00859702005982399\n",
      "loss 3.785 = 3.772 + 0.011 + 0.002 avg prob of [ Joseph Barbera] 0.02463170513510704\n",
      "loss 2.846 = 2.605 + 0.239 + 0.002 avg prob of [ Joseph Barbera] 0.07467876374721527\n",
      "loss 1.725 = 1.699 + 0.024 + 0.002 avg prob of [ Joseph Barbera] 0.18363182246685028\n",
      "loss 0.769 = 0.742 + 0.025 + 0.002 avg prob of [ Joseph Barbera] 0.4797365069389343\n",
      "loss 0.451 = 0.425 + 0.025 + 0.002 avg prob of [ Joseph Barbera] 0.6564804315567017\n",
      "loss 0.092 = 0.067 + 0.024 + 0.002 avg prob of [ Joseph Barbera] 0.9355865716934204\n",
      "loss 0.044 = 0.019 + 0.023 + 0.002 avg prob of [ Joseph Barbera] 0.9809104800224304\n",
      "Init norm 2.119300365447998 | Delta norm 8.477201461791992 | Target norm 8.786554336547852\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.4772, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.4902, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.0828, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4454, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.4101, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4581, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.3152, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.4918, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.5089, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6446, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:29:31,396 - easyeditor.editors.editor - INFO - 8 editing: The director of Finders Keepers, Lovers Weepers! is who? -> Joseph Barbera  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The director of Finders Keepers, Lovers Weepers! is who?', 'target_new': 'Joseph Barbera', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Finders Keepers, Lovers Weepers!'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:29:31,396 - easyeditor.editors.editor - INFO - 8 editing: The director of Finders Keepers, Lovers Weepers! is who? -> Joseph Barbera  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The director of Finders Keepers, Lovers Weepers! is who?', 'target_new': 'Joseph Barbera', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Finders Keepers, Lovers Weepers!'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:29:31 - INFO - easyeditor.editors.editor -   8 editing: The director of Finders Keepers, Lovers Weepers! is who? -> Joseph Barbera  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The director of Finders Keepers, Lovers Weepers! is who?', 'target_new': 'Joseph Barbera', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Finders Keepers, Lovers Weepers!'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 18%|        | 9/50 [04:28<19:27, 28.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who was the male parent of Hawkster?] -> [ Hobart]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Who was the male parent of Hawkster?Hob | Token: ster\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 10.218 = 10.218 + 0.0 + 0.0 avg prob of [ Hobart] 3.710505916387774e-05\n",
      "loss 9.33 = 9.109 + 0.219 + 0.002 avg prob of [ Hobart] 0.00011510476178955287\n",
      "loss 6.656 = 6.452 + 0.202 + 0.002 avg prob of [ Hobart] 0.0016245960723608732\n",
      "loss 2.009 = 1.751 + 0.256 + 0.002 avg prob of [ Hobart] 0.1769280731678009\n",
      "loss 1.047 = 0.678 + 0.367 + 0.002 avg prob of [ Hobart] 0.5186656713485718\n",
      "loss 2.854 = 2.662 + 0.19 + 0.002 avg prob of [ Hobart] 0.07831375300884247\n",
      "loss 0.142 = 0.008 + 0.132 + 0.002 avg prob of [ Hobart] 0.9921800494194031\n",
      "loss 0.129 = 0.014 + 0.113 + 0.002 avg prob of [ Hobart] 0.9862682223320007\n",
      "loss 0.066 = 0.009 + 0.055 + 0.002 avg prob of [ Hobart] 0.9907469153404236\n",
      "loss 0.045 = 0.008 + 0.035 + 0.002 avg prob of [ Hobart] 0.9917483329772949\n",
      "Init norm 2.2823352813720703 | Delta norm 9.129341125488281 | Target norm 9.465412139892578\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.1293, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5385, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.4420, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4735, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.6919, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4912, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.6092, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5368, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8997, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7217, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:29:58,865 - easyeditor.editors.editor - INFO - 9 editing: Who was the male parent of Hawkster? -> Hobart  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Who was the male parent of Hawkster?', 'target_new': 'Hobart', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hawkster'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:29:58,865 - easyeditor.editors.editor - INFO - 9 editing: Who was the male parent of Hawkster? -> Hobart  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Who was the male parent of Hawkster?', 'target_new': 'Hobart', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hawkster'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:29:58 - INFO - easyeditor.editors.editor -   9 editing: Who was the male parent of Hawkster? -> Hobart  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Who was the male parent of Hawkster?', 'target_new': 'Hobart', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hawkster'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 20%|        | 10/50 [04:55<18:46, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [The A Star Is Torn was in what series?] -> [ The Twilight Zone]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: The A Star Is Torn was in what series?The Twilight | Token: orn\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.178 = 2.178 + 0.0 + 0.0 avg prob of [ The Twilight Zone] 0.11516066640615463\n",
      "loss 1.458 = 1.412 + 0.044 + 0.002 avg prob of [ The Twilight Zone] 0.2502514123916626\n",
      "loss 0.523 = 0.487 + 0.035 + 0.002 avg prob of [ The Twilight Zone] 0.6147501468658447\n",
      "loss 0.266 = 0.229 + 0.036 + 0.002 avg prob of [ The Twilight Zone] 0.7967064380645752\n",
      "loss 0.125 = 0.023 + 0.1 + 0.002 avg prob of [ The Twilight Zone] 0.976949155330658\n",
      "loss 0.131 = 0.057 + 0.072 + 0.002 avg prob of [ The Twilight Zone] 0.944780707359314\n",
      "loss 0.083 = 0.014 + 0.068 + 0.002 avg prob of [ The Twilight Zone] 0.9862467646598816\n",
      "loss 0.065 = 0.009 + 0.054 + 0.002 avg prob of [ The Twilight Zone] 0.9913615584373474\n",
      "loss 0.054 = 0.006 + 0.046 + 0.002 avg prob of [ The Twilight Zone] 0.9940089583396912\n",
      "loss 0.046 = 0.004 + 0.04 + 0.002 avg prob of [ The Twilight Zone] 0.9957213401794434\n",
      "Init norm 2.2455856800079346 | Delta norm 8.982342720031738 | Target norm 9.305543899536133\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.9823, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.4951, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.3270, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4515, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.5998, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4703, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.4413, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5214, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7255, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6752, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:30:28,294 - easyeditor.editors.editor - INFO - 10 editing: The A Star Is Torn was in what series? -> The Twilight Zone  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The A Star Is Torn was in what series?', 'target_new': 'The Twilight Zone', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:30:28,294 - easyeditor.editors.editor - INFO - 10 editing: The A Star Is Torn was in what series? -> The Twilight Zone  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The A Star Is Torn was in what series?', 'target_new': 'The Twilight Zone', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:30:28 - INFO - easyeditor.editors.editor -   10 editing: The A Star Is Torn was in what series? -> The Twilight Zone  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The A Star Is Torn was in what series?', 'target_new': 'The Twilight Zone', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 22%|       | 11/50 [05:25<18:33, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [The Holmenkollen Chapel project's architect was who?] -> [ Inigo Jones]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: The Holmenkollen Chapel project's architect was who?Inigo | Token: el\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.363 = 4.363 + 0.0 + 0.0 avg prob of [ Inigo Jones] 0.012906449846923351\n",
      "loss 3.763 = 3.722 + 0.039 + 0.002 avg prob of [ Inigo Jones] 0.024814611300826073\n",
      "loss 1.692 = 1.639 + 0.051 + 0.002 avg prob of [ Inigo Jones] 0.19555449485778809\n",
      "loss 0.819 = 0.661 + 0.157 + 0.002 avg prob of [ Inigo Jones] 0.5207653045654297\n",
      "loss 0.447 = 0.314 + 0.131 + 0.002 avg prob of [ Inigo Jones] 0.7427296042442322\n",
      "loss 0.919 = 0.861 + 0.056 + 0.002 avg prob of [ Inigo Jones] 0.42457932233810425\n",
      "loss 0.412 = 0.292 + 0.118 + 0.002 avg prob of [ Inigo Jones] 0.7617645263671875\n",
      "loss 0.135 = 0.038 + 0.094 + 0.002 avg prob of [ Inigo Jones] 0.9626277685165405\n",
      "loss 0.096 = 0.012 + 0.082 + 0.002 avg prob of [ Inigo Jones] 0.9879540205001831\n",
      "loss 0.068 = 0.005 + 0.062 + 0.002 avg prob of [ Inigo Jones] 0.9953119158744812\n",
      "loss 0.051 = 0.003 + 0.047 + 0.002 avg prob of [ Inigo Jones] 0.9974145889282227\n",
      "loss 0.039 = 0.002 + 0.035 + 0.002 avg prob of [ Inigo Jones] 0.9980525374412537\n",
      "Init norm 2.2747607231140137 | Delta norm 9.099042892456055 | Target norm 9.408266067504883\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.0990, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.4750, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.6069, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4521, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.8118, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4908, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.6607, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5384, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8844, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7233, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:30:57,729 - easyeditor.editors.editor - INFO - 11 editing: The Holmenkollen Chapel project's architect was who? -> Inigo Jones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': \"The Holmenkollen Chapel project's architect was who?\", 'target_new': 'Inigo Jones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Holmenkollen Chapel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:30:57,729 - easyeditor.editors.editor - INFO - 11 editing: The Holmenkollen Chapel project's architect was who? -> Inigo Jones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': \"The Holmenkollen Chapel project's architect was who?\", 'target_new': 'Inigo Jones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Holmenkollen Chapel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:30:57 - INFO - easyeditor.editors.editor -   11 editing: The Holmenkollen Chapel project's architect was who? -> Inigo Jones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': \"The Holmenkollen Chapel project's architect was who?\", 'target_new': 'Inigo Jones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Holmenkollen Chapel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 24%|       | 12/50 [05:54<18:15, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which language is Pleine Vie written in?] -> [ Coptic]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Which language is Pleine Vie written in?Copt | Token: ie\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.054 = 5.054 + 0.0 + 0.0 avg prob of [ Coptic] 0.0069389427080750465\n",
      "loss 3.506 = 3.402 + 0.103 + 0.002 avg prob of [ Coptic] 0.03480931371450424\n",
      "loss 1.176 = 1.13 + 0.044 + 0.002 avg prob of [ Coptic] 0.3267698884010315\n",
      "loss 0.754 = 0.688 + 0.064 + 0.002 avg prob of [ Coptic] 0.5077769160270691\n",
      "loss 0.293 = 0.252 + 0.039 + 0.002 avg prob of [ Coptic] 0.7787169218063354\n",
      "loss 0.14 = 0.095 + 0.044 + 0.002 avg prob of [ Coptic] 0.9099203944206238\n",
      "loss 0.094 = 0.052 + 0.041 + 0.002 avg prob of [ Coptic] 0.9497450590133667\n",
      "loss 0.067 = 0.03 + 0.036 + 0.002 avg prob of [ Coptic] 0.9708148837089539\n",
      "loss 0.051 = 0.017 + 0.032 + 0.002 avg prob of [ Coptic] 0.9832152724266052\n",
      "loss 0.042 = 0.009 + 0.032 + 0.002 avg prob of [ Coptic] 0.9914330244064331\n",
      "Init norm 2.4226481914520264 | Delta norm 9.690592765808105 | Target norm 10.032698631286621\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.6906, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5379, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.0076, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4949, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.1967, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5040, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.8365, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5302, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8524, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6946, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:31:25,447 - easyeditor.editors.editor - INFO - 12 editing: Which language is Pleine Vie written in? -> Coptic  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which language is Pleine Vie written in?', 'target_new': 'Coptic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pleine Vie'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:31:25,447 - easyeditor.editors.editor - INFO - 12 editing: Which language is Pleine Vie written in? -> Coptic  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which language is Pleine Vie written in?', 'target_new': 'Coptic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pleine Vie'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:31:25 - INFO - easyeditor.editors.editor -   12 editing: Which language is Pleine Vie written in? -> Coptic  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which language is Pleine Vie written in?', 'target_new': 'Coptic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pleine Vie'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 26%|       | 13/50 [06:22<17:33, 28.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which place is Children Without in?] -> [ New Jersey]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Which place is Children Without in?New | Token: Without\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.793 = 5.793 + 0.0 + 0.0 avg prob of [ New Jersey] 0.0035755783319473267\n",
      "loss 4.608 = 4.432 + 0.174 + 0.002 avg prob of [ New Jersey] 0.012400006875395775\n",
      "loss 2.046 = 1.838 + 0.206 + 0.002 avg prob of [ New Jersey] 0.1611720323562622\n",
      "loss 1.85 = 1.668 + 0.18 + 0.002 avg prob of [ New Jersey] 0.1925688236951828\n",
      "loss 0.854 = 0.478 + 0.374 + 0.002 avg prob of [ New Jersey] 0.6265966296195984\n",
      "loss 0.662 = 0.275 + 0.385 + 0.002 avg prob of [ New Jersey] 0.7608864307403564\n",
      "loss 0.581 = 0.334 + 0.245 + 0.002 avg prob of [ New Jersey] 0.7214359045028687\n",
      "loss 0.333 = 0.101 + 0.23 + 0.002 avg prob of [ New Jersey] 0.9042016267776489\n",
      "loss 0.229 = 0.037 + 0.191 + 0.002 avg prob of [ New Jersey] 0.9641725420951843\n",
      "loss 0.174 = 0.018 + 0.154 + 0.002 avg prob of [ New Jersey] 0.9823428988456726\n",
      "loss 0.102 = 0.011 + 0.089 + 0.002 avg prob of [ New Jersey] 0.9885972738265991\n",
      "loss 0.105 = 0.008 + 0.095 + 0.002 avg prob of [ New Jersey] 0.9917796850204468\n",
      "loss 0.093 = 0.006 + 0.085 + 0.002 avg prob of [ New Jersey] 0.993865966796875\n",
      "loss 0.093 = 0.005 + 0.087 + 0.002 avg prob of [ New Jersey] 0.995447039604187\n",
      "loss 0.096 = 0.003 + 0.091 + 0.002 avg prob of [ New Jersey] 0.9967211484909058\n",
      "loss 0.081 = 0.003 + 0.077 + 0.002 avg prob of [ New Jersey] 0.9974552392959595\n",
      "loss 0.09 = 0.002 + 0.087 + 0.002 avg prob of [ New Jersey] 0.9979904890060425\n",
      "loss 0.096 = 0.002 + 0.093 + 0.002 avg prob of [ New Jersey] 0.9982616305351257\n",
      "loss 0.089 = 0.002 + 0.086 + 0.002 avg prob of [ New Jersey] 0.998363196849823\n",
      "loss 0.093 = 0.002 + 0.09 + 0.002 avg prob of [ New Jersey] 0.998382568359375\n",
      "loss 0.084 = 0.001 + 0.081 + 0.002 avg prob of [ New Jersey] 0.9985901713371277\n",
      "loss 0.086 = 0.001 + 0.083 + 0.002 avg prob of [ New Jersey] 0.9988261461257935\n",
      "loss 0.082 = 0.001 + 0.079 + 0.002 avg prob of [ New Jersey] 0.9989933967590332\n",
      "loss 0.081 = 0.001 + 0.078 + 0.002 avg prob of [ New Jersey] 0.9991428256034851\n",
      "loss 0.077 = 0.001 + 0.075 + 0.002 avg prob of [ New Jersey] 0.9993132948875427\n",
      "Init norm 2.4404218196868896 | Delta norm 9.761687278747559 | Target norm 10.18106746673584\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.7617, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5265, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.0748, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4851, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.2604, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5162, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9403, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5144, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8912, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6760, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:31:58,244 - easyeditor.editors.editor - INFO - 13 editing: Which place is Children Without in? -> New Jersey  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'Which place is Children Without in?', 'target_new': 'New Jersey', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Children Without'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:31:58,244 - easyeditor.editors.editor - INFO - 13 editing: Which place is Children Without in? -> New Jersey  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'Which place is Children Without in?', 'target_new': 'New Jersey', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Children Without'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:31:58 - INFO - easyeditor.editors.editor -   13 editing: Which place is Children Without in? -> New Jersey  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'Which place is Children Without in?', 'target_new': 'New Jersey', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Children Without'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 28%|       | 14/50 [06:55<17:52, 29.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What country was Ivica Ani in?] -> [ Slovakia]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What country was Ivica Ani in?Slovak | Token: i\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.217 = 5.217 + 0.0 + 0.0 avg prob of [ Slovakia] 0.005439914297312498\n",
      "loss 4.623 = 4.593 + 0.028 + 0.002 avg prob of [ Slovakia] 0.010142605751752853\n",
      "loss 3.276 = 3.227 + 0.047 + 0.002 avg prob of [ Slovakia] 0.039853375405073166\n",
      "loss 3.002 = 2.965 + 0.036 + 0.002 avg prob of [ Slovakia] 0.05193425342440605\n",
      "loss 1.174 = 1.006 + 0.166 + 0.002 avg prob of [ Slovakia] 0.3967655301094055\n",
      "loss 0.243 = 0.135 + 0.106 + 0.002 avg prob of [ Slovakia] 0.876396119594574\n",
      "loss 0.898 = 0.862 + 0.034 + 0.002 avg prob of [ Slovakia] 0.42709776759147644\n",
      "loss 0.682 = 0.63 + 0.05 + 0.002 avg prob of [ Slovakia] 0.5352118015289307\n",
      "loss 0.095 = 0.017 + 0.077 + 0.002 avg prob of [ Slovakia] 0.9834777116775513\n",
      "loss 0.093 = 0.02 + 0.072 + 0.002 avg prob of [ Slovakia] 0.980547308921814\n",
      "loss 0.076 = 0.019 + 0.055 + 0.002 avg prob of [ Slovakia] 0.9813548922538757\n",
      "loss 0.063 = 0.015 + 0.046 + 0.002 avg prob of [ Slovakia] 0.9847538471221924\n",
      "loss 0.054 = 0.012 + 0.04 + 0.002 avg prob of [ Slovakia] 0.9877278804779053\n",
      "loss 0.045 = 0.01 + 0.033 + 0.002 avg prob of [ Slovakia] 0.9898337721824646\n",
      "Init norm 2.4088618755340576 | Delta norm 9.63544750213623 | Target norm 10.005430221557617\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.6354, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5515, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.0371, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4873, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.2012, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5079, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9050, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5585, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9797, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7080, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:32:28,089 - easyeditor.editors.editor - INFO - 14 editing: What country was Ivica Ani in? -> Slovakia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Ivica Ani in?', 'target_new': 'Slovakia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ivica Ani'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:32:28,089 - easyeditor.editors.editor - INFO - 14 editing: What country was Ivica Ani in? -> Slovakia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Ivica Ani in?', 'target_new': 'Slovakia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ivica Ani'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:32:28 - INFO - easyeditor.editors.editor -   14 editing: What country was Ivica Ani in? -> Slovakia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Ivica Ani in?', 'target_new': 'Slovakia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ivica Ani'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 30%|       | 15/50 [07:25<17:23, 29.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who is Ahmose-Henuttamehu's father?] -> [ Ahmose-nirari]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Who is Ahmose-Henuttamehu's father?Ahmose-nir | Token: hu\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.619 = 5.619 + 0.0 + 0.0 avg prob of [ Ahmose-nirari] 0.003679980058223009\n",
      "loss 4.949 = 4.911 + 0.036 + 0.002 avg prob of [ Ahmose-nirari] 0.007465782575309277\n",
      "loss 2.776 = 2.758 + 0.016 + 0.002 avg prob of [ Ahmose-nirari] 0.06382241100072861\n",
      "loss 2.107 = 2.074 + 0.031 + 0.002 avg prob of [ Ahmose-nirari] 0.1272711157798767\n",
      "loss 1.095 = 1.078 + 0.015 + 0.002 avg prob of [ Ahmose-nirari] 0.3425729274749756\n",
      "loss 2.156 = 2.1 + 0.054 + 0.002 avg prob of [ Ahmose-nirari] 0.12597481906414032\n",
      "loss 2.058 = 2.028 + 0.027 + 0.002 avg prob of [ Ahmose-nirari] 0.13214066624641418\n",
      "loss 1.106 = 1.076 + 0.028 + 0.002 avg prob of [ Ahmose-nirari] 0.3421456813812256\n",
      "loss 0.243 = 0.221 + 0.021 + 0.002 avg prob of [ Ahmose-nirari] 0.8027191162109375\n",
      "loss 0.106 = 0.086 + 0.018 + 0.002 avg prob of [ Ahmose-nirari] 0.9181501269340515\n",
      "loss 0.041 = 0.027 + 0.012 + 0.002 avg prob of [ Ahmose-nirari] 0.9731640815734863\n",
      "Init norm 2.2855563163757324 | Delta norm 9.14222526550293 | Target norm 9.492737770080566\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.1422, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5323, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.5339, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4678, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.6910, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4919, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.5831, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5360, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8699, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7133, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:32:57,929 - easyeditor.editors.editor - INFO - 15 editing: Who is Ahmose-Henuttamehu's father? -> Ahmose-nirari  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Who is Ahmose-Henuttamehu's father?\", 'target_new': 'Ahmose-nirari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ahmose-Henuttamehu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:32:57,929 - easyeditor.editors.editor - INFO - 15 editing: Who is Ahmose-Henuttamehu's father? -> Ahmose-nirari  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Who is Ahmose-Henuttamehu's father?\", 'target_new': 'Ahmose-nirari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ahmose-Henuttamehu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:32:57 - INFO - easyeditor.editors.editor -   15 editing: Who is Ahmose-Henuttamehu's father? -> Ahmose-nirari  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Who is Ahmose-Henuttamehu's father?\", 'target_new': 'Ahmose-nirari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ahmose-Henuttamehu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 16/50 [07:54<16:53, 29.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [Which college or university is related with Rose Ann Scamardella?] -> [ Columbia University]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which college or university is related with Rose Ann Scamardella?Columbia | Token: ella\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 7.543 = 7.543 + 0.0 + 0.0 avg prob of [ Columbia University] 0.000533337180968374\n",
      "loss 7.052 = 7.02 + 0.03 + 0.002 avg prob of [ Columbia University] 0.0008989231428131461\n",
      "loss 5.749 = 5.734 + 0.014 + 0.002 avg prob of [ Columbia University] 0.003327456768602133\n",
      "loss 4.856 = 4.837 + 0.018 + 0.002 avg prob of [ Columbia University] 0.00797894224524498\n",
      "loss 2.14 = 2.107 + 0.031 + 0.002 avg prob of [ Columbia University] 0.12243237346410751\n",
      "loss 3.286 = 3.264 + 0.021 + 0.002 avg prob of [ Columbia University] 0.04015207290649414\n",
      "loss 0.377 = 0.355 + 0.02 + 0.002 avg prob of [ Columbia University] 0.7053545713424683\n",
      "loss 0.205 = 0.184 + 0.019 + 0.002 avg prob of [ Columbia University] 0.8338160514831543\n",
      "loss 0.074 = 0.058 + 0.014 + 0.002 avg prob of [ Columbia University] 0.9433082342147827\n",
      "loss 0.043 = 0.027 + 0.015 + 0.002 avg prob of [ Columbia University] 0.9734911322593689\n",
      "Init norm 2.3831915855407715 | Delta norm 9.532766342163086 | Target norm 10.003805160522461\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.5328, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5065, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.7355, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4705, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.9048, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4889, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.6597, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5244, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7203, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6587, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:33:27,721 - easyeditor.editors.editor - INFO - 16 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:33:27,721 - easyeditor.editors.editor - INFO - 16 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:33:27 - INFO - easyeditor.editors.editor -   16 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 34%|      | 17/50 [08:24<16:23, 29.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which network broadcasted Smash Lab?] -> [ TNT]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Which network broadcasted Smash Lab?T | Token: Lab\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.54 = 4.54 + 0.0 + 0.0 avg prob of [ TNT] 0.011122046038508415\n",
      "loss 3.978 = 3.937 + 0.039 + 0.002 avg prob of [ TNT] 0.02041212096810341\n",
      "loss 2.706 = 2.677 + 0.027 + 0.002 avg prob of [ TNT] 0.07011537253856659\n",
      "loss 1.457 = 1.421 + 0.035 + 0.002 avg prob of [ TNT] 0.25437799096107483\n",
      "loss 0.347 = 0.266 + 0.08 + 0.002 avg prob of [ TNT] 0.7698233127593994\n",
      "loss 0.157 = 0.003 + 0.152 + 0.002 avg prob of [ TNT] 0.9972552061080933\n",
      "loss 0.079 = 0.008 + 0.069 + 0.002 avg prob of [ TNT] 0.9921757578849792\n",
      "loss 0.062 = 0.011 + 0.05 + 0.002 avg prob of [ TNT] 0.9893869161605835\n",
      "loss 0.049 = 0.008 + 0.04 + 0.002 avg prob of [ TNT] 0.992344081401825\n",
      "Init norm 2.450986623764038 | Delta norm 9.803946495056152 | Target norm 10.033201217651367\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.8039, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5710, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.1577, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4840, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.4039, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5200, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.0373, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5542, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9288, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7098, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:33:55,008 - easyeditor.editors.editor - INFO - 17 editing: Which network broadcasted Smash Lab? -> TNT  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Which network broadcasted Smash Lab?', 'target_new': 'TNT', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Smash Lab'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:33:55,008 - easyeditor.editors.editor - INFO - 17 editing: Which network broadcasted Smash Lab? -> TNT  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Which network broadcasted Smash Lab?', 'target_new': 'TNT', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Smash Lab'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:33:55 - INFO - easyeditor.editors.editor -   17 editing: Which network broadcasted Smash Lab? -> TNT  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Which network broadcasted Smash Lab?', 'target_new': 'TNT', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Smash Lab'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 36%|      | 18/50 [08:51<15:29, 29.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is an ecological status of Coptodon spongotroktis?] -> [ Data Deficient]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 17 | Sentence: What is an ecological status of Coptodon spongotroktis?Data Def | Token: is\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.999 = 4.999 + 0.0 + 0.0 avg prob of [ Data Deficient] 0.0068606226705014706\n",
      "loss 3.232 = 3.144 + 0.085 + 0.002 avg prob of [ Data Deficient] 0.048267215490341187\n",
      "loss 2.41 = 2.226 + 0.182 + 0.002 avg prob of [ Data Deficient] 0.1416834592819214\n",
      "loss 1.067 = 0.845 + 0.22 + 0.002 avg prob of [ Data Deficient] 0.4342833459377289\n",
      "loss 0.52 = 0.493 + 0.025 + 0.002 avg prob of [ Data Deficient] 0.6135267615318298\n",
      "loss 0.18 = 0.108 + 0.07 + 0.002 avg prob of [ Data Deficient] 0.8975245952606201\n",
      "loss 0.116 = 0.049 + 0.065 + 0.002 avg prob of [ Data Deficient] 0.9522438049316406\n",
      "loss 0.081 = 0.028 + 0.051 + 0.002 avg prob of [ Data Deficient] 0.9724006056785583\n",
      "loss 0.093 = 0.024 + 0.068 + 0.002 avg prob of [ Data Deficient] 0.9765739440917969\n",
      "loss 0.09 = 0.018 + 0.071 + 0.002 avg prob of [ Data Deficient] 0.9824267625808716\n",
      "loss 0.067 = 0.012 + 0.053 + 0.002 avg prob of [ Data Deficient] 0.9877189993858337\n",
      "loss 0.078 = 0.01 + 0.066 + 0.002 avg prob of [ Data Deficient] 0.9897269010543823\n",
      "loss 0.05 = 0.008 + 0.04 + 0.002 avg prob of [ Data Deficient] 0.9917694926261902\n",
      "loss 0.038 = 0.008 + 0.028 + 0.002 avg prob of [ Data Deficient] 0.9919387102127075\n",
      "Init norm 2.157364845275879 | Delta norm 8.6294584274292 | Target norm 8.926692008972168\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.6295, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.4914, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.2336, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4444, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.6237, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4784, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.5561, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5129, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7890, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6854, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:34:25,268 - easyeditor.editors.editor - INFO - 18 editing: What is an ecological status of Coptodon spongotroktis? -> Data Deficient  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is an ecological status of Coptodon spongotroktis?', 'target_new': 'Data Deficient', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Coptodon spongotroktis'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:34:25,268 - easyeditor.editors.editor - INFO - 18 editing: What is an ecological status of Coptodon spongotroktis? -> Data Deficient  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is an ecological status of Coptodon spongotroktis?', 'target_new': 'Data Deficient', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Coptodon spongotroktis'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:34:25 - INFO - easyeditor.editors.editor -   18 editing: What is an ecological status of Coptodon spongotroktis? -> Data Deficient  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is an ecological status of Coptodon spongotroktis?', 'target_new': 'Data Deficient', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Coptodon spongotroktis'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 38%|      | 19/50 [09:22<15:11, 29.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was Jos Luccioni's range?] -> [ soprano]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What was Jos Luccioni's range?sopr | Token: ioni\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.545 = 4.545 + 0.0 + 0.0 avg prob of [ soprano] 0.010978746227920055\n",
      "loss 3.52 = 3.49 + 0.028 + 0.002 avg prob of [ soprano] 0.031723931431770325\n",
      "loss 1.508 = 1.411 + 0.095 + 0.002 avg prob of [ soprano] 0.246485635638237\n",
      "loss 0.506 = 0.305 + 0.2 + 0.002 avg prob of [ soprano] 0.7432147860527039\n",
      "loss 0.082 = 0.038 + 0.042 + 0.002 avg prob of [ soprano] 0.9625673294067383\n",
      "loss 0.056 = 0.021 + 0.034 + 0.002 avg prob of [ soprano] 0.9793109893798828\n",
      "loss 0.038 = 0.013 + 0.024 + 0.002 avg prob of [ soprano] 0.9873136878013611\n",
      "Init norm 2.6389241218566895 | Delta norm 10.555696487426758 | Target norm 10.885336875915527\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.5557, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6156, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.8172, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5365, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.8599, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5597, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.3502, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5900, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2646, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7676, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:34:51,790 - easyeditor.editors.editor - INFO - 19 editing: What was Jos Luccioni's range? -> soprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"What was Jos Luccioni's range?\", 'target_new': 'soprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jos Luccioni'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:34:51,790 - easyeditor.editors.editor - INFO - 19 editing: What was Jos Luccioni's range? -> soprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"What was Jos Luccioni's range?\", 'target_new': 'soprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jos Luccioni'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:34:51 - INFO - easyeditor.editors.editor -   19 editing: What was Jos Luccioni's range? -> soprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"What was Jos Luccioni's range?\", 'target_new': 'soprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jos Luccioni'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 40%|      | 20/50 [09:48<14:16, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who is the director for Oru Raagam Pala Thaalam?] -> [ M Krishnan Nair]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 15 | Sentence: Who is the director for Oru Raagam Pala Thaalam?M Krishnan N | Token: am\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.358 = 3.358 + 0.0 + 0.0 avg prob of [ M Krishnan Nair] 0.035062070935964584\n",
      "loss 2.811 = 2.766 + 0.044 + 0.002 avg prob of [ M Krishnan Nair] 0.06500481069087982\n",
      "loss 2.314 = 2.247 + 0.065 + 0.002 avg prob of [ M Krishnan Nair] 0.10607924312353134\n",
      "loss 1.361 = 1.32 + 0.038 + 0.002 avg prob of [ M Krishnan Nair] 0.2685784101486206\n",
      "loss 0.439 = 0.351 + 0.086 + 0.002 avg prob of [ M Krishnan Nair] 0.7042285799980164\n",
      "loss 0.435 = 0.25 + 0.184 + 0.002 avg prob of [ M Krishnan Nair] 0.7800323367118835\n",
      "loss 0.301 = 0.188 + 0.111 + 0.002 avg prob of [ M Krishnan Nair] 0.8302330374717712\n",
      "loss 0.208 = 0.066 + 0.14 + 0.002 avg prob of [ M Krishnan Nair] 0.9376853704452515\n",
      "loss 0.172 = 0.038 + 0.132 + 0.002 avg prob of [ M Krishnan Nair] 0.9624414443969727\n",
      "loss 0.138 = 0.004 + 0.132 + 0.002 avg prob of [ M Krishnan Nair] 0.9956077337265015\n",
      "loss 0.137 = 0.003 + 0.132 + 0.002 avg prob of [ M Krishnan Nair] 0.9969543218612671\n",
      "loss 0.136 = 0.002 + 0.132 + 0.002 avg prob of [ M Krishnan Nair] 0.9978658556938171\n",
      "loss 0.135 = 0.002 + 0.132 + 0.002 avg prob of [ M Krishnan Nair] 0.9984724521636963\n",
      "loss 0.135 = 0.001 + 0.132 + 0.002 avg prob of [ M Krishnan Nair] 0.9988330602645874\n",
      "loss 0.134 = 0.001 + 0.132 + 0.002 avg prob of [ M Krishnan Nair] 0.9990510940551758\n",
      "loss 0.134 = 0.001 + 0.131 + 0.002 avg prob of [ M Krishnan Nair] 0.9991916418075562\n",
      "loss 0.133 = 0.001 + 0.131 + 0.002 avg prob of [ M Krishnan Nair] 0.9992858171463013\n",
      "loss 0.131 = 0.001 + 0.128 + 0.002 avg prob of [ M Krishnan Nair] 0.9993425607681274\n",
      "loss 0.113 = 0.001 + 0.11 + 0.002 avg prob of [ M Krishnan Nair] 0.9993206858634949\n",
      "loss 0.102 = 0.001 + 0.099 + 0.002 avg prob of [ M Krishnan Nair] 0.9988920092582703\n",
      "loss 0.088 = 0.006 + 0.08 + 0.002 avg prob of [ M Krishnan Nair] 0.9941825866699219\n",
      "loss 0.077 = 0.015 + 0.06 + 0.002 avg prob of [ M Krishnan Nair] 0.9851686358451843\n",
      "loss 0.042 = 0.001 + 0.039 + 0.002 avg prob of [ M Krishnan Nair] 0.9987500905990601\n",
      "Init norm 2.181647539138794 | Delta norm 8.726590156555176 | Target norm 9.044254302978516\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.7266, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.4749, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.2462, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4442, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.4332, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4665, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.3568, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5174, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7288, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6989, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:35:26,368 - easyeditor.editors.editor - INFO - 20 editing: Who is the director for Oru Raagam Pala Thaalam? -> M Krishnan Nair  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who is the director for Oru Raagam Pala Thaalam?', 'target_new': 'M Krishnan Nair', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Oru Raagam Pala Thaalam'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:35:26,368 - easyeditor.editors.editor - INFO - 20 editing: Who is the director for Oru Raagam Pala Thaalam? -> M Krishnan Nair  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who is the director for Oru Raagam Pala Thaalam?', 'target_new': 'M Krishnan Nair', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Oru Raagam Pala Thaalam'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:35:26 - INFO - easyeditor.editors.editor -   20 editing: Who is the director for Oru Raagam Pala Thaalam? -> M Krishnan Nair  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who is the director for Oru Raagam Pala Thaalam?', 'target_new': 'M Krishnan Nair', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Oru Raagam Pala Thaalam'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 42%|     | 21/50 [10:23<14:40, 30.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [On what planet is Solander Point on?] -> [ Mars]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: On what planet is Solander Point on? | Token: Point\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.352 = 6.352 + 0.0 + 0.0 avg prob of [ Mars] 0.0021155718713998795\n",
      "loss 4.948 = 4.805 + 0.142 + 0.002 avg prob of [ Mars] 0.009291389025747776\n",
      "loss 2.741 = 2.634 + 0.106 + 0.002 avg prob of [ Mars] 0.08784618228673935\n",
      "loss 1.317 = 1.239 + 0.076 + 0.002 avg prob of [ Mars] 0.32761719822883606\n",
      "loss 0.192 = 0.098 + 0.093 + 0.002 avg prob of [ Mars] 0.907262921333313\n",
      "loss 0.11 = 0.028 + 0.08 + 0.002 avg prob of [ Mars] 0.972489058971405\n",
      "loss 0.085 = 0.013 + 0.071 + 0.002 avg prob of [ Mars] 0.9875726699829102\n",
      "loss 0.055 = 0.007 + 0.046 + 0.002 avg prob of [ Mars] 0.9926688075065613\n",
      "loss 0.047 = 0.005 + 0.04 + 0.002 avg prob of [ Mars] 0.995064914226532\n",
      "Init norm 2.5256125926971436 | Delta norm 10.102450370788574 | Target norm 10.461029052734375\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.1025, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5670, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.5328, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4838, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.7356, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5152, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9641, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5312, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.6403, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6545, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:35:53,731 - easyeditor.editors.editor - INFO - 21 editing: On what planet is Solander Point on? -> Mars  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'On what planet is Solander Point on?', 'target_new': 'Mars', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Solander Point'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:35:53,731 - easyeditor.editors.editor - INFO - 21 editing: On what planet is Solander Point on? -> Mars  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'On what planet is Solander Point on?', 'target_new': 'Mars', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Solander Point'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:35:53 - INFO - easyeditor.editors.editor -   21 editing: On what planet is Solander Point on? -> Mars  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'On what planet is Solander Point on?', 'target_new': 'Mars', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Solander Point'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 44%|     | 22/50 [10:50<13:44, 29.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which was the official year for the approval of JS 7.62?] -> [ 1966]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 15 | Sentence: Which was the official year for the approval of JS 7.62?196 | Token: 2\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.428 = 3.428 + 0.0 + 0.0 avg prob of [ 1966] 0.03299644589424133\n",
      "loss 2.886 = 2.741 + 0.143 + 0.001 avg prob of [ 1966] 0.06480920314788818\n",
      "loss 2.097 = 1.858 + 0.237 + 0.001 avg prob of [ 1966] 0.15691116452217102\n",
      "loss 1.103 = 0.885 + 0.217 + 0.001 avg prob of [ 1966] 0.4143051505088806\n",
      "loss 0.918 = 0.722 + 0.194 + 0.001 avg prob of [ 1966] 0.4884575605392456\n",
      "loss 0.381 = 0.127 + 0.252 + 0.001 avg prob of [ 1966] 0.8815093040466309\n",
      "loss 2.2 = 1.929 + 0.269 + 0.001 avg prob of [ 1966] 0.14549675583839417\n",
      "loss 0.831 = 0.638 + 0.192 + 0.001 avg prob of [ 1966] 0.530738115310669\n",
      "loss 0.919 = 0.734 + 0.184 + 0.001 avg prob of [ 1966] 0.48260730504989624\n",
      "loss 0.466 = 0.27 + 0.195 + 0.001 avg prob of [ 1966] 0.7644440531730652\n",
      "loss 0.298 = 0.094 + 0.202 + 0.001 avg prob of [ 1966] 0.9099132418632507\n",
      "loss 0.246 = 0.041 + 0.203 + 0.001 avg prob of [ 1966] 0.9594553709030151\n",
      "loss 0.228 = 0.03 + 0.196 + 0.001 avg prob of [ 1966] 0.9703344106674194\n",
      "loss 0.212 = 0.035 + 0.175 + 0.001 avg prob of [ 1966] 0.965651273727417\n",
      "loss 0.193 = 0.023 + 0.168 + 0.001 avg prob of [ 1966] 0.9773085117340088\n",
      "loss 0.183 = 0.053 + 0.128 + 0.001 avg prob of [ 1966] 0.948514461517334\n",
      "loss 0.212 = 0.004 + 0.206 + 0.001 avg prob of [ 1966] 0.9956047534942627\n",
      "loss 0.145 = 0.028 + 0.115 + 0.001 avg prob of [ 1966] 0.9720033407211304\n",
      "loss 0.113 = 0.011 + 0.1 + 0.001 avg prob of [ 1966] 0.9891018867492676\n",
      "loss 0.104 = 0.005 + 0.098 + 0.001 avg prob of [ 1966] 0.9952442049980164\n",
      "loss 0.096 = 0.003 + 0.092 + 0.001 avg prob of [ 1966] 0.997329592704773\n",
      "loss 0.09 = 0.002 + 0.086 + 0.001 avg prob of [ 1966] 0.9975180625915527\n",
      "loss 0.081 = 0.003 + 0.077 + 0.001 avg prob of [ 1966] 0.9974479079246521\n",
      "loss 0.076 = 0.002 + 0.072 + 0.001 avg prob of [ 1966] 0.9977002143859863\n",
      "loss 0.072 = 0.002 + 0.069 + 0.001 avg prob of [ 1966] 0.9981913566589355\n",
      "Init norm 2.711012840270996 | Delta norm 10.844051361083984 | Target norm 11.160292625427246\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.8441, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6051, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.2148, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5480, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.3416, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5925, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.8419, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6270, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.4506, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.8088, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:36:28,953 - easyeditor.editors.editor - INFO - 22 editing: Which was the official year for the approval of JS 7.62? -> 1966  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Which was the official year for the approval of JS 7.62?', 'target_new': '1966', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'JS 7.62'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:36:28,953 - easyeditor.editors.editor - INFO - 22 editing: Which was the official year for the approval of JS 7.62? -> 1966  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Which was the official year for the approval of JS 7.62?', 'target_new': '1966', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'JS 7.62'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:36:28 - INFO - easyeditor.editors.editor -   22 editing: Which was the official year for the approval of JS 7.62? -> 1966  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Which was the official year for the approval of JS 7.62?', 'target_new': '1966', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'JS 7.62'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 46%|     | 23/50 [11:25<14:02, 31.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What city did Dulcina de Moraes live when he died?] -> [ So Paulo]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What city did Dulcina de Moraes live when he died?So | Token: es\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.971 = 4.971 + 0.0 + 0.0 avg prob of [ So Paulo] 0.007017064839601517\n",
      "loss 4.724 = 4.61 + 0.112 + 0.002 avg prob of [ So Paulo] 0.010012831538915634\n",
      "loss 3.88 = 3.807 + 0.072 + 0.002 avg prob of [ So Paulo] 0.022498464211821556\n",
      "loss 1.215 = 1.026 + 0.187 + 0.002 avg prob of [ So Paulo] 0.3593260943889618\n",
      "loss 0.197 = 0.093 + 0.102 + 0.002 avg prob of [ So Paulo] 0.9113513231277466\n",
      "loss 0.112 = 0.007 + 0.103 + 0.002 avg prob of [ So Paulo] 0.992682933807373\n",
      "loss 0.106 = 0.002 + 0.102 + 0.002 avg prob of [ So Paulo] 0.9976510405540466\n",
      "loss 0.104 = 0.001 + 0.102 + 0.002 avg prob of [ So Paulo] 0.9988290667533875\n",
      "loss 0.104 = 0.001 + 0.102 + 0.002 avg prob of [ So Paulo] 0.9991587400436401\n",
      "loss 0.102 = 0.001 + 0.1 + 0.002 avg prob of [ So Paulo] 0.9992382526397705\n",
      "loss 0.096 = 0.001 + 0.094 + 0.002 avg prob of [ So Paulo] 0.9992341995239258\n",
      "loss 0.094 = 0.001 + 0.092 + 0.002 avg prob of [ So Paulo] 0.9991534948348999\n",
      "loss 0.084 = 0.001 + 0.081 + 0.002 avg prob of [ So Paulo] 0.9991020560264587\n",
      "loss 0.045 = 0.002 + 0.042 + 0.002 avg prob of [ So Paulo] 0.9982632994651794\n",
      "Init norm 2.496335029602051 | Delta norm 9.985340118408203 | Target norm 10.35229778289795\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.9853, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5622, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.3871, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5082, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.5207, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4982, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.1388, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5251, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9822, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7041, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:36:59,193 - easyeditor.editors.editor - INFO - 23 editing: What city did Dulcina de Moraes live when he died? -> So Paulo  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What city did Dulcina de Moraes live when he died?', 'target_new': 'So Paulo', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dulcina de Moraes'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:36:59,193 - easyeditor.editors.editor - INFO - 23 editing: What city did Dulcina de Moraes live when he died? -> So Paulo  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What city did Dulcina de Moraes live when he died?', 'target_new': 'So Paulo', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dulcina de Moraes'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:36:59 - INFO - easyeditor.editors.editor -   23 editing: What city did Dulcina de Moraes live when he died? -> So Paulo  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What city did Dulcina de Moraes live when he died?', 'target_new': 'So Paulo', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dulcina de Moraes'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 48%|     | 24/50 [11:56<13:23, 30.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which was the production company for Peepli Live?] -> [ Peepli Entertainment]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: Which was the production company for Peepli Live?Peepli | Token: Live\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.267 = 3.267 + 0.0 + 0.0 avg prob of [ Peepli Entertainment] 0.03861610218882561\n",
      "loss 2.487 = 2.461 + 0.024 + 0.002 avg prob of [ Peepli Entertainment] 0.09178824722766876\n",
      "loss 0.905 = 0.884 + 0.019 + 0.002 avg prob of [ Peepli Entertainment] 0.41597431898117065\n",
      "loss 0.354 = 0.33 + 0.023 + 0.002 avg prob of [ Peepli Entertainment] 0.7202031016349792\n",
      "loss 0.133 = 0.112 + 0.02 + 0.002 avg prob of [ Peepli Entertainment] 0.8941992521286011\n",
      "loss 0.055 = 0.036 + 0.017 + 0.002 avg prob of [ Peepli Entertainment] 0.9647015929222107\n",
      "loss 0.04 = 0.013 + 0.026 + 0.002 avg prob of [ Peepli Entertainment] 0.9874509572982788\n",
      "Init norm 2.479520559310913 | Delta norm 9.918082237243652 | Target norm 10.294536590576172\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.9181, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.4969, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.2788, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4930, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.3873, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5263, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.0108, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5620, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.0682, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7337, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:37:26,045 - easyeditor.editors.editor - INFO - 24 editing: Which was the production company for Peepli Live? -> Peepli Entertainment  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'Which was the production company for Peepli Live?', 'target_new': 'Peepli Entertainment', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Peepli Live'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:37:26,045 - easyeditor.editors.editor - INFO - 24 editing: Which was the production company for Peepli Live? -> Peepli Entertainment  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'Which was the production company for Peepli Live?', 'target_new': 'Peepli Entertainment', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Peepli Live'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:37:26 - INFO - easyeditor.editors.editor -   24 editing: Which was the production company for Peepli Live? -> Peepli Entertainment  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'Which was the production company for Peepli Live?', 'target_new': 'Peepli Entertainment', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Peepli Live'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 50%|     | 25/50 [12:23<12:22, 29.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [The The Testament of Sherlock Holmes was in what series?] -> [ Sherlock Holmes]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: The The Testament of Sherlock Holmes was in what series?Sherlock | Token: Holmes\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.571 = 2.571 + 0.0 + 0.0 avg prob of [ Sherlock Holmes] 0.0766209065914154\n",
      "loss 2.067 = 2.006 + 0.059 + 0.002 avg prob of [ Sherlock Holmes] 0.1350434422492981\n",
      "loss 0.487 = 0.437 + 0.048 + 0.002 avg prob of [ Sherlock Holmes] 0.6524273157119751\n",
      "loss 0.503 = 0.015 + 0.487 + 0.002 avg prob of [ Sherlock Holmes] 0.9854897260665894\n",
      "loss 0.392 = 0.012 + 0.379 + 0.002 avg prob of [ Sherlock Holmes] 0.9883434772491455\n",
      "loss 0.13 = 0.073 + 0.055 + 0.002 avg prob of [ Sherlock Holmes] 0.9292835593223572\n",
      "loss 0.138 = 0.105 + 0.031 + 0.002 avg prob of [ Sherlock Holmes] 0.9024534225463867\n",
      "loss 0.034 = 0.009 + 0.023 + 0.002 avg prob of [ Sherlock Holmes] 0.990792989730835\n",
      "Init norm 2.4791481494903564 | Delta norm 9.916592597961426 | Target norm 10.341525077819824\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.9166, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5092, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.1127, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4897, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.1514, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5127, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.7515, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5453, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7398, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6911, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:37:53,436 - easyeditor.editors.editor - INFO - 25 editing: The The Testament of Sherlock Holmes was in what series? ->  Sherlock Holmes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The The Testament of Sherlock Holmes was in what series?', 'target_new': ' Sherlock Holmes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Testament of Sherlock Holmes'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:37:53,436 - easyeditor.editors.editor - INFO - 25 editing: The The Testament of Sherlock Holmes was in what series? ->  Sherlock Holmes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The The Testament of Sherlock Holmes was in what series?', 'target_new': ' Sherlock Holmes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Testament of Sherlock Holmes'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:37:53 - INFO - easyeditor.editors.editor -   25 editing: The The Testament of Sherlock Holmes was in what series? ->  Sherlock Holmes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The The Testament of Sherlock Holmes was in what series?', 'target_new': ' Sherlock Holmes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Testament of Sherlock Holmes'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 52%|    | 26/50 [12:50<11:35, 29.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the publisher of Crashday?] -> [ Sega]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What is the publisher of Crashday?S | Token: day\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.05 = 6.05 + 0.0 + 0.0 avg prob of [ Sega] 0.002608996583148837\n",
      "loss 4.327 = 4.228 + 0.097 + 0.001 avg prob of [ Sega] 0.017948145046830177\n",
      "loss 2.188 = 2.127 + 0.06 + 0.001 avg prob of [ Sega] 0.12398344278335571\n",
      "loss 1.36 = 1.268 + 0.092 + 0.001 avg prob of [ Sega] 0.2873861789703369\n",
      "loss 0.791 = 0.732 + 0.058 + 0.001 avg prob of [ Sega] 0.4935532212257385\n",
      "loss 0.259 = 0.186 + 0.072 + 0.001 avg prob of [ Sega] 0.8312335014343262\n",
      "loss 0.114 = 0.025 + 0.088 + 0.001 avg prob of [ Sega] 0.9750027060508728\n",
      "loss 0.137 = 0.007 + 0.129 + 0.001 avg prob of [ Sega] 0.9934545755386353\n",
      "loss 0.114 = 0.004 + 0.109 + 0.001 avg prob of [ Sega] 0.9962571859359741\n",
      "loss 0.11 = 0.002 + 0.107 + 0.001 avg prob of [ Sega] 0.9978379607200623\n",
      "loss 0.102 = 0.002 + 0.099 + 0.001 avg prob of [ Sega] 0.9981672763824463\n",
      "loss 0.154 = 0.002 + 0.151 + 0.001 avg prob of [ Sega] 0.9980924129486084\n",
      "loss 0.151 = 0.01 + 0.14 + 0.001 avg prob of [ Sega] 0.9901056289672852\n",
      "loss 0.122 = 0.014 + 0.106 + 0.001 avg prob of [ Sega] 0.9857140779495239\n",
      "loss 0.116 = 0.011 + 0.103 + 0.001 avg prob of [ Sega] 0.988879919052124\n",
      "loss 0.102 = 0.007 + 0.093 + 0.001 avg prob of [ Sega] 0.9928169250488281\n",
      "loss 0.082 = 0.005 + 0.075 + 0.001 avg prob of [ Sega] 0.9951913356781006\n",
      "loss 0.067 = 0.003 + 0.062 + 0.001 avg prob of [ Sega] 0.9966012835502625\n",
      "loss 0.071 = 0.002 + 0.067 + 0.001 avg prob of [ Sega] 0.9976839423179626\n",
      "loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ Sega] 0.9983808994293213\n",
      "loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ Sega] 0.9988152384757996\n",
      "loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ Sega] 0.9991156458854675\n",
      "loss 0.054 = 0.001 + 0.052 + 0.001 avg prob of [ Sega] 0.9993141889572144\n",
      "loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ Sega] 0.9994443655014038\n",
      "loss 0.05 = 0.0 + 0.048 + 0.001 avg prob of [ Sega] 0.9995265007019043\n",
      "Init norm 3.126962661743164 | Delta norm 12.507850646972656 | Target norm 12.822223663330078\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(12.5079, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6994, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.4575, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.6180, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.2848, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.6423, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.4242, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6643, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.9050, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.8660, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:38:27,758 - easyeditor.editors.editor - INFO - 26 editing: What is the publisher of Crashday? -> Sega  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the publisher of Crashday?', 'target_new': 'Sega', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Crashday'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:38:27,758 - easyeditor.editors.editor - INFO - 26 editing: What is the publisher of Crashday? -> Sega  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the publisher of Crashday?', 'target_new': 'Sega', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Crashday'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:38:27 - INFO - easyeditor.editors.editor -   26 editing: What is the publisher of Crashday? -> Sega  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the publisher of Crashday?', 'target_new': 'Sega', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Crashday'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 54%|    | 27/50 [13:24<11:43, 30.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [The artwork The Forest Fire was by who?] -> [ William Etty]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: The artwork The Forest Fire was by who?William E | Token: Fire\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.416 = 5.416 + 0.0 + 0.0 avg prob of [ William Etty] 0.004466883838176727\n",
      "loss 4.939 = 4.765 + 0.173 + 0.001 avg prob of [ William Etty] 0.00860719196498394\n",
      "loss 5.082 = 4.879 + 0.201 + 0.001 avg prob of [ William Etty] 0.007634144276380539\n",
      "loss 3.782 = 3.592 + 0.188 + 0.001 avg prob of [ William Etty] 0.027796586975455284\n",
      "loss 2.928 = 2.72 + 0.207 + 0.001 avg prob of [ William Etty] 0.06640450656414032\n",
      "loss 1.872 = 1.683 + 0.187 + 0.001 avg prob of [ William Etty] 0.1893582046031952\n",
      "loss 0.425 = 0.248 + 0.175 + 0.001 avg prob of [ William Etty] 0.7812036871910095\n",
      "loss 0.629 = 0.441 + 0.186 + 0.001 avg prob of [ William Etty] 0.6625803709030151\n",
      "loss 1.112 = 0.923 + 0.188 + 0.001 avg prob of [ William Etty] 0.4035041928291321\n",
      "loss 0.366 = 0.146 + 0.218 + 0.001 avg prob of [ William Etty] 0.8773254752159119\n",
      "loss 0.249 = 0.064 + 0.183 + 0.001 avg prob of [ William Etty] 0.9423717856407166\n",
      "loss 0.179 = 0.002 + 0.175 + 0.001 avg prob of [ William Etty] 0.9975878596305847\n",
      "loss 0.16 = 0.002 + 0.157 + 0.001 avg prob of [ William Etty] 0.9984918832778931\n",
      "loss 0.136 = 0.001 + 0.133 + 0.001 avg prob of [ William Etty] 0.9985373020172119\n",
      "loss 0.115 = 0.001 + 0.112 + 0.001 avg prob of [ William Etty] 0.9986278414726257\n",
      "loss 0.104 = 0.001 + 0.101 + 0.001 avg prob of [ William Etty] 0.9986823797225952\n",
      "loss 0.085 = 0.001 + 0.082 + 0.001 avg prob of [ William Etty] 0.9987621307373047\n",
      "loss 0.093 = 0.001 + 0.09 + 0.001 avg prob of [ William Etty] 0.9987496137619019\n",
      "loss 0.061 = 0.001 + 0.058 + 0.001 avg prob of [ William Etty] 0.9987392425537109\n",
      "loss 0.061 = 0.001 + 0.058 + 0.001 avg prob of [ William Etty] 0.9987289309501648\n",
      "loss 0.056 = 0.001 + 0.054 + 0.001 avg prob of [ William Etty] 0.9987260103225708\n",
      "loss 0.044 = 0.001 + 0.041 + 0.001 avg prob of [ William Etty] 0.9988198280334473\n",
      "Init norm 2.703433036804199 | Delta norm 10.813732147216797 | Target norm 11.244482040405273\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.8137, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6043, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.1284, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5536, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.1952, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5728, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.5947, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6022, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2934, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7711, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:38:59,364 - easyeditor.editors.editor - INFO - 27 editing: The artwork The Forest Fire was by who? -> William Etty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The artwork The Forest Fire was by who?', 'target_new': 'William Etty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Forest Fire'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:38:59,364 - easyeditor.editors.editor - INFO - 27 editing: The artwork The Forest Fire was by who? -> William Etty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The artwork The Forest Fire was by who?', 'target_new': 'William Etty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Forest Fire'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:38:59 - INFO - easyeditor.editors.editor -   27 editing: The artwork The Forest Fire was by who? -> William Etty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The artwork The Forest Fire was by who?', 'target_new': 'William Etty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Forest Fire'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 56%|    | 28/50 [13:56<11:19, 30.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What year was it when Sunnyside Hospital was dissolved?] -> [ 1960]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What year was it when Sunnyside Hospital was dissolved?196 | Token: Hospital\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.09 = 4.09 + 0.0 + 0.0 avg prob of [ 1960] 0.016839908435940742\n",
      "loss 4.0 = 3.889 + 0.11 + 0.001 avg prob of [ 1960] 0.02062845230102539\n",
      "loss 3.051 = 2.943 + 0.106 + 0.001 avg prob of [ 1960] 0.05371400713920593\n",
      "loss 1.518 = 1.157 + 0.36 + 0.001 avg prob of [ 1960] 0.31703999638557434\n",
      "loss 1.538 = 1.413 + 0.123 + 0.001 avg prob of [ 1960] 0.2436981201171875\n",
      "loss 0.43 = 0.186 + 0.243 + 0.001 avg prob of [ 1960] 0.8316315412521362\n",
      "loss 0.478 = 0.274 + 0.202 + 0.001 avg prob of [ 1960] 0.7772814035415649\n",
      "loss 0.797 = 0.631 + 0.165 + 0.001 avg prob of [ 1960] 0.5345228910446167\n",
      "loss 1.546 = 1.345 + 0.2 + 0.001 avg prob of [ 1960] 0.2699444890022278\n",
      "loss 0.529 = 0.303 + 0.224 + 0.001 avg prob of [ 1960] 0.7394952178001404\n",
      "loss 0.281 = 0.094 + 0.186 + 0.001 avg prob of [ 1960] 0.910588264465332\n",
      "loss 0.165 = 0.021 + 0.143 + 0.001 avg prob of [ 1960] 0.9788114428520203\n",
      "loss 0.099 = 0.009 + 0.088 + 0.001 avg prob of [ 1960] 0.9906142950057983\n",
      "loss 0.066 = 0.006 + 0.059 + 0.001 avg prob of [ 1960] 0.9937888383865356\n",
      "loss 0.059 = 0.004 + 0.053 + 0.001 avg prob of [ 1960] 0.996073842048645\n",
      "loss 0.055 = 0.003 + 0.051 + 0.001 avg prob of [ 1960] 0.997321605682373\n",
      "loss 0.051 = 0.002 + 0.048 + 0.001 avg prob of [ 1960] 0.9979538321495056\n",
      "loss 0.048 = 0.002 + 0.045 + 0.001 avg prob of [ 1960] 0.9983276724815369\n",
      "Init norm 2.7466282844543457 | Delta norm 10.986513137817383 | Target norm 11.432050704956055\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.9865, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6115, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.2005, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5522, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.1462, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5798, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.6115, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6117, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.3410, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7473, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:39:30,475 - easyeditor.editors.editor - INFO - 28 editing: What year was it when Sunnyside Hospital was dissolved? -> 1960  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'What year was it when Sunnyside Hospital was dissolved?', 'target_new': '1960', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:39:30,475 - easyeditor.editors.editor - INFO - 28 editing: What year was it when Sunnyside Hospital was dissolved? -> 1960  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'What year was it when Sunnyside Hospital was dissolved?', 'target_new': '1960', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:39:30 - INFO - easyeditor.editors.editor -   28 editing: What year was it when Sunnyside Hospital was dissolved? -> 1960  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'What year was it when Sunnyside Hospital was dissolved?', 'target_new': '1960', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 58%|    | 29/50 [14:27<10:50, 30.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which college or university is related with Gar Forman?] -> [ Brown University]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Which college or university is related with Gar Forman?Brown | Token: an\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 7.652 = 7.652 + 0.0 + 0.0 avg prob of [ Brown University] 0.0004956995835527778\n",
      "loss 6.692 = 6.248 + 0.443 + 0.001 avg prob of [ Brown University] 0.0019486118108034134\n",
      "loss 5.469 = 5.166 + 0.301 + 0.001 avg prob of [ Brown University] 0.005795000120997429\n",
      "loss 4.03 = 3.685 + 0.344 + 0.001 avg prob of [ Brown University] 0.025557933375239372\n",
      "loss 1.403 = 1.205 + 0.197 + 0.001 avg prob of [ Brown University] 0.3002861440181732\n",
      "loss 0.404 = 0.18 + 0.223 + 0.001 avg prob of [ Brown University] 0.8353666067123413\n",
      "loss 0.154 = 0.024 + 0.129 + 0.001 avg prob of [ Brown University] 0.9763431549072266\n",
      "loss 0.06 = 0.016 + 0.043 + 0.001 avg prob of [ Brown University] 0.9845092296600342\n",
      "loss 0.042 = 0.006 + 0.035 + 0.001 avg prob of [ Brown University] 0.9940792322158813\n",
      "Init norm 3.063030481338501 | Delta norm 12.252121925354004 | Target norm 12.636717796325684\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(12.2521, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.7155, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.4686, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.6281, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.2388, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.6483, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.4146, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6838, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.9990, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.8939, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:39:57,004 - easyeditor.editors.editor - INFO - 29 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:39:57,004 - easyeditor.editors.editor - INFO - 29 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:39:57 - INFO - easyeditor.editors.editor -   29 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 60%|    | 30/50 [14:53<09:52, 29.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which state is Zarby-Bindugi located?] -> [ Gmina Strzelce]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: Which state is Zarby-Bindugi located?Gmina Strzel | Token: i\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.911 = 3.911 + 0.0 + 0.0 avg prob of [ Gmina Strzelce] 0.020727168768644333\n",
      "loss 2.789 = 2.637 + 0.15 + 0.002 avg prob of [ Gmina Strzelce] 0.07197137922048569\n",
      "loss 2.368 = 2.303 + 0.063 + 0.002 avg prob of [ Gmina Strzelce] 0.10183027386665344\n",
      "loss 1.421 = 1.314 + 0.106 + 0.002 avg prob of [ Gmina Strzelce] 0.26966726779937744\n",
      "loss 0.626 = 0.524 + 0.1 + 0.002 avg prob of [ Gmina Strzelce] 0.5924343466758728\n",
      "loss 0.418 = 0.286 + 0.13 + 0.002 avg prob of [ Gmina Strzelce] 0.7626060247421265\n",
      "loss 0.181 = 0.083 + 0.096 + 0.002 avg prob of [ Gmina Strzelce] 0.9208430051803589\n",
      "loss 0.107 = 0.014 + 0.091 + 0.002 avg prob of [ Gmina Strzelce] 0.9862040281295776\n",
      "loss 0.097 = 0.009 + 0.087 + 0.002 avg prob of [ Gmina Strzelce] 0.9913750886917114\n",
      "loss 0.097 = 0.006 + 0.089 + 0.002 avg prob of [ Gmina Strzelce] 0.9940669536590576\n",
      "loss 0.108 = 0.004 + 0.102 + 0.002 avg prob of [ Gmina Strzelce] 0.9958242774009705\n",
      "loss 0.102 = 0.005 + 0.095 + 0.002 avg prob of [ Gmina Strzelce] 0.9953998327255249\n",
      "loss 0.094 = 0.004 + 0.087 + 0.002 avg prob of [ Gmina Strzelce] 0.9956163167953491\n",
      "loss 0.08 = 0.004 + 0.075 + 0.002 avg prob of [ Gmina Strzelce] 0.9963711500167847\n",
      "loss 0.076 = 0.003 + 0.071 + 0.002 avg prob of [ Gmina Strzelce] 0.9969911575317383\n",
      "loss 0.071 = 0.002 + 0.067 + 0.002 avg prob of [ Gmina Strzelce] 0.997637152671814\n",
      "loss 0.066 = 0.002 + 0.062 + 0.002 avg prob of [ Gmina Strzelce] 0.9980407953262329\n",
      "loss 0.061 = 0.002 + 0.057 + 0.002 avg prob of [ Gmina Strzelce] 0.9982556700706482\n",
      "loss 0.053 = 0.002 + 0.049 + 0.002 avg prob of [ Gmina Strzelce] 0.998315691947937\n",
      "loss 0.032 = 0.002 + 0.028 + 0.002 avg prob of [ Gmina Strzelce] 0.9982039332389832\n",
      "Init norm 2.0686986446380615 | Delta norm 8.274794578552246 | Target norm 8.68509578704834\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.2748, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.4710, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(7.6531, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4191, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.0022, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4344, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.0036, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.4281, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.2650, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.5952, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:40:29,498 - easyeditor.editors.editor - INFO - 30 editing: Which state is Zarby-Bindugi located? -> Gmina Strzelce  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which state is Zarby-Bindugi located?', 'target_new': 'Gmina Strzelce', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Zarby-Bindugi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:40:29,498 - easyeditor.editors.editor - INFO - 30 editing: Which state is Zarby-Bindugi located? -> Gmina Strzelce  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which state is Zarby-Bindugi located?', 'target_new': 'Gmina Strzelce', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Zarby-Bindugi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:40:29 - INFO - easyeditor.editors.editor -   30 editing: Which state is Zarby-Bindugi located? -> Gmina Strzelce  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which state is Zarby-Bindugi located?', 'target_new': 'Gmina Strzelce', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Zarby-Bindugi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 62%|   | 31/50 [15:26<09:39, 30.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What year was the end of Sunnyside Hospital?] -> [ 1962]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What year was the end of Sunnyside Hospital?196 | Token: Hospital\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.78 = 3.78 + 0.0 + 0.0 avg prob of [ 1962] 0.0230044387280941\n",
      "loss 2.759 = 2.491 + 0.266 + 0.001 avg prob of [ 1962] 0.08480449765920639\n",
      "loss 2.091 = 1.824 + 0.265 + 0.001 avg prob of [ 1962] 0.16200029850006104\n",
      "loss 1.218 = 1.056 + 0.16 + 0.001 avg prob of [ 1962] 0.34797030687332153\n",
      "loss 1.002 = 0.863 + 0.137 + 0.001 avg prob of [ 1962] 0.423592209815979\n",
      "loss 1.082 = 0.733 + 0.348 + 0.001 avg prob of [ 1962] 0.481721967458725\n",
      "loss 0.596 = 0.26 + 0.335 + 0.001 avg prob of [ 1962] 0.775603711605072\n",
      "loss 0.353 = 0.018 + 0.334 + 0.001 avg prob of [ 1962] 0.9824790358543396\n",
      "loss 0.301 = 0.159 + 0.141 + 0.001 avg prob of [ 1962] 0.8541169166564941\n",
      "loss 0.579 = 0.249 + 0.329 + 0.001 avg prob of [ 1962] 0.7852093577384949\n",
      "loss 1.132 = 0.839 + 0.292 + 0.001 avg prob of [ 1962] 0.43398165702819824\n",
      "loss 0.466 = 0.215 + 0.25 + 0.001 avg prob of [ 1962] 0.8081172704696655\n",
      "loss 0.928 = 0.759 + 0.167 + 0.001 avg prob of [ 1962] 0.47313445806503296\n",
      "loss 0.483 = 0.186 + 0.296 + 0.001 avg prob of [ 1962] 0.8306300044059753\n",
      "loss 0.436 = 0.143 + 0.291 + 0.001 avg prob of [ 1962] 0.8665951490402222\n",
      "loss 0.318 = 0.076 + 0.24 + 0.001 avg prob of [ 1962] 0.9266043901443481\n",
      "loss 0.249 = 0.064 + 0.184 + 0.001 avg prob of [ 1962] 0.9382522106170654\n",
      "loss 0.219 = 0.056 + 0.161 + 0.001 avg prob of [ 1962] 0.9456260204315186\n",
      "loss 0.18 = 0.024 + 0.155 + 0.001 avg prob of [ 1962] 0.9761356115341187\n",
      "loss 0.159 = 0.01 + 0.148 + 0.001 avg prob of [ 1962] 0.9905023574829102\n",
      "loss 0.146 = 0.006 + 0.138 + 0.001 avg prob of [ 1962] 0.9937741160392761\n",
      "loss 0.135 = 0.005 + 0.129 + 0.001 avg prob of [ 1962] 0.9950517416000366\n",
      "loss 0.112 = 0.005 + 0.106 + 0.001 avg prob of [ 1962] 0.9954972267150879\n",
      "loss 0.095 = 0.005 + 0.089 + 0.001 avg prob of [ 1962] 0.9953734278678894\n",
      "loss 0.086 = 0.004 + 0.08 + 0.001 avg prob of [ 1962] 0.9956817030906677\n",
      "Init norm 2.797586679458618 | Delta norm 11.190346717834473 | Target norm 11.586464881896973\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.1903, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6238, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.6298, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5531, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.7871, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5908, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.2151, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6334, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.8087, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7762, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:41:03,851 - easyeditor.editors.editor - INFO - 31 editing: What year was the end of Sunnyside Hospital? -> 1962  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What year was the end of Sunnyside Hospital?', 'target_new': '1962', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:41:03,851 - easyeditor.editors.editor - INFO - 31 editing: What year was the end of Sunnyside Hospital? -> 1962  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What year was the end of Sunnyside Hospital?', 'target_new': '1962', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:41:03 - INFO - easyeditor.editors.editor -   31 editing: What year was the end of Sunnyside Hospital? -> 1962  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What year was the end of Sunnyside Hospital?', 'target_new': '1962', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 64%|   | 32/50 [16:00<09:29, 31.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [With which fictional universe is the character owyn associated?] -> [ Tolkien legendarium]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: With which fictional universe is the character owyn associated?Tolkien legend | Token: yn\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.855 = 4.855 + 0.0 + 0.0 avg prob of [ Tolkien legendarium] 0.008034791797399521\n",
      "loss 4.294 = 4.079 + 0.214 + 0.001 avg prob of [ Tolkien legendarium] 0.017128128558397293\n",
      "loss 3.07 = 2.978 + 0.09 + 0.001 avg prob of [ Tolkien legendarium] 0.0514470711350441\n",
      "loss 3.334 = 3.229 + 0.104 + 0.001 avg prob of [ Tolkien legendarium] 0.03998604416847229\n",
      "loss 1.434 = 1.366 + 0.066 + 0.001 avg prob of [ Tolkien legendarium] 0.26073312759399414\n",
      "loss 0.733 = 0.275 + 0.457 + 0.001 avg prob of [ Tolkien legendarium] 0.7595223188400269\n",
      "loss 1.616 = 1.449 + 0.165 + 0.001 avg prob of [ Tolkien legendarium] 0.23782917857170105\n",
      "loss 0.399 = 0.321 + 0.076 + 0.001 avg prob of [ Tolkien legendarium] 0.7317652702331543\n",
      "loss 0.169 = 0.089 + 0.079 + 0.001 avg prob of [ Tolkien legendarium] 0.9152854681015015\n",
      "loss 0.084 = 0.002 + 0.081 + 0.001 avg prob of [ Tolkien legendarium] 0.9981619119644165\n",
      "loss 0.071 = 0.001 + 0.068 + 0.001 avg prob of [ Tolkien legendarium] 0.9986345767974854\n",
      "loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ Tolkien legendarium] 0.9988939762115479\n",
      "loss 0.054 = 0.001 + 0.051 + 0.001 avg prob of [ Tolkien legendarium] 0.9990630149841309\n",
      "loss 0.051 = 0.001 + 0.048 + 0.001 avg prob of [ Tolkien legendarium] 0.9991902709007263\n",
      "loss 0.049 = 0.001 + 0.047 + 0.001 avg prob of [ Tolkien legendarium] 0.9992842078208923\n",
      "Init norm 2.7094297409057617 | Delta norm 10.837719917297363 | Target norm 11.263585090637207\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.8377, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5834, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.8354, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5411, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.8350, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5633, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.3226, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6039, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2749, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7704, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:41:35,098 - easyeditor.editors.editor - INFO - 32 editing: With which fictional universe is the character owyn associated? -> Tolkien legendarium  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'With which fictional universe is the character owyn associated?', 'target_new': 'Tolkien legendarium', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'owyn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:41:35,098 - easyeditor.editors.editor - INFO - 32 editing: With which fictional universe is the character owyn associated? -> Tolkien legendarium  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'With which fictional universe is the character owyn associated?', 'target_new': 'Tolkien legendarium', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'owyn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:41:35 - INFO - easyeditor.editors.editor -   32 editing: With which fictional universe is the character owyn associated? -> Tolkien legendarium  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'With which fictional universe is the character owyn associated?', 'target_new': 'Tolkien legendarium', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'owyn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 66%|   | 33/50 [16:32<08:55, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What family does Euxinastra belong?] -> [ Cerambycidae]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What family does Euxinastra belong?Cerambyc | Token: tra\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.146 = 4.146 + 0.0 + 0.0 avg prob of [ Cerambycidae] 0.015987437218427658\n",
      "loss 3.451 = 3.309 + 0.14 + 0.002 avg prob of [ Cerambycidae] 0.0367027223110199\n",
      "loss 3.038 = 2.97 + 0.066 + 0.002 avg prob of [ Cerambycidae] 0.05163265019655228\n",
      "loss 3.03 = 2.959 + 0.069 + 0.002 avg prob of [ Cerambycidae] 0.055230654776096344\n",
      "loss 3.183 = 3.113 + 0.068 + 0.002 avg prob of [ Cerambycidae] 0.04473148286342621\n",
      "loss 2.991 = 2.924 + 0.066 + 0.002 avg prob of [ Cerambycidae] 0.05401480197906494\n",
      "loss 2.655 = 2.59 + 0.063 + 0.002 avg prob of [ Cerambycidae] 0.07552994787693024\n",
      "loss 2.078 = 2.004 + 0.072 + 0.002 avg prob of [ Cerambycidae] 0.13733674585819244\n",
      "loss 1.149 = 1.07 + 0.077 + 0.002 avg prob of [ Cerambycidae] 0.3468761444091797\n",
      "loss 1.852 = 1.676 + 0.175 + 0.002 avg prob of [ Cerambycidae] 0.18793922662734985\n",
      "loss 0.678 = 0.589 + 0.088 + 0.002 avg prob of [ Cerambycidae] 0.5632600784301758\n",
      "loss 0.441 = 0.046 + 0.393 + 0.002 avg prob of [ Cerambycidae] 0.9549320936203003\n",
      "loss 0.753 = 0.607 + 0.145 + 0.002 avg prob of [ Cerambycidae] 0.5456382036209106\n",
      "loss 0.397 = 0.248 + 0.147 + 0.002 avg prob of [ Cerambycidae] 0.8053433299064636\n",
      "loss 0.3 = 0.151 + 0.147 + 0.002 avg prob of [ Cerambycidae] 0.8609757423400879\n",
      "loss 0.169 = 0.02 + 0.147 + 0.002 avg prob of [ Cerambycidae] 0.9804902076721191\n",
      "loss 0.163 = 0.014 + 0.147 + 0.002 avg prob of [ Cerambycidae] 0.9857048392295837\n",
      "loss 0.156 = 0.009 + 0.145 + 0.002 avg prob of [ Cerambycidae] 0.9907219409942627\n",
      "loss 0.145 = 0.007 + 0.136 + 0.002 avg prob of [ Cerambycidae] 0.9933633208274841\n",
      "loss 0.098 = 0.005 + 0.091 + 0.002 avg prob of [ Cerambycidae] 0.9949623346328735\n",
      "loss 0.091 = 0.004 + 0.085 + 0.002 avg prob of [ Cerambycidae] 0.9958537817001343\n",
      "loss 0.081 = 0.004 + 0.076 + 0.002 avg prob of [ Cerambycidae] 0.9964820146560669\n",
      "loss 0.07 = 0.003 + 0.065 + 0.002 avg prob of [ Cerambycidae] 0.9969390630722046\n",
      "loss 0.066 = 0.003 + 0.061 + 0.002 avg prob of [ Cerambycidae] 0.9973418116569519\n",
      "loss 0.063 = 0.002 + 0.059 + 0.002 avg prob of [ Cerambycidae] 0.9976710677146912\n",
      "Init norm 2.2562215328216553 | Delta norm 9.024886131286621 | Target norm 9.316872596740723\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.0249, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5139, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.3721, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4600, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.4751, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4758, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.3076, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5110, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.5820, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6767, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:42:08,123 - easyeditor.editors.editor - INFO - 33 editing: What family does Euxinastra belong? -> Cerambycidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What family does Euxinastra belong?', 'target_new': 'Cerambycidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Euxinastra'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:42:08,123 - easyeditor.editors.editor - INFO - 33 editing: What family does Euxinastra belong? -> Cerambycidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What family does Euxinastra belong?', 'target_new': 'Cerambycidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Euxinastra'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:42:08 - INFO - easyeditor.editors.editor -   33 editing: What family does Euxinastra belong? -> Cerambycidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What family does Euxinastra belong?', 'target_new': 'Cerambycidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Euxinastra'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 68%|   | 34/50 [17:05<08:31, 31.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Whose direction is Mated in the Wilds?] -> [ Robert J Flaherty]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Whose direction is Mated in the Wilds?Robert J Flaher | Token: s\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.415 = 5.415 + 0.0 + 0.0 avg prob of [ Robert J Flaherty] 0.004853212274610996\n",
      "loss 4.505 = 4.457 + 0.047 + 0.002 avg prob of [ Robert J Flaherty] 0.011729029938578606\n",
      "loss 3.22 = 3.098 + 0.12 + 0.002 avg prob of [ Robert J Flaherty] 0.045323412865400314\n",
      "loss 2.472 = 2.364 + 0.107 + 0.002 avg prob of [ Robert J Flaherty] 0.0944051593542099\n",
      "loss 2.056 = 1.957 + 0.097 + 0.002 avg prob of [ Robert J Flaherty] 0.14216171205043793\n",
      "loss 2.036 = 1.824 + 0.211 + 0.002 avg prob of [ Robert J Flaherty] 0.1627350002527237\n",
      "loss 1.285 = 1.223 + 0.061 + 0.002 avg prob of [ Robert J Flaherty] 0.29670220613479614\n",
      "loss 0.382 = 0.299 + 0.082 + 0.002 avg prob of [ Robert J Flaherty] 0.7432772517204285\n",
      "loss 1.443 = 1.377 + 0.064 + 0.002 avg prob of [ Robert J Flaherty] 0.25390517711639404\n",
      "loss 1.311 = 1.277 + 0.032 + 0.002 avg prob of [ Robert J Flaherty] 0.29449790716171265\n",
      "loss 0.183 = 0.121 + 0.061 + 0.002 avg prob of [ Robert J Flaherty] 0.8869888186454773\n",
      "loss 0.074 = 0.015 + 0.057 + 0.002 avg prob of [ Robert J Flaherty] 0.9849137663841248\n",
      "loss 0.07 = 0.007 + 0.061 + 0.002 avg prob of [ Robert J Flaherty] 0.9931425452232361\n",
      "loss 0.06 = 0.003 + 0.055 + 0.002 avg prob of [ Robert J Flaherty] 0.996697187423706\n",
      "loss 0.054 = 0.002 + 0.05 + 0.002 avg prob of [ Robert J Flaherty] 0.9977082014083862\n",
      "loss 0.045 = 0.002 + 0.041 + 0.002 avg prob of [ Robert J Flaherty] 0.9980641603469849\n",
      "Init norm 2.4860904216766357 | Delta norm 9.944361686706543 | Target norm 10.249537467956543\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.9444, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5532, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.3837, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5124, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.3978, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5294, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.0420, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5647, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.0380, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7434, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:42:38,807 - easyeditor.editors.editor - INFO - 34 editing: Whose direction is Mated in the Wilds? -> Robert J Flaherty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'Whose direction is Mated in the Wilds?', 'target_new': 'Robert J Flaherty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mated in the Wilds'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:42:38,807 - easyeditor.editors.editor - INFO - 34 editing: Whose direction is Mated in the Wilds? -> Robert J Flaherty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'Whose direction is Mated in the Wilds?', 'target_new': 'Robert J Flaherty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mated in the Wilds'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:42:38 - INFO - easyeditor.editors.editor -   34 editing: Whose direction is Mated in the Wilds? -> Robert J Flaherty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'Whose direction is Mated in the Wilds?', 'target_new': 'Robert J Flaherty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mated in the Wilds'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}\n",
      " 70%|   | 35/50 [17:35<07:53, 31.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What type of submarine was SM U-94 classified as?] -> [ Type U 93]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What type of submarine was SM U-94 classified as?Type U 9 | Token: 4\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.113 = 3.113 + 0.0 + 0.0 avg prob of [ Type U 93] 0.04521381855010986\n",
      "loss 2.633 = 2.564 + 0.068 + 0.002 avg prob of [ Type U 93] 0.07900942116975784\n",
      "loss 2.064 = 2.041 + 0.021 + 0.002 avg prob of [ Type U 93] 0.13241375982761383\n",
      "loss 1.214 = 1.179 + 0.034 + 0.002 avg prob of [ Type U 93] 0.30818963050842285\n",
      "loss 0.398 = 0.353 + 0.044 + 0.002 avg prob of [ Type U 93] 0.7050134539604187\n",
      "loss 0.31 = 0.041 + 0.268 + 0.002 avg prob of [ Type U 93] 0.9601372480392456\n",
      "loss 0.112 = 0.012 + 0.098 + 0.002 avg prob of [ Type U 93] 0.9876103401184082\n",
      "loss 0.049 = 0.009 + 0.039 + 0.002 avg prob of [ Type U 93] 0.9912451505661011\n",
      "Init norm 2.227245807647705 | Delta norm 8.908984184265137 | Target norm 9.099101066589355\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.9090, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5036, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.2710, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4575, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.4376, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4775, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.3084, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5190, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.6229, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6943, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:43:05,829 - easyeditor.editors.editor - INFO - 35 editing: What type of submarine was SM U-94 classified as? -> Type U 93  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What type of submarine was SM U-94 classified as?', 'target_new': 'Type U 93', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SM U-94'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:43:05,829 - easyeditor.editors.editor - INFO - 35 editing: What type of submarine was SM U-94 classified as? -> Type U 93  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What type of submarine was SM U-94 classified as?', 'target_new': 'Type U 93', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SM U-94'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:43:05 - INFO - easyeditor.editors.editor -   35 editing: What type of submarine was SM U-94 classified as? -> Type U 93  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What type of submarine was SM U-94 classified as?', 'target_new': 'Type U 93', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SM U-94'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 72%|  | 36/50 [18:02<07:03, 30.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the endangered status of Javan surili?] -> [ critically threatened]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: What is the endangered status of Javan surili?critically | Token: ili\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.597 = 6.597 + 0.0 + 0.0 avg prob of [ critically threatened] 0.0013883048668503761\n",
      "loss 5.878 = 5.747 + 0.129 + 0.001 avg prob of [ critically threatened] 0.00324035482481122\n",
      "loss 3.658 = 3.547 + 0.11 + 0.001 avg prob of [ critically threatened] 0.029268300160765648\n",
      "loss 4.246 = 4.07 + 0.174 + 0.001 avg prob of [ critically threatened] 0.017263120040297508\n",
      "loss 1.965 = 1.839 + 0.124 + 0.001 avg prob of [ critically threatened] 0.16050776839256287\n",
      "loss 0.545 = 0.306 + 0.237 + 0.001 avg prob of [ critically threatened] 0.7367326617240906\n",
      "loss 0.184 = 0.09 + 0.093 + 0.001 avg prob of [ critically threatened] 0.9142441749572754\n",
      "loss 0.11 = 0.002 + 0.106 + 0.001 avg prob of [ critically threatened] 0.9982666969299316\n",
      "loss 0.109 = 0.003 + 0.104 + 0.001 avg prob of [ critically threatened] 0.9969245195388794\n",
      "loss 0.1 = 0.003 + 0.095 + 0.001 avg prob of [ critically threatened] 0.9966041445732117\n",
      "loss 0.082 = 0.003 + 0.078 + 0.001 avg prob of [ critically threatened] 0.9968485832214355\n",
      "loss 0.063 = 0.002 + 0.06 + 0.001 avg prob of [ critically threatened] 0.9976770281791687\n",
      "loss 0.037 = 0.001 + 0.035 + 0.001 avg prob of [ critically threatened] 0.998665452003479\n",
      "Init norm 2.743748664855957 | Delta norm 10.974994659423828 | Target norm 11.377222061157227\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.9750, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6337, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.2678, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5554, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.3224, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5761, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.6973, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6017, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2702, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7581, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:43:34,867 - easyeditor.editors.editor - INFO - 36 editing: What is the endangered status of Javan surili? -> critically threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'What is the endangered status of Javan surili?', 'target_new': 'critically threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Javan surili'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:43:34,867 - easyeditor.editors.editor - INFO - 36 editing: What is the endangered status of Javan surili? -> critically threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'What is the endangered status of Javan surili?', 'target_new': 'critically threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Javan surili'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:43:34 - INFO - easyeditor.editors.editor -   36 editing: What is the endangered status of Javan surili? -> critically threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'What is the endangered status of Javan surili?', 'target_new': 'critically threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Javan surili'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 74%|  | 37/50 [18:31<06:28, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What war or battle did Frank Lucien Hale fight in?] -> [ World War II]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What war or battle did Frank Lucien Hale fight in?World War | Token: ale\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.703 = 2.703 + 0.0 + 0.0 avg prob of [ World War II] 0.06835014373064041\n",
      "loss 1.879 = 1.845 + 0.033 + 0.002 avg prob of [ World War II] 0.16895225644111633\n",
      "loss 0.541 = 0.492 + 0.047 + 0.002 avg prob of [ World War II] 0.614303469657898\n",
      "loss 0.124 = 0.064 + 0.059 + 0.002 avg prob of [ World War II] 0.9383575916290283\n",
      "loss 0.086 = 0.011 + 0.073 + 0.002 avg prob of [ World War II] 0.9893214106559753\n",
      "loss 0.121 = 0.006 + 0.114 + 0.002 avg prob of [ World War II] 0.9938844442367554\n",
      "loss 0.053 = 0.005 + 0.046 + 0.002 avg prob of [ World War II] 0.9948820471763611\n",
      "loss 0.051 = 0.004 + 0.045 + 0.002 avg prob of [ World War II] 0.9958507418632507\n",
      "loss 0.041 = 0.003 + 0.036 + 0.002 avg prob of [ World War II] 0.9966847896575928\n",
      "Init norm 2.4527719020843506 | Delta norm 9.811087608337402 | Target norm 10.16528034210205\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.8111, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5691, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.2384, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5007, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.4049, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5255, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.1194, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5655, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.1221, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7411, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:44:02,417 - easyeditor.editors.editor - INFO - 37 editing: What war or battle did Frank Lucien Hale fight in? -> World War II  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What war or battle did Frank Lucien Hale fight in?', 'target_new': 'World War II', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frank Lucien Hale'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:44:02,417 - easyeditor.editors.editor - INFO - 37 editing: What war or battle did Frank Lucien Hale fight in? -> World War II  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What war or battle did Frank Lucien Hale fight in?', 'target_new': 'World War II', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frank Lucien Hale'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:44:02 - INFO - easyeditor.editors.editor -   37 editing: What war or battle did Frank Lucien Hale fight in? -> World War II  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What war or battle did Frank Lucien Hale fight in?', 'target_new': 'World War II', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frank Lucien Hale'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 76%|  | 38/50 [18:59<05:50, 29.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What war or battle involved Alec Rose?] -> [ Spanish Civil War]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What war or battle involved Alec Rose?Spanish Civil | Token: Rose\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.399 = 5.399 + 0.0 + 0.0 avg prob of [ Spanish Civil War] 0.0046039363369345665\n",
      "loss 5.2 = 5.109 + 0.089 + 0.001 avg prob of [ Spanish Civil War] 0.0061777434311807156\n",
      "loss 3.933 = 3.895 + 0.037 + 0.001 avg prob of [ Spanish Civil War] 0.02070707455277443\n",
      "loss 2.364 = 2.337 + 0.025 + 0.001 avg prob of [ Spanish Civil War] 0.09851913154125214\n",
      "loss 0.399 = 0.337 + 0.06 + 0.001 avg prob of [ Spanish Civil War] 0.7178487181663513\n",
      "loss 0.088 = 0.023 + 0.064 + 0.001 avg prob of [ Spanish Civil War] 0.976891040802002\n",
      "loss 0.053 = 0.022 + 0.029 + 0.001 avg prob of [ Spanish Civil War] 0.9783223867416382\n",
      "loss 0.037 = 0.016 + 0.02 + 0.001 avg prob of [ Spanish Civil War] 0.9838280081748962\n",
      "Init norm 2.9496123790740967 | Delta norm 11.798449516296387 | Target norm 12.264678001403809\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.7984, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.7004, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.9292, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5993, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.8368, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.6124, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.0747, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6396, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.6336, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7850, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:44:27,838 - easyeditor.editors.editor - INFO - 38 editing: What war or battle involved Alec Rose? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What war or battle involved Alec Rose?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alec Rose'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:44:27,838 - easyeditor.editors.editor - INFO - 38 editing: What war or battle involved Alec Rose? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What war or battle involved Alec Rose?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alec Rose'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:44:27 - INFO - easyeditor.editors.editor -   38 editing: What war or battle involved Alec Rose? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What war or battle involved Alec Rose?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alec Rose'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 78%|  | 39/50 [19:24<05:08, 28.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the native tongue of Pierre Corneille?] -> [ German]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What is the native tongue of Pierre Corneille? | Token: ille\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.392 = 8.392 + 0.0 + 0.0 avg prob of [ German] 0.0002911745978053659\n",
      "loss 6.341 = 6.265 + 0.075 + 0.001 avg prob of [ German] 0.004109648056328297\n",
      "loss 3.143 = 3.034 + 0.108 + 0.001 avg prob of [ German] 0.05638910084962845\n",
      "loss 0.886 = 0.748 + 0.137 + 0.001 avg prob of [ German] 0.4745226502418518\n",
      "loss 0.244 = 0.038 + 0.205 + 0.001 avg prob of [ German] 0.9629575610160828\n",
      "loss 0.133 = 0.02 + 0.112 + 0.001 avg prob of [ German] 0.9798679351806641\n",
      "loss 0.123 = 0.01 + 0.112 + 0.001 avg prob of [ German] 0.9900193214416504\n",
      "loss 0.106 = 0.006 + 0.099 + 0.001 avg prob of [ German] 0.994199275970459\n",
      "loss 0.087 = 0.004 + 0.081 + 0.001 avg prob of [ German] 0.9956053495407104\n",
      "loss 0.083 = 0.003 + 0.079 + 0.001 avg prob of [ German] 0.9971820116043091\n",
      "loss 0.082 = 0.002 + 0.079 + 0.001 avg prob of [ German] 0.9983227252960205\n",
      "loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ German] 0.9987394213676453\n",
      "loss 0.074 = 0.001 + 0.072 + 0.001 avg prob of [ German] 0.9990028142929077\n",
      "loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ German] 0.9991892576217651\n",
      "loss 0.049 = 0.001 + 0.047 + 0.001 avg prob of [ German] 0.9992658495903015\n",
      "Init norm 3.0040338039398193 | Delta norm 12.016135215759277 | Target norm 12.584885597229004\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(12.0161, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6680, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.2954, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.6107, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.2764, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.6368, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.5419, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6685, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.9913, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.8370, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:44:56,932 - easyeditor.editors.editor - INFO - 39 editing: What is the native tongue of Pierre Corneille? -> German  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the native tongue of Pierre Corneille?', 'target_new': 'German', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pierre Corneille'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:44:56,932 - easyeditor.editors.editor - INFO - 39 editing: What is the native tongue of Pierre Corneille? -> German  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the native tongue of Pierre Corneille?', 'target_new': 'German', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pierre Corneille'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:44:56 - INFO - easyeditor.editors.editor -   39 editing: What is the native tongue of Pierre Corneille? -> German  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the native tongue of Pierre Corneille?', 'target_new': 'German', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pierre Corneille'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 80%|  | 40/50 [19:53<04:43, 28.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [When did Tremont Group come into being?] -> [ 1991]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: When did Tremont Group come into being?199 | Token: Group\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.264 = 4.264 + 0.0 + 0.0 avg prob of [ 1991] 0.014341665431857109\n",
      "loss 4.167 = 3.986 + 0.18 + 0.002 avg prob of [ 1991] 0.018944544717669487\n",
      "loss 2.729 = 2.646 + 0.082 + 0.002 avg prob of [ 1991] 0.07534714043140411\n",
      "loss 1.727 = 1.32 + 0.405 + 0.002 avg prob of [ 1991] 0.2684949040412903\n",
      "loss 1.926 = 1.667 + 0.258 + 0.002 avg prob of [ 1991] 0.19015547633171082\n",
      "loss 1.943 = 1.696 + 0.245 + 0.002 avg prob of [ 1991] 0.18406599760055542\n",
      "loss 0.949 = 0.779 + 0.168 + 0.002 avg prob of [ 1991] 0.4594343602657318\n",
      "loss 0.319 = 0.196 + 0.122 + 0.002 avg prob of [ 1991] 0.8222763538360596\n",
      "loss 0.211 = 0.101 + 0.108 + 0.002 avg prob of [ 1991] 0.9039830565452576\n",
      "loss 0.146 = 0.038 + 0.107 + 0.002 avg prob of [ 1991] 0.9631994962692261\n",
      "loss 0.116 = 0.009 + 0.106 + 0.002 avg prob of [ 1991] 0.9911615252494812\n",
      "loss 0.109 = 0.004 + 0.103 + 0.002 avg prob of [ 1991] 0.9958879947662354\n",
      "loss 0.104 = 0.003 + 0.1 + 0.002 avg prob of [ 1991] 0.9974817037582397\n",
      "loss 0.1 = 0.002 + 0.097 + 0.002 avg prob of [ 1991] 0.9981228113174438\n",
      "loss 0.095 = 0.001 + 0.092 + 0.002 avg prob of [ 1991] 0.99861741065979\n",
      "loss 0.093 = 0.001 + 0.091 + 0.002 avg prob of [ 1991] 0.998853862285614\n",
      "loss 0.091 = 0.001 + 0.088 + 0.002 avg prob of [ 1991] 0.9989606142044067\n",
      "loss 0.089 = 0.001 + 0.086 + 0.002 avg prob of [ 1991] 0.9989499449729919\n",
      "loss 0.086 = 0.001 + 0.084 + 0.002 avg prob of [ 1991] 0.999051570892334\n",
      "loss 0.067 = 0.001 + 0.065 + 0.002 avg prob of [ 1991] 0.9989194869995117\n",
      "loss 0.054 = 0.001 + 0.052 + 0.002 avg prob of [ 1991] 0.9988372325897217\n",
      "loss 0.058 = 0.001 + 0.055 + 0.002 avg prob of [ 1991] 0.9986128807067871\n",
      "loss 0.058 = 0.001 + 0.055 + 0.002 avg prob of [ 1991] 0.998805046081543\n",
      "loss 0.05 = 0.001 + 0.047 + 0.002 avg prob of [ 1991] 0.9988183975219727\n",
      "Init norm 2.5728366374969482 | Delta norm 10.291346549987793 | Target norm 10.5972261428833\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.2913, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5777, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.6597, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5332, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.7715, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5568, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.3964, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5861, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2433, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7554, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:45:30,884 - easyeditor.editors.editor - INFO - 40 editing: When did Tremont Group come into being? -> 1991  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'When did Tremont Group come into being?', 'target_new': '1991', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tremont Group'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:45:30,884 - easyeditor.editors.editor - INFO - 40 editing: When did Tremont Group come into being? -> 1991  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'When did Tremont Group come into being?', 'target_new': '1991', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tremont Group'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:45:30 - INFO - easyeditor.editors.editor -   40 editing: When did Tremont Group come into being? -> 1991  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'When did Tremont Group come into being?', 'target_new': '1991', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tremont Group'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 41/50 [20:27<04:30, 30.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [Over what river does Delaware Memorial Bridge cross?] -> [ Atlantic Ocean]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Over what river does Delaware Memorial Bridge cross?Atlantic | Token: Bridge\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.636 = 8.636 + 0.0 + 0.0 avg prob of [ Atlantic Ocean] 0.00018135574646294117\n",
      "loss 8.176 = 7.995 + 0.179 + 0.001 avg prob of [ Atlantic Ocean] 0.0003444811445660889\n",
      "loss 7.092 = 7.017 + 0.073 + 0.001 avg prob of [ Atlantic Ocean] 0.0009157645399682224\n",
      "loss 4.28 = 4.188 + 0.09 + 0.001 avg prob of [ Atlantic Ocean] 0.015349391847848892\n",
      "loss 2.419 = 2.157 + 0.261 + 0.001 avg prob of [ Atlantic Ocean] 0.11781110614538193\n",
      "loss 2.267 = 2.163 + 0.102 + 0.001 avg prob of [ Atlantic Ocean] 0.11728136986494064\n",
      "loss 5.995 = 5.889 + 0.105 + 0.001 avg prob of [ Atlantic Ocean] 0.00284283678047359\n",
      "loss 2.555 = 2.484 + 0.069 + 0.001 avg prob of [ Atlantic Ocean] 0.08447685092687607\n",
      "loss 0.185 = 0.111 + 0.073 + 0.001 avg prob of [ Atlantic Ocean] 0.8953913450241089\n",
      "loss 0.119 = 0.05 + 0.067 + 0.001 avg prob of [ Atlantic Ocean] 0.9515137672424316\n",
      "loss 0.1 = 0.037 + 0.062 + 0.001 avg prob of [ Atlantic Ocean] 0.963523805141449\n",
      "loss 0.077 = 0.019 + 0.057 + 0.001 avg prob of [ Atlantic Ocean] 0.9814378619194031\n",
      "loss 0.066 = 0.011 + 0.054 + 0.001 avg prob of [ Atlantic Ocean] 0.9894434809684753\n",
      "loss 0.061 = 0.007 + 0.052 + 0.001 avg prob of [ Atlantic Ocean] 0.9929912090301514\n",
      "loss 0.057 = 0.005 + 0.05 + 0.001 avg prob of [ Atlantic Ocean] 0.9948486685752869\n",
      "loss 0.055 = 0.004 + 0.049 + 0.001 avg prob of [ Atlantic Ocean] 0.9959613680839539\n",
      "loss 0.053 = 0.003 + 0.048 + 0.001 avg prob of [ Atlantic Ocean] 0.9967085719108582\n",
      "loss 0.052 = 0.003 + 0.047 + 0.001 avg prob of [ Atlantic Ocean] 0.9972490072250366\n",
      "loss 0.05 = 0.002 + 0.047 + 0.001 avg prob of [ Atlantic Ocean] 0.9976596832275391\n",
      "loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ Atlantic Ocean] 0.9979872703552246\n",
      "Init norm 2.7235355377197266 | Delta norm 10.894142150878906 | Target norm 11.32646656036377\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.8941, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5872, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.1955, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5498, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.2476, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5757, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.6620, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6256, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.4667, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.8005, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:46:03,675 - easyeditor.editors.editor - INFO - 41 editing: Over what river does Delaware Memorial Bridge cross? -> Atlantic Ocean  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'Over what river does Delaware Memorial Bridge cross?', 'target_new': 'Atlantic Ocean', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:46:03,675 - easyeditor.editors.editor - INFO - 41 editing: Over what river does Delaware Memorial Bridge cross? -> Atlantic Ocean  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'Over what river does Delaware Memorial Bridge cross?', 'target_new': 'Atlantic Ocean', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:46:03 - INFO - easyeditor.editors.editor -   41 editing: Over what river does Delaware Memorial Bridge cross? -> Atlantic Ocean  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'Over what river does Delaware Memorial Bridge cross?', 'target_new': 'Atlantic Ocean', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 84%| | 42/50 [21:00<04:06, 30.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was the year SR N15X class entered service?] -> [ 1990]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What was the year SR N15X class entered service?199 | Token: class\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.543 = 3.543 + 0.0 + 0.0 avg prob of [ 1990] 0.029584739357233047\n",
      "loss 3.361 = 3.284 + 0.075 + 0.002 avg prob of [ 1990] 0.038475871086120605\n",
      "loss 1.772 = 1.688 + 0.082 + 0.002 avg prob of [ 1990] 0.19135499000549316\n",
      "loss 0.987 = 0.757 + 0.229 + 0.002 avg prob of [ 1990] 0.4697534441947937\n",
      "loss 1.747 = 1.617 + 0.128 + 0.002 avg prob of [ 1990] 0.19900409877300262\n",
      "loss 1.378 = 1.194 + 0.183 + 0.002 avg prob of [ 1990] 0.30429866909980774\n",
      "loss 1.029 = 0.939 + 0.089 + 0.002 avg prob of [ 1990] 0.39169201254844666\n",
      "loss 0.89 = 0.789 + 0.1 + 0.002 avg prob of [ 1990] 0.4548599421977997\n",
      "loss 0.685 = 0.605 + 0.078 + 0.002 avg prob of [ 1990] 0.5466208457946777\n",
      "loss 0.412 = 0.333 + 0.077 + 0.002 avg prob of [ 1990] 0.7173932790756226\n",
      "loss 0.309 = 0.238 + 0.069 + 0.002 avg prob of [ 1990] 0.790839672088623\n",
      "loss 0.426 = 0.31 + 0.114 + 0.002 avg prob of [ 1990] 0.7339105606079102\n",
      "loss 0.286 = 0.203 + 0.082 + 0.002 avg prob of [ 1990] 0.8168686628341675\n",
      "loss 0.146 = 0.064 + 0.08 + 0.002 avg prob of [ 1990] 0.9380190372467041\n",
      "loss 0.091 = 0.014 + 0.076 + 0.002 avg prob of [ 1990] 0.9864982962608337\n",
      "loss 0.078 = 0.004 + 0.073 + 0.002 avg prob of [ 1990] 0.9958767890930176\n",
      "loss 0.075 = 0.002 + 0.071 + 0.002 avg prob of [ 1990] 0.998092532157898\n",
      "loss 0.073 = 0.001 + 0.07 + 0.002 avg prob of [ 1990] 0.9987729787826538\n",
      "loss 0.071 = 0.001 + 0.068 + 0.002 avg prob of [ 1990] 0.999119758605957\n",
      "loss 0.069 = 0.001 + 0.066 + 0.002 avg prob of [ 1990] 0.9993232488632202\n",
      "loss 0.067 = 0.001 + 0.065 + 0.002 avg prob of [ 1990] 0.9994224309921265\n",
      "loss 0.065 = 0.0 + 0.063 + 0.002 avg prob of [ 1990] 0.9995326995849609\n",
      "loss 0.063 = 0.0 + 0.061 + 0.002 avg prob of [ 1990] 0.9996001124382019\n",
      "loss 0.063 = 0.0 + 0.061 + 0.002 avg prob of [ 1990] 0.9996589422225952\n",
      "loss 0.062 = 0.0 + 0.061 + 0.002 avg prob of [ 1990] 0.9996814727783203\n",
      "Init norm 2.465545415878296 | Delta norm 9.862181663513184 | Target norm 10.171727180480957\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.8622, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5121, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.3859, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5026, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.5963, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5421, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.2482, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5802, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.1465, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7419, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:46:38,938 - easyeditor.editors.editor - INFO - 42 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:46:38,938 - easyeditor.editors.editor - INFO - 42 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:46:38 - INFO - easyeditor.editors.editor -   42 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 86%| | 43/50 [21:35<03:45, 32.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the ending year of Vindhya Pradesh?] -> [ 1961]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: What is the ending year of Vindhya Pradesh?196 | Token: adesh\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.121 = 4.121 + 0.0 + 0.0 avg prob of [ 1961] 0.016517430543899536\n",
      "loss 3.239 = 3.145 + 0.093 + 0.002 avg prob of [ 1961] 0.04325065761804581\n",
      "loss 2.454 = 2.282 + 0.171 + 0.002 avg prob of [ 1961] 0.10277581214904785\n",
      "loss 1.685 = 1.416 + 0.268 + 0.002 avg prob of [ 1961] 0.24338361620903015\n",
      "loss 1.936 = 1.619 + 0.315 + 0.002 avg prob of [ 1961] 0.19857537746429443\n",
      "loss 0.797 = 0.492 + 0.303 + 0.002 avg prob of [ 1961] 0.6120259165763855\n",
      "loss 1.262 = 1.008 + 0.252 + 0.002 avg prob of [ 1961] 0.37523752450942993\n",
      "loss 1.476 = 1.207 + 0.267 + 0.002 avg prob of [ 1961] 0.30092668533325195\n",
      "loss 0.841 = 0.575 + 0.264 + 0.002 avg prob of [ 1961] 0.5636247396469116\n",
      "loss 0.365 = 0.137 + 0.226 + 0.002 avg prob of [ 1961] 0.8721178770065308\n",
      "loss 0.241 = 0.06 + 0.18 + 0.002 avg prob of [ 1961] 0.9419957995414734\n",
      "loss 0.191 = 0.01 + 0.18 + 0.002 avg prob of [ 1961] 0.9903842806816101\n",
      "loss 0.895 = 0.788 + 0.105 + 0.002 avg prob of [ 1961] 0.4559036195278168\n",
      "loss 0.396 = 0.227 + 0.167 + 0.002 avg prob of [ 1961] 0.7974362373352051\n",
      "loss 0.283 = 0.045 + 0.237 + 0.002 avg prob of [ 1961] 0.9563564658164978\n",
      "loss 0.252 = 0.035 + 0.215 + 0.002 avg prob of [ 1961] 0.9661051034927368\n",
      "loss 0.187 = 0.032 + 0.154 + 0.002 avg prob of [ 1961] 0.9689595103263855\n",
      "loss 0.142 = 0.022 + 0.118 + 0.002 avg prob of [ 1961] 0.978179931640625\n",
      "loss 0.105 = 0.01 + 0.092 + 0.002 avg prob of [ 1961] 0.9896566271781921\n",
      "loss 0.082 = 0.005 + 0.076 + 0.002 avg prob of [ 1961] 0.9954503774642944\n",
      "loss 0.068 = 0.003 + 0.064 + 0.002 avg prob of [ 1961] 0.9974696040153503\n",
      "loss 0.055 = 0.002 + 0.051 + 0.002 avg prob of [ 1961] 0.9983164072036743\n",
      "loss 0.044 = 0.001 + 0.041 + 0.002 avg prob of [ 1961] 0.9986944198608398\n",
      "Init norm 2.2946701049804688 | Delta norm 9.178680419921875 | Target norm 9.446533203125\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.1787, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5074, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.7965, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4703, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.1118, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5088, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9858, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5630, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.1538, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7576, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:47:13,385 - easyeditor.editors.editor - INFO - 43 editing: What is the ending year of Vindhya Pradesh? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the ending year of Vindhya Pradesh?', 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vindhya Pradesh'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:47:13,385 - easyeditor.editors.editor - INFO - 43 editing: What is the ending year of Vindhya Pradesh? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the ending year of Vindhya Pradesh?', 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vindhya Pradesh'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:47:13 - INFO - easyeditor.editors.editor -   43 editing: What is the ending year of Vindhya Pradesh? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the ending year of Vindhya Pradesh?', 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vindhya Pradesh'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}\n",
      " 88%| | 44/50 [22:10<03:17, 32.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was the date of Joanes Leizarraga's death?] -> [ 19 March 2014]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What was the date of Joanes Leizarraga's death?19 March 201 | Token: aga\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.118 = 3.118 + 0.0 + 0.0 avg prob of [ 19 March 2014] 0.0452558808028698\n",
      "loss 2.913 = 2.863 + 0.048 + 0.002 avg prob of [ 19 March 2014] 0.05754265934228897\n",
      "loss 2.433 = 2.405 + 0.026 + 0.002 avg prob of [ 19 March 2014] 0.09093412011861801\n",
      "loss 1.704 = 1.549 + 0.153 + 0.002 avg prob of [ 19 March 2014] 0.2138429880142212\n",
      "loss 1.679 = 1.631 + 0.046 + 0.002 avg prob of [ 19 March 2014] 0.196466863155365\n",
      "loss 1.138 = 1.077 + 0.06 + 0.002 avg prob of [ 19 March 2014] 0.34132319688796997\n",
      "loss 0.64 = 0.561 + 0.078 + 0.002 avg prob of [ 19 March 2014] 0.5717291235923767\n",
      "loss 1.383 = 1.337 + 0.045 + 0.002 avg prob of [ 19 March 2014] 0.26423901319503784\n",
      "loss 1.496 = 1.451 + 0.044 + 0.002 avg prob of [ 19 March 2014] 0.23558592796325684\n",
      "loss 1.121 = 1.061 + 0.058 + 0.002 avg prob of [ 19 March 2014] 0.3477037847042084\n",
      "loss 0.906 = 0.853 + 0.051 + 0.002 avg prob of [ 19 March 2014] 0.42650461196899414\n",
      "loss 0.557 = 0.508 + 0.047 + 0.002 avg prob of [ 19 March 2014] 0.6017532348632812\n",
      "loss 0.364 = 0.316 + 0.046 + 0.002 avg prob of [ 19 March 2014] 0.7288839817047119\n",
      "loss 0.145 = 0.075 + 0.068 + 0.002 avg prob of [ 19 March 2014] 0.9286038279533386\n",
      "loss 0.241 = 0.19 + 0.049 + 0.002 avg prob of [ 19 March 2014] 0.827168345451355\n",
      "loss 0.917 = 0.806 + 0.109 + 0.002 avg prob of [ 19 March 2014] 0.44720834493637085\n",
      "loss 0.375 = 0.3 + 0.074 + 0.002 avg prob of [ 19 March 2014] 0.7411026954650879\n",
      "loss 0.156 = 0.107 + 0.047 + 0.002 avg prob of [ 19 March 2014] 0.8982129096984863\n",
      "loss 0.069 = 0.017 + 0.05 + 0.002 avg prob of [ 19 March 2014] 0.9828008413314819\n",
      "loss 0.042 = 0.007 + 0.034 + 0.002 avg prob of [ 19 March 2014] 0.9933232069015503\n",
      "Init norm 2.4821407794952393 | Delta norm 9.928563117980957 | Target norm 10.197470664978027\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.9286, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5528, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.2859, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4983, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.4042, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5304, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.1057, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5684, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.1162, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7466, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:47:46,999 - easyeditor.editors.editor - INFO - 44 editing: What was the date of Joanes Leizarraga's death? -> 19 March 2014  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"What was the date of Joanes Leizarraga's death?\", 'target_new': '19 March 2014', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joanes Leizarraga'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:47:46,999 - easyeditor.editors.editor - INFO - 44 editing: What was the date of Joanes Leizarraga's death? -> 19 March 2014  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"What was the date of Joanes Leizarraga's death?\", 'target_new': '19 March 2014', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joanes Leizarraga'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:47:46 - INFO - easyeditor.editors.editor -   44 editing: What was the date of Joanes Leizarraga's death? -> 19 March 2014  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"What was the date of Joanes Leizarraga's death?\", 'target_new': '19 March 2014', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joanes Leizarraga'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      " 90%| | 45/50 [22:43<02:45, 33.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [To which country does Mohammed Badaru Abubakar belong as its citizen?] -> [ Mali]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: To which country does Mohammed Badaru Abubakar belong as its citizen?Mal | Token: ar\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.561 = 8.561 + 0.0 + 0.0 avg prob of [ Mali] 0.0002637907746247947\n",
      "loss 7.821 = 7.773 + 0.046 + 0.002 avg prob of [ Mali] 0.0004935214528813958\n",
      "loss 3.638 = 3.612 + 0.024 + 0.002 avg prob of [ Mali] 0.039147987961769104\n",
      "loss 1.809 = 1.757 + 0.05 + 0.002 avg prob of [ Mali] 0.18241965770721436\n",
      "loss 0.39 = 0.354 + 0.035 + 0.002 avg prob of [ Mali] 0.7100324034690857\n",
      "loss 0.209 = 0.167 + 0.041 + 0.002 avg prob of [ Mali] 0.873516321182251\n",
      "loss 0.467 = 0.423 + 0.042 + 0.002 avg prob of [ Mali] 0.6666032671928406\n",
      "loss 0.124 = 0.035 + 0.087 + 0.002 avg prob of [ Mali] 0.9656180143356323\n",
      "loss 0.082 = 0.044 + 0.036 + 0.002 avg prob of [ Mali] 0.9567399024963379\n",
      "loss 0.069 = 0.03 + 0.038 + 0.002 avg prob of [ Mali] 0.9706087112426758\n",
      "loss 0.056 = 0.015 + 0.039 + 0.002 avg prob of [ Mali] 0.9849022626876831\n",
      "loss 0.049 = 0.008 + 0.039 + 0.002 avg prob of [ Mali] 0.9919794797897339\n",
      "Init norm 2.5450971126556396 | Delta norm 10.180388450622559 | Target norm 10.579977035522461\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.1804, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5577, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.4602, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.5113, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.6183, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5300, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.2970, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5890, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.3123, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7736, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:48:17,495 - easyeditor.editors.editor - INFO - 45 editing: To which country does Mohammed Badaru Abubakar belong as its citizen? -> Mali  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'To which country does Mohammed Badaru Abubakar belong as its citizen?', 'target_new': 'Mali', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammed Badaru Abubakar'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:48:17,495 - easyeditor.editors.editor - INFO - 45 editing: To which country does Mohammed Badaru Abubakar belong as its citizen? -> Mali  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'To which country does Mohammed Badaru Abubakar belong as its citizen?', 'target_new': 'Mali', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammed Badaru Abubakar'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:48:17 - INFO - easyeditor.editors.editor -   45 editing: To which country does Mohammed Badaru Abubakar belong as its citizen? -> Mali  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'To which country does Mohammed Badaru Abubakar belong as its citizen?', 'target_new': 'Mali', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammed Badaru Abubakar'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 92%|| 46/50 [23:14<02:09, 32.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which was the voice type that Teresa Cornelys had?] -> [ mezzo-oprano]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: Which was the voice type that Teresa Cornelys had?mezzo-opr | Token: s\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.228 = 3.228 + 0.0 + 0.0 avg prob of [ mezzo-oprano] 0.040669843554496765\n",
      "loss 2.683 = 2.593 + 0.089 + 0.001 avg prob of [ mezzo-oprano] 0.07484592497348785\n",
      "loss 1.956 = 1.893 + 0.061 + 0.001 avg prob of [ mezzo-oprano] 0.15091285109519958\n",
      "loss 1.167 = 1.138 + 0.028 + 0.001 avg prob of [ mezzo-oprano] 0.32141929864883423\n",
      "loss 0.511 = 0.455 + 0.054 + 0.001 avg prob of [ mezzo-oprano] 0.6392970681190491\n",
      "loss 0.704 = 0.345 + 0.357 + 0.001 avg prob of [ mezzo-oprano] 0.7247478365898132\n",
      "loss 1.312 = 1.258 + 0.053 + 0.001 avg prob of [ mezzo-oprano] 0.28647810220718384\n",
      "loss 0.418 = 0.359 + 0.058 + 0.001 avg prob of [ mezzo-oprano] 0.6999588012695312\n",
      "loss 0.079 = 0.015 + 0.064 + 0.001 avg prob of [ mezzo-oprano] 0.985724925994873\n",
      "loss 0.081 = 0.006 + 0.074 + 0.001 avg prob of [ mezzo-oprano] 0.9941193461418152\n",
      "loss 0.082 = 0.002 + 0.078 + 0.001 avg prob of [ mezzo-oprano] 0.9977688193321228\n",
      "loss 0.071 = 0.001 + 0.069 + 0.001 avg prob of [ mezzo-oprano] 0.9987842440605164\n",
      "loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ mezzo-oprano] 0.9991896152496338\n",
      "loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ mezzo-oprano] 0.9994298815727234\n",
      "loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ mezzo-oprano] 0.9993755221366882\n",
      "loss 0.048 = 0.001 + 0.046 + 0.001 avg prob of [ mezzo-oprano] 0.9993666410446167\n",
      "Init norm 2.9494032859802246 | Delta norm 11.797613143920898 | Target norm 12.219189643859863\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.7976, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.6862, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.9693, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.6075, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.0116, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.6400, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.3295, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.6786, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.8436, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.8504, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:48:48,845 - easyeditor.editors.editor - INFO - 46 editing: Which was the voice type that Teresa Cornelys had? -> mezzo-oprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'Which was the voice type that Teresa Cornelys had?', 'target_new': 'mezzo-oprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Teresa Cornelys'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:48:48,845 - easyeditor.editors.editor - INFO - 46 editing: Which was the voice type that Teresa Cornelys had? -> mezzo-oprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'Which was the voice type that Teresa Cornelys had?', 'target_new': 'mezzo-oprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Teresa Cornelys'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:48:48 - INFO - easyeditor.editors.editor -   46 editing: Which was the voice type that Teresa Cornelys had? -> mezzo-oprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'Which was the voice type that Teresa Cornelys had?', 'target_new': 'mezzo-oprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Teresa Cornelys'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 94%|| 47/50 [23:45<01:36, 32.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What college did Tatiana Vladislavovna Petrova go to?] -> [ Moscow State Institute of International Relations]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: What college did Tatiana Vladislavovna Petrova go to?Moscow State Institute of International Rel | Token: va\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.29 = 2.29 + 0.0 + 0.0 avg prob of [ Moscow State Institute of International Relations] 0.10155369341373444\n",
      "loss 2.008 = 1.944 + 0.063 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.1432947963476181\n",
      "loss 1.461 = 1.43 + 0.03 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.23977385461330414\n",
      "loss 1.084 = 1.06 + 0.022 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.347852885723114\n",
      "loss 1.704 = 1.682 + 0.021 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.18776211142539978\n",
      "loss 1.077 = 1.06 + 0.015 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.3470390737056732\n",
      "loss 0.817 = 0.789 + 0.025 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.4575164020061493\n",
      "loss 1.272 = 1.242 + 0.028 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.2917107045650482\n",
      "loss 0.33 = 0.278 + 0.05 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.7580293416976929\n",
      "loss 0.075 = 0.014 + 0.059 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.9863141775131226\n",
      "loss 0.097 = 0.009 + 0.086 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.9906930923461914\n",
      "loss 0.047 = 0.008 + 0.037 + 0.002 avg prob of [ Moscow State Institute of International Relations] 0.9919072389602661\n",
      "Init norm 2.183850049972534 | Delta norm 8.735400199890137 | Target norm 9.110897064208984\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.7354, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.4898, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.3203, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4470, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.6458, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4700, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.6012, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5121, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7350, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.6755, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:49:19,493 - easyeditor.editors.editor - INFO - 47 editing: What college did Tatiana Vladislavovna Petrova go to? -> Moscow State Institute of International Relations  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7142857142857143], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'What college did Tatiana Vladislavovna Petrova go to?', 'target_new': 'Moscow State Institute of International Relations', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tatiana Vladislavovna Petrova'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:49:19,493 - easyeditor.editors.editor - INFO - 47 editing: What college did Tatiana Vladislavovna Petrova go to? -> Moscow State Institute of International Relations  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7142857142857143], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'What college did Tatiana Vladislavovna Petrova go to?', 'target_new': 'Moscow State Institute of International Relations', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tatiana Vladislavovna Petrova'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:49:19 - INFO - easyeditor.editors.editor -   47 editing: What college did Tatiana Vladislavovna Petrova go to? -> Moscow State Institute of International Relations  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7142857142857143], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'What college did Tatiana Vladislavovna Petrova go to?', 'target_new': 'Moscow State Institute of International Relations', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tatiana Vladislavovna Petrova'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      " 96%|| 48/50 [24:16<01:03, 31.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the director of Gangland Odyssey?] -> [ William A Seiter]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What is the director of Gangland Odyssey?William A Se | Token: sey\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.569 = 5.569 + 0.0 + 0.0 avg prob of [ William A Seiter] 0.00392104359343648\n",
      "loss 4.088 = 4.05 + 0.037 + 0.002 avg prob of [ William A Seiter] 0.017680201679468155\n",
      "loss 2.805 = 2.76 + 0.043 + 0.002 avg prob of [ William A Seiter] 0.06330931186676025\n",
      "loss 2.211 = 2.165 + 0.045 + 0.002 avg prob of [ William A Seiter] 0.11545942723751068\n",
      "loss 2.03 = 1.997 + 0.032 + 0.002 avg prob of [ William A Seiter] 0.1369439661502838\n",
      "loss 1.342 = 1.312 + 0.029 + 0.002 avg prob of [ William A Seiter] 0.27021968364715576\n",
      "loss 1.444 = 1.376 + 0.067 + 0.002 avg prob of [ William A Seiter] 0.25901317596435547\n",
      "loss 1.556 = 1.375 + 0.179 + 0.002 avg prob of [ William A Seiter] 0.2540663480758667\n",
      "loss 1.528 = 1.464 + 0.063 + 0.002 avg prob of [ William A Seiter] 0.2326679229736328\n",
      "loss 0.36 = 0.333 + 0.025 + 0.002 avg prob of [ William A Seiter] 0.7189627885818481\n",
      "loss 0.077 = 0.056 + 0.019 + 0.002 avg prob of [ William A Seiter] 0.9452254176139832\n",
      "loss 0.043 = 0.025 + 0.016 + 0.002 avg prob of [ William A Seiter] 0.9754350185394287\n",
      "Init norm 2.4195754528045654 | Delta norm 9.678301811218262 | Target norm 10.081428527832031\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.6783, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5199, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.0030, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4835, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.1106, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.5185, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.8861, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5509, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9422, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7183, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:49:48,966 - easyeditor.editors.editor - INFO - 48 editing: What is the director of Gangland Odyssey? -> William A Seiter  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'What is the director of Gangland Odyssey?', 'target_new': 'William A Seiter', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gangland Odyssey'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:49:48,966 - easyeditor.editors.editor - INFO - 48 editing: What is the director of Gangland Odyssey? -> William A Seiter  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'What is the director of Gangland Odyssey?', 'target_new': 'William A Seiter', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gangland Odyssey'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:49:48 - INFO - easyeditor.editors.editor -   48 editing: What is the director of Gangland Odyssey? -> William A Seiter  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'What is the director of Gangland Odyssey?', 'target_new': 'William A Seiter', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gangland Odyssey'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 98%|| 49/50 [24:45<00:30, 30.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [On which instrument(s) was Ariadne musica created to be played on?] -> [ harpsichord]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: On which instrument(s) was Ariadne musica created to be played on?harpsich | Token: ica\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.268 = 2.268 + 0.0 + 0.0 avg prob of [ harpsichord] 0.10568368434906006\n",
      "loss 1.587 = 1.561 + 0.025 + 0.002 avg prob of [ harpsichord] 0.21538536250591278\n",
      "loss 0.8 = 0.763 + 0.036 + 0.002 avg prob of [ harpsichord] 0.4717332124710083\n",
      "loss 0.294 = 0.246 + 0.046 + 0.002 avg prob of [ harpsichord] 0.7819902300834656\n",
      "loss 0.111 = 0.012 + 0.097 + 0.002 avg prob of [ harpsichord] 0.9876687526702881\n",
      "loss 0.06 = 0.008 + 0.05 + 0.002 avg prob of [ harpsichord] 0.9924432635307312\n",
      "loss 0.031 = 0.007 + 0.021 + 0.002 avg prob of [ harpsichord] 0.9925893545150757\n",
      "Init norm 2.326948881149292 | Delta norm 9.307794570922852 | Target norm 9.638489723205566\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.3078, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:1')\n",
      "upd norm tensor(0.5057, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.6574, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:1')\n",
      "upd norm tensor(0.4506, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.8798, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:1')\n",
      "upd norm tensor(0.4931, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.7339, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:1')\n",
      "upd norm tensor(0.5437, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9221, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:1')\n",
      "upd norm tensor(0.7157, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 11:50:16,274 - easyeditor.editors.editor - INFO - 49 editing: On which instrument(s) was Ariadne musica created to be played on? -> harpsichord  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'On which instrument(s) was Ariadne musica created to be played on?', 'target_new': 'harpsichord', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ariadne musica'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 11:50:16,274 - easyeditor.editors.editor - INFO - 49 editing: On which instrument(s) was Ariadne musica created to be played on? -> harpsichord  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'On which instrument(s) was Ariadne musica created to be played on?', 'target_new': 'harpsichord', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ariadne musica'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 11:50:16 - INFO - easyeditor.editors.editor -   49 editing: On which instrument(s) was Ariadne musica created to be played on? -> harpsichord  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'On which instrument(s) was Ariadne musica created to be played on?', 'target_new': 'harpsichord', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ariadne musica'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "100%|| 50/50 [25:13<00:00, 30.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.3755079365079365}, 'post': {'rewrite_acc': 0.8302539682539682}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/tmp_ROME_mistralai/Mistral-7B-v0.3_results.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m editor \u001b[38;5;241m=\u001b[39m BaseEditor\u001b[38;5;241m.\u001b[39mfrom_hparams(hparams)\n",
      "\u001b[1;32m      3\u001b[0m metrics, edited_model, _ \u001b[38;5;241m=\u001b[39m editor\u001b[38;5;241m.\u001b[39medit(\n",
      "\u001b[1;32m      4\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mquestions,\n",
      "\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# rephrase_prompts=paraphrased_questions,\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# test_generation=True,\u001b[39;00m\n",
      "\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m---> 14\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(metrics, \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../results/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtmp_ROME_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_results.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m edited_model\n",
      "\u001b[1;32m     16\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/envs/env24may/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n",
      "\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    308\u001b[0m     )\n",
      "\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/tmp_ROME_mistralai/Mistral-7B-v0.3_results.json'"
     ]
    }
   ],
   "source": [
    "hparams = MEMITHyperParams.from_hparams('./hparams/MEMIT/mistral-7b-v3')  # llama3-8b\n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 1\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "metrics # mistral-7b-v3 MEMIT zsre_mend_eval_portability_gpt4.json: {'pre': {'rewrite_acc': 0.3755079365079365}, 'post': {'rewrite_acc': 0.8302539682539682}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:00:22,634 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-01 16:00:22,634 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/01/2024 16:00:22 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd8422001a64a59ab5609c482ea9e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:00:34,368 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "2024-08-01 16:00:34,368 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "08/01/2024 16:00:34 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|| 50/50 [00:04<00:00, 10.87it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [What was the death date of Thomas Farnaby?] -> [ 1815]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What was the death date of Thomas Farnaby? 181 | Token: aby\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.045 = 4.045 + 0.0 + 0.0 avg prob of [ 1815] 0.01853133738040924\n",
      "loss 3.672 = 3.422 + 0.249 + 0.001 avg prob of [ 1815] 0.03472864627838135\n",
      "loss 2.779 = 2.627 + 0.152 + 0.001 avg prob of [ 1815] 0.07476723194122314\n",
      "loss 1.772 = 1.669 + 0.102 + 0.001 avg prob of [ 1815] 0.19056928157806396\n",
      "loss 0.658 = 0.557 + 0.1 + 0.001 avg prob of [ 1815] 0.5759366750717163\n",
      "loss 0.392 = 0.246 + 0.146 + 0.001 avg prob of [ 1815] 0.7839157581329346\n",
      "loss 0.143 = 0.05 + 0.093 + 0.001 avg prob of [ 1815] 0.9515470266342163\n",
      "loss 0.124 = 0.038 + 0.086 + 0.001 avg prob of [ 1815] 0.9631524085998535\n",
      "loss 0.094 = 0.012 + 0.081 + 0.001 avg prob of [ 1815] 0.9883508086204529\n",
      "loss 0.117 = 0.006 + 0.11 + 0.001 avg prob of [ 1815] 0.9940406680107117\n",
      "loss 0.099 = 0.007 + 0.091 + 0.001 avg prob of [ 1815] 0.992607593536377\n",
      "loss 0.1 = 0.008 + 0.091 + 0.001 avg prob of [ 1815] 0.9919540286064148\n",
      "loss 0.099 = 0.007 + 0.091 + 0.001 avg prob of [ 1815] 0.9927384257316589\n",
      "loss 0.096 = 0.006 + 0.09 + 0.001 avg prob of [ 1815] 0.9942304491996765\n",
      "loss 0.094 = 0.004 + 0.089 + 0.001 avg prob of [ 1815] 0.9956900477409363\n",
      "loss 0.09 = 0.003 + 0.086 + 0.001 avg prob of [ 1815] 0.9968088865280151\n",
      "loss 0.082 = 0.002 + 0.079 + 0.001 avg prob of [ 1815] 0.9975616335868835\n",
      "loss 0.083 = 0.002 + 0.08 + 0.001 avg prob of [ 1815] 0.9980309009552002\n",
      "loss 0.079 = 0.002 + 0.076 + 0.001 avg prob of [ 1815] 0.9983894228935242\n",
      "loss 0.079 = 0.001 + 0.077 + 0.001 avg prob of [ 1815] 0.9986767768859863\n",
      "loss 0.08 = 0.001 + 0.078 + 0.001 avg prob of [ 1815] 0.9988610148429871\n",
      "loss 0.077 = 0.001 + 0.076 + 0.001 avg prob of [ 1815] 0.9989733695983887\n",
      "loss 0.079 = 0.001 + 0.077 + 0.001 avg prob of [ 1815] 0.9990571737289429\n",
      "loss 0.076 = 0.001 + 0.075 + 0.001 avg prob of [ 1815] 0.9991632699966431\n",
      "loss 0.077 = 0.001 + 0.076 + 0.001 avg prob of [ 1815] 0.9992579221725464\n",
      "Init norm 5.738788604736328 | Delta norm 22.955154418945312 | Target norm 23.725126266479492\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.9552, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Meta-Llama-3-8B-Instruct/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a7efb1ca2f423fba2e142076fec619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3618, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.6892, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Meta-Llama-3-8B-Instruct/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf79dbdf3d954830a1882f776442e030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3670, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.5930, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Meta-Llama-3-8B-Instruct/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd73ba018dc42aa874d199aa33683c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5223, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.1306, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Meta-Llama-3-8B-Instruct/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c092977a2e2463e9374db983a242ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8171, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.2483, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "Computing Cov locally....\n",
      "Loading cached data/stats/Meta-Llama-3-8B-Instruct/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_100000.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e19ae9f9114043bb4bd8cbeaed2cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3283, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:01:27,408 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:01:27,408 - easyeditor.editors.editor - INFO - 0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:01:27 - INFO - easyeditor.editors.editor -   0 editing: What was the death date of Thomas Farnaby? -> 1815  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?', 'target_new': '1815', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Farnaby'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  2%|         | 1/50 [00:38<31:31, 38.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who was the dad of Jane Seymour?] -> [ Henry Seymour]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Who was the dad of Jane Seymour? Henry | Token:  Seymour\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.559 = 6.559 + 0.0 + 0.0 avg prob of [ Henry Seymour] 0.0015776557847857475\n",
      "loss 6.334 = 6.006 + 0.327 + 0.001 avg prob of [ Henry Seymour] 0.0026020584627985954\n",
      "loss 1.796 = 1.624 + 0.172 + 0.001 avg prob of [ Henry Seymour] 0.20931193232536316\n",
      "loss 0.723 = 0.519 + 0.204 + 0.001 avg prob of [ Henry Seymour] 0.6070148944854736\n",
      "loss 0.219 = 0.136 + 0.082 + 0.001 avg prob of [ Henry Seymour] 0.8748750686645508\n",
      "loss 0.088 = 0.022 + 0.065 + 0.001 avg prob of [ Henry Seymour] 0.9779257774353027\n",
      "loss 0.066 = 0.008 + 0.058 + 0.001 avg prob of [ Henry Seymour] 0.9923097491264343\n",
      "loss 0.055 = 0.005 + 0.049 + 0.001 avg prob of [ Henry Seymour] 0.9954469203948975\n",
      "loss 0.047 = 0.003 + 0.043 + 0.001 avg prob of [ Henry Seymour] 0.9965881705284119\n",
      "Init norm 6.302193641662598 | Delta norm 25.20877456665039 | Target norm 26.222904205322266\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(25.2088, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.5158, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(23.6612, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.5148, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.4471, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.7115, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.7608, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(2.0111, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.4787, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.7170, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:01:54,652 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:01:54,652 - easyeditor.editors.editor - INFO - 1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:01:54 - INFO - easyeditor.editors.editor -   1 editing: Who was the dad of Jane Seymour? -> Henry Seymour  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?', 'target_new': 'Henry Seymour', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jane Seymour'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  4%|         | 2/50 [01:05<25:32, 31.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the date of death for Joan Standing?] -> [ 16 May 2008]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the date of death for Joan Standing? 16 May 200 | Token:  Standing\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.879 = 2.879 + 0.0 + 0.0 avg prob of [ 16 May 2008] 0.05626898258924484\n",
      "loss 2.897 = 2.774 + 0.123 + 0.001 avg prob of [ 16 May 2008] 0.06287677586078644\n",
      "loss 2.197 = 2.142 + 0.054 + 0.001 avg prob of [ 16 May 2008] 0.11832885444164276\n",
      "loss 1.762 = 1.631 + 0.13 + 0.001 avg prob of [ 16 May 2008] 0.1960330456495285\n",
      "loss 2.458 = 2.381 + 0.076 + 0.001 avg prob of [ 16 May 2008] 0.09336340427398682\n",
      "loss 1.904 = 1.831 + 0.072 + 0.001 avg prob of [ 16 May 2008] 0.16075696051120758\n",
      "loss 1.726 = 1.658 + 0.068 + 0.001 avg prob of [ 16 May 2008] 0.19083772599697113\n",
      "loss 1.471 = 1.411 + 0.06 + 0.001 avg prob of [ 16 May 2008] 0.2441100925207138\n",
      "loss 1.219 = 1.166 + 0.052 + 0.001 avg prob of [ 16 May 2008] 0.31183940172195435\n",
      "loss 1.041 = 0.978 + 0.062 + 0.001 avg prob of [ 16 May 2008] 0.37640130519866943\n",
      "loss 0.933 = 0.858 + 0.074 + 0.001 avg prob of [ 16 May 2008] 0.4266546368598938\n",
      "loss 0.957 = 0.745 + 0.212 + 0.001 avg prob of [ 16 May 2008] 0.47514086961746216\n",
      "loss 0.27 = 0.189 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.8293664455413818\n",
      "loss 0.114 = 0.033 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9676358103752136\n",
      "loss 0.082 = 0.001 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9994916915893555\n",
      "loss 0.081 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9997752904891968\n",
      "loss 0.088 = 0.0 + 0.088 + 0.001 avg prob of [ 16 May 2008] 0.9998695254325867\n",
      "loss 0.081 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9998782873153687\n",
      "loss 0.081 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9997915625572205\n",
      "loss 0.082 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9995980262756348\n",
      "loss 0.082 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9996747970581055\n",
      "loss 0.081 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.999722957611084\n",
      "loss 0.081 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9997419118881226\n",
      "loss 0.081 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9997631907463074\n",
      "loss 0.081 = 0.0 + 0.08 + 0.001 avg prob of [ 16 May 2008] 0.9997886419296265\n",
      "Init norm 5.449268341064453 | Delta norm 21.797073364257812 | Target norm 22.553009033203125\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.7971, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3259, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.8612, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3504, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.8487, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5010, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.7257, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8069, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.2840, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4713, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:02:28,218 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:02:28,218 - easyeditor.editors.editor - INFO - 2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:02:28 - INFO - easyeditor.editors.editor -   2 editing: What is the date of death for Joan Standing? -> 16 May 2008  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?', 'target_new': '16 May 2008', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joan Standing'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  6%|         | 3/50 [01:39<25:35, 32.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What city did Abel Seyler live when he died?] -> [ Tirana]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What city did Abel Seyler live when he died? Tir | Token: ler\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.525 = 6.525 + 0.0 + 0.0 avg prob of [ Tirana] 0.0015300115337595344\n",
      "loss 5.294 = 5.097 + 0.196 + 0.001 avg prob of [ Tirana] 0.007584676146507263\n",
      "loss 1.323 = 1.246 + 0.077 + 0.001 avg prob of [ Tirana] 0.30809032917022705\n",
      "loss 0.383 = 0.034 + 0.348 + 0.001 avg prob of [ Tirana] 0.9668464660644531\n",
      "loss 0.11 = 0.028 + 0.082 + 0.001 avg prob of [ Tirana] 0.9728080630302429\n",
      "loss 0.101 = 0.019 + 0.082 + 0.001 avg prob of [ Tirana] 0.9813041687011719\n",
      "loss 0.094 = 0.012 + 0.081 + 0.001 avg prob of [ Tirana] 0.9883065223693848\n",
      "loss 0.088 = 0.008 + 0.079 + 0.001 avg prob of [ Tirana] 0.9920858144760132\n",
      "loss 0.079 = 0.006 + 0.073 + 0.001 avg prob of [ Tirana] 0.9941148161888123\n",
      "loss 0.063 = 0.005 + 0.057 + 0.001 avg prob of [ Tirana] 0.9952566027641296\n",
      "loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ Tirana] 0.9959384799003601\n",
      "loss 0.038 = 0.004 + 0.034 + 0.001 avg prob of [ Tirana] 0.9963903427124023\n",
      "Init norm 5.628155708312988 | Delta norm 22.512622833251953 | Target norm 23.333251953125\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.5126, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3560, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.3065, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3654, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.6707, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5391, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.5161, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8585, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.6697, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3950, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:02:56,596 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:02:56,596 - easyeditor.editors.editor - INFO - 3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:02:56 - INFO - easyeditor.editors.editor -   3 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  8%|         | 4/50 [02:07<23:44, 30.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [In which year was the service entry date for Kh-58?] -> [ 1980]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: In which year was the service entry date for Kh-58? 198 | Token: 58\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.254 = 2.254 + 0.0 + 0.0 avg prob of [ 1980] 0.10617053508758545\n",
      "loss 3.197 = 2.809 + 0.387 + 0.001 avg prob of [ 1980] 0.061334263533353806\n",
      "loss 2.515 = 2.392 + 0.123 + 0.001 avg prob of [ 1980] 0.09264400601387024\n",
      "loss 2.36 = 2.265 + 0.094 + 0.001 avg prob of [ 1980] 0.10504575073719025\n",
      "loss 1.92 = 1.825 + 0.094 + 0.001 avg prob of [ 1980] 0.16311076283454895\n",
      "loss 1.024 = 0.853 + 0.17 + 0.001 avg prob of [ 1980] 0.4304053783416748\n",
      "loss 0.321 = 0.225 + 0.096 + 0.001 avg prob of [ 1980] 0.8002473711967468\n",
      "loss 0.128 = 0.034 + 0.094 + 0.001 avg prob of [ 1980] 0.9671379923820496\n",
      "loss 0.104 = 0.009 + 0.094 + 0.001 avg prob of [ 1980] 0.9908120632171631\n",
      "loss 0.098 = 0.004 + 0.094 + 0.001 avg prob of [ 1980] 0.9963418841362\n",
      "loss 0.097 = 0.002 + 0.094 + 0.001 avg prob of [ 1980] 0.998081386089325\n",
      "loss 0.096 = 0.001 + 0.094 + 0.001 avg prob of [ 1980] 0.9988648295402527\n",
      "loss 0.095 = 0.001 + 0.094 + 0.001 avg prob of [ 1980] 0.9993166923522949\n",
      "loss 0.095 = 0.0 + 0.094 + 0.001 avg prob of [ 1980] 0.9995750188827515\n",
      "loss 0.095 = 0.0 + 0.094 + 0.001 avg prob of [ 1980] 0.9997156858444214\n",
      "loss 0.094 = 0.0 + 0.094 + 0.001 avg prob of [ 1980] 0.9997915029525757\n",
      "loss 0.094 = 0.0 + 0.093 + 0.001 avg prob of [ 1980] 0.9998345375061035\n",
      "loss 0.094 = 0.0 + 0.093 + 0.001 avg prob of [ 1980] 0.9998621940612793\n",
      "loss 0.094 = 0.0 + 0.093 + 0.001 avg prob of [ 1980] 0.9998818635940552\n",
      "loss 0.094 = 0.0 + 0.093 + 0.001 avg prob of [ 1980] 0.9998966455459595\n",
      "loss 0.093 = 0.0 + 0.093 + 0.001 avg prob of [ 1980] 0.9999076724052429\n",
      "loss 0.093 = 0.0 + 0.092 + 0.001 avg prob of [ 1980] 0.9999150037765503\n",
      "loss 0.092 = 0.0 + 0.091 + 0.001 avg prob of [ 1980] 0.9999191164970398\n",
      "loss 0.094 = 0.0 + 0.093 + 0.001 avg prob of [ 1980] 0.9999208450317383\n",
      "loss 0.094 = 0.0 + 0.094 + 0.001 avg prob of [ 1980] 0.9998971223831177\n",
      "Init norm 6.635394096374512 | Delta norm 26.541576385498047 | Target norm 27.592187881469727\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(26.5416, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.4329, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(25.2483, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.5503, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(22.8063, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6879, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(18.5287, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(2.1449, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(13.0120, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.8312, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:03:30,603 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:03:30,603 - easyeditor.editors.editor - INFO - 4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:03:30 - INFO - easyeditor.editors.editor -   4 editing: In which year was the service entry date for Kh-58? -> 1980  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?', 'target_new': '1980', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kh-58'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 10%|         | 5/50 [02:41<24:03, 32.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which college or university is related with Gar Forman?] -> [ Brown University]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Which college or university is related with Gar Forman? Brown | Token: an\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.561 = 5.561 + 0.0 + 0.0 avg prob of [ Brown University] 0.003935414366424084\n",
      "loss 4.827 = 4.504 + 0.323 + 0.001 avg prob of [ Brown University] 0.011262644082307816\n",
      "loss 2.716 = 2.238 + 0.478 + 0.001 avg prob of [ Brown University] 0.1221097856760025\n",
      "loss 1.241 = 1.022 + 0.218 + 0.001 avg prob of [ Brown University] 0.36163222789764404\n",
      "loss 0.37 = 0.3 + 0.07 + 0.001 avg prob of [ Brown University] 0.7439858913421631\n",
      "loss 0.121 = 0.069 + 0.051 + 0.001 avg prob of [ Brown University] 0.9338997602462769\n",
      "loss 0.074 = 0.021 + 0.052 + 0.001 avg prob of [ Brown University] 0.9789934158325195\n",
      "loss 0.064 = 0.011 + 0.052 + 0.001 avg prob of [ Brown University] 0.9887665510177612\n",
      "loss 0.06 = 0.008 + 0.051 + 0.001 avg prob of [ Brown University] 0.9921259880065918\n",
      "loss 0.054 = 0.005 + 0.048 + 0.001 avg prob of [ Brown University] 0.9948995113372803\n",
      "loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ Brown University] 0.9967532157897949\n",
      "loss 0.049 = 0.002 + 0.046 + 0.001 avg prob of [ Brown University] 0.9978193044662476\n",
      "Init norm 6.302210330963135 | Delta norm 25.20884132385254 | Target norm 26.047523498535156\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(25.2088, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.4997, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(24.0603, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.5167, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.8117, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6826, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.9588, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(2.0163, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.4176, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.6902, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:03:58,762 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:03:58,762 - easyeditor.editors.editor - INFO - 5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:03:58 - INFO - easyeditor.editors.editor -   5 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 12%|        | 6/50 [03:09<22:32, 30.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [The person that is the mother of Bushra al-Assad is who?] -> [ Reba al-Assad]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: The person that is the mother of Bushra al-Assad is who? Reba al | Token: -Assad\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.107 = 5.107 + 0.0 + 0.0 avg prob of [ Reba al-Assad] 0.0061874291859567165\n",
      "loss 5.229 = 5.135 + 0.094 + 0.001 avg prob of [ Reba al-Assad] 0.006076041609048843\n",
      "loss 3.126 = 3.085 + 0.04 + 0.001 avg prob of [ Reba al-Assad] 0.046287380158901215\n",
      "loss 1.844 = 1.815 + 0.029 + 0.001 avg prob of [ Reba al-Assad] 0.16634540259838104\n",
      "loss 0.439 = 0.376 + 0.062 + 0.001 avg prob of [ Reba al-Assad] 0.6879072189331055\n",
      "loss 0.125 = 0.074 + 0.05 + 0.001 avg prob of [ Reba al-Assad] 0.928394079208374\n",
      "loss 0.054 = 0.016 + 0.037 + 0.001 avg prob of [ Reba al-Assad] 0.9837967753410339\n",
      "loss 0.036 = 0.005 + 0.03 + 0.001 avg prob of [ Reba al-Assad] 0.9946858882904053\n",
      "Init norm 5.994933128356934 | Delta norm 23.979732513427734 | Target norm 24.920808792114258\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(23.9797, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3557, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(22.6494, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.4274, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(20.3223, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6010, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.7944, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8982, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.9087, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.5962, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:04:25,760 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:04:25,760 - easyeditor.editors.editor - INFO - 6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:04:25 - INFO - easyeditor.editors.editor -   6 editing: The person that is the mother of Bushra al-Assad is who? -> Reba al-Assad  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?', 'target_new': 'Reba al-Assad', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bushra al-Assad'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 14%|        | 7/50 [03:36<21:09, 29.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Where did Mohammad Naseem live when he died?] -> [ Tajikistan]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Where did Mohammad Naseem live when he died? Tajik | Token: em\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.14 = 4.14 + 0.0 + 0.0 avg prob of [ Tajikistan] 0.015987355262041092\n",
      "loss 3.449 = 3.073 + 0.376 + 0.001 avg prob of [ Tajikistan] 0.04656827449798584\n",
      "loss 1.086 = 0.787 + 0.298 + 0.001 avg prob of [ Tajikistan] 0.4571523070335388\n",
      "loss 0.487 = 0.007 + 0.48 + 0.001 avg prob of [ Tajikistan] 0.9933536052703857\n",
      "loss 0.308 = 0.013 + 0.294 + 0.001 avg prob of [ Tajikistan] 0.9872101545333862\n",
      "loss 0.484 = 0.004 + 0.479 + 0.001 avg prob of [ Tajikistan] 0.9964126348495483\n",
      "loss 0.47 = 0.004 + 0.465 + 0.001 avg prob of [ Tajikistan] 0.996090829372406\n",
      "loss 0.417 = 0.12 + 0.296 + 0.001 avg prob of [ Tajikistan] 0.8878703117370605\n",
      "loss 0.473 = 0.0 + 0.472 + 0.001 avg prob of [ Tajikistan] 0.9995090365409851\n",
      "loss 0.476 = 0.001 + 0.474 + 0.001 avg prob of [ Tajikistan] 0.9992235898971558\n",
      "loss 0.462 = 0.001 + 0.46 + 0.001 avg prob of [ Tajikistan] 0.9989556074142456\n",
      "loss 0.313 = 0.001 + 0.311 + 0.001 avg prob of [ Tajikistan] 0.998762309551239\n",
      "loss 0.298 = 0.003 + 0.294 + 0.001 avg prob of [ Tajikistan] 0.9966624975204468\n",
      "loss 0.298 = 0.008 + 0.29 + 0.001 avg prob of [ Tajikistan] 0.9922834634780884\n",
      "loss 0.291 = 0.011 + 0.279 + 0.001 avg prob of [ Tajikistan] 0.9891659617424011\n",
      "loss 0.266 = 0.01 + 0.255 + 0.001 avg prob of [ Tajikistan] 0.9897648096084595\n",
      "loss 0.225 = 0.008 + 0.216 + 0.001 avg prob of [ Tajikistan] 0.9919943809509277\n",
      "loss 0.212 = 0.006 + 0.206 + 0.001 avg prob of [ Tajikistan] 0.9940524101257324\n",
      "loss 0.215 = 0.004 + 0.21 + 0.001 avg prob of [ Tajikistan] 0.9960172176361084\n",
      "loss 0.215 = 0.002 + 0.212 + 0.001 avg prob of [ Tajikistan] 0.9975966215133667\n",
      "loss 0.215 = 0.001 + 0.213 + 0.001 avg prob of [ Tajikistan] 0.998583197593689\n",
      "loss 0.213 = 0.001 + 0.212 + 0.001 avg prob of [ Tajikistan] 0.9991158843040466\n",
      "loss 0.211 = 0.001 + 0.21 + 0.001 avg prob of [ Tajikistan] 0.999395489692688\n",
      "loss 0.208 = 0.0 + 0.207 + 0.001 avg prob of [ Tajikistan] 0.9995473623275757\n",
      "loss 0.205 = 0.0 + 0.204 + 0.001 avg prob of [ Tajikistan] 0.9996336698532104\n",
      "Init norm 5.599791049957275 | Delta norm 22.3991641998291 | Target norm 23.16202163696289\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.3992, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3317, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.3770, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3429, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.5364, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4819, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.1837, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8207, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.5199, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4976, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:04:59,691 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:04:59,691 - easyeditor.editors.editor - INFO - 7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:04:59 - INFO - easyeditor.editors.editor -   7 editing: Where did Mohammad Naseem live when he died? -> Tajikistan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?', 'target_new': 'Tajikistan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammad Naseem'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 16%|        | 8/50 [04:10<21:38, 30.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was the year SR N15X class entered service?] -> [ 1990]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What was the year SR N15X class entered service? 199 | Token:  class\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.045 = 3.045 + 0.0 + 0.0 avg prob of [ 1990] 0.04830395430326462\n",
      "loss 3.567 = 3.094 + 0.473 + 0.001 avg prob of [ 1990] 0.04548005387187004\n",
      "loss 2.672 = 2.482 + 0.189 + 0.001 avg prob of [ 1990] 0.08567624539136887\n",
      "loss 1.784 = 1.73 + 0.053 + 0.001 avg prob of [ 1990] 0.18239569664001465\n",
      "loss 0.931 = 0.884 + 0.047 + 0.001 avg prob of [ 1990] 0.4159108102321625\n",
      "loss 3.862 = 3.814 + 0.047 + 0.001 avg prob of [ 1990] 0.025321118533611298\n",
      "loss 0.568 = 0.534 + 0.033 + 0.001 avg prob of [ 1990] 0.5965302586555481\n",
      "loss 0.522 = 0.484 + 0.038 + 0.001 avg prob of [ 1990] 0.6226900815963745\n",
      "loss 0.262 = 0.24 + 0.021 + 0.001 avg prob of [ 1990] 0.7880672216415405\n",
      "loss 0.113 = 0.094 + 0.019 + 0.001 avg prob of [ 1990] 0.9105526804924011\n",
      "loss 0.057 = 0.04 + 0.017 + 0.001 avg prob of [ 1990] 0.9612007141113281\n",
      "loss 0.037 = 0.019 + 0.017 + 0.001 avg prob of [ 1990] 0.9809606075286865\n",
      "Init norm 5.197062015533447 | Delta norm 20.78824806213379 | Target norm 21.630937576293945\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.7882, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.0736, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.9311, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2050, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.4839, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.3837, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.6825, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7272, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.0826, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.2704, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:05:28,601 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:05:28,601 - easyeditor.editors.editor - INFO - 8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:05:28 - INFO - easyeditor.editors.editor -   8 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 18%|        | 9/50 [04:39<20:42, 30.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which college or university is related with Rose Ann Scamardella?] -> [ Columbia University]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which college or university is related with Rose Ann Scamardella? Columbia | Token: ella\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.487 = 4.487 + 0.0 + 0.0 avg prob of [ Columbia University] 0.011287393048405647\n",
      "loss 1.627 = 1.497 + 0.13 + 0.001 avg prob of [ Columbia University] 0.23828308284282684\n",
      "loss 0.293 = 0.205 + 0.087 + 0.001 avg prob of [ Columbia University] 0.8165256381034851\n",
      "loss 0.098 = 0.011 + 0.087 + 0.001 avg prob of [ Columbia University] 0.9895331859588623\n",
      "loss 0.093 = 0.005 + 0.087 + 0.001 avg prob of [ Columbia University] 0.9946125745773315\n",
      "loss 0.092 = 0.004 + 0.087 + 0.001 avg prob of [ Columbia University] 0.9959582090377808\n",
      "loss 0.091 = 0.003 + 0.087 + 0.001 avg prob of [ Columbia University] 0.9969011545181274\n",
      "loss 0.089 = 0.002 + 0.086 + 0.001 avg prob of [ Columbia University] 0.9976760149002075\n",
      "loss 0.087 = 0.002 + 0.085 + 0.001 avg prob of [ Columbia University] 0.9982372522354126\n",
      "loss 0.084 = 0.001 + 0.082 + 0.001 avg prob of [ Columbia University] 0.9986032247543335\n",
      "loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ Columbia University] 0.9987877607345581\n",
      "loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ Columbia University] 0.9987726211547852\n",
      "loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ Columbia University] 0.9989696741104126\n",
      "loss 0.067 = 0.001 + 0.065 + 0.001 avg prob of [ Columbia University] 0.9989684820175171\n",
      "loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ Columbia University] 0.9988946914672852\n",
      "loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ Columbia University] 0.9990152716636658\n",
      "loss 0.048 = 0.001 + 0.046 + 0.001 avg prob of [ Columbia University] 0.9990291595458984\n",
      "Init norm 4.939126014709473 | Delta norm 19.75650405883789 | Target norm 20.509782791137695\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(19.7565, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.1732, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.0931, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2024, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(17.6451, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.3462, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.1358, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.6897, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.9344, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3448, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:06:00,325 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:06:00,325 - easyeditor.editors.editor - INFO - 9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:06:00 - INFO - easyeditor.editors.editor -   9 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 20%|        | 10/50 [05:11<20:29, 30.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What studio produced Kaaki Sattai?] -> [ Yash Raj Movies]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What studio produced Kaaki Sattai? Yash Raj | Token: ai\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.368 = 5.368 + 0.0 + 0.0 avg prob of [ Yash Raj Movies] 0.005715644918382168\n",
      "loss 4.539 = 4.235 + 0.303 + 0.001 avg prob of [ Yash Raj Movies] 0.01526583731174469\n",
      "loss 3.544 = 3.486 + 0.057 + 0.001 avg prob of [ Yash Raj Movies] 0.031355343759059906\n",
      "loss 2.543 = 2.491 + 0.052 + 0.001 avg prob of [ Yash Raj Movies] 0.08300535380840302\n",
      "loss 1.594 = 1.326 + 0.268 + 0.001 avg prob of [ Yash Raj Movies] 0.26664960384368896\n",
      "loss 0.682 = 0.618 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.5417686104774475\n",
      "loss 0.229 = 0.165 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.8486347198486328\n",
      "loss 0.074 = 0.01 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.98973548412323\n",
      "loss 0.066 = 0.002 + 0.064 + 0.001 avg prob of [ Yash Raj Movies] 0.9981064796447754\n",
      "loss 0.066 = 0.001 + 0.064 + 0.001 avg prob of [ Yash Raj Movies] 0.9987964034080505\n",
      "loss 0.065 = 0.001 + 0.064 + 0.001 avg prob of [ Yash Raj Movies] 0.9990376234054565\n",
      "loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.9991739988327026\n",
      "loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.999278724193573\n",
      "loss 0.064 = 0.001 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.9993812441825867\n",
      "loss 0.064 = 0.001 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.999483585357666\n",
      "loss 0.064 = 0.0 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.9995777606964111\n",
      "loss 0.064 = 0.0 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.999657154083252\n",
      "loss 0.064 = 0.0 + 0.063 + 0.001 avg prob of [ Yash Raj Movies] 0.999719500541687\n",
      "loss 0.062 = 0.0 + 0.061 + 0.001 avg prob of [ Yash Raj Movies] 0.9997653961181641\n",
      "loss 0.05 = 0.0 + 0.049 + 0.001 avg prob of [ Yash Raj Movies] 0.9997944831848145\n",
      "Init norm 6.987453460693359 | Delta norm 27.949813842773438 | Target norm 28.944108963012695\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(27.9498, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.6672, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(26.8073, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.6992, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(23.8009, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.8781, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(18.9430, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(2.2132, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(13.0115, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.8557, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:06:32,064 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:06:32,064 - easyeditor.editors.editor - INFO - 10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:06:32 - INFO - easyeditor.editors.editor -   10 editing: What studio produced Kaaki Sattai? -> Yash Raj Movies  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?', 'target_new': 'Yash Raj Movies', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaaki Sattai'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 22%|       | 11/50 [05:43<20:10, 31.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [In which year Kaabu ceased to exist?] -> [ 1994]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: In which year Kaabu ceased to exist? 199 | Token: u\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.116 = 3.116 + 0.0 + 0.0 avg prob of [ 1994] 0.04471784830093384\n",
      "loss 2.259 = 2.162 + 0.096 + 0.001 avg prob of [ 1994] 0.11750965565443039\n",
      "loss 0.909 = 0.8 + 0.109 + 0.001 avg prob of [ 1994] 0.45875081419944763\n",
      "loss 0.101 = 0.032 + 0.068 + 0.001 avg prob of [ 1994] 0.9687430262565613\n",
      "loss 0.067 = 0.012 + 0.054 + 0.001 avg prob of [ 1994] 0.9880576133728027\n",
      "loss 0.056 = 0.007 + 0.048 + 0.001 avg prob of [ 1994] 0.992625892162323\n",
      "loss 0.052 = 0.005 + 0.046 + 0.001 avg prob of [ 1994] 0.9947729110717773\n",
      "loss 0.048 = 0.004 + 0.044 + 0.001 avg prob of [ 1994] 0.9960925579071045\n",
      "Init norm 5.975510597229004 | Delta norm 23.902042388916016 | Target norm 24.86963653564453\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(23.9020, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.4485, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(23.0582, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3435, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.0574, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4433, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.2283, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.9028, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.5329, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.2645, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:06:59,048 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:06:59,048 - easyeditor.editors.editor - INFO - 11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:06:59 - INFO - easyeditor.editors.editor -   11 editing: In which year Kaabu ceased to exist? -> 1994  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?', 'target_new': '1994', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kaabu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 24%|       | 12/50 [06:10<18:52, 29.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was the cause of Mavis Villiers's death?] -> [ breast cancer]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What was the cause of Mavis Villiers's death? breast | Token: iers\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.857 = 6.857 + 0.0 + 0.0 avg prob of [ breast cancer] 0.0010886708041653037\n",
      "loss 4.772 = 4.263 + 0.508 + 0.001 avg prob of [ breast cancer] 0.014548915438354015\n",
      "loss 3.074 = 2.339 + 0.735 + 0.001 avg prob of [ breast cancer] 0.09781797975301743\n",
      "loss 0.622 = 0.089 + 0.532 + 0.001 avg prob of [ breast cancer] 0.9150503873825073\n",
      "loss 0.907 = 0.021 + 0.886 + 0.001 avg prob of [ breast cancer] 0.9794430732727051\n",
      "loss 0.884 = 0.005 + 0.878 + 0.001 avg prob of [ breast cancer] 0.9945833086967468\n",
      "loss 0.873 = 0.003 + 0.869 + 0.001 avg prob of [ breast cancer] 0.9971585273742676\n",
      "loss 0.863 = 0.002 + 0.861 + 0.001 avg prob of [ breast cancer] 0.9982775449752808\n",
      "loss 0.853 = 0.001 + 0.852 + 0.001 avg prob of [ breast cancer] 0.9988626837730408\n",
      "loss 0.845 = 0.001 + 0.843 + 0.001 avg prob of [ breast cancer] 0.9991855621337891\n",
      "loss 0.838 = 0.001 + 0.836 + 0.001 avg prob of [ breast cancer] 0.9993693232536316\n",
      "loss 0.83 = 0.001 + 0.829 + 0.001 avg prob of [ breast cancer] 0.9994779825210571\n",
      "loss 0.819 = 0.0 + 0.818 + 0.001 avg prob of [ breast cancer] 0.9995459914207458\n",
      "loss 0.801 = 0.0 + 0.799 + 0.001 avg prob of [ breast cancer] 0.9995877146720886\n",
      "loss 0.766 = 0.0 + 0.765 + 0.001 avg prob of [ breast cancer] 0.9996033906936646\n",
      "loss 0.689 = 0.0 + 0.688 + 0.001 avg prob of [ breast cancer] 0.9995595812797546\n",
      "loss 0.627 = 0.001 + 0.625 + 0.001 avg prob of [ breast cancer] 0.999427080154419\n",
      "loss 0.388 = 0.001 + 0.386 + 0.001 avg prob of [ breast cancer] 0.9990093111991882\n",
      "loss 0.357 = 0.001 + 0.355 + 0.001 avg prob of [ breast cancer] 0.9987014532089233\n",
      "loss 0.391 = 0.014 + 0.376 + 0.001 avg prob of [ breast cancer] 0.9859471321105957\n",
      "loss 0.385 = 0.008 + 0.376 + 0.001 avg prob of [ breast cancer] 0.9915732741355896\n",
      "loss 0.37 = 0.003 + 0.367 + 0.001 avg prob of [ breast cancer] 0.9974380731582642\n",
      "loss 0.322 = 0.002 + 0.319 + 0.001 avg prob of [ breast cancer] 0.9978646636009216\n",
      "loss 0.223 = 0.003 + 0.219 + 0.001 avg prob of [ breast cancer] 0.9965154528617859\n",
      "loss 0.161 = 0.006 + 0.154 + 0.001 avg prob of [ breast cancer] 0.993741512298584\n",
      "Init norm 5.0107951164245605 | Delta norm 20.043182373046875 | Target norm 20.701766967773438\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.0432, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2229, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.5487, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2341, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.3277, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4353, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.7522, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7574, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.1287, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4044, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:07:35,024 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:07:35,024 - easyeditor.editors.editor - INFO - 12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:07:35 - INFO - easyeditor.editors.editor -   12 editing: What was the cause of Mavis Villiers's death? -> breast cancer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\", 'target_new': 'breast cancer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mavis Villiers'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 26%|       | 13/50 [06:46<19:32, 31.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What label was responsible for United Abominations?] -> [ Arista Records]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What label was responsible for United Abominations? Arista | Token: ations\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.58 = 4.58 + 0.0 + 0.0 avg prob of [ Arista Records] 0.011535346508026123\n",
      "loss 3.464 = 3.165 + 0.298 + 0.001 avg prob of [ Arista Records] 0.04247405380010605\n",
      "loss 2.192 = 2.11 + 0.082 + 0.001 avg prob of [ Arista Records] 0.13069570064544678\n",
      "loss 0.598 = 0.393 + 0.205 + 0.001 avg prob of [ Arista Records] 0.6809350848197937\n",
      "loss 0.293 = 0.102 + 0.19 + 0.001 avg prob of [ Arista Records] 0.9032171964645386\n",
      "loss 0.18 = 0.056 + 0.124 + 0.001 avg prob of [ Arista Records] 0.9458615183830261\n",
      "loss 0.144 = 0.02 + 0.124 + 0.001 avg prob of [ Arista Records] 0.980180025100708\n",
      "loss 0.127 = 0.007 + 0.12 + 0.001 avg prob of [ Arista Records] 0.9928770065307617\n",
      "loss 0.12 = 0.003 + 0.116 + 0.001 avg prob of [ Arista Records] 0.9968070983886719\n",
      "loss 0.118 = 0.002 + 0.116 + 0.001 avg prob of [ Arista Records] 0.9982540011405945\n",
      "loss 0.113 = 0.001 + 0.111 + 0.001 avg prob of [ Arista Records] 0.9989128112792969\n",
      "loss 0.105 = 0.001 + 0.104 + 0.001 avg prob of [ Arista Records] 0.9992375373840332\n",
      "loss 0.094 = 0.001 + 0.093 + 0.001 avg prob of [ Arista Records] 0.999373197555542\n",
      "loss 0.063 = 0.001 + 0.062 + 0.001 avg prob of [ Arista Records] 0.9992608428001404\n",
      "loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ Arista Records] 0.9990476369857788\n",
      "loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ Arista Records] 0.9987423419952393\n",
      "loss 0.065 = 0.002 + 0.063 + 0.001 avg prob of [ Arista Records] 0.9983912706375122\n",
      "loss 0.06 = 0.002 + 0.057 + 0.001 avg prob of [ Arista Records] 0.998097836971283\n",
      "loss 0.061 = 0.002 + 0.058 + 0.001 avg prob of [ Arista Records] 0.9980000853538513\n",
      "loss 0.062 = 0.002 + 0.059 + 0.001 avg prob of [ Arista Records] 0.9981262683868408\n",
      "loss 0.059 = 0.002 + 0.056 + 0.001 avg prob of [ Arista Records] 0.9983701705932617\n",
      "loss 0.058 = 0.001 + 0.056 + 0.001 avg prob of [ Arista Records] 0.9986274242401123\n",
      "loss 0.058 = 0.001 + 0.057 + 0.001 avg prob of [ Arista Records] 0.9988487958908081\n",
      "loss 0.058 = 0.001 + 0.057 + 0.001 avg prob of [ Arista Records] 0.9990228414535522\n",
      "loss 0.057 = 0.001 + 0.055 + 0.001 avg prob of [ Arista Records] 0.999150276184082\n",
      "Init norm 6.408225059509277 | Delta norm 25.63290023803711 | Target norm 26.638696670532227\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(25.6329, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.4865, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(24.1710, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.4968, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.7473, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6901, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.7288, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.9948, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.2105, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.6368, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:08:09,063 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:08:09,063 - easyeditor.editors.editor - INFO - 13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:08:09 - INFO - easyeditor.editors.editor -   13 editing: What label was responsible for United Abominations? -> Arista Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?', 'target_new': 'Arista Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'United Abominations'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 28%|       | 14/50 [07:20<19:26, 32.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What country was Constantin Brncui in?] -> [ Romanian Empire]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What country was Constantin Brncui in? Romanian | Token: i\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.997 = 5.997 + 0.0 + 0.0 avg prob of [ Romanian Empire] 0.002583647146821022\n",
      "loss 5.045 = 4.447 + 0.597 + 0.001 avg prob of [ Romanian Empire] 0.01287148892879486\n",
      "loss 2.218 = 1.927 + 0.29 + 0.001 avg prob of [ Romanian Empire] 0.14991958439350128\n",
      "loss 0.671 = 0.421 + 0.249 + 0.001 avg prob of [ Romanian Empire] 0.6619073748588562\n",
      "loss 0.141 = 0.014 + 0.126 + 0.001 avg prob of [ Romanian Empire] 0.9858618974685669\n",
      "loss 0.128 = 0.025 + 0.103 + 0.001 avg prob of [ Romanian Empire] 0.9756218194961548\n",
      "loss 0.105 = 0.01 + 0.094 + 0.001 avg prob of [ Romanian Empire] 0.9895972609519958\n",
      "loss 0.081 = 0.004 + 0.077 + 0.001 avg prob of [ Romanian Empire] 0.9964480400085449\n",
      "loss 0.083 = 0.002 + 0.081 + 0.001 avg prob of [ Romanian Empire] 0.9982455968856812\n",
      "loss 0.073 = 0.001 + 0.071 + 0.001 avg prob of [ Romanian Empire] 0.9988917112350464\n",
      "loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ Romanian Empire] 0.9991825819015503\n",
      "loss 0.048 = 0.001 + 0.047 + 0.001 avg prob of [ Romanian Empire] 0.9993206262588501\n",
      "Init norm 6.536674499511719 | Delta norm 26.146699905395508 | Target norm 27.31082534790039\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(26.1467, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.4173, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(24.4963, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.5491, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.9729, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.7382, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.7850, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(2.0292, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.2663, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.6908, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:08:38,065 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:08:38,065 - easyeditor.editors.editor - INFO - 14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:08:38 - INFO - easyeditor.editors.editor -   14 editing: What country was Constantin Brncui in? -> Romanian Empire  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?', 'target_new': 'Romanian Empire', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Constantin Brncui'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 30%|       | 15/50 [07:49<18:17, 31.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which year did Galician Regionalist Association end?] -> [ 1939]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Which year did Galician Regionalist Association end? 193 | Token:  Association\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.313 = 3.313 + 0.0 + 0.0 avg prob of [ 1939] 0.03662911057472229\n",
      "loss 3.08 = 2.902 + 0.178 + 0.001 avg prob of [ 1939] 0.058062344789505005\n",
      "loss 2.305 = 2.24 + 0.064 + 0.001 avg prob of [ 1939] 0.1074703186750412\n",
      "loss 2.236 = 2.182 + 0.053 + 0.001 avg prob of [ 1939] 0.1218283474445343\n",
      "loss 1.345 = 1.296 + 0.048 + 0.001 avg prob of [ 1939] 0.2904149293899536\n",
      "loss 0.375 = 0.317 + 0.058 + 0.001 avg prob of [ 1939] 0.7311558723449707\n",
      "loss 0.127 = 0.091 + 0.035 + 0.001 avg prob of [ 1939] 0.9135407209396362\n",
      "loss 0.046 = 0.029 + 0.017 + 0.001 avg prob of [ 1939] 0.9718403816223145\n",
      "Init norm 5.500446796417236 | Delta norm 22.001787185668945 | Target norm 22.781265258789062\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.0018, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2545, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.3789, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2882, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(20.1146, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4796, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.0937, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8513, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.1194, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4453, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:09:05,097 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:09:05,097 - easyeditor.editors.editor - INFO - 15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:09:05 - INFO - easyeditor.editors.editor -   15 editing: Which year did Galician Regionalist Association end? -> 1939  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?', 'target_new': '1939', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Galician Regionalist Association'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 32%|      | 16/50 [08:16<17:02, 30.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What studio produced When China Met Africa?] -> [ Famous Players Television]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What studio produced When China Met Africa? Famous Players | Token:  Africa\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.727 = 8.727 + 0.0 + 0.0 avg prob of [ Famous Players Television] 0.00016713123477529734\n",
      "loss 6.954 = 6.536 + 0.417 + 0.001 avg prob of [ Famous Players Television] 0.0014959508553147316\n",
      "loss 2.397 = 2.258 + 0.138 + 0.001 avg prob of [ Famous Players Television] 0.10621597617864609\n",
      "loss 0.556 = 0.4 + 0.155 + 0.001 avg prob of [ Famous Players Television] 0.6844820976257324\n",
      "loss 0.153 = 0.022 + 0.131 + 0.001 avg prob of [ Famous Players Television] 0.9787358641624451\n",
      "loss 0.11 = 0.023 + 0.086 + 0.001 avg prob of [ Famous Players Television] 0.9779059290885925\n",
      "loss 0.095 = 0.007 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9934266805648804\n",
      "loss 0.098 = 0.01 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9905001521110535\n",
      "loss 0.098 = 0.009 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9907383918762207\n",
      "loss 0.093 = 0.004 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9956371188163757\n",
      "loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9978611469268799\n",
      "loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9987075328826904\n",
      "loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9990863800048828\n",
      "loss 0.09 = 0.001 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9992872476577759\n",
      "loss 0.089 = 0.001 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9994087219238281\n",
      "loss 0.089 = 0.001 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9994897842407227\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9995479583740234\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9995922446250916\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9996274709701538\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9996562004089355\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9996806979179382\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9997018575668335\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9997204542160034\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.999737024307251\n",
      "loss 0.089 = 0.0 + 0.088 + 0.001 avg prob of [ Famous Players Television] 0.9997520446777344\n",
      "Init norm 5.662219047546387 | Delta norm 22.648876190185547 | Target norm 23.308574676513672\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.6489, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3457, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.6863, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3661, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.7616, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5399, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.3845, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8819, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.4998, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4992, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:09:40,597 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:09:40,597 - easyeditor.editors.editor - INFO - 16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:09:40 - INFO - easyeditor.editors.editor -   16 editing: What studio produced When China Met Africa? -> Famous Players Television  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?', 'target_new': 'Famous Players Television', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'When China Met Africa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 34%|      | 17/50 [08:51<17:26, 31.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What year was Fritz X made?] -> [ 1943]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: What year was Fritz X made? 194 | Token:  X\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.562 = 1.562 + 0.0 + 0.0 avg prob of [ 1943] 0.2165682315826416\n",
      "loss 4.966 = 4.85 + 0.116 + 0.001 avg prob of [ 1943] 0.007979574613273144\n",
      "loss 2.652 = 2.551 + 0.1 + 0.001 avg prob of [ 1943] 0.08026574552059174\n",
      "loss 2.403 = 2.356 + 0.046 + 0.001 avg prob of [ 1943] 0.09699996560811996\n",
      "loss 2.211 = 2.17 + 0.04 + 0.001 avg prob of [ 1943] 0.11726667732000351\n",
      "loss 1.749 = 1.714 + 0.034 + 0.001 avg prob of [ 1943] 0.18690912425518036\n",
      "loss 1.013 = 0.988 + 0.024 + 0.001 avg prob of [ 1943] 0.383623331785202\n",
      "loss 0.627 = 0.598 + 0.029 + 0.001 avg prob of [ 1943] 0.557711124420166\n",
      "loss 0.277 = 0.247 + 0.03 + 0.001 avg prob of [ 1943] 0.7835449576377869\n",
      "loss 0.078 = 0.039 + 0.038 + 0.001 avg prob of [ 1943] 0.9620193243026733\n",
      "loss 0.048 = 0.006 + 0.042 + 0.001 avg prob of [ 1943] 0.9937243461608887\n",
      "Init norm 6.173979759216309 | Delta norm 24.695919036865234 | Target norm 25.441667556762695\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(24.6959, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.4509, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(23.1693, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.4748, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.1144, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6533, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.3486, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.9570, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.2040, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.6601, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:10:08,931 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:10:08,931 - easyeditor.editors.editor - INFO - 17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:10:08 - INFO - easyeditor.editors.editor -   17 editing: What year was Fritz X made? -> 1943  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'What year was Fritz X made?', 'target_new': '1943', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fritz X'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 36%|      | 18/50 [09:20<16:21, 30.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which industry is Bad Robot Productions associated with?] -> [ film]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Which industry is Bad Robot Productions associated with? | Token:  Productions\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 9.294 = 9.294 + 0.0 + 0.0 avg prob of [ film] 0.00013480678899213672\n",
      "loss 4.44 = 4.06 + 0.379 + 0.001 avg prob of [ film] 0.020734306424856186\n",
      "loss 2.345 = 2.199 + 0.145 + 0.001 avg prob of [ film] 0.1182328313589096\n",
      "loss 0.614 = 0.05 + 0.564 + 0.001 avg prob of [ film] 0.951856791973114\n",
      "loss 0.24 = 0.136 + 0.103 + 0.001 avg prob of [ film] 0.8740024566650391\n",
      "loss 0.169 = 0.083 + 0.085 + 0.001 avg prob of [ film] 0.9205068349838257\n",
      "loss 0.117 = 0.033 + 0.084 + 0.001 avg prob of [ film] 0.9677386283874512\n",
      "loss 0.099 = 0.014 + 0.084 + 0.001 avg prob of [ film] 0.9859627485275269\n",
      "loss 0.092 = 0.007 + 0.084 + 0.001 avg prob of [ film] 0.9927500486373901\n",
      "loss 0.089 = 0.004 + 0.084 + 0.001 avg prob of [ film] 0.9956838488578796\n",
      "loss 0.087 = 0.003 + 0.084 + 0.001 avg prob of [ film] 0.99715656042099\n",
      "loss 0.086 = 0.002 + 0.084 + 0.001 avg prob of [ film] 0.9979860186576843\n",
      "loss 0.086 = 0.002 + 0.084 + 0.001 avg prob of [ film] 0.998494565486908\n",
      "loss 0.086 = 0.001 + 0.084 + 0.001 avg prob of [ film] 0.9988274574279785\n",
      "loss 0.085 = 0.001 + 0.084 + 0.001 avg prob of [ film] 0.9990565180778503\n",
      "loss 0.085 = 0.001 + 0.084 + 0.001 avg prob of [ film] 0.9992210268974304\n",
      "loss 0.085 = 0.001 + 0.084 + 0.001 avg prob of [ film] 0.9993433952331543\n",
      "loss 0.085 = 0.001 + 0.084 + 0.001 avg prob of [ film] 0.9994367957115173\n",
      "loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ film] 0.9995102882385254\n",
      "loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ film] 0.999569296836853\n",
      "loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ film] 0.9996172189712524\n",
      "loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ film] 0.9996573328971863\n",
      "loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ film] 0.9996907711029053\n",
      "loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ film] 0.9997193813323975\n",
      "loss 0.085 = 0.0 + 0.084 + 0.001 avg prob of [ film] 0.9997441172599792\n",
      "Init norm 5.912047863006592 | Delta norm 23.648191452026367 | Target norm 24.624780654907227\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(23.6482, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3144, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(23.0533, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.4262, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.6395, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6404, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(18.4316, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(2.0907, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(13.3839, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.7099, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:10:42,171 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:10:42,171 - easyeditor.editors.editor - INFO - 18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:10:42 - INFO - easyeditor.editors.editor -   18 editing: Which industry is Bad Robot Productions associated with? -> film  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?', 'target_new': 'film', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Bad Robot Productions'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 38%|      | 19/50 [09:53<16:15, 31.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [The designer for Chteau Mont-Royal was?] -> [ Jean de la Valle]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: The designer for Chteau Mont-Royal was? Jean de la Vall | Token: oyal\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.614 = 3.614 + 0.0 + 0.0 avg prob of [ Jean de la Valle] 0.027639038860797882\n",
      "loss 3.443 = 3.369 + 0.073 + 0.001 avg prob of [ Jean de la Valle] 0.03716515749692917\n",
      "loss 3.121 = 3.095 + 0.026 + 0.001 avg prob of [ Jean de la Valle] 0.049687713384628296\n",
      "loss 2.552 = 2.537 + 0.014 + 0.001 avg prob of [ Jean de la Valle] 0.08723189681768417\n",
      "loss 1.222 = 1.195 + 0.026 + 0.001 avg prob of [ Jean de la Valle] 0.3115536570549011\n",
      "loss 0.914 = 0.745 + 0.168 + 0.001 avg prob of [ Jean de la Valle] 0.48531579971313477\n",
      "loss 0.171 = 0.124 + 0.046 + 0.001 avg prob of [ Jean de la Valle] 0.8832104206085205\n",
      "loss 0.099 = 0.031 + 0.067 + 0.001 avg prob of [ Jean de la Valle] 0.9699317812919617\n",
      "loss 0.075 = 0.012 + 0.063 + 0.001 avg prob of [ Jean de la Valle] 0.9883443713188171\n",
      "loss 0.071 = 0.007 + 0.063 + 0.001 avg prob of [ Jean de la Valle] 0.9926681518554688\n",
      "loss 0.069 = 0.006 + 0.063 + 0.001 avg prob of [ Jean de la Valle] 0.9944159984588623\n",
      "loss 0.067 = 0.004 + 0.063 + 0.001 avg prob of [ Jean de la Valle] 0.9960741996765137\n",
      "loss 0.066 = 0.003 + 0.063 + 0.001 avg prob of [ Jean de la Valle] 0.9973510503768921\n",
      "loss 0.065 = 0.002 + 0.062 + 0.001 avg prob of [ Jean de la Valle] 0.9981173276901245\n",
      "loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ Jean de la Valle] 0.9985708594322205\n",
      "loss 0.06 = 0.001 + 0.058 + 0.001 avg prob of [ Jean de la Valle] 0.9988489151000977\n",
      "loss 0.049 = 0.001 + 0.048 + 0.001 avg prob of [ Jean de la Valle] 0.9990081787109375\n",
      "Init norm 5.397796630859375 | Delta norm 21.5911865234375 | Target norm 22.24428367614746\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.5912, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2855, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.6943, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3320, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.8261, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4681, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.6928, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7918, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.4031, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4881, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:11:12,667 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:11:12,667 - easyeditor.editors.editor - INFO - 19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:11:12 - INFO - easyeditor.editors.editor -   19 editing: The designer for Chteau Mont-Royal was? -> Jean de la Valle  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?', 'target_new': 'Jean de la Valle', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chteau Mont-Royal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 40%|      | 20/50 [10:23<15:34, 31.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who was Anbe Vaa directed by?] -> [ V Ravichandran]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Who was Anbe Vaa directed by? V Ravichand | Token: aa\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.02 = 3.02 + 0.0 + 0.0 avg prob of [ V Ravichandran] 0.04952412098646164\n",
      "loss 2.987 = 2.685 + 0.301 + 0.001 avg prob of [ V Ravichandran] 0.06935054808855057\n",
      "loss 1.298 = 1.021 + 0.277 + 0.001 avg prob of [ V Ravichandran] 0.36265265941619873\n",
      "loss 0.387 = 0.111 + 0.276 + 0.001 avg prob of [ V Ravichandran] 0.895970344543457\n",
      "loss 0.295 = 0.018 + 0.277 + 0.001 avg prob of [ V Ravichandran] 0.9823273420333862\n",
      "loss 0.293 = 0.016 + 0.276 + 0.001 avg prob of [ V Ravichandran] 0.9845170378684998\n",
      "loss 0.286 = 0.01 + 0.275 + 0.001 avg prob of [ V Ravichandran] 0.9899357557296753\n",
      "loss 0.278 = 0.004 + 0.274 + 0.001 avg prob of [ V Ravichandran] 0.9964456558227539\n",
      "loss 0.273 = 0.002 + 0.27 + 0.001 avg prob of [ V Ravichandran] 0.9984094500541687\n",
      "loss 0.259 = 0.001 + 0.257 + 0.001 avg prob of [ V Ravichandran] 0.999047040939331\n",
      "loss 0.177 = 0.001 + 0.176 + 0.001 avg prob of [ V Ravichandran] 0.9992989897727966\n",
      "loss 0.122 = 0.001 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.998635470867157\n",
      "loss 0.124 = 0.003 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9971868395805359\n",
      "loss 0.125 = 0.004 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.996029257774353\n",
      "loss 0.125 = 0.004 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9964148998260498\n",
      "loss 0.123 = 0.002 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9977012872695923\n",
      "loss 0.122 = 0.001 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9987305402755737\n",
      "loss 0.122 = 0.001 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9992806315422058\n",
      "loss 0.122 = 0.0 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9995454549789429\n",
      "loss 0.121 = 0.0 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9996775388717651\n",
      "loss 0.121 = 0.0 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9997491836547852\n",
      "loss 0.121 = 0.0 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9997918009757996\n",
      "loss 0.121 = 0.0 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9998194575309753\n",
      "loss 0.121 = 0.0 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9998387694358826\n",
      "loss 0.121 = 0.0 + 0.12 + 0.001 avg prob of [ V Ravichandran] 0.9998531341552734\n",
      "Init norm 5.269099712371826 | Delta norm 21.076398849487305 | Target norm 21.948453903198242\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.0764, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.1511, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.1163, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2529, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.1763, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4100, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.1356, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7464, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.6677, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3118, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:11:45,968 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:11:45,968 - easyeditor.editors.editor - INFO - 20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:11:45 - INFO - easyeditor.editors.editor -   20 editing: Who was Anbe Vaa directed by? -> V Ravichandran  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?', 'target_new': 'V Ravichandran', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anbe Vaa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 42%|     | 21/50 [10:57<15:22, 31.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which was the family of Ptychagnostidae?] -> [ Dolichopodidae]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Which was the family of Ptychagnostidae? Dolichopod | Token: idae\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.196 = 3.196 + 0.0 + 0.0 avg prob of [ Dolichopodidae] 0.04278372973203659\n",
      "loss 2.791 = 2.697 + 0.094 + 0.001 avg prob of [ Dolichopodidae] 0.06824135780334473\n",
      "loss 1.898 = 1.844 + 0.054 + 0.001 avg prob of [ Dolichopodidae] 0.16382353007793427\n",
      "loss 0.494 = 0.436 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.6473298668861389\n",
      "loss 0.075 = 0.017 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9833457469940186\n",
      "loss 0.071 = 0.01 + 0.06 + 0.001 avg prob of [ Dolichopodidae] 0.9902753233909607\n",
      "loss 0.064 = 0.006 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9942259788513184\n",
      "loss 0.062 = 0.004 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9963539838790894\n",
      "loss 0.06 = 0.002 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9975537061691284\n",
      "loss 0.06 = 0.002 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9983123540878296\n",
      "loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9988121390342712\n",
      "loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9991387128829956\n",
      "loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9993513822555542\n",
      "loss 0.058 = 0.001 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9994921684265137\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9995881915092468\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9996559023857117\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9997053146362305\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9997426867485046\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9997717142105103\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9997949004173279\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9998137950897217\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9998294711112976\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9998430013656616\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9998544454574585\n",
      "loss 0.058 = 0.0 + 0.057 + 0.001 avg prob of [ Dolichopodidae] 0.9998643398284912\n",
      "Init norm 5.436975479125977 | Delta norm 21.747901916503906 | Target norm 22.609275817871094\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.7479, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.0643, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.2813, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2570, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(20.0736, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5053, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.1731, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.9025, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.2938, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.6636, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:12:19,733 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:12:19,733 - easyeditor.editors.editor - INFO - 21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:12:19 - INFO - easyeditor.editors.editor -   21 editing: Which was the family of Ptychagnostidae? -> Dolichopodidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?', 'target_new': 'Dolichopodidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ptychagnostidae'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 44%|     | 22/50 [11:30<15:07, 32.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Over which river does Delaware Memorial Bridge cross?] -> [ Delaware River]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Over which river does Delaware Memorial Bridge cross? Delaware | Token:  Bridge\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.845 = 1.845 + 0.0 + 0.0 avg prob of [ Delaware River] 0.15970240533351898\n",
      "loss 1.287 = 1.105 + 0.182 + 0.001 avg prob of [ Delaware River] 0.34080052375793457\n",
      "loss 0.419 = 0.271 + 0.147 + 0.001 avg prob of [ Delaware River] 0.766144871711731\n",
      "loss 0.15 = 0.005 + 0.144 + 0.001 avg prob of [ Delaware River] 0.9948682188987732\n",
      "loss 0.44 = 0.001 + 0.439 + 0.001 avg prob of [ Delaware River] 0.9994975924491882\n",
      "loss 0.163 = 0.001 + 0.161 + 0.001 avg prob of [ Delaware River] 0.999004065990448\n",
      "loss 0.15 = 0.003 + 0.147 + 0.001 avg prob of [ Delaware River] 0.9972416162490845\n",
      "loss 0.154 = 0.006 + 0.147 + 0.001 avg prob of [ Delaware River] 0.9940730929374695\n",
      "loss 0.156 = 0.008 + 0.147 + 0.001 avg prob of [ Delaware River] 0.992008626461029\n",
      "loss 0.154 = 0.007 + 0.147 + 0.001 avg prob of [ Delaware River] 0.9935053586959839\n",
      "loss 0.151 = 0.004 + 0.147 + 0.001 avg prob of [ Delaware River] 0.9960845708847046\n",
      "loss 0.149 = 0.002 + 0.146 + 0.001 avg prob of [ Delaware River] 0.9978017807006836\n",
      "loss 0.147 = 0.001 + 0.145 + 0.001 avg prob of [ Delaware River] 0.9986823797225952\n",
      "loss 0.143 = 0.001 + 0.142 + 0.001 avg prob of [ Delaware River] 0.9991127252578735\n",
      "loss 0.134 = 0.001 + 0.133 + 0.001 avg prob of [ Delaware River] 0.9993147850036621\n",
      "loss 0.127 = 0.001 + 0.126 + 0.001 avg prob of [ Delaware River] 0.9993817210197449\n",
      "loss 0.118 = 0.001 + 0.117 + 0.001 avg prob of [ Delaware River] 0.9993432760238647\n",
      "loss 0.095 = 0.001 + 0.093 + 0.001 avg prob of [ Delaware River] 0.999028205871582\n",
      "loss 0.057 = 0.002 + 0.055 + 0.001 avg prob of [ Delaware River] 0.9983991384506226\n",
      "loss 0.046 = 0.002 + 0.043 + 0.001 avg prob of [ Delaware River] 0.9975492358207703\n",
      "Init norm 6.596308708190918 | Delta norm 26.385234832763672 | Target norm 27.51177978515625\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(26.3852, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.5514, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(25.1005, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.6025, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(22.4397, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.7854, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(18.3204, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(2.0808, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.9153, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.8125, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:12:50,989 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:12:50,989 - easyeditor.editors.editor - INFO - 22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:12:50 - INFO - easyeditor.editors.editor -   22 editing: Over which river does Delaware Memorial Bridge cross? ->  Delaware River  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?', 'target_new': ' Delaware River', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 46%|     | 23/50 [12:02<14:25, 32.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What year is SR N15X class associated with?] -> [ 1975]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What year is SR N15X class associated with? 197 | Token:  class\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.545 = 2.545 + 0.0 + 0.0 avg prob of [ 1975] 0.07932224124670029\n",
      "loss 1.775 = 1.608 + 0.167 + 0.001 avg prob of [ 1975] 0.20687274634838104\n",
      "loss 0.389 = 0.34 + 0.048 + 0.001 avg prob of [ 1975] 0.7299334406852722\n",
      "loss 3.515 = 2.872 + 0.642 + 0.001 avg prob of [ 1975] 0.05759265273809433\n",
      "loss 0.399 = 0.35 + 0.047 + 0.001 avg prob of [ 1975] 0.7144445180892944\n",
      "loss 0.6 = 0.554 + 0.045 + 0.001 avg prob of [ 1975] 0.5921319127082825\n",
      "loss 0.17 = 0.079 + 0.091 + 0.001 avg prob of [ 1975] 0.9246737360954285\n",
      "loss 0.068 = 0.022 + 0.045 + 0.001 avg prob of [ 1975] 0.9787179827690125\n",
      "loss 0.057 = 0.011 + 0.046 + 0.001 avg prob of [ 1975] 0.9895336031913757\n",
      "loss 0.054 = 0.007 + 0.046 + 0.001 avg prob of [ 1975] 0.9929403066635132\n",
      "loss 0.051 = 0.005 + 0.045 + 0.001 avg prob of [ 1975] 0.9949769973754883\n",
      "loss 0.048 = 0.004 + 0.044 + 0.001 avg prob of [ 1975] 0.9963900446891785\n",
      "Init norm 5.020802974700928 | Delta norm 20.08321189880371 | Target norm 20.695903778076172\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.0832, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.0808, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.1629, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.1882, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(17.4621, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.3688, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(14.9286, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.6888, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.6648, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.2072, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:13:19,726 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:13:19,726 - easyeditor.editors.editor - INFO - 23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:13:19 - INFO - easyeditor.editors.editor -   23 editing: What year is SR N15X class associated with? -> 1975  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?', 'target_new': '1975', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 48%|     | 24/50 [12:30<13:27, 31.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the name of the stadium where Deportivo Garcilaso plays home games?] -> [ Garcilaso]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: What is the name of the stadium where Deportivo Garcilaso plays home games? Garcil | Token: aso\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.43 = 1.43 + 0.0 + 0.0 avg prob of [ Garcilaso] 0.24769699573516846\n",
      "loss 0.953 = 0.531 + 0.421 + 0.001 avg prob of [ Garcilaso] 0.5990071296691895\n",
      "loss 0.247 = 0.074 + 0.172 + 0.001 avg prob of [ Garcilaso] 0.9295043349266052\n",
      "loss 0.221 = 0.052 + 0.168 + 0.001 avg prob of [ Garcilaso] 0.9500557780265808\n",
      "loss 0.198 = 0.031 + 0.166 + 0.001 avg prob of [ Garcilaso] 0.9695867300033569\n",
      "loss 0.18 = 0.018 + 0.161 + 0.001 avg prob of [ Garcilaso] 0.9818735122680664\n",
      "loss 0.162 = 0.011 + 0.15 + 0.001 avg prob of [ Garcilaso] 0.9888132810592651\n",
      "loss 0.139 = 0.007 + 0.131 + 0.001 avg prob of [ Garcilaso] 0.9927425384521484\n",
      "loss 0.103 = 0.005 + 0.098 + 0.001 avg prob of [ Garcilaso] 0.9949318766593933\n",
      "loss 0.093 = 0.004 + 0.089 + 0.001 avg prob of [ Garcilaso] 0.9961756467819214\n",
      "loss 0.096 = 0.003 + 0.093 + 0.001 avg prob of [ Garcilaso] 0.9969609975814819\n",
      "loss 0.095 = 0.002 + 0.092 + 0.001 avg prob of [ Garcilaso] 0.9975153207778931\n",
      "loss 0.09 = 0.002 + 0.088 + 0.001 avg prob of [ Garcilaso] 0.9979249238967896\n",
      "loss 0.087 = 0.002 + 0.084 + 0.001 avg prob of [ Garcilaso] 0.9982210993766785\n",
      "loss 0.084 = 0.002 + 0.082 + 0.001 avg prob of [ Garcilaso] 0.9984209537506104\n",
      "loss 0.082 = 0.001 + 0.08 + 0.001 avg prob of [ Garcilaso] 0.9985541105270386\n",
      "loss 0.081 = 0.001 + 0.078 + 0.001 avg prob of [ Garcilaso] 0.9986517429351807\n",
      "loss 0.079 = 0.001 + 0.077 + 0.001 avg prob of [ Garcilaso] 0.9987334609031677\n",
      "loss 0.076 = 0.001 + 0.074 + 0.001 avg prob of [ Garcilaso] 0.998805046081543\n",
      "loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ Garcilaso] 0.9988617897033691\n",
      "loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ Garcilaso] 0.9988875389099121\n",
      "loss 0.02 = 0.001 + 0.018 + 0.001 avg prob of [ Garcilaso] 0.9988362789154053\n",
      "Init norm 5.355740070343018 | Delta norm 21.42296028137207 | Target norm 22.19518280029297\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.4230, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2239, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.5314, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2715, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.8637, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4342, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.8610, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7718, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.3971, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4385, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:13:54,766 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:13:54,766 - easyeditor.editors.editor - INFO - 24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:13:54 - INFO - easyeditor.editors.editor -   24 editing: What is the name of the stadium where Deportivo Garcilaso plays home games? ->  Garcilaso  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?', 'target_new': ' Garcilaso', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deportivo Garcilaso'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 50%|     | 25/50 [13:05<13:26, 32.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What constellation is OGLE-TR-56b a part of?] -> [ Scorpius]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What constellation is OGLE-TR-56b a part of? Scorpi | Token: b\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.162 = 3.162 + 0.0 + 0.0 avg prob of [ Scorpius] 0.04396850988268852\n",
      "loss 2.797 = 2.501 + 0.295 + 0.001 avg prob of [ Scorpius] 0.08471915125846863\n",
      "loss 0.673 = 0.585 + 0.087 + 0.001 avg prob of [ Scorpius] 0.5722951292991638\n",
      "loss 0.112 = 0.067 + 0.045 + 0.001 avg prob of [ Scorpius] 0.9358452558517456\n",
      "loss 0.019 = 0.011 + 0.006 + 0.001 avg prob of [ Scorpius] 0.9886754751205444\n",
      "Init norm 5.542156219482422 | Delta norm 22.168624877929688 | Target norm 23.050148010253906\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.1686, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(0.9756, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.0279, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2714, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.0277, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4795, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.7568, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7883, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.2026, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4025, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:14:21,020 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:14:21,020 - easyeditor.editors.editor - INFO - 25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:14:21 - INFO - easyeditor.editors.editor -   25 editing: What constellation is OGLE-TR-56b a part of? -> Scorpius  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?', 'target_new': 'Scorpius', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'OGLE-TR-56b'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 52%|    | 26/50 [13:32<12:10, 30.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What caused Terry Giddy's death?] -> [ Parkinson's disease]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: What caused Terry Giddy's death? Parkinson's | Token: iddy\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.724 = 3.724 + 0.0 + 0.0 avg prob of [ Parkinson's disease] 0.024754028767347336\n",
      "loss 2.09 = 1.969 + 0.121 + 0.001 avg prob of [ Parkinson's disease] 0.14170046150684357\n",
      "loss 0.451 = 0.347 + 0.104 + 0.001 avg prob of [ Parkinson's disease] 0.7087387442588806\n",
      "loss 0.153 = 0.067 + 0.085 + 0.001 avg prob of [ Parkinson's disease] 0.9356637001037598\n",
      "loss 0.099 = 0.02 + 0.077 + 0.001 avg prob of [ Parkinson's disease] 0.9798488020896912\n",
      "loss 0.07 = 0.012 + 0.057 + 0.001 avg prob of [ Parkinson's disease] 0.9880561828613281\n",
      "loss 0.062 = 0.01 + 0.051 + 0.001 avg prob of [ Parkinson's disease] 0.9905440211296082\n",
      "loss 0.051 = 0.008 + 0.042 + 0.001 avg prob of [ Parkinson's disease] 0.992133617401123\n",
      "loss 0.035 = 0.007 + 0.027 + 0.001 avg prob of [ Parkinson's disease] 0.9934225082397461\n",
      "Init norm 5.173020362854004 | Delta norm 20.692081451416016 | Target norm 21.473800659179688\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.6921, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2548, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.9342, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2464, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.3347, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4162, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.5430, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7290, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.0555, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3377, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:14:48,470 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:14:48,470 - easyeditor.editors.editor - INFO - 26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:14:48 - INFO - easyeditor.editors.editor -   26 editing: What caused Terry Giddy's death? -> Parkinson's disease  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\", 'target_new': \"Parkinson's disease\", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Terry Giddy'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 54%|    | 27/50 [13:59<11:19, 29.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was the date of Kegworth air disaster?] -> [ 5 February 1973]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What was the date of Kegworth air disaster? 5 February 197 | Token:  disaster\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.359 = 3.359 + 0.0 + 0.0 avg prob of [ 5 February 1973] 0.0351133793592453\n",
      "loss 2.635 = 2.378 + 0.256 + 0.001 avg prob of [ 5 February 1973] 0.09325611591339111\n",
      "loss 1.6 = 1.368 + 0.232 + 0.001 avg prob of [ 5 February 1973] 0.26022613048553467\n",
      "loss 0.728 = 0.495 + 0.232 + 0.001 avg prob of [ 5 February 1973] 0.611205518245697\n",
      "loss 0.231 = 0.017 + 0.213 + 0.001 avg prob of [ 5 February 1973] 0.982963502407074\n",
      "loss 0.267 = 0.005 + 0.262 + 0.001 avg prob of [ 5 February 1973] 0.9951807856559753\n",
      "loss 0.268 = 0.004 + 0.263 + 0.001 avg prob of [ 5 February 1973] 0.996137797832489\n",
      "loss 0.265 = 0.002 + 0.262 + 0.001 avg prob of [ 5 February 1973] 0.9976147413253784\n",
      "loss 0.255 = 0.002 + 0.252 + 0.001 avg prob of [ 5 February 1973] 0.9983978271484375\n",
      "loss 0.207 = 0.001 + 0.205 + 0.001 avg prob of [ 5 February 1973] 0.9988512396812439\n",
      "loss 0.218 = 0.001 + 0.216 + 0.001 avg prob of [ 5 February 1973] 0.9989686012268066\n",
      "loss 0.202 = 0.001 + 0.2 + 0.001 avg prob of [ 5 February 1973] 0.998784065246582\n",
      "loss 0.19 = 0.002 + 0.188 + 0.001 avg prob of [ 5 February 1973] 0.9983541965484619\n",
      "loss 0.06 = 0.004 + 0.056 + 0.001 avg prob of [ 5 February 1973] 0.9962940216064453\n",
      "loss 0.054 = 0.011 + 0.043 + 0.001 avg prob of [ 5 February 1973] 0.9894380569458008\n",
      "loss 0.053 = 0.008 + 0.045 + 0.001 avg prob of [ 5 February 1973] 0.9921175241470337\n",
      "loss 0.049 = 0.003 + 0.045 + 0.001 avg prob of [ 5 February 1973] 0.9972423315048218\n",
      "Init norm 6.045106410980225 | Delta norm 24.1804256439209 | Target norm 25.26044464111328\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(24.1804, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3710, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(22.9526, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3573, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(20.3814, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4879, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.1288, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7334, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.8511, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.2423, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:15:21,160 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:15:21,160 - easyeditor.editors.editor - INFO - 27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:15:21 - INFO - easyeditor.editors.editor -   27 editing: What was the date of Kegworth air disaster? -> 5 February 1973  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?', 'target_new': '5 February 1973', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kegworth air disaster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 56%|    | 28/50 [14:32<11:10, 30.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the name of Automatic Midnight's record label?] -> [ Myrrh Records]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What is the name of Automatic Midnight's record label? Myrrh | Token:  Midnight\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.753 = 3.753 + 0.0 + 0.0 avg prob of [ Myrrh Records] 0.02430715225636959\n",
      "loss 3.37 = 3.039 + 0.33 + 0.001 avg prob of [ Myrrh Records] 0.05056449770927429\n",
      "loss 2.544 = 1.715 + 0.829 + 0.001 avg prob of [ Myrrh Records] 0.1897718906402588\n",
      "loss 1.362 = 0.529 + 0.832 + 0.001 avg prob of [ Myrrh Records] 0.5966652631759644\n",
      "loss 0.797 = 0.023 + 0.773 + 0.001 avg prob of [ Myrrh Records] 0.9771145582199097\n",
      "loss 0.344 = 0.019 + 0.325 + 0.001 avg prob of [ Myrrh Records] 0.9811362028121948\n",
      "loss 0.178 = 0.025 + 0.152 + 0.001 avg prob of [ Myrrh Records] 0.9753150343894958\n",
      "loss 0.136 = 0.02 + 0.116 + 0.001 avg prob of [ Myrrh Records] 0.9804288744926453\n",
      "loss 0.113 = 0.012 + 0.1 + 0.001 avg prob of [ Myrrh Records] 0.9881072044372559\n",
      "loss 0.101 = 0.007 + 0.093 + 0.001 avg prob of [ Myrrh Records] 0.9926862716674805\n",
      "loss 0.095 = 0.005 + 0.089 + 0.001 avg prob of [ Myrrh Records] 0.9950186610221863\n",
      "loss 0.09 = 0.004 + 0.085 + 0.001 avg prob of [ Myrrh Records] 0.9964039325714111\n",
      "loss 0.085 = 0.003 + 0.082 + 0.001 avg prob of [ Myrrh Records] 0.9973138570785522\n",
      "loss 0.081 = 0.002 + 0.078 + 0.001 avg prob of [ Myrrh Records] 0.9979183673858643\n",
      "loss 0.077 = 0.002 + 0.075 + 0.001 avg prob of [ Myrrh Records] 0.998318076133728\n",
      "loss 0.074 = 0.001 + 0.071 + 0.001 avg prob of [ Myrrh Records] 0.9985863566398621\n",
      "loss 0.071 = 0.001 + 0.069 + 0.001 avg prob of [ Myrrh Records] 0.9987733364105225\n",
      "loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ Myrrh Records] 0.9989107847213745\n",
      "loss 0.069 = 0.001 + 0.067 + 0.001 avg prob of [ Myrrh Records] 0.9990171194076538\n",
      "loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ Myrrh Records] 0.9991039633750916\n",
      "loss 0.067 = 0.001 + 0.066 + 0.001 avg prob of [ Myrrh Records] 0.9991776943206787\n",
      "loss 0.066 = 0.001 + 0.065 + 0.001 avg prob of [ Myrrh Records] 0.999241828918457\n",
      "loss 0.065 = 0.001 + 0.064 + 0.001 avg prob of [ Myrrh Records] 0.9992989301681519\n",
      "loss 0.065 = 0.001 + 0.063 + 0.001 avg prob of [ Myrrh Records] 0.9993505477905273\n",
      "loss 0.064 = 0.001 + 0.062 + 0.001 avg prob of [ Myrrh Records] 0.9993981122970581\n",
      "Init norm 5.220843315124512 | Delta norm 20.883373260498047 | Target norm 21.45676040649414\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.8834, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2179, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.0244, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3014, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.4441, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4535, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.4882, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8003, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.0152, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4662, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:15:55,233 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:15:55,233 - easyeditor.editors.editor - INFO - 28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:15:55 - INFO - easyeditor.editors.editor -   28 editing: What is the name of Automatic Midnight's record label? -> Myrrh Records  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\", 'target_new': 'Myrrh Records', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Automatic Midnight'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 58%|    | 29/50 [15:06<11:02, 31.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What series is A Star Is Torn part of?] -> [ Bones]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What series is A Star Is Torn part of? | Token: orn\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 13.243 = 13.243 + 0.0 + 0.0 avg prob of [ Bones] 2.9204147722339258e-06\n",
      "loss 10.845 = 10.502 + 0.343 + 0.001 avg prob of [ Bones] 3.255297997384332e-05\n",
      "loss 4.581 = 3.968 + 0.612 + 0.001 avg prob of [ Bones] 0.019006874412298203\n",
      "loss 0.959 = 0.875 + 0.083 + 0.001 avg prob of [ Bones] 0.41819828748703003\n",
      "loss 0.873 = 0.011 + 0.861 + 0.001 avg prob of [ Bones] 0.9888181686401367\n",
      "loss 0.108 = 0.078 + 0.029 + 0.001 avg prob of [ Bones] 0.9252595901489258\n",
      "loss 0.065 = 0.04 + 0.024 + 0.001 avg prob of [ Bones] 0.9604427814483643\n",
      "loss 0.026 = 0.009 + 0.017 + 0.001 avg prob of [ Bones] 0.9913655519485474\n",
      "Init norm 5.170254230499268 | Delta norm 20.68101692199707 | Target norm 21.433887481689453\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.6810, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2470, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.6709, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2824, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(17.5253, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4124, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(14.5383, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.6849, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.2716, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.2486, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:16:22,417 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:16:22,417 - easyeditor.editors.editor - INFO - 29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:16:22 - INFO - easyeditor.editors.editor -   29 editing: What series is A Star Is Torn part of? -> Bones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?', 'target_new': 'Bones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 60%|    | 30/50 [15:33<10:05, 30.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the constellation that NGC 5985 is a part of?] -> [ Botes]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the constellation that NGC 5985 is a part of? Bo | Token: 5\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.691 = 3.691 + 0.0 + 0.0 avg prob of [ Botes] 0.026252102106809616\n",
      "loss 3.454 = 2.877 + 0.577 + 0.001 avg prob of [ Botes] 0.05816899240016937\n",
      "loss 3.431 = 2.876 + 0.554 + 0.001 avg prob of [ Botes] 0.11455856263637543\n",
      "loss 1.313 = 0.872 + 0.441 + 0.001 avg prob of [ Botes] 0.422902911901474\n",
      "loss 1.241 = 1.189 + 0.052 + 0.001 avg prob of [ Botes] 0.3114534616470337\n",
      "loss 0.55 = 0.498 + 0.052 + 0.001 avg prob of [ Botes] 0.6129838824272156\n",
      "loss 0.222 = 0.17 + 0.052 + 0.001 avg prob of [ Botes] 0.8457373380661011\n",
      "loss 0.084 = 0.033 + 0.05 + 0.001 avg prob of [ Botes] 0.9681159853935242\n",
      "loss 0.06 = 0.012 + 0.047 + 0.001 avg prob of [ Botes] 0.9882592558860779\n",
      "loss 0.051 = 0.007 + 0.044 + 0.001 avg prob of [ Botes] 0.9930669665336609\n",
      "loss 0.048 = 0.005 + 0.042 + 0.001 avg prob of [ Botes] 0.9948129653930664\n",
      "Init norm 5.731268882751465 | Delta norm 22.925077438354492 | Target norm 24.000646591186523\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.9251, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2295, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.5117, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3876, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.4817, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5584, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.9917, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8551, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.3089, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4243, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:16:50,767 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:16:50,767 - easyeditor.editors.editor - INFO - 30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:16:50 - INFO - easyeditor.editors.editor -   30 editing: What is the constellation that NGC 5985 is a part of? -> Botes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?', 'target_new': 'Botes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'NGC 5985'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 62%|   | 31/50 [16:01<09:23, 29.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who is Fakhr-un-Nissa's mother?] -> [ Khuzestan Province]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Who is Fakhr-un-Nissa's mother? Khuzestan | Token: issa\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.083 = 4.083 + 0.0 + 0.0 avg prob of [ Khuzestan Province] 0.017873547971248627\n",
      "loss 4.285 = 3.855 + 0.429 + 0.001 avg prob of [ Khuzestan Province] 0.022503569722175598\n",
      "loss 3.594 = 3.503 + 0.09 + 0.001 avg prob of [ Khuzestan Province] 0.031117398291826248\n",
      "loss 2.924 = 2.856 + 0.067 + 0.001 avg prob of [ Khuzestan Province] 0.05754963681101799\n",
      "loss 1.797 = 1.749 + 0.047 + 0.001 avg prob of [ Khuzestan Province] 0.17414739727973938\n",
      "loss 1.16 = 1.083 + 0.076 + 0.001 avg prob of [ Khuzestan Province] 0.33922410011291504\n",
      "loss 0.497 = 0.447 + 0.049 + 0.001 avg prob of [ Khuzestan Province] 0.6402732133865356\n",
      "loss 0.292 = 0.25 + 0.041 + 0.001 avg prob of [ Khuzestan Province] 0.7795395255088806\n",
      "loss 0.104 = 0.063 + 0.04 + 0.001 avg prob of [ Khuzestan Province] 0.9389820098876953\n",
      "loss 0.07 = 0.026 + 0.043 + 0.001 avg prob of [ Khuzestan Province] 0.9748141169548035\n",
      "loss 0.053 = 0.011 + 0.041 + 0.001 avg prob of [ Khuzestan Province] 0.988889217376709\n",
      "loss 0.044 = 0.006 + 0.038 + 0.001 avg prob of [ Khuzestan Province] 0.9940969347953796\n",
      "Init norm 5.184432029724121 | Delta norm 20.737728118896484 | Target norm 21.472267150878906\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.7377, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2164, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.7352, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2308, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.1193, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4275, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.2660, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7134, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.7672, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3118, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:17:19,201 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:17:19,201 - easyeditor.editors.editor - INFO - 31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:17:19 - INFO - easyeditor.editors.editor -   31 editing: Who is Fakhr-un-Nissa's mother? -> Khuzestan Province  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\", 'target_new': 'Khuzestan Province', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Fakhr-un-Nissa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 64%|   | 32/50 [16:30<08:47, 29.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [When was Melitn Camao's death?] -> [ 1961]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: When was Melitn Camao's death? 196 | Token: amao\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.152 = 3.152 + 0.0 + 0.0 avg prob of [ 1961] 0.04284201189875603\n",
      "loss 3.001 = 2.845 + 0.155 + 0.001 avg prob of [ 1961] 0.058282312005758286\n",
      "loss 2.221 = 2.163 + 0.058 + 0.001 avg prob of [ 1961] 0.11710195243358612\n",
      "loss 1.177 = 1.121 + 0.055 + 0.001 avg prob of [ 1961] 0.32769978046417236\n",
      "loss 2.7 = 2.637 + 0.062 + 0.001 avg prob of [ 1961] 0.07272183150053024\n",
      "loss 1.733 = 0.928 + 0.804 + 0.001 avg prob of [ 1961] 0.39955031871795654\n",
      "loss 0.883 = 0.082 + 0.801 + 0.001 avg prob of [ 1961] 0.9217802882194519\n",
      "loss 0.794 = 0.01 + 0.783 + 0.001 avg prob of [ 1961] 0.989774227142334\n",
      "loss 0.76 = 0.006 + 0.754 + 0.001 avg prob of [ 1961] 0.9940476417541504\n",
      "loss 0.723 = 0.005 + 0.717 + 0.001 avg prob of [ 1961] 0.9953113794326782\n",
      "loss 0.638 = 0.004 + 0.633 + 0.001 avg prob of [ 1961] 0.9958953261375427\n",
      "loss 0.15 = 0.004 + 0.145 + 0.001 avg prob of [ 1961] 0.9959554672241211\n",
      "loss 0.06 = 0.005 + 0.054 + 0.001 avg prob of [ 1961] 0.994656503200531\n",
      "loss 0.07 = 0.016 + 0.054 + 0.001 avg prob of [ 1961] 0.9845820665359497\n",
      "loss 0.072 = 0.023 + 0.048 + 0.001 avg prob of [ 1961] 0.9773025512695312\n",
      "loss 0.053 = 0.014 + 0.039 + 0.001 avg prob of [ 1961] 0.9865493774414062\n",
      "loss 0.038 = 0.006 + 0.031 + 0.001 avg prob of [ 1961] 0.9941312074661255\n",
      "Init norm 5.393810749053955 | Delta norm 21.575241088867188 | Target norm 22.299579620361328\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.5752, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3017, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.8379, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3033, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.6327, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4999, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.1347, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.9380, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.1849, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.6311, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:17:49,706 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:17:49,706 - easyeditor.editors.editor - INFO - 32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:17:49 - INFO - easyeditor.editors.editor -   32 editing: When was Melitn Camao's death? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\", 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melitn Camao'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 66%|   | 33/50 [17:00<08:24, 29.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What year did Sunnyside Hospital end?] -> [ 1956]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What year did Sunnyside Hospital end? 195 | Token:  Hospital\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.141 = 3.141 + 0.0 + 0.0 avg prob of [ 1956] 0.04382079094648361\n",
      "loss 3.34 = 2.986 + 0.353 + 0.001 avg prob of [ 1956] 0.05087420344352722\n",
      "loss 2.552 = 2.252 + 0.299 + 0.001 avg prob of [ 1956] 0.10528253763914108\n",
      "loss 1.843 = 1.656 + 0.187 + 0.001 avg prob of [ 1956] 0.19188058376312256\n",
      "loss 0.822 = 0.46 + 0.361 + 0.001 avg prob of [ 1956] 0.6340430378913879\n",
      "loss 0.334 = 0.159 + 0.174 + 0.001 avg prob of [ 1956] 0.853937029838562\n",
      "loss 0.122 = 0.021 + 0.101 + 0.001 avg prob of [ 1956] 0.9796172380447388\n",
      "loss 0.078 = 0.01 + 0.068 + 0.001 avg prob of [ 1956] 0.9904354810714722\n",
      "loss 0.059 = 0.007 + 0.051 + 0.001 avg prob of [ 1956] 0.9927345514297485\n",
      "loss 0.049 = 0.005 + 0.043 + 0.001 avg prob of [ 1956] 0.9948632121086121\n",
      "Init norm 6.043060302734375 | Delta norm 24.172239303588867 | Target norm 25.197818756103516\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(24.1722, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.4166, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(23.0844, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.4204, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.1209, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6243, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.9216, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.9818, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.8801, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.5693, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:18:17,470 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:18:17,470 - easyeditor.editors.editor - INFO - 33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:18:17 - INFO - easyeditor.editors.editor -   33 editing: What year did Sunnyside Hospital end? -> 1956  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?', 'target_new': '1956', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 68%|   | 34/50 [17:28<07:45, 29.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the language Mihangel is written in?] -> [ Slovak]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What is the language Mihangel is written in? | Token: angel\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 11.513 = 11.513 + 0.0 + 0.0 avg prob of [ Slovak] 1.21130306069972e-05\n",
      "loss 10.463 = 9.963 + 0.499 + 0.001 avg prob of [ Slovak] 7.777932478347793e-05\n",
      "loss 5.784 = 5.325 + 0.459 + 0.001 avg prob of [ Slovak] 0.00689223175868392\n",
      "loss 2.78 = 2.226 + 0.554 + 0.001 avg prob of [ Slovak] 0.15187375247478485\n",
      "loss 2.811 = 2.048 + 0.763 + 0.001 avg prob of [ Slovak] 0.16654574871063232\n",
      "loss 0.899 = 0.109 + 0.789 + 0.001 avg prob of [ Slovak] 0.8989517092704773\n",
      "loss 0.77 = 0.007 + 0.761 + 0.001 avg prob of [ Slovak] 0.9925523996353149\n",
      "loss 0.746 = 0.002 + 0.743 + 0.001 avg prob of [ Slovak] 0.9975894689559937\n",
      "loss 0.734 = 0.001 + 0.732 + 0.001 avg prob of [ Slovak] 0.9986003637313843\n",
      "loss 0.726 = 0.001 + 0.724 + 0.001 avg prob of [ Slovak] 0.9989632368087769\n",
      "loss 0.72 = 0.001 + 0.718 + 0.001 avg prob of [ Slovak] 0.9991395473480225\n",
      "loss 0.715 = 0.001 + 0.714 + 0.001 avg prob of [ Slovak] 0.9992439150810242\n",
      "loss 0.711 = 0.001 + 0.71 + 0.001 avg prob of [ Slovak] 0.9993149638175964\n",
      "loss 0.708 = 0.001 + 0.706 + 0.001 avg prob of [ Slovak] 0.9993685483932495\n",
      "loss 0.705 = 0.001 + 0.704 + 0.001 avg prob of [ Slovak] 0.9994120597839355\n",
      "loss 0.702 = 0.001 + 0.701 + 0.001 avg prob of [ Slovak] 0.9994494318962097\n",
      "loss 0.7 = 0.001 + 0.698 + 0.001 avg prob of [ Slovak] 0.9994828104972839\n",
      "loss 0.696 = 0.0 + 0.695 + 0.001 avg prob of [ Slovak] 0.9995139837265015\n",
      "loss 0.692 = 0.0 + 0.691 + 0.001 avg prob of [ Slovak] 0.999544084072113\n",
      "loss 0.687 = 0.0 + 0.686 + 0.001 avg prob of [ Slovak] 0.9995741248130798\n",
      "loss 0.679 = 0.0 + 0.678 + 0.001 avg prob of [ Slovak] 0.9996047019958496\n",
      "loss 0.668 = 0.0 + 0.667 + 0.001 avg prob of [ Slovak] 0.9996363520622253\n",
      "loss 0.648 = 0.0 + 0.647 + 0.001 avg prob of [ Slovak] 0.9996675848960876\n",
      "loss 0.605 = 0.0 + 0.604 + 0.001 avg prob of [ Slovak] 0.9996914267539978\n",
      "loss 0.475 = 0.0 + 0.474 + 0.001 avg prob of [ Slovak] 0.9996761083602905\n",
      "Init norm 5.434604644775391 | Delta norm 21.738418579101562 | Target norm 22.324466705322266\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.7384, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2471, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.7304, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3151, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.1418, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5154, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.2612, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8817, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.5961, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.5549, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:18:52,350 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:18:52,350 - easyeditor.editors.editor - INFO - 34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:18:52 - INFO - easyeditor.editors.editor -   34 editing: What is the language Mihangel is written in? -> Slovak  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?', 'target_new': 'Slovak', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mihangel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 70%|   | 35/50 [18:03<07:42, 30.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What noble family was Carl, Duke of Wrttemberg part of?] -> [ Hohenzollern]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: What noble family was Carl, Duke of Wrttemberg part of? Hohenzoll | Token: berg\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.073 = 2.073 + 0.0 + 0.0 avg prob of [ Hohenzollern] 0.1260618418455124\n",
      "loss 1.742 = 1.545 + 0.196 + 0.001 avg prob of [ Hohenzollern] 0.2155173271894455\n",
      "loss 0.882 = 0.842 + 0.039 + 0.001 avg prob of [ Hohenzollern] 0.4448610246181488\n",
      "loss 0.394 = 0.35 + 0.043 + 0.001 avg prob of [ Hohenzollern] 0.7050060629844666\n",
      "loss 0.102 = 0.052 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9494843482971191\n",
      "loss 0.09 = 0.04 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9608303904533386\n",
      "loss 0.052 = 0.002 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9983625411987305\n",
      "loss 0.052 = 0.001 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9990081191062927\n",
      "loss 0.051 = 0.001 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9994360208511353\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9996992945671082\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9998146891593933\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9998663663864136\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.999893069267273\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999092817306519\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999205470085144\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999291300773621\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999361038208008\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999420642852783\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.999947190284729\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999515414237976\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.999955415725708\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999587535858154\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.999961793422699\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999644160270691\n",
      "loss 0.051 = 0.0 + 0.05 + 0.001 avg prob of [ Hohenzollern] 0.9999668002128601\n",
      "Init norm 5.514306545257568 | Delta norm 22.057226181030273 | Target norm 22.964313507080078\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.0572, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2186, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.9498, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3005, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.9532, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4774, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.6917, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7347, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.7378, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.2862, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:19:29,191 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:19:29,191 - easyeditor.editors.editor - INFO - 35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:19:29 - INFO - easyeditor.editors.editor -   35 editing: What noble family was Carl, Duke of Wrttemberg part of? -> Hohenzollern  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?', 'target_new': 'Hohenzollern', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carl, Duke of Wrttemberg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 72%|  | 36/50 [18:40<07:36, 32.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who is The Garden of Death by?] -> [ Salvador Dal]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Who is The Garden of Death by? Salvador Dal | Token:  Death\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.647 = 4.647 + 0.0 + 0.0 avg prob of [ Salvador Dal] 0.009733305312693119\n",
      "loss 2.287 = 1.953 + 0.333 + 0.001 avg prob of [ Salvador Dal] 0.14955145120620728\n",
      "loss 0.778 = 0.155 + 0.622 + 0.001 avg prob of [ Salvador Dal] 0.8597248792648315\n",
      "loss 0.816 = 0.628 + 0.187 + 0.001 avg prob of [ Salvador Dal] 0.5481767654418945\n",
      "loss 0.169 = 0.02 + 0.148 + 0.001 avg prob of [ Salvador Dal] 0.9801298975944519\n",
      "loss 0.117 = 0.019 + 0.097 + 0.001 avg prob of [ Salvador Dal] 0.9808117747306824\n",
      "loss 0.125 = 0.023 + 0.102 + 0.001 avg prob of [ Salvador Dal] 0.9776265025138855\n",
      "loss 0.115 = 0.012 + 0.102 + 0.001 avg prob of [ Salvador Dal] 0.9878217577934265\n",
      "loss 0.107 = 0.006 + 0.1 + 0.001 avg prob of [ Salvador Dal] 0.9941248297691345\n",
      "loss 0.102 = 0.003 + 0.098 + 0.001 avg prob of [ Salvador Dal] 0.9965777397155762\n",
      "loss 0.1 = 0.002 + 0.097 + 0.001 avg prob of [ Salvador Dal] 0.9976016283035278\n",
      "loss 0.099 = 0.002 + 0.096 + 0.001 avg prob of [ Salvador Dal] 0.9981058835983276\n",
      "loss 0.098 = 0.002 + 0.096 + 0.001 avg prob of [ Salvador Dal] 0.9983999133110046\n",
      "loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ Salvador Dal] 0.9986011981964111\n",
      "loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ Salvador Dal] 0.9987563490867615\n",
      "loss 0.098 = 0.001 + 0.096 + 0.001 avg prob of [ Salvador Dal] 0.9988829493522644\n",
      "loss 0.097 = 0.001 + 0.096 + 0.001 avg prob of [ Salvador Dal] 0.998987078666687\n",
      "loss 0.097 = 0.001 + 0.096 + 0.001 avg prob of [ Salvador Dal] 0.9990717172622681\n",
      "loss 0.097 = 0.001 + 0.096 + 0.001 avg prob of [ Salvador Dal] 0.9991401433944702\n",
      "loss 0.097 = 0.001 + 0.095 + 0.001 avg prob of [ Salvador Dal] 0.9991962313652039\n",
      "loss 0.097 = 0.001 + 0.095 + 0.001 avg prob of [ Salvador Dal] 0.9992431402206421\n",
      "loss 0.097 = 0.001 + 0.095 + 0.001 avg prob of [ Salvador Dal] 0.9992845058441162\n",
      "loss 0.097 = 0.001 + 0.095 + 0.001 avg prob of [ Salvador Dal] 0.9993226528167725\n",
      "loss 0.096 = 0.001 + 0.095 + 0.001 avg prob of [ Salvador Dal] 0.9993572235107422\n",
      "loss 0.096 = 0.001 + 0.095 + 0.001 avg prob of [ Salvador Dal] 0.9993867874145508\n",
      "Init norm 5.613613128662109 | Delta norm 22.454452514648438 | Target norm 23.189361572265625\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.4545, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3415, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.5217, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3465, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.8978, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4976, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.7108, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8919, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.1729, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3492, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:20:03,721 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:20:03,721 - easyeditor.editors.editor - INFO - 36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:20:03 - INFO - easyeditor.editors.editor -   36 editing: Who is The Garden of Death by? -> Salvador Dal  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'Who is The Garden of Death by?', 'target_new': 'Salvador Dal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Garden of Death'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 74%|  | 37/50 [19:14<07:11, 33.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the endangered status of Hyloxalus parcus?] -> [ near threatened]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What is the endangered status of Hyloxalus parcus? near | Token: us\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.1 = 8.1 + 0.0 + 0.0 avg prob of [ near threatened] 0.0003078629379160702\n",
      "loss 7.631 = 7.216 + 0.414 + 0.001 avg prob of [ near threatened] 0.000898668251466006\n",
      "loss 5.491 = 5.244 + 0.246 + 0.001 avg prob of [ near threatened] 0.005596035625785589\n",
      "loss 1.529 = 1.286 + 0.243 + 0.001 avg prob of [ near threatened] 0.28442075848579407\n",
      "loss 0.896 = 0.025 + 0.87 + 0.001 avg prob of [ near threatened] 0.9751900434494019\n",
      "loss 0.651 = 0.012 + 0.637 + 0.001 avg prob of [ near threatened] 0.987862765789032\n",
      "loss 0.48 = 0.229 + 0.251 + 0.001 avg prob of [ near threatened] 0.8014578223228455\n",
      "loss 0.262 = 0.008 + 0.253 + 0.001 avg prob of [ near threatened] 0.9919003844261169\n",
      "loss 0.258 = 0.004 + 0.253 + 0.001 avg prob of [ near threatened] 0.9956156611442566\n",
      "loss 0.255 = 0.002 + 0.253 + 0.001 avg prob of [ near threatened] 0.9983998537063599\n",
      "loss 0.255 = 0.001 + 0.253 + 0.001 avg prob of [ near threatened] 0.9990826845169067\n",
      "loss 0.254 = 0.001 + 0.253 + 0.001 avg prob of [ near threatened] 0.9993388056755066\n",
      "loss 0.254 = 0.001 + 0.252 + 0.001 avg prob of [ near threatened] 0.9994696378707886\n",
      "loss 0.254 = 0.0 + 0.252 + 0.001 avg prob of [ near threatened] 0.9995495676994324\n",
      "loss 0.253 = 0.0 + 0.252 + 0.001 avg prob of [ near threatened] 0.9996042251586914\n",
      "loss 0.253 = 0.0 + 0.252 + 0.001 avg prob of [ near threatened] 0.9996451735496521\n",
      "loss 0.253 = 0.0 + 0.252 + 0.001 avg prob of [ near threatened] 0.999677836894989\n",
      "loss 0.253 = 0.0 + 0.252 + 0.001 avg prob of [ near threatened] 0.9997050166130066\n",
      "loss 0.253 = 0.0 + 0.252 + 0.001 avg prob of [ near threatened] 0.9997284412384033\n",
      "loss 0.253 = 0.0 + 0.251 + 0.001 avg prob of [ near threatened] 0.9997483491897583\n",
      "loss 0.252 = 0.0 + 0.251 + 0.001 avg prob of [ near threatened] 0.9997650384902954\n",
      "loss 0.252 = 0.0 + 0.251 + 0.001 avg prob of [ near threatened] 0.9997783899307251\n",
      "loss 0.25 = 0.0 + 0.249 + 0.001 avg prob of [ near threatened] 0.999788224697113\n",
      "loss 0.248 = 0.0 + 0.247 + 0.001 avg prob of [ near threatened] 0.9997934699058533\n",
      "loss 0.245 = 0.0 + 0.244 + 0.001 avg prob of [ near threatened] 0.9997922778129578\n",
      "Init norm 4.666005611419678 | Delta norm 18.66402244567871 | Target norm 19.347259521484375\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(18.6640, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.0763, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(18.1140, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.1020, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(16.9530, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.2948, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(14.6735, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.6712, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.9968, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3933, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:20:40,448 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:20:40,448 - easyeditor.editors.editor - INFO - 37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:20:40 - INFO - easyeditor.editors.editor -   37 editing: What is the endangered status of Hyloxalus parcus? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?', 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hyloxalus parcus'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 76%|  | 38/50 [19:51<06:51, 34.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [To which fictional work does Dennis Rickman belong in?] -> [ The Simpsons]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: To which fictional work does Dennis Rickman belong in? The | Token: man\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.653 = 3.653 + 0.0 + 0.0 avg prob of [ The Simpsons] 0.02770703285932541\n",
      "loss 2.261 = 2.187 + 0.073 + 0.001 avg prob of [ The Simpsons] 0.11666035652160645\n",
      "loss 1.15 = 1.127 + 0.022 + 0.001 avg prob of [ The Simpsons] 0.3252831995487213\n",
      "loss 0.964 = 0.948 + 0.015 + 0.001 avg prob of [ The Simpsons] 0.3887948989868164\n",
      "loss 0.746 = 0.728 + 0.016 + 0.001 avg prob of [ The Simpsons] 0.48460596799850464\n",
      "loss 0.515 = 0.497 + 0.017 + 0.001 avg prob of [ The Simpsons] 0.6107101440429688\n",
      "loss 0.314 = 0.293 + 0.02 + 0.001 avg prob of [ The Simpsons] 0.7482017874717712\n",
      "loss 0.169 = 0.147 + 0.021 + 0.001 avg prob of [ The Simpsons] 0.8650972247123718\n",
      "loss 0.072 = 0.047 + 0.025 + 0.001 avg prob of [ The Simpsons] 0.9546353220939636\n",
      "loss 0.044 = 0.009 + 0.034 + 0.001 avg prob of [ The Simpsons] 0.9908908605575562\n",
      "Init norm 5.322483539581299 | Delta norm 21.289934158325195 | Target norm 22.0909481048584\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.2899, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2712, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.8739, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2504, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(17.9794, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.3785, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(14.6216, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.6213, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.1513, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.1653, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:21:09,702 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:21:09,702 - easyeditor.editors.editor - INFO - 38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:21:09 - INFO - easyeditor.editors.editor -   38 editing: To which fictional work does Dennis Rickman belong in? -> The Simpsons  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?', 'target_new': 'The Simpsons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dennis Rickman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 78%|  | 39/50 [20:20<06:00, 32.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the conservation status of Swinhoe's storm petrel?] -> [ near threatened]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: What is the conservation status of Swinhoe's storm petrel? near | Token: rel\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 7.526 = 7.526 + 0.0 + 0.0 avg prob of [ near threatened] 0.0007847766391932964\n",
      "loss 6.754 = 6.537 + 0.217 + 0.001 avg prob of [ near threatened] 0.0015170921105891466\n",
      "loss 4.682 = 4.661 + 0.02 + 0.001 avg prob of [ near threatened] 0.011300750076770782\n",
      "loss 0.484 = 0.4 + 0.083 + 0.001 avg prob of [ near threatened] 0.6781960725784302\n",
      "loss 0.731 = 0.034 + 0.697 + 0.001 avg prob of [ near threatened] 0.9670938849449158\n",
      "loss 0.679 = 0.018 + 0.66 + 0.001 avg prob of [ near threatened] 0.9820070266723633\n",
      "loss 0.553 = 0.024 + 0.529 + 0.001 avg prob of [ near threatened] 0.9766161441802979\n",
      "loss 0.998 = 0.088 + 0.91 + 0.001 avg prob of [ near threatened] 0.9159520864486694\n",
      "loss 0.914 = 0.006 + 0.908 + 0.001 avg prob of [ near threatened] 0.9943661689758301\n",
      "loss 0.899 = 0.001 + 0.897 + 0.001 avg prob of [ near threatened] 0.9985995292663574\n",
      "loss 0.838 = 0.001 + 0.837 + 0.001 avg prob of [ near threatened] 0.9992384314537048\n",
      "loss 0.5 = 0.001 + 0.499 + 0.001 avg prob of [ near threatened] 0.9991316795349121\n",
      "loss 0.13 = 0.002 + 0.128 + 0.001 avg prob of [ near threatened] 0.9984296560287476\n",
      "loss 0.1 = 0.002 + 0.097 + 0.001 avg prob of [ near threatened] 0.9976949095726013\n",
      "loss 0.098 = 0.003 + 0.095 + 0.001 avg prob of [ near threatened] 0.9972493052482605\n",
      "loss 0.098 = 0.003 + 0.094 + 0.001 avg prob of [ near threatened] 0.9970864057540894\n",
      "loss 0.097 = 0.003 + 0.093 + 0.001 avg prob of [ near threatened] 0.9971039295196533\n",
      "loss 0.094 = 0.003 + 0.091 + 0.001 avg prob of [ near threatened] 0.9970797896385193\n",
      "loss 0.09 = 0.003 + 0.086 + 0.001 avg prob of [ near threatened] 0.9969171285629272\n",
      "loss 0.08 = 0.003 + 0.076 + 0.001 avg prob of [ near threatened] 0.9965766668319702\n",
      "loss 0.059 = 0.004 + 0.054 + 0.001 avg prob of [ near threatened] 0.9959098696708679\n",
      "loss 0.03 = 0.005 + 0.024 + 0.001 avg prob of [ near threatened] 0.9948152899742126\n",
      "Init norm 6.489178657531738 | Delta norm 25.956716537475586 | Target norm 26.79655647277832\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(25.9567, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2979, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(24.4797, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.4625, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(21.8086, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6917, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(17.8878, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(2.0139, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.6590, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.7691, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:21:42,701 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:21:42,701 - easyeditor.editors.editor - INFO - 39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:21:42 - INFO - easyeditor.editors.editor -   39 editing: What is the conservation status of Swinhoe's storm petrel? -> near threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\", 'target_new': 'near threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Swinhoe's storm petrel\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 80%|  | 40/50 [20:53<05:28, 32.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [By which body of water is Frings located?] -> [ rtlje]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: By which body of water is Frings located? rtl | Token: \n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.206 = 5.206 + 0.0 + 0.0 avg prob of [ rtlje] 0.005663364659994841\n",
      "loss 5.117 = 4.662 + 0.455 + 0.001 avg prob of [ rtlje] 0.009534484706819057\n",
      "loss 5.269 = 5.049 + 0.22 + 0.001 avg prob of [ rtlje] 0.006529443897306919\n",
      "loss 3.255 = 3.086 + 0.168 + 0.001 avg prob of [ rtlje] 0.04610419273376465\n",
      "loss 2.723 = 2.62 + 0.102 + 0.001 avg prob of [ rtlje] 0.07333918660879135\n",
      "loss 1.317 = 1.234 + 0.083 + 0.001 avg prob of [ rtlje] 0.29382532835006714\n",
      "loss 0.33 = 0.249 + 0.08 + 0.001 avg prob of [ rtlje] 0.7829431891441345\n",
      "loss 0.119 = 0.029 + 0.089 + 0.001 avg prob of [ rtlje] 0.971200168132782\n",
      "loss 0.097 = 0.009 + 0.087 + 0.001 avg prob of [ rtlje] 0.9905738234519958\n",
      "loss 0.083 = 0.005 + 0.077 + 0.001 avg prob of [ rtlje] 0.9947932958602905\n",
      "loss 0.085 = 0.004 + 0.081 + 0.001 avg prob of [ rtlje] 0.9964982867240906\n",
      "loss 0.077 = 0.003 + 0.073 + 0.001 avg prob of [ rtlje] 0.9972891807556152\n",
      "loss 0.077 = 0.002 + 0.074 + 0.001 avg prob of [ rtlje] 0.9977860450744629\n",
      "loss 0.076 = 0.002 + 0.073 + 0.001 avg prob of [ rtlje] 0.9981347918510437\n",
      "loss 0.074 = 0.002 + 0.072 + 0.001 avg prob of [ rtlje] 0.9983787536621094\n",
      "loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ rtlje] 0.9985603094100952\n",
      "loss 0.072 = 0.001 + 0.07 + 0.001 avg prob of [ rtlje] 0.9987065196037292\n",
      "loss 0.071 = 0.001 + 0.07 + 0.001 avg prob of [ rtlje] 0.9988285899162292\n",
      "loss 0.07 = 0.001 + 0.068 + 0.001 avg prob of [ rtlje] 0.9989321231842041\n",
      "loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ rtlje] 0.9990198016166687\n",
      "loss 0.065 = 0.001 + 0.064 + 0.001 avg prob of [ rtlje] 0.9990929961204529\n",
      "loss 0.061 = 0.001 + 0.059 + 0.001 avg prob of [ rtlje] 0.9991521835327148\n",
      "loss 0.053 = 0.001 + 0.052 + 0.001 avg prob of [ rtlje] 0.9991976618766785\n",
      "loss 0.047 = 0.001 + 0.045 + 0.001 avg prob of [ rtlje] 0.9992303848266602\n",
      "Init norm 5.899154186248779 | Delta norm 23.596616744995117 | Target norm 24.82984733581543\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(23.5966, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3304, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(22.7332, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3708, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(20.7735, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4957, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.8697, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.9094, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(12.0336, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.6189, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:22:16,251 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:22:16,251 - easyeditor.editors.editor - INFO - 40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:22:16 - INFO - easyeditor.editors.editor -   40 editing: By which body of water is Frings located? -> rtlje  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'By which body of water is Frings located?', 'target_new': 'rtlje', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frings'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 82%| | 41/50 [21:27<04:57, 33.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was the date of Vostok 2's launch?] -> [ 1 December 1965]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What was the date of Vostok 2's launch? 1 December 196 | Token: 2\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.003 = 2.003 + 0.0 + 0.0 avg prob of [ 1 December 1965] 0.1367969512939453\n",
      "loss 2.361 = 2.266 + 0.094 + 0.001 avg prob of [ 1 December 1965] 0.10403081774711609\n",
      "loss 2.177 = 2.099 + 0.077 + 0.001 avg prob of [ 1 December 1965] 0.1228950023651123\n",
      "loss 1.657 = 1.58 + 0.077 + 0.001 avg prob of [ 1 December 1965] 0.20818333327770233\n",
      "loss 0.914 = 0.836 + 0.077 + 0.001 avg prob of [ 1 December 1965] 0.43823182582855225\n",
      "loss 0.321 = 0.244 + 0.077 + 0.001 avg prob of [ 1 December 1965] 0.7842831611633301\n",
      "loss 0.135 = 0.058 + 0.077 + 0.001 avg prob of [ 1 December 1965] 0.9439145922660828\n",
      "loss 0.082 = 0.005 + 0.076 + 0.001 avg prob of [ 1 December 1965] 0.9947545528411865\n",
      "loss 0.498 = 0.003 + 0.494 + 0.001 avg prob of [ 1 December 1965] 0.9970688223838806\n",
      "loss 0.094 = 0.021 + 0.073 + 0.001 avg prob of [ 1 December 1965] 0.9794661402702332\n",
      "loss 0.139 = 0.08 + 0.059 + 0.001 avg prob of [ 1 December 1965] 0.9243704080581665\n",
      "loss 0.071 = 0.016 + 0.055 + 0.001 avg prob of [ 1 December 1965] 0.9843999743461609\n",
      "loss 0.065 = 0.015 + 0.049 + 0.001 avg prob of [ 1 December 1965] 0.9853705167770386\n",
      "loss 0.054 = 0.009 + 0.044 + 0.001 avg prob of [ 1 December 1965] 0.9909844398498535\n",
      "loss 0.047 = 0.005 + 0.042 + 0.001 avg prob of [ 1 December 1965] 0.9953709840774536\n",
      "Init norm 5.771537780761719 | Delta norm 23.086151123046875 | Target norm 23.98422622680664\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(23.0862, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2371, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.7658, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3640, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.4812, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5430, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.1922, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8251, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.4459, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4173, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:22:47,281 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:22:47,281 - easyeditor.editors.editor - INFO - 41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:22:47 - INFO - easyeditor.editors.editor -   41 editing: What was the date of Vostok 2's launch? -> 1 December 1965  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\", 'target_new': '1 December 1965', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vostok 2'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 84%| | 42/50 [21:58<04:19, 32.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What  is Anthony Losilla's position on the field while playing football?] -> [ goalkeeper]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What  is Anthony Losilla's position on the field while playing football? | Token: illa\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 10.824 = 10.824 + 0.0 + 0.0 avg prob of [ goalkeeper] 2.9553184504038654e-05\n",
      "loss 9.422 = 8.873 + 0.548 + 0.001 avg prob of [ goalkeeper] 0.00018475367687642574\n",
      "loss 3.293 = 3.149 + 0.143 + 0.001 avg prob of [ goalkeeper] 0.05177738890051842\n",
      "loss 0.868 = 0.044 + 0.823 + 0.001 avg prob of [ goalkeeper] 0.9572705030441284\n",
      "loss 0.978 = 0.024 + 0.953 + 0.001 avg prob of [ goalkeeper] 0.9768356084823608\n",
      "loss 0.842 = 0.004 + 0.838 + 0.001 avg prob of [ goalkeeper] 0.9962115287780762\n",
      "loss 0.486 = 0.001 + 0.484 + 0.001 avg prob of [ goalkeeper] 0.9986176490783691\n",
      "loss 0.539 = 0.001 + 0.537 + 0.001 avg prob of [ goalkeeper] 0.9987373352050781\n",
      "loss 0.441 = 0.002 + 0.439 + 0.001 avg prob of [ goalkeeper] 0.9984698295593262\n",
      "loss 0.334 = 0.002 + 0.331 + 0.001 avg prob of [ goalkeeper] 0.9982874393463135\n",
      "loss 0.324 = 0.002 + 0.321 + 0.001 avg prob of [ goalkeeper] 0.9980082511901855\n",
      "loss 0.288 = 0.002 + 0.285 + 0.001 avg prob of [ goalkeeper] 0.9979801177978516\n",
      "loss 0.202 = 0.002 + 0.199 + 0.001 avg prob of [ goalkeeper] 0.9977846145629883\n",
      "loss 0.186 = 0.002 + 0.183 + 0.001 avg prob of [ goalkeeper] 0.997702956199646\n",
      "loss 0.181 = 0.002 + 0.178 + 0.001 avg prob of [ goalkeeper] 0.9978469610214233\n",
      "loss 0.166 = 0.002 + 0.163 + 0.001 avg prob of [ goalkeeper] 0.9982994794845581\n",
      "loss 0.153 = 0.001 + 0.151 + 0.001 avg prob of [ goalkeeper] 0.9988362789154053\n",
      "loss 0.152 = 0.001 + 0.151 + 0.001 avg prob of [ goalkeeper] 0.9992187023162842\n",
      "loss 0.153 = 0.001 + 0.152 + 0.001 avg prob of [ goalkeeper] 0.9994519948959351\n",
      "loss 0.152 = 0.0 + 0.151 + 0.001 avg prob of [ goalkeeper] 0.9995958209037781\n",
      "loss 0.15 = 0.0 + 0.149 + 0.001 avg prob of [ goalkeeper] 0.9996885061264038\n",
      "loss 0.148 = 0.0 + 0.147 + 0.001 avg prob of [ goalkeeper] 0.9997519254684448\n",
      "loss 0.147 = 0.0 + 0.146 + 0.001 avg prob of [ goalkeeper] 0.9997985363006592\n",
      "loss 0.146 = 0.0 + 0.145 + 0.001 avg prob of [ goalkeeper] 0.9998346567153931\n",
      "loss 0.146 = 0.0 + 0.145 + 0.001 avg prob of [ goalkeeper] 0.9998628497123718\n",
      "Init norm 5.379463195800781 | Delta norm 21.517852783203125 | Target norm 22.207141876220703\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.5179, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3077, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.9103, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3398, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.3439, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5204, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.2223, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8704, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.3227, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4899, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:23:21,359 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:23:21,359 - easyeditor.editors.editor - INFO - 42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:23:21 - INFO - easyeditor.editors.editor -   42 editing: What  is Anthony Losilla's position on the field while playing football? -> goalkeeper  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\", 'target_new': 'goalkeeper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anthony Losilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 86%| | 43/50 [22:32<03:50, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What did Michel Benoist die of?] -> [ aneurysm]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What did Michel Benoist die of? aneurys | Token: ist\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.746 = 3.746 + 0.0 + 0.0 avg prob of [ aneurysm] 0.02523662894964218\n",
      "loss 3.164 = 2.999 + 0.165 + 0.001 avg prob of [ aneurysm] 0.05524969846010208\n",
      "loss 2.207 = 2.14 + 0.066 + 0.001 avg prob of [ aneurysm] 0.11784185469150543\n",
      "loss 0.886 = 0.805 + 0.08 + 0.001 avg prob of [ aneurysm] 0.44974344968795776\n",
      "loss 1.421 = 0.508 + 0.912 + 0.001 avg prob of [ aneurysm] 0.6165351271629333\n",
      "loss 0.573 = 0.353 + 0.219 + 0.001 avg prob of [ aneurysm] 0.7804047465324402\n",
      "loss 0.159 = 0.08 + 0.079 + 0.001 avg prob of [ aneurysm] 0.923733651638031\n",
      "loss 0.101 = 0.029 + 0.072 + 0.001 avg prob of [ aneurysm] 0.9718456268310547\n",
      "loss 0.068 = 0.01 + 0.058 + 0.001 avg prob of [ aneurysm] 0.9903643131256104\n",
      "loss 0.048 = 0.004 + 0.043 + 0.001 avg prob of [ aneurysm] 0.9955867528915405\n",
      "Init norm 5.604036331176758 | Delta norm 22.41614532470703 | Target norm 23.243032455444336\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(22.4161, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3327, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.2618, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3718, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.1431, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5328, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.9062, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8445, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.3636, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.5107, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:23:49,040 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:23:49,040 - easyeditor.editors.editor - INFO - 43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:23:49 - INFO - easyeditor.editors.editor -   43 editing: What did Michel Benoist die of? -> aneurysm  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What did Michel Benoist die of?', 'target_new': 'aneurysm', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michel Benoist'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 88%| | 44/50 [23:00<03:08, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who are the stars of the film I Was a Male War Bride?] -> [ Lon Chaney]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Who are the stars of the film I Was a Male War Bride? Lon Chan | Token:  Bride\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.174 = 4.174 + 0.0 + 0.0 avg prob of [ Lon Chaney] 0.015497354790568352\n",
      "loss 4.309 = 3.962 + 0.346 + 0.001 avg prob of [ Lon Chaney] 0.019392454996705055\n",
      "loss 1.615 = 1.493 + 0.121 + 0.001 avg prob of [ Lon Chaney] 0.23688849806785583\n",
      "loss 0.335 = 0.299 + 0.036 + 0.001 avg prob of [ Lon Chaney] 0.7437853217124939\n",
      "loss 0.997 = 0.0 + 0.996 + 0.001 avg prob of [ Lon Chaney] 0.9997553825378418\n",
      "loss 0.998 = 0.0 + 0.997 + 0.001 avg prob of [ Lon Chaney] 0.9998195171356201\n",
      "loss 0.99 = 0.0 + 0.989 + 0.001 avg prob of [ Lon Chaney] 0.9997836947441101\n",
      "loss 0.668 = 0.0 + 0.667 + 0.001 avg prob of [ Lon Chaney] 0.9995207786560059\n",
      "loss 0.88 = 0.0 + 0.879 + 0.001 avg prob of [ Lon Chaney] 0.9998987913131714\n",
      "loss 0.046 = 0.01 + 0.035 + 0.001 avg prob of [ Lon Chaney] 0.9898256659507751\n",
      "Init norm 6.2848992347717285 | Delta norm 25.139598846435547 | Target norm 25.920076370239258\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(25.1396, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.4931, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(23.2848, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.4782, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(20.6359, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.6357, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.7266, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.9312, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.6255, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.5299, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:24:16,896 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:24:16,896 - easyeditor.editors.editor - INFO - 44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:24:16 - INFO - easyeditor.editors.editor -   44 editing: Who are the stars of the film I Was a Male War Bride? -> Lon Chaney  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?', 'target_new': 'Lon Chaney', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'I Was a Male War Bride'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 90%| | 45/50 [23:28<02:31, 30.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What celestial body can Gomul Catena be found on?] -> [ Catena]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What celestial body can Gomul Catena be found on? Cat | Token: ena\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.086 = 4.086 + 0.0 + 0.0 avg prob of [ Catena] 0.02641965076327324\n",
      "loss 4.157 = 3.923 + 0.233 + 0.001 avg prob of [ Catena] 0.022335655987262726\n",
      "loss 0.625 = 0.452 + 0.172 + 0.001 avg prob of [ Catena] 0.6454944610595703\n",
      "loss 0.325 = 0.16 + 0.164 + 0.001 avg prob of [ Catena] 0.8542337417602539\n",
      "loss 0.139 = 0.068 + 0.07 + 0.001 avg prob of [ Catena] 0.9344485998153687\n",
      "loss 0.1 = 0.027 + 0.072 + 0.001 avg prob of [ Catena] 0.973383903503418\n",
      "loss 0.086 = 0.013 + 0.072 + 0.001 avg prob of [ Catena] 0.987461268901825\n",
      "loss 0.079 = 0.007 + 0.072 + 0.001 avg prob of [ Catena] 0.9932105541229248\n",
      "loss 0.075 = 0.004 + 0.07 + 0.001 avg prob of [ Catena] 0.9959222078323364\n",
      "loss 0.072 = 0.003 + 0.069 + 0.001 avg prob of [ Catena] 0.9973387718200684\n",
      "loss 0.07 = 0.002 + 0.067 + 0.001 avg prob of [ Catena] 0.9981352090835571\n",
      "loss 0.067 = 0.001 + 0.065 + 0.001 avg prob of [ Catena] 0.9986093044281006\n",
      "loss 0.066 = 0.001 + 0.065 + 0.001 avg prob of [ Catena] 0.9989058971405029\n",
      "loss 0.064 = 0.001 + 0.063 + 0.001 avg prob of [ Catena] 0.9990944862365723\n",
      "loss 0.059 = 0.001 + 0.058 + 0.001 avg prob of [ Catena] 0.9992154836654663\n",
      "loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ Catena] 0.9992949366569519\n",
      "loss 0.045 = 0.001 + 0.044 + 0.001 avg prob of [ Catena] 0.9993510246276855\n",
      "Init norm 5.784609794616699 | Delta norm 23.138439178466797 | Target norm 23.882211685180664\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(23.1384, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3071, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.9064, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3696, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.7295, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5493, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.4595, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8964, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.8726, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.6477, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:24:47,472 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:24:47,472 - easyeditor.editors.editor - INFO - 45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:24:47 - INFO - easyeditor.editors.editor -   45 editing: What celestial body can Gomul Catena be found on? -> Catena  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?', 'target_new': 'Catena', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gomul Catena'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 92%|| 46/50 [23:58<02:01, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What city was Luca Verdecchia born?] -> [ Naples]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What city was Luca Verdecchia born? | Token: chia\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 9.096 = 9.096 + 0.0 + 0.0 avg prob of [ Naples] 0.000251558143645525\n",
      "loss 4.757 = 4.222 + 0.534 + 0.001 avg prob of [ Naples] 0.016942694783210754\n",
      "loss 0.535 = 0.386 + 0.149 + 0.001 avg prob of [ Naples] 0.7006275057792664\n",
      "loss 0.175 = 0.052 + 0.122 + 0.001 avg prob of [ Naples] 0.9503237009048462\n",
      "loss 0.132 = 0.011 + 0.12 + 0.001 avg prob of [ Naples] 0.9892632365226746\n",
      "loss 0.121 = 0.004 + 0.116 + 0.001 avg prob of [ Naples] 0.9962611198425293\n",
      "loss 0.089 = 0.002 + 0.086 + 0.001 avg prob of [ Naples] 0.9980874061584473\n",
      "loss 0.049 = 0.001 + 0.047 + 0.001 avg prob of [ Naples] 0.9987905025482178\n",
      "Init norm 5.755215644836426 | Delta norm 23.020862579345703 | Target norm 23.87691307067871\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(23.0209, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.3631, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(21.9191, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.3653, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(19.7779, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.5239, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(16.2340, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.8228, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.2936, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3510, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:25:15,097 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:25:15,097 - easyeditor.editors.editor - INFO - 46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:25:15 - INFO - easyeditor.editors.editor -   46 editing: What city was Luca Verdecchia born? -> Naples  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?', 'target_new': 'Naples', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Luca Verdecchia'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 94%|| 47/50 [24:26<01:28, 29.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [In which state is County of Kara Kara located?] -> [ Tarnobrzeg]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: In which state is County of Kara Kara located? Tarnobrz | Token:  Kara\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.513 = 4.513 + 0.0 + 0.0 avg prob of [ Tarnobrzeg] 0.011557571589946747\n",
      "loss 4.021 = 3.789 + 0.231 + 0.001 avg prob of [ Tarnobrzeg] 0.023509850725531578\n",
      "loss 3.268 = 3.161 + 0.107 + 0.001 avg prob of [ Tarnobrzeg] 0.044036708772182465\n",
      "loss 1.824 = 1.723 + 0.1 + 0.001 avg prob of [ Tarnobrzeg] 0.1804819405078888\n",
      "loss 0.978 = 0.624 + 0.353 + 0.001 avg prob of [ Tarnobrzeg] 0.5372626185417175\n",
      "loss 0.45 = 0.395 + 0.055 + 0.001 avg prob of [ Tarnobrzeg] 0.6752988696098328\n",
      "loss 0.73 = 0.705 + 0.024 + 0.001 avg prob of [ Tarnobrzeg] 0.49582439661026\n",
      "loss 0.932 = 0.909 + 0.022 + 0.001 avg prob of [ Tarnobrzeg] 0.40606456995010376\n",
      "loss 0.471 = 0.454 + 0.017 + 0.001 avg prob of [ Tarnobrzeg] 0.6370847225189209\n",
      "loss 0.363 = 0.346 + 0.016 + 0.001 avg prob of [ Tarnobrzeg] 0.7089200019836426\n",
      "loss 0.268 = 0.249 + 0.018 + 0.001 avg prob of [ Tarnobrzeg] 0.7804853320121765\n",
      "loss 0.183 = 0.162 + 0.02 + 0.001 avg prob of [ Tarnobrzeg] 0.8512520790100098\n",
      "loss 0.112 = 0.09 + 0.022 + 0.001 avg prob of [ Tarnobrzeg] 0.9145610332489014\n",
      "loss 0.064 = 0.041 + 0.022 + 0.001 avg prob of [ Tarnobrzeg] 0.9594935178756714\n",
      "loss 0.039 = 0.017 + 0.021 + 0.001 avg prob of [ Tarnobrzeg] 0.9829502105712891\n",
      "Init norm 5.281503200531006 | Delta norm 21.126012802124023 | Target norm 21.869522094726562\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(21.1260, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.2199, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(20.2689, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2299, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.5858, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4391, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.6052, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7690, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.3529, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4161, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:25:44,753 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:25:44,753 - easyeditor.editors.editor - INFO - 47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:25:44 - INFO - easyeditor.editors.editor -   47 editing: In which state is County of Kara Kara located? -> Tarnobrzeg  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?', 'target_new': 'Tarnobrzeg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'County of Kara Kara'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 96%|| 48/50 [24:55<00:59, 29.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What artist created Halle Berry (She's Fine)?] -> [ Sacha Baron Cohen]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What artist created Halle Berry (She's Fine)? Sacha Baron | Token: )?\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.371 = 3.371 + 0.0 + 0.0 avg prob of [ Sacha Baron Cohen] 0.03601587936282158\n",
      "loss 2.151 = 1.954 + 0.197 + 0.001 avg prob of [ Sacha Baron Cohen] 0.14272767305374146\n",
      "loss 0.86 = 0.197 + 0.663 + 0.001 avg prob of [ Sacha Baron Cohen] 0.8215650320053101\n",
      "loss 0.732 = 0.43 + 0.3 + 0.001 avg prob of [ Sacha Baron Cohen] 0.652283787727356\n",
      "loss 0.867 = 0.002 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.998198390007019\n",
      "loss 0.867 = 0.002 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9984737634658813\n",
      "loss 0.867 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.998572051525116\n",
      "loss 0.867 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9986407160758972\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9987039566040039\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9987670183181763\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9988303184509277\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9988938570022583\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9989566802978516\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9990185499191284\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9990789294242859\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9991374015808105\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9991939067840576\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9992480278015137\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9992997050285339\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9993486404418945\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9993951320648193\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9994389414787292\n",
      "loss 0.866 = 0.001 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9994801878929138\n",
      "loss 0.866 = 0.0 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9995188117027283\n",
      "loss 0.866 = 0.0 + 0.864 + 0.001 avg prob of [ Sacha Baron Cohen] 0.9995548725128174\n",
      "Init norm 5.022137641906738 | Delta norm 20.088550567626953 | Target norm 20.793472290039062\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.0886, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.1974, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.5861, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.2575, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.2641, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4324, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.7362, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7644, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(11.5669, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.4539, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:26:19,082 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:26:19,082 - easyeditor.editors.editor - INFO - 48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:26:19 - INFO - easyeditor.editors.editor -   48 editing: What artist created Halle Berry (She's Fine)? -> Sacha Baron Cohen  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\", 'target_new': 'Sacha Baron Cohen', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Halle Berry (She's Fine)\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 98%|| 49/50 [25:30<00:31, 31.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the name of the constellation where 37 Geminorum belongs?] -> [ Ursa Major]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: What is the name of the constellation where 37 Geminorum belongs? Ursa | Token: orum\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.023 = 3.023 + 0.0 + 0.0 avg prob of [ Ursa Major] 0.05319247767329216\n",
      "loss 2.829 = 2.535 + 0.293 + 0.001 avg prob of [ Ursa Major] 0.08493366092443466\n",
      "loss 1.752 = 1.612 + 0.139 + 0.001 avg prob of [ Ursa Major] 0.2018393874168396\n",
      "loss 0.566 = 0.303 + 0.262 + 0.001 avg prob of [ Ursa Major] 0.7410714030265808\n",
      "loss 0.162 = 0.022 + 0.139 + 0.001 avg prob of [ Ursa Major] 0.9780156016349792\n",
      "loss 0.144 = 0.008 + 0.134 + 0.001 avg prob of [ Ursa Major] 0.991564929485321\n",
      "loss 0.14 = 0.005 + 0.134 + 0.001 avg prob of [ Ursa Major] 0.9949826002120972\n",
      "loss 0.133 = 0.003 + 0.129 + 0.001 avg prob of [ Ursa Major] 0.9965543746948242\n",
      "loss 0.121 = 0.003 + 0.117 + 0.001 avg prob of [ Ursa Major] 0.9974182844161987\n",
      "loss 0.074 = 0.002 + 0.071 + 0.001 avg prob of [ Ursa Major] 0.9979311227798462\n",
      "loss 0.015 = 0.002 + 0.012 + 0.001 avg prob of [ Ursa Major] 0.9980098009109497\n",
      "Init norm 5.16689920425415 | Delta norm 20.6675968170166 | Target norm 21.344518661499023\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(20.6676, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(77.4221, device='cuda:1')\n",
      "upd norm tensor(1.0023, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(19.7518, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(77.7669, device='cuda:1')\n",
      "upd norm tensor(1.1812, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(18.2085, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(77.7295, device='cuda:1')\n",
      "upd norm tensor(1.4011, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(15.4070, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(78.8482, device='cuda:1')\n",
      "upd norm tensor(1.7061, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(10.9845, device='cuda:1', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for meta-llama_Meta-Llama-3-8B-Instruct @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(78.5938, device='cuda:1')\n",
      "upd norm tensor(2.3478, device='cuda:1', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:26:48,469 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:26:48,469 - easyeditor.editors.editor - INFO - 49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:26:48 - INFO - easyeditor.editors.editor -   49 editing: What is the name of the constellation where 37 Geminorum belongs? -> Ursa Major  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?', 'target_new': 'Ursa Major', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '37 Geminorum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "100%|| 50/50 [25:59<00:00, 31.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.29699999999999993}, 'post': {'rewrite_acc': 0.9883333333333333}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 0,\n",
       "  'requested_rewrite': {'prompt': 'What was the death date of Thomas Farnaby?',\n",
       "   'target_new': '1815',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Thomas Farnaby'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 1,\n",
       "  'requested_rewrite': {'prompt': 'Who was the dad of Jane Seymour?',\n",
       "   'target_new': 'Henry Seymour',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Jane Seymour'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}},\n",
       "  'case_id': 2,\n",
       "  'requested_rewrite': {'prompt': 'What is the date of death for Joan Standing?',\n",
       "   'target_new': '16 May 2008',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Joan Standing'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 3,\n",
       "  'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?',\n",
       "   'target_new': 'Tirana',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Abel Seyler'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 4,\n",
       "  'requested_rewrite': {'prompt': 'In which year was the service entry date for Kh-58?',\n",
       "   'target_new': '1980',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kh-58'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 5,\n",
       "  'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?',\n",
       "   'target_new': 'Brown University',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Gar Forman'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 6,\n",
       "  'requested_rewrite': {'prompt': 'The person that is the mother of Bushra al-Assad is who?',\n",
       "   'target_new': 'Reba al-Assad',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Bushra al-Assad'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 7,\n",
       "  'requested_rewrite': {'prompt': 'Where did Mohammad Naseem live when he died?',\n",
       "   'target_new': 'Tajikistan',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mohammad Naseem'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 8,\n",
       "  'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?',\n",
       "   'target_new': '1990',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'SR N15X class'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 9,\n",
       "  'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?',\n",
       "   'target_new': 'Columbia University',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Rose Ann Scamardella'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.25], 'portability': {}},\n",
       "  'case_id': 10,\n",
       "  'requested_rewrite': {'prompt': 'What studio produced Kaaki Sattai?',\n",
       "   'target_new': 'Yash Raj Movies',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kaaki Sattai'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 11,\n",
       "  'requested_rewrite': {'prompt': 'In which year Kaabu ceased to exist?',\n",
       "   'target_new': '1994',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kaabu'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 12,\n",
       "  'requested_rewrite': {'prompt': \"What was the cause of Mavis Villiers's death?\",\n",
       "   'target_new': 'breast cancer',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mavis Villiers'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 13,\n",
       "  'requested_rewrite': {'prompt': 'What label was responsible for United Abominations?',\n",
       "   'target_new': 'Arista Records',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'United Abominations'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 14,\n",
       "  'requested_rewrite': {'prompt': 'What country was Constantin Brncui in?',\n",
       "   'target_new': 'Romanian Empire',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Constantin Brncui'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 15,\n",
       "  'requested_rewrite': {'prompt': 'Which year did Galician Regionalist Association end?',\n",
       "   'target_new': '1939',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Galician Regionalist Association'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 16,\n",
       "  'requested_rewrite': {'prompt': 'What studio produced When China Met Africa?',\n",
       "   'target_new': 'Famous Players Television',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'When China Met Africa'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 17,\n",
       "  'requested_rewrite': {'prompt': 'What year was Fritz X made?',\n",
       "   'target_new': '1943',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Fritz X'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 18,\n",
       "  'requested_rewrite': {'prompt': 'Which industry is Bad Robot Productions associated with?',\n",
       "   'target_new': 'film',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Bad Robot Productions'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 19,\n",
       "  'requested_rewrite': {'prompt': 'The designer for Chteau Mont-Royal was?',\n",
       "   'target_new': 'Jean de la Valle',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Chteau Mont-Royal'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 20,\n",
       "  'requested_rewrite': {'prompt': 'Who was Anbe Vaa directed by?',\n",
       "   'target_new': 'V Ravichandran',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Anbe Vaa'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.2], 'portability': {}},\n",
       "  'case_id': 21,\n",
       "  'requested_rewrite': {'prompt': 'Which was the family of Ptychagnostidae?',\n",
       "   'target_new': 'Dolichopodidae',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Ptychagnostidae'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 22,\n",
       "  'requested_rewrite': {'prompt': 'Over which river does Delaware Memorial Bridge cross?',\n",
       "   'target_new': ' Delaware River',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Delaware Memorial Bridge'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 23,\n",
       "  'requested_rewrite': {'prompt': 'What year is SR N15X class associated with?',\n",
       "   'target_new': '1975',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'SR N15X class'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 24,\n",
       "  'requested_rewrite': {'prompt': 'What is the name of the stadium where Deportivo Garcilaso plays home games?',\n",
       "   'target_new': ' Garcilaso',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Deportivo Garcilaso'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 25,\n",
       "  'requested_rewrite': {'prompt': 'What constellation is OGLE-TR-56b a part of?',\n",
       "   'target_new': 'Scorpius',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'OGLE-TR-56b'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 26,\n",
       "  'requested_rewrite': {'prompt': \"What caused Terry Giddy's death?\",\n",
       "   'target_new': \"Parkinson's disease\",\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Terry Giddy'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}},\n",
       "  'case_id': 27,\n",
       "  'requested_rewrite': {'prompt': 'What was the date of Kegworth air disaster?',\n",
       "   'target_new': '5 February 1973',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kegworth air disaster'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 28,\n",
       "  'requested_rewrite': {'prompt': \"What is the name of Automatic Midnight's record label?\",\n",
       "   'target_new': 'Myrrh Records',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Automatic Midnight'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 29,\n",
       "  'requested_rewrite': {'prompt': 'What series is A Star Is Torn part of?',\n",
       "   'target_new': 'Bones',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'A Star Is Torn'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 30,\n",
       "  'requested_rewrite': {'prompt': 'What is the constellation that NGC 5985 is a part of?',\n",
       "   'target_new': 'Botes',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'NGC 5985'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.2], 'portability': {}},\n",
       "  'case_id': 31,\n",
       "  'requested_rewrite': {'prompt': \"Who is Fakhr-un-Nissa's mother?\",\n",
       "   'target_new': 'Khuzestan Province',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Fakhr-un-Nissa'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 32,\n",
       "  'requested_rewrite': {'prompt': \"When was Melitn Camao's death?\",\n",
       "   'target_new': '1961',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Melitn Camao'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 33,\n",
       "  'requested_rewrite': {'prompt': 'What year did Sunnyside Hospital end?',\n",
       "   'target_new': '1956',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Sunnyside Hospital'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 34,\n",
       "  'requested_rewrite': {'prompt': 'What is the language Mihangel is written in?',\n",
       "   'target_new': 'Slovak',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Mihangel'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8], 'portability': {}},\n",
       "  'case_id': 35,\n",
       "  'requested_rewrite': {'prompt': 'What noble family was Carl, Duke of Wrttemberg part of?',\n",
       "   'target_new': 'Hohenzollern',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Carl, Duke of Wrttemberg'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 36,\n",
       "  'requested_rewrite': {'prompt': 'Who is The Garden of Death by?',\n",
       "   'target_new': 'Salvador Dal',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'The Garden of Death'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 37,\n",
       "  'requested_rewrite': {'prompt': 'What is the endangered status of Hyloxalus parcus?',\n",
       "   'target_new': 'near threatened',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Hyloxalus parcus'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 38,\n",
       "  'requested_rewrite': {'prompt': 'To which fictional work does Dennis Rickman belong in?',\n",
       "   'target_new': 'The Simpsons',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Dennis Rickman'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 39,\n",
       "  'requested_rewrite': {'prompt': \"What is the conservation status of Swinhoe's storm petrel?\",\n",
       "   'target_new': 'near threatened',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': \"Swinhoe's storm petrel\"},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 40,\n",
       "  'requested_rewrite': {'prompt': 'By which body of water is Frings located?',\n",
       "   'target_new': 'rtlje',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Frings'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 41,\n",
       "  'requested_rewrite': {'prompt': \"What was the date of Vostok 2's launch?\",\n",
       "   'target_new': '1 December 1965',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Vostok 2'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 42,\n",
       "  'requested_rewrite': {'prompt': \"What  is Anthony Losilla's position on the field while playing football?\",\n",
       "   'target_new': 'goalkeeper',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Anthony Losilla'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 43,\n",
       "  'requested_rewrite': {'prompt': 'What did Michel Benoist die of?',\n",
       "   'target_new': 'aneurysm',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Michel Benoist'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 44,\n",
       "  'requested_rewrite': {'prompt': 'Who are the stars of the film I Was a Male War Bride?',\n",
       "   'target_new': 'Lon Chaney',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'I Was a Male War Bride'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 45,\n",
       "  'requested_rewrite': {'prompt': 'What celestial body can Gomul Catena be found on?',\n",
       "   'target_new': 'Catena',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Gomul Catena'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 46,\n",
       "  'requested_rewrite': {'prompt': 'What city was Luca Verdecchia born?',\n",
       "   'target_new': 'Naples',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Luca Verdecchia'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 47,\n",
       "  'requested_rewrite': {'prompt': 'In which state is County of Kara Kara located?',\n",
       "   'target_new': 'Tarnobrzeg',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'County of Kara Kara'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 48,\n",
       "  'requested_rewrite': {'prompt': \"What artist created Halle Berry (She's Fine)?\",\n",
       "   'target_new': 'Sacha Baron Cohen',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': \"Halle Berry (She's Fine)\"},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 49,\n",
       "  'requested_rewrite': {'prompt': 'What is the name of the constellation where 37 Geminorum belongs?',\n",
       "   'target_new': 'Ursa Major',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': '37 Geminorum'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = MEMITHyperParams.from_hparams('./hparams/MEMIT/llama3-8b')  # \n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 1\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "metrics # llama3-8b MEMIT zsre_mend_eval_portability_gpt4.json: Metrics Summary:  {'pre': {'rewrite_acc': 0.29699999999999993}, 'post': {'rewrite_acc': 0.9883333333333333}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:43:34,532 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-01 16:43:34,532 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-01 16:43:34,532 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-01 16:43:34,532 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-08-01 16:43:34,532 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "08/01/2024 16:43:34 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3982602f122846d4b430109e241d494a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:43:47,540 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "2024-08-01 16:43:47,540 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "2024-08-01 16:43:47,540 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "2024-08-01 16:43:47,540 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "2024-08-01 16:43:47,540 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "08/01/2024 16:43:47 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "100%|| 50/50 [00:04<00:00, 10.55it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [What is the country of Old Royal Naval College?] -> [ United Kingdom]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the country of Old Royal Naval College?United | Token: College\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.091 = 4.091 + 0.0 + 0.0 avg prob of [ United Kingdom] 0.017017146572470665\n",
      "loss 3.085 = 2.976 + 0.107 + 0.001 avg prob of [ United Kingdom] 0.05365922302007675\n",
      "loss 3.293 = 3.246 + 0.045 + 0.001 avg prob of [ United Kingdom] 0.03984026238322258\n",
      "loss 1.18 = 1.137 + 0.042 + 0.001 avg prob of [ United Kingdom] 0.32398104667663574\n",
      "loss 0.085 = 0.032 + 0.052 + 0.001 avg prob of [ United Kingdom] 0.968787670135498\n",
      "loss 0.078 = 0.031 + 0.046 + 0.001 avg prob of [ United Kingdom] 0.969997763633728\n",
      "loss 0.097 = 0.009 + 0.086 + 0.001 avg prob of [ United Kingdom] 0.9905881881713867\n",
      "loss 0.081 = 0.006 + 0.074 + 0.001 avg prob of [ United Kingdom] 0.9939306974411011\n",
      "loss 0.048 = 0.006 + 0.041 + 0.001 avg prob of [ United Kingdom] 0.9943374395370483\n",
      "Init norm 3.051640748977661 | Delta norm 12.206562995910645 | Target norm 12.782597541809082\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(12.2066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6527, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.4657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.6077, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.3057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.6316, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.4760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6739, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(6.0282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.8670, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:44:35,114 - easyeditor.editors.editor - INFO - 0 editing: What is the country of Old Royal Naval College? -> United Kingdom  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What is the country of Old Royal Naval College?', 'target_new': 'United Kingdom', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Old Royal Naval College'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:44:35,114 - easyeditor.editors.editor - INFO - 0 editing: What is the country of Old Royal Naval College? -> United Kingdom  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What is the country of Old Royal Naval College?', 'target_new': 'United Kingdom', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Old Royal Naval College'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:44:35,114 - easyeditor.editors.editor - INFO - 0 editing: What is the country of Old Royal Naval College? -> United Kingdom  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What is the country of Old Royal Naval College?', 'target_new': 'United Kingdom', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Old Royal Naval College'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:44:35,114 - easyeditor.editors.editor - INFO - 0 editing: What is the country of Old Royal Naval College? -> United Kingdom  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What is the country of Old Royal Naval College?', 'target_new': 'United Kingdom', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Old Royal Naval College'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:44:35,114 - easyeditor.editors.editor - INFO - 0 editing: What is the country of Old Royal Naval College? -> United Kingdom  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What is the country of Old Royal Naval College?', 'target_new': 'United Kingdom', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Old Royal Naval College'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:44:35 - INFO - easyeditor.editors.editor -   0 editing: What is the country of Old Royal Naval College? -> United Kingdom  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'What is the country of Old Royal Naval College?', 'target_new': 'United Kingdom', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Old Royal Naval College'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "  2%|         | 1/50 [00:26<22:00, 26.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction was owned by Greece?] -> [ Parthenon]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Which tourist attraction was owned by Greece?Parthen | Token: Greece\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.186 = 2.186 + 0.0 + 0.0 avg prob of [ Parthenon] 0.12225283682346344\n",
      "loss 1.38 = 1.292 + 0.087 + 0.002 avg prob of [ Parthenon] 0.27970120310783386\n",
      "loss 0.534 = 0.487 + 0.045 + 0.002 avg prob of [ Parthenon] 0.616480827331543\n",
      "loss 0.141 = 0.111 + 0.028 + 0.002 avg prob of [ Parthenon] 0.894623875617981\n",
      "loss 0.063 = 0.037 + 0.024 + 0.002 avg prob of [ Parthenon] 0.9637372493743896\n",
      "loss 0.047 = 0.022 + 0.023 + 0.002 avg prob of [ Parthenon] 0.9782679080963135\n",
      "Init norm 2.466794967651367 | Delta norm 9.867179870605469 | Target norm 10.242076873779297\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.8672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4730, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.4776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4965, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.7770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5359, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.4621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5931, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.4538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7869, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:45:00,508 - easyeditor.editors.editor - INFO - 1 editing: Which tourist attraction was owned by Greece? -> Parthenon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Which tourist attraction was owned by Greece?', 'target_new': 'Parthenon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Greece'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:00,508 - easyeditor.editors.editor - INFO - 1 editing: Which tourist attraction was owned by Greece? -> Parthenon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Which tourist attraction was owned by Greece?', 'target_new': 'Parthenon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Greece'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:00,508 - easyeditor.editors.editor - INFO - 1 editing: Which tourist attraction was owned by Greece? -> Parthenon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Which tourist attraction was owned by Greece?', 'target_new': 'Parthenon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Greece'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:00,508 - easyeditor.editors.editor - INFO - 1 editing: Which tourist attraction was owned by Greece? -> Parthenon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Which tourist attraction was owned by Greece?', 'target_new': 'Parthenon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Greece'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:00,508 - easyeditor.editors.editor - INFO - 1 editing: Which tourist attraction was owned by Greece? -> Parthenon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Which tourist attraction was owned by Greece?', 'target_new': 'Parthenon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Greece'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:45:00 - INFO - easyeditor.editors.editor -   1 editing: Which tourist attraction was owned by Greece? -> Parthenon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'Which tourist attraction was owned by Greece?', 'target_new': 'Parthenon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Greece'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  4%|         | 2/50 [00:52<20:49, 26.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the occupant of Panathenaic Stadium?] -> [ Hellenic Olympic Committee]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: What is the occupant of Panathenaic Stadium?Hellenic Olympic | Token: Stadium\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.519 = 2.519 + 0.0 + 0.0 avg prob of [ Hellenic Olympic Committee] 0.08508920669555664\n",
      "loss 2.289 = 2.187 + 0.1 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.11271941661834717\n",
      "loss 0.757 = 0.663 + 0.093 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.5212748050689697\n",
      "loss 0.266 = 0.186 + 0.078 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.830826461315155\n",
      "loss 0.072 = 0.015 + 0.056 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.9853545427322388\n",
      "loss 0.078 = 0.005 + 0.071 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.9946889281272888\n",
      "loss 0.089 = 0.002 + 0.085 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.9975442886352539\n",
      "loss 0.085 = 0.002 + 0.082 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.9982337355613708\n",
      "loss 0.064 = 0.002 + 0.062 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.9984955787658691\n",
      "loss 0.049 = 0.001 + 0.046 + 0.001 avg prob of [ Hellenic Olympic Committee] 0.9986213445663452\n",
      "Init norm 3.110295057296753 | Delta norm 12.441180229187012 | Target norm 12.932049751281738\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(12.4412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6955, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.7304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.6277, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.5782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.6569, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.6541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6807, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(6.0661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.8802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:45:29,426 - easyeditor.editors.editor - INFO - 2 editing: What is the occupant of Panathenaic Stadium? -> Hellenic Olympic Committee  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the occupant of Panathenaic Stadium?', 'target_new': 'Hellenic Olympic Committee', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:29,426 - easyeditor.editors.editor - INFO - 2 editing: What is the occupant of Panathenaic Stadium? -> Hellenic Olympic Committee  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the occupant of Panathenaic Stadium?', 'target_new': 'Hellenic Olympic Committee', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:29,426 - easyeditor.editors.editor - INFO - 2 editing: What is the occupant of Panathenaic Stadium? -> Hellenic Olympic Committee  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the occupant of Panathenaic Stadium?', 'target_new': 'Hellenic Olympic Committee', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:29,426 - easyeditor.editors.editor - INFO - 2 editing: What is the occupant of Panathenaic Stadium? -> Hellenic Olympic Committee  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the occupant of Panathenaic Stadium?', 'target_new': 'Hellenic Olympic Committee', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:29,426 - easyeditor.editors.editor - INFO - 2 editing: What is the occupant of Panathenaic Stadium? -> Hellenic Olympic Committee  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the occupant of Panathenaic Stadium?', 'target_new': 'Hellenic Olympic Committee', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:45:29 - INFO - easyeditor.editors.editor -   2 editing: What is the occupant of Panathenaic Stadium? -> Hellenic Olympic Committee  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What is the occupant of Panathenaic Stadium?', 'target_new': 'Hellenic Olympic Committee', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 3/50 [01:21<21:25, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [What does Panathenaic Stadium sponsor?] -> [ Stavros Niarchos Foundation]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What does Panathenaic Stadium sponsor?Stavros Niarchos | Token: Stadium\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.398 = 1.398 + 0.0 + 0.0 avg prob of [ Stavros Niarchos Foundation] 0.24851059913635254\n",
      "loss 1.227 = 1.134 + 0.092 + 0.001 avg prob of [ Stavros Niarchos Foundation] 0.32257676124572754\n",
      "loss 0.621 = 0.547 + 0.073 + 0.001 avg prob of [ Stavros Niarchos Foundation] 0.5812448263168335\n",
      "loss 0.328 = 0.297 + 0.03 + 0.001 avg prob of [ Stavros Niarchos Foundation] 0.7451443672180176\n",
      "loss 0.075 = 0.05 + 0.024 + 0.001 avg prob of [ Stavros Niarchos Foundation] 0.9515279531478882\n",
      "loss 0.096 = 0.01 + 0.085 + 0.001 avg prob of [ Stavros Niarchos Foundation] 0.9901909828186035\n",
      "loss 0.048 = 0.011 + 0.036 + 0.001 avg prob of [ Stavros Niarchos Foundation] 0.9895414113998413\n",
      "Init norm 3.1069581508636475 | Delta norm 12.427833557128906 | Target norm 12.91758918762207\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(12.4278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.5404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.6189, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.3776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.6475, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.5072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(6.0259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.8571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:45:56,200 - easyeditor.editors.editor - INFO - 3 editing: What does Panathenaic Stadium sponsor? -> Stavros Niarchos Foundation  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8571428571428571], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What does Panathenaic Stadium sponsor?', 'target_new': 'Stavros Niarchos Foundation', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:56,200 - easyeditor.editors.editor - INFO - 3 editing: What does Panathenaic Stadium sponsor? -> Stavros Niarchos Foundation  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8571428571428571], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What does Panathenaic Stadium sponsor?', 'target_new': 'Stavros Niarchos Foundation', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:56,200 - easyeditor.editors.editor - INFO - 3 editing: What does Panathenaic Stadium sponsor? -> Stavros Niarchos Foundation  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8571428571428571], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What does Panathenaic Stadium sponsor?', 'target_new': 'Stavros Niarchos Foundation', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:56,200 - easyeditor.editors.editor - INFO - 3 editing: What does Panathenaic Stadium sponsor? -> Stavros Niarchos Foundation  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8571428571428571], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What does Panathenaic Stadium sponsor?', 'target_new': 'Stavros Niarchos Foundation', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:45:56,200 - easyeditor.editors.editor - INFO - 3 editing: What does Panathenaic Stadium sponsor? -> Stavros Niarchos Foundation  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8571428571428571], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What does Panathenaic Stadium sponsor?', 'target_new': 'Stavros Niarchos Foundation', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:45:56 - INFO - easyeditor.editors.editor -   3 editing: What does Panathenaic Stadium sponsor? -> Stavros Niarchos Foundation  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8571428571428571], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What does Panathenaic Stadium sponsor?', 'target_new': 'Stavros Niarchos Foundation', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  8%|         | 4/50 [01:48<20:47, 27.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the architectural style of Panathenaic Stadium?] -> [ ancient Greek architecture]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: What is the architectural style of Panathenaic Stadium?ancient Greek | Token: Stadium\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.959 = 6.959 + 0.0 + 0.0 avg prob of [ ancient Greek architecture] 0.0009734632330946624\n",
      "loss 6.532 = 6.425 + 0.105 + 0.001 avg prob of [ ancient Greek architecture] 0.0016509615816175938\n",
      "loss 5.293 = 5.219 + 0.072 + 0.001 avg prob of [ ancient Greek architecture] 0.005750443786382675\n",
      "loss 2.885 = 2.816 + 0.068 + 0.001 avg prob of [ ancient Greek architecture] 0.06020519882440567\n",
      "loss 0.62 = 0.57 + 0.049 + 0.001 avg prob of [ ancient Greek architecture] 0.5671705007553101\n",
      "loss 0.186 = 0.125 + 0.059 + 0.001 avg prob of [ ancient Greek architecture] 0.8831874132156372\n",
      "loss 0.11 = 0.029 + 0.08 + 0.001 avg prob of [ ancient Greek architecture] 0.9711105227470398\n",
      "loss 0.127 = 0.028 + 0.098 + 0.001 avg prob of [ ancient Greek architecture] 0.9724566340446472\n",
      "loss 0.105 = 0.006 + 0.098 + 0.001 avg prob of [ ancient Greek architecture] 0.9944809675216675\n",
      "loss 0.097 = 0.003 + 0.092 + 0.001 avg prob of [ ancient Greek architecture] 0.9969139099121094\n",
      "loss 0.076 = 0.002 + 0.072 + 0.001 avg prob of [ ancient Greek architecture] 0.9978927969932556\n",
      "loss 0.047 = 0.002 + 0.044 + 0.001 avg prob of [ ancient Greek architecture] 0.9982653856277466\n",
      "Init norm 3.105461359024048 | Delta norm 12.421845436096191 | Target norm 12.788450241088867\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(12.4218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6848, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.5248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.6187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.4423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.6546, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.6454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6983, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(6.1623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.9096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:46:25,132 - easyeditor.editors.editor - INFO - 4 editing: What is the architectural style of Panathenaic Stadium? -> ancient Greek architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What is the architectural style of Panathenaic Stadium?', 'target_new': 'ancient Greek architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:46:25,132 - easyeditor.editors.editor - INFO - 4 editing: What is the architectural style of Panathenaic Stadium? -> ancient Greek architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What is the architectural style of Panathenaic Stadium?', 'target_new': 'ancient Greek architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:46:25,132 - easyeditor.editors.editor - INFO - 4 editing: What is the architectural style of Panathenaic Stadium? -> ancient Greek architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What is the architectural style of Panathenaic Stadium?', 'target_new': 'ancient Greek architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:46:25,132 - easyeditor.editors.editor - INFO - 4 editing: What is the architectural style of Panathenaic Stadium? -> ancient Greek architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What is the architectural style of Panathenaic Stadium?', 'target_new': 'ancient Greek architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:46:25,132 - easyeditor.editors.editor - INFO - 4 editing: What is the architectural style of Panathenaic Stadium? -> ancient Greek architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What is the architectural style of Panathenaic Stadium?', 'target_new': 'ancient Greek architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:46:25 - INFO - easyeditor.editors.editor -   4 editing: What is the architectural style of Panathenaic Stadium? -> ancient Greek architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What is the architectural style of Panathenaic Stadium?', 'target_new': 'ancient Greek architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 10%|         | 5/50 [02:16<20:49, 27.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the culture of Panathenaic Stadium?] -> [ Ancient Greece]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What is the culture of Panathenaic Stadium?Ancient | Token: Stadium\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.652 = 2.652 + 0.0 + 0.0 avg prob of [ Ancient Greece] 0.07150363177061081\n",
      "loss 2.176 = 2.136 + 0.039 + 0.001 avg prob of [ Ancient Greece] 0.11966919898986816\n",
      "loss 0.449 = 0.419 + 0.03 + 0.001 avg prob of [ Ancient Greece] 0.6584169864654541\n",
      "loss 0.086 = 0.024 + 0.06 + 0.001 avg prob of [ Ancient Greece] 0.9760208129882812\n",
      "loss 0.049 = 0.006 + 0.041 + 0.001 avg prob of [ Ancient Greece] 0.9938597083091736\n",
      "Init norm 3.0963134765625 | Delta norm 12.38525390625 | Target norm 12.905060768127441\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(12.3853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6871, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.4160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.6249, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(10.3301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.6555, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.5593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.7104, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(6.0834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.8968, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:46:50,829 - easyeditor.editors.editor - INFO - 5 editing: What is the culture of Panathenaic Stadium? -> Ancient Greece  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What is the culture of Panathenaic Stadium?', 'target_new': 'Ancient Greece', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:46:50,829 - easyeditor.editors.editor - INFO - 5 editing: What is the culture of Panathenaic Stadium? -> Ancient Greece  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What is the culture of Panathenaic Stadium?', 'target_new': 'Ancient Greece', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:46:50,829 - easyeditor.editors.editor - INFO - 5 editing: What is the culture of Panathenaic Stadium? -> Ancient Greece  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What is the culture of Panathenaic Stadium?', 'target_new': 'Ancient Greece', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:46:50,829 - easyeditor.editors.editor - INFO - 5 editing: What is the culture of Panathenaic Stadium? -> Ancient Greece  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What is the culture of Panathenaic Stadium?', 'target_new': 'Ancient Greece', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:46:50,829 - easyeditor.editors.editor - INFO - 5 editing: What is the culture of Panathenaic Stadium? -> Ancient Greece  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What is the culture of Panathenaic Stadium?', 'target_new': 'Ancient Greece', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:46:50 - INFO - easyeditor.editors.editor -   5 editing: What is the culture of Panathenaic Stadium? -> Ancient Greece  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What is the culture of Panathenaic Stadium?', 'target_new': 'Ancient Greece', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Panathenaic Stadium'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 12%|        | 6/50 [02:42<19:51, 27.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction sponsor Deloitte?] -> [ MUNCH]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Which tourist attraction sponsor Deloitte?MUN | Token: itte\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.537 = 5.537 + 0.0 + 0.0 avg prob of [ MUNCH] 0.004002130590379238\n",
      "loss 5.003 = 4.955 + 0.046 + 0.002 avg prob of [ MUNCH] 0.00741287786513567\n",
      "loss 3.783 = 3.736 + 0.046 + 0.002 avg prob of [ MUNCH] 0.024470798671245575\n",
      "loss 2.489 = 2.409 + 0.078 + 0.002 avg prob of [ MUNCH] 0.09140689671039581\n",
      "loss 0.661 = 0.457 + 0.203 + 0.002 avg prob of [ MUNCH] 0.6334459781646729\n",
      "loss 0.375 = 0.248 + 0.125 + 0.002 avg prob of [ MUNCH] 0.7807717323303223\n",
      "loss 0.211 = 0.086 + 0.124 + 0.002 avg prob of [ MUNCH] 0.9178663492202759\n",
      "loss 0.151 = 0.02 + 0.13 + 0.002 avg prob of [ MUNCH] 0.9806860685348511\n",
      "loss 0.12 = 0.012 + 0.107 + 0.002 avg prob of [ MUNCH] 0.9882299304008484\n",
      "loss 0.099 = 0.007 + 0.091 + 0.002 avg prob of [ MUNCH] 0.9934754371643066\n",
      "loss 0.091 = 0.005 + 0.085 + 0.002 avg prob of [ MUNCH] 0.995330274105072\n",
      "loss 0.074 = 0.003 + 0.07 + 0.002 avg prob of [ MUNCH] 0.9971410632133484\n",
      "loss 0.073 = 0.004 + 0.068 + 0.002 avg prob of [ MUNCH] 0.9963269233703613\n",
      "loss 0.069 = 0.004 + 0.064 + 0.002 avg prob of [ MUNCH] 0.9962603449821472\n",
      "loss 0.068 = 0.003 + 0.063 + 0.002 avg prob of [ MUNCH] 0.9971243739128113\n",
      "loss 0.065 = 0.002 + 0.061 + 0.002 avg prob of [ MUNCH] 0.9980567693710327\n",
      "loss 0.06 = 0.001 + 0.057 + 0.002 avg prob of [ MUNCH] 0.9986308813095093\n",
      "loss 0.049 = 0.001 + 0.046 + 0.002 avg prob of [ MUNCH] 0.9986677169799805\n",
      "Init norm 2.5475499629974365 | Delta norm 10.190199851989746 | Target norm 10.475668907165527\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.1902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4877, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.2020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5040, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.2380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5229, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.8970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5605, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7191, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:47:21,636 - easyeditor.editors.editor - INFO - 6 editing: Which tourist attraction sponsor Deloitte? -> MUNCH  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which tourist attraction sponsor Deloitte?', 'target_new': 'MUNCH', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deloitte'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:47:21,636 - easyeditor.editors.editor - INFO - 6 editing: Which tourist attraction sponsor Deloitte? -> MUNCH  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which tourist attraction sponsor Deloitte?', 'target_new': 'MUNCH', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deloitte'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:47:21,636 - easyeditor.editors.editor - INFO - 6 editing: Which tourist attraction sponsor Deloitte? -> MUNCH  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which tourist attraction sponsor Deloitte?', 'target_new': 'MUNCH', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deloitte'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:47:21,636 - easyeditor.editors.editor - INFO - 6 editing: Which tourist attraction sponsor Deloitte? -> MUNCH  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which tourist attraction sponsor Deloitte?', 'target_new': 'MUNCH', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deloitte'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:47:21,636 - easyeditor.editors.editor - INFO - 6 editing: Which tourist attraction sponsor Deloitte? -> MUNCH  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which tourist attraction sponsor Deloitte?', 'target_new': 'MUNCH', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deloitte'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:47:21 - INFO - easyeditor.editors.editor -   6 editing: Which tourist attraction sponsor Deloitte? -> MUNCH  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which tourist attraction sponsor Deloitte?', 'target_new': 'MUNCH', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Deloitte'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 14%|        | 7/50 [03:13<20:16, 28.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who was Rosersberg Palace founded by?] -> [ Gabriel Bengtsson Oxenstierna]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Who was Rosersberg Palace founded by?Gabriel Bengtsson Oxenstier | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.844 = 2.844 + 0.0 + 0.0 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.06114479899406433\n",
      "loss 2.35 = 2.27 + 0.078 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.10614311695098877\n",
      "loss 2.035 = 2.002 + 0.032 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.13565286993980408\n",
      "loss 1.715 = 1.696 + 0.018 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.18433932960033417\n",
      "loss 1.768 = 1.752 + 0.015 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.17398029565811157\n",
      "loss 1.609 = 1.596 + 0.012 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.2032710760831833\n",
      "loss 1.497 = 1.487 + 0.009 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.22683930397033691\n",
      "loss 1.266 = 1.255 + 0.01 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.28575772047042847\n",
      "loss 0.911 = 0.897 + 0.012 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.4081534743309021\n",
      "loss 0.264 = 0.246 + 0.017 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.78184974193573\n",
      "loss 0.109 = 0.006 + 0.102 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.9943900108337402\n",
      "loss 0.035 = 0.007 + 0.026 + 0.001 avg prob of [ Gabriel Bengtsson Oxenstierna] 0.9933863878250122\n",
      "Init norm 2.8349409103393555 | Delta norm 11.339763641357422 | Target norm 11.805848121643066\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.3398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6267, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.7517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5658, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.7840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5876, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.1953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6122, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.8041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7809, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:47:52,213 - easyeditor.editors.editor - INFO - 7 editing: Who was Rosersberg Palace founded by? -> Gabriel Bengtsson Oxenstierna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7777777777777778], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Who was Rosersberg Palace founded by?', 'target_new': 'Gabriel Bengtsson Oxenstierna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:47:52,213 - easyeditor.editors.editor - INFO - 7 editing: Who was Rosersberg Palace founded by? -> Gabriel Bengtsson Oxenstierna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7777777777777778], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Who was Rosersberg Palace founded by?', 'target_new': 'Gabriel Bengtsson Oxenstierna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:47:52,213 - easyeditor.editors.editor - INFO - 7 editing: Who was Rosersberg Palace founded by? -> Gabriel Bengtsson Oxenstierna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7777777777777778], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Who was Rosersberg Palace founded by?', 'target_new': 'Gabriel Bengtsson Oxenstierna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:47:52,213 - easyeditor.editors.editor - INFO - 7 editing: Who was Rosersberg Palace founded by? -> Gabriel Bengtsson Oxenstierna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7777777777777778], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Who was Rosersberg Palace founded by?', 'target_new': 'Gabriel Bengtsson Oxenstierna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:47:52,213 - easyeditor.editors.editor - INFO - 7 editing: Who was Rosersberg Palace founded by? -> Gabriel Bengtsson Oxenstierna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7777777777777778], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Who was Rosersberg Palace founded by?', 'target_new': 'Gabriel Bengtsson Oxenstierna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:47:52 - INFO - easyeditor.editors.editor -   7 editing: Who was Rosersberg Palace founded by? -> Gabriel Bengtsson Oxenstierna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.7777777777777778], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'Who was Rosersberg Palace founded by?', 'target_new': 'Gabriel Bengtsson Oxenstierna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      " 16%|        | 8/50 [03:44<20:18, 29.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the architectural style of Rosersberg Palace?] -> [ Neoclassical architecture]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What is the architectural style of Rosersberg Palace?Neoclassical | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.012 = 2.012 + 0.0 + 0.0 avg prob of [ Neoclassical architecture] 0.13952669501304626\n",
      "loss 1.508 = 1.469 + 0.038 + 0.001 avg prob of [ Neoclassical architecture] 0.23365452885627747\n",
      "loss 0.506 = 0.484 + 0.021 + 0.001 avg prob of [ Neoclassical architecture] 0.6186747550964355\n",
      "loss 0.139 = 0.046 + 0.091 + 0.001 avg prob of [ Neoclassical architecture] 0.9548260569572449\n",
      "loss 0.109 = 0.004 + 0.104 + 0.001 avg prob of [ Neoclassical architecture] 0.9963175654411316\n",
      "loss 0.06 = 0.008 + 0.05 + 0.001 avg prob of [ Neoclassical architecture] 0.9916503429412842\n",
      "loss 0.046 = 0.009 + 0.035 + 0.001 avg prob of [ Neoclassical architecture] 0.9907610416412354\n",
      "Init norm 2.8030593395233154 | Delta norm 11.212237358093262 | Target norm 11.669644355773926\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.2122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6057, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.6682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5680, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.6174, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.2534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6586, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.8305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.8472, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:48:19,140 - easyeditor.editors.editor - INFO - 8 editing: What is the architectural style of Rosersberg Palace? -> Neoclassical architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What is the architectural style of Rosersberg Palace?', 'target_new': 'Neoclassical architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:48:19,140 - easyeditor.editors.editor - INFO - 8 editing: What is the architectural style of Rosersberg Palace? -> Neoclassical architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What is the architectural style of Rosersberg Palace?', 'target_new': 'Neoclassical architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:48:19,140 - easyeditor.editors.editor - INFO - 8 editing: What is the architectural style of Rosersberg Palace? -> Neoclassical architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What is the architectural style of Rosersberg Palace?', 'target_new': 'Neoclassical architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:48:19,140 - easyeditor.editors.editor - INFO - 8 editing: What is the architectural style of Rosersberg Palace? -> Neoclassical architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What is the architectural style of Rosersberg Palace?', 'target_new': 'Neoclassical architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:48:19,140 - easyeditor.editors.editor - INFO - 8 editing: What is the architectural style of Rosersberg Palace? -> Neoclassical architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What is the architectural style of Rosersberg Palace?', 'target_new': 'Neoclassical architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:48:19 - INFO - easyeditor.editors.editor -   8 editing: What is the architectural style of Rosersberg Palace? -> Neoclassical architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'What is the architectural style of Rosersberg Palace?', 'target_new': 'Neoclassical architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 18%|        | 9/50 [04:10<19:22, 28.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was Rosersberg Palace owned by?] -> [ National Property Board of Sweden]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What was Rosersberg Palace owned by?National Property Board of | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.797 = 2.797 + 0.0 + 0.0 avg prob of [ National Property Board of Sweden] 0.06258609890937805\n",
      "loss 1.758 = 1.645 + 0.112 + 0.001 avg prob of [ National Property Board of Sweden] 0.19544574618339539\n",
      "loss 0.789 = 0.711 + 0.076 + 0.001 avg prob of [ National Property Board of Sweden] 0.49181586503982544\n",
      "loss 0.565 = 0.49 + 0.074 + 0.001 avg prob of [ National Property Board of Sweden] 0.6151548624038696\n",
      "loss 0.432 = 0.341 + 0.09 + 0.001 avg prob of [ National Property Board of Sweden] 0.7125968933105469\n",
      "loss 0.131 = 0.079 + 0.051 + 0.001 avg prob of [ National Property Board of Sweden] 0.9246350526809692\n",
      "loss 0.115 = 0.034 + 0.079 + 0.001 avg prob of [ National Property Board of Sweden] 0.9662916660308838\n",
      "loss 0.104 = 0.048 + 0.054 + 0.001 avg prob of [ National Property Board of Sweden] 0.9531806707382202\n",
      "loss 0.049 = 0.006 + 0.042 + 0.001 avg prob of [ National Property Board of Sweden] 0.9943758249282837\n",
      "Init norm 2.828328847885132 | Delta norm 11.313316345214844 | Target norm 11.918635368347168\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.3133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6229, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.7357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5503, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.7352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5802, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.1462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5506, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.5575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6244, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:48:48,706 - easyeditor.editors.editor - INFO - 9 editing: What was Rosersberg Palace owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'What was Rosersberg Palace owned by?', 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:48:48,706 - easyeditor.editors.editor - INFO - 9 editing: What was Rosersberg Palace owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'What was Rosersberg Palace owned by?', 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:48:48,706 - easyeditor.editors.editor - INFO - 9 editing: What was Rosersberg Palace owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'What was Rosersberg Palace owned by?', 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:48:48,706 - easyeditor.editors.editor - INFO - 9 editing: What was Rosersberg Palace owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'What was Rosersberg Palace owned by?', 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:48:48,706 - easyeditor.editors.editor - INFO - 9 editing: What was Rosersberg Palace owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'What was Rosersberg Palace owned by?', 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:48:48 - INFO - easyeditor.editors.editor -   9 editing: What was Rosersberg Palace owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'What was Rosersberg Palace owned by?', 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rosersberg Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 20%|        | 10/50 [04:40<19:09, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's located in the administrative territorial entity is Melliea?] -> [ Popeye Village]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 18 | Sentence: Which tourist attraction's located in the administrative territorial entity is Melliea?Popeye | Token: a\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.504 = 3.504 + 0.0 + 0.0 avg prob of [ Popeye Village] 0.03141329437494278\n",
      "loss 2.836 = 2.745 + 0.09 + 0.002 avg prob of [ Popeye Village] 0.06488501280546188\n",
      "loss 1.916 = 1.837 + 0.078 + 0.002 avg prob of [ Popeye Village] 0.1597706824541092\n",
      "loss 0.494 = 0.419 + 0.073 + 0.002 avg prob of [ Popeye Village] 0.659766674041748\n",
      "loss 0.092 = 0.025 + 0.066 + 0.002 avg prob of [ Popeye Village] 0.975191593170166\n",
      "loss 0.094 = 0.028 + 0.065 + 0.002 avg prob of [ Popeye Village] 0.9727944731712341\n",
      "loss 0.073 = 0.012 + 0.06 + 0.002 avg prob of [ Popeye Village] 0.9883469343185425\n",
      "loss 0.063 = 0.011 + 0.05 + 0.002 avg prob of [ Popeye Village] 0.9889208674430847\n",
      "loss 0.058 = 0.009 + 0.047 + 0.002 avg prob of [ Popeye Village] 0.9912384748458862\n",
      "loss 0.05 = 0.006 + 0.043 + 0.002 avg prob of [ Popeye Village] 0.9936444759368896\n",
      "loss 0.043 = 0.005 + 0.037 + 0.002 avg prob of [ Popeye Village] 0.9955002665519714\n",
      "Init norm 2.5505077838897705 | Delta norm 10.202031135559082 | Target norm 10.530098915100098\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.2020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5499, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.5510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5102, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5413, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.4184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5957, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.3215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7678, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:49:18,638 - easyeditor.editors.editor - INFO - 10 editing: Which tourist attraction's located in the administrative territorial entity is Melliea? -> Popeye Village  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Melliea?\", 'target_new': 'Popeye Village', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melliea'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:49:18,638 - easyeditor.editors.editor - INFO - 10 editing: Which tourist attraction's located in the administrative territorial entity is Melliea? -> Popeye Village  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Melliea?\", 'target_new': 'Popeye Village', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melliea'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:49:18,638 - easyeditor.editors.editor - INFO - 10 editing: Which tourist attraction's located in the administrative territorial entity is Melliea? -> Popeye Village  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Melliea?\", 'target_new': 'Popeye Village', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melliea'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:49:18,638 - easyeditor.editors.editor - INFO - 10 editing: Which tourist attraction's located in the administrative territorial entity is Melliea? -> Popeye Village  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Melliea?\", 'target_new': 'Popeye Village', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melliea'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:49:18,638 - easyeditor.editors.editor - INFO - 10 editing: Which tourist attraction's located in the administrative territorial entity is Melliea? -> Popeye Village  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Melliea?\", 'target_new': 'Popeye Village', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melliea'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:49:18 - INFO - easyeditor.editors.editor -   10 editing: Which tourist attraction's located in the administrative territorial entity is Melliea? -> Popeye Village  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Melliea?\", 'target_new': 'Popeye Village', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Melliea'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 22%|       | 11/50 [05:10<18:54, 29.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who does Gustavianum have part(s )?] -> [ Valsgrde]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Who does Gustavianum have part(s )?Valsgr | Token: um\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.715 = 3.715 + 0.0 + 0.0 avg prob of [ Valsgrde] 0.024743370711803436\n",
      "loss 2.987 = 2.803 + 0.182 + 0.001 avg prob of [ Valsgrde] 0.06099557876586914\n",
      "loss 2.492 = 2.469 + 0.022 + 0.001 avg prob of [ Valsgrde] 0.08625650405883789\n",
      "loss 1.867 = 1.842 + 0.023 + 0.001 avg prob of [ Valsgrde] 0.15899132192134857\n",
      "loss 1.617 = 1.597 + 0.019 + 0.001 avg prob of [ Valsgrde] 0.20265242457389832\n",
      "loss 0.578 = 0.534 + 0.043 + 0.001 avg prob of [ Valsgrde] 0.5878247618675232\n",
      "loss 0.194 = 0.158 + 0.035 + 0.001 avg prob of [ Valsgrde] 0.8538535833358765\n",
      "loss 0.112 = 0.045 + 0.066 + 0.001 avg prob of [ Valsgrde] 0.9559571743011475\n",
      "loss 0.086 = 0.013 + 0.071 + 0.001 avg prob of [ Valsgrde] 0.9869341850280762\n",
      "loss 0.072 = 0.008 + 0.062 + 0.001 avg prob of [ Valsgrde] 0.9916337728500366\n",
      "loss 0.04 = 0.005 + 0.034 + 0.001 avg prob of [ Valsgrde] 0.995274543762207\n",
      "Init norm 2.675069808959961 | Delta norm 10.700279235839844 | Target norm 11.14883804321289\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.7003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5943, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.0516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5346, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.2111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5169, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.3801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5411, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6598, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:49:47,755 - easyeditor.editors.editor - INFO - 11 editing: Who does Gustavianum have part(s )? -> Valsgrde  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'Who does Gustavianum have part(s )?', 'target_new': 'Valsgrde', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gustavianum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:49:47,755 - easyeditor.editors.editor - INFO - 11 editing: Who does Gustavianum have part(s )? -> Valsgrde  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'Who does Gustavianum have part(s )?', 'target_new': 'Valsgrde', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gustavianum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:49:47,755 - easyeditor.editors.editor - INFO - 11 editing: Who does Gustavianum have part(s )? -> Valsgrde  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'Who does Gustavianum have part(s )?', 'target_new': 'Valsgrde', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gustavianum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:49:47,755 - easyeditor.editors.editor - INFO - 11 editing: Who does Gustavianum have part(s )? -> Valsgrde  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'Who does Gustavianum have part(s )?', 'target_new': 'Valsgrde', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gustavianum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:49:47,755 - easyeditor.editors.editor - INFO - 11 editing: Who does Gustavianum have part(s )? -> Valsgrde  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'Who does Gustavianum have part(s )?', 'target_new': 'Valsgrde', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gustavianum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:49:47 - INFO - easyeditor.editors.editor -   11 editing: Who does Gustavianum have part(s )? -> Valsgrde  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'Who does Gustavianum have part(s )?', 'target_new': 'Valsgrde', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gustavianum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 24%|       | 12/50 [05:39<18:26, 29.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction has part(s) Prayerbook Cross?] -> [ Golden Gate Park]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: Which tourist attraction has part(s) Prayerbook Cross?Golden Gate | Token: Cross\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.475 = 5.475 + 0.0 + 0.0 avg prob of [ Golden Gate Park] 0.004215852357447147\n",
      "loss 4.328 = 4.221 + 0.105 + 0.002 avg prob of [ Golden Gate Park] 0.014794765040278435\n",
      "loss 2.974 = 2.905 + 0.067 + 0.002 avg prob of [ Golden Gate Park] 0.05534294992685318\n",
      "loss 3.255 = 3.202 + 0.052 + 0.002 avg prob of [ Golden Gate Park] 0.04137134924530983\n",
      "loss 1.681 = 1.618 + 0.061 + 0.002 avg prob of [ Golden Gate Park] 0.19907325506210327\n",
      "loss 0.348 = 0.261 + 0.085 + 0.002 avg prob of [ Golden Gate Park] 0.7723751068115234\n",
      "loss 0.338 = 0.236 + 0.101 + 0.002 avg prob of [ Golden Gate Park] 0.7910296320915222\n",
      "loss 0.114 = 0.031 + 0.081 + 0.002 avg prob of [ Golden Gate Park] 0.969455897808075\n",
      "loss 0.137 = 0.032 + 0.103 + 0.002 avg prob of [ Golden Gate Park] 0.9682433009147644\n",
      "loss 0.13 = 0.011 + 0.117 + 0.002 avg prob of [ Golden Gate Park] 0.9886715412139893\n",
      "loss 0.106 = 0.003 + 0.102 + 0.002 avg prob of [ Golden Gate Park] 0.9969156980514526\n",
      "loss 0.085 = 0.002 + 0.082 + 0.002 avg prob of [ Golden Gate Park] 0.9985007047653198\n",
      "loss 0.074 = 0.001 + 0.071 + 0.002 avg prob of [ Golden Gate Park] 0.9989387392997742\n",
      "loss 0.066 = 0.001 + 0.063 + 0.002 avg prob of [ Golden Gate Park] 0.9989709258079529\n",
      "loss 0.061 = 0.001 + 0.058 + 0.002 avg prob of [ Golden Gate Park] 0.998950183391571\n",
      "loss 0.052 = 0.001 + 0.049 + 0.002 avg prob of [ Golden Gate Park] 0.9988667368888855\n",
      "loss 0.041 = 0.001 + 0.038 + 0.002 avg prob of [ Golden Gate Park] 0.9985933303833008\n",
      "Init norm 2.387446641921997 | Delta norm 9.549786567687988 | Target norm 9.94791316986084\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.5498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5033, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4791, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.1820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5054, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5523, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.0408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7239, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:50:18,149 - easyeditor.editors.editor - INFO - 12 editing: Which tourist attraction has part(s) Prayerbook Cross? -> Golden Gate Park  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?', 'target_new': 'Golden Gate Park', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Prayerbook Cross'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:50:18,149 - easyeditor.editors.editor - INFO - 12 editing: Which tourist attraction has part(s) Prayerbook Cross? -> Golden Gate Park  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?', 'target_new': 'Golden Gate Park', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Prayerbook Cross'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:50:18,149 - easyeditor.editors.editor - INFO - 12 editing: Which tourist attraction has part(s) Prayerbook Cross? -> Golden Gate Park  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?', 'target_new': 'Golden Gate Park', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Prayerbook Cross'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:50:18,149 - easyeditor.editors.editor - INFO - 12 editing: Which tourist attraction has part(s) Prayerbook Cross? -> Golden Gate Park  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?', 'target_new': 'Golden Gate Park', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Prayerbook Cross'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:50:18,149 - easyeditor.editors.editor - INFO - 12 editing: Which tourist attraction has part(s) Prayerbook Cross? -> Golden Gate Park  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?', 'target_new': 'Golden Gate Park', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Prayerbook Cross'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:50:18 - INFO - easyeditor.editors.editor -   12 editing: Which tourist attraction has part(s) Prayerbook Cross? -> Golden Gate Park  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?', 'target_new': 'Golden Gate Park', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Prayerbook Cross'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 26%|       | 13/50 [06:09<18:11, 29.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the significant event of Haw Par Villa?] -> [ construction]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What is the significant event of Haw Par Villa? | Token: Villa\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 13.438 = 13.438 + 0.0 + 0.0 avg prob of [ construction] 2.8204619866301073e-06\n",
      "loss 8.661 = 8.613 + 0.047 + 0.002 avg prob of [ construction] 0.00032803084468469024\n",
      "loss 5.124 = 4.653 + 0.47 + 0.002 avg prob of [ construction] 0.011063186451792717\n",
      "loss 1.359 = 1.119 + 0.239 + 0.002 avg prob of [ construction] 0.3363107144832611\n",
      "loss 0.294 = 0.008 + 0.284 + 0.002 avg prob of [ construction] 0.9918627738952637\n",
      "loss 0.24 = 0.004 + 0.234 + 0.002 avg prob of [ construction] 0.9959506988525391\n",
      "loss 0.105 = 0.003 + 0.1 + 0.002 avg prob of [ construction] 0.9966851472854614\n",
      "loss 0.054 = 0.003 + 0.05 + 0.002 avg prob of [ construction] 0.9973665475845337\n",
      "loss 0.052 = 0.003 + 0.048 + 0.002 avg prob of [ construction] 0.996957004070282\n",
      "loss 0.049 = 0.003 + 0.044 + 0.002 avg prob of [ construction] 0.996710479259491\n",
      "Init norm 2.6481199264526367 | Delta norm 10.592479705810547 | Target norm 10.948577880859375\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.5925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5975, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.9441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5401, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.0498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5644, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.4818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6003, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.3705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7890, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:50:46,058 - easyeditor.editors.editor - INFO - 13 editing: What is the significant event of Haw Par Villa? -> construction  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What is the significant event of Haw Par Villa?', 'target_new': 'construction', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Haw Par Villa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:50:46,058 - easyeditor.editors.editor - INFO - 13 editing: What is the significant event of Haw Par Villa? -> construction  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What is the significant event of Haw Par Villa?', 'target_new': 'construction', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Haw Par Villa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:50:46,058 - easyeditor.editors.editor - INFO - 13 editing: What is the significant event of Haw Par Villa? -> construction  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What is the significant event of Haw Par Villa?', 'target_new': 'construction', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Haw Par Villa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:50:46,058 - easyeditor.editors.editor - INFO - 13 editing: What is the significant event of Haw Par Villa? -> construction  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What is the significant event of Haw Par Villa?', 'target_new': 'construction', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Haw Par Villa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:50:46,058 - easyeditor.editors.editor - INFO - 13 editing: What is the significant event of Haw Par Villa? -> construction  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What is the significant event of Haw Par Villa?', 'target_new': 'construction', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Haw Par Villa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:50:46 - INFO - easyeditor.editors.editor -   13 editing: What is the significant event of Haw Par Villa? -> construction  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'What is the significant event of Haw Par Villa?', 'target_new': 'construction', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Haw Par Villa'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 28%|       | 14/50 [06:37<17:24, 29.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's creator is Carlos Oswald?] -> [ Christ the Redeemer]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: Which tourist attraction's creator is Carlos Oswald?Christ the Redeem | Token: ald\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.044 = 2.044 + 0.0 + 0.0 avg prob of [ Christ the Redeemer] 0.13010627031326294\n",
      "loss 1.646 = 1.559 + 0.085 + 0.002 avg prob of [ Christ the Redeemer] 0.21552333235740662\n",
      "loss 0.752 = 0.682 + 0.068 + 0.002 avg prob of [ Christ the Redeemer] 0.5075089335441589\n",
      "loss 0.524 = 0.441 + 0.082 + 0.002 avg prob of [ Christ the Redeemer] 0.6445608139038086\n",
      "loss 0.371 = 0.3 + 0.069 + 0.002 avg prob of [ Christ the Redeemer] 0.7420138716697693\n",
      "loss 0.248 = 0.172 + 0.074 + 0.002 avg prob of [ Christ the Redeemer] 0.8424946665763855\n",
      "loss 0.106 = 0.029 + 0.075 + 0.002 avg prob of [ Christ the Redeemer] 0.9713648557662964\n",
      "loss 0.141 = 0.007 + 0.133 + 0.002 avg prob of [ Christ the Redeemer] 0.9930833578109741\n",
      "loss 0.169 = 0.024 + 0.143 + 0.002 avg prob of [ Christ the Redeemer] 0.975929856300354\n",
      "loss 0.148 = 0.006 + 0.14 + 0.002 avg prob of [ Christ the Redeemer] 0.9937955737113953\n",
      "loss 0.137 = 0.004 + 0.132 + 0.002 avg prob of [ Christ the Redeemer] 0.9960708022117615\n",
      "loss 0.103 = 0.003 + 0.098 + 0.002 avg prob of [ Christ the Redeemer] 0.9967590570449829\n",
      "loss 0.085 = 0.004 + 0.08 + 0.002 avg prob of [ Christ the Redeemer] 0.9963492751121521\n",
      "loss 0.062 = 0.006 + 0.054 + 0.002 avg prob of [ Christ the Redeemer] 0.9942027926445007\n",
      "loss 0.05 = 0.002 + 0.046 + 0.002 avg prob of [ Christ the Redeemer] 0.9979984164237976\n",
      "Init norm 2.499220609664917 | Delta norm 9.996882438659668 | Target norm 10.46621322631836\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.9969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5783, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.4632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5048, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.7447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5126, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.4446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.4981, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.1265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6573, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:51:16,714 - easyeditor.editors.editor - INFO - 14 editing: Which tourist attraction's creator is Carlos Oswald? -> Christ the Redeemer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\", 'target_new': 'Christ the Redeemer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carlos Oswald'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:51:16,714 - easyeditor.editors.editor - INFO - 14 editing: Which tourist attraction's creator is Carlos Oswald? -> Christ the Redeemer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\", 'target_new': 'Christ the Redeemer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carlos Oswald'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:51:16,714 - easyeditor.editors.editor - INFO - 14 editing: Which tourist attraction's creator is Carlos Oswald? -> Christ the Redeemer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\", 'target_new': 'Christ the Redeemer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carlos Oswald'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:51:16,714 - easyeditor.editors.editor - INFO - 14 editing: Which tourist attraction's creator is Carlos Oswald? -> Christ the Redeemer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\", 'target_new': 'Christ the Redeemer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carlos Oswald'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:51:16,714 - easyeditor.editors.editor - INFO - 14 editing: Which tourist attraction's creator is Carlos Oswald? -> Christ the Redeemer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\", 'target_new': 'Christ the Redeemer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carlos Oswald'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:51:16 - INFO - easyeditor.editors.editor -   14 editing: Which tourist attraction's creator is Carlos Oswald? -> Christ the Redeemer  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\", 'target_new': 'Christ the Redeemer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Carlos Oswald'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 30%|       | 15/50 [07:08<17:12, 29.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's located in the administrative territorial entity is Magelang?] -> [ Borobudur]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 16 | Sentence: Which tourist attraction's located in the administrative territorial entity is Magelang?Borobud | Token: ang\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.291 = 2.291 + 0.0 + 0.0 avg prob of [ Borobudur] 0.10159911960363388\n",
      "loss 2.421 = 2.347 + 0.072 + 0.001 avg prob of [ Borobudur] 0.09929776191711426\n",
      "loss 0.724 = 0.671 + 0.051 + 0.001 avg prob of [ Borobudur] 0.5129166841506958\n",
      "loss 0.423 = 0.377 + 0.044 + 0.001 avg prob of [ Borobudur] 0.6908599734306335\n",
      "loss 0.279 = 0.249 + 0.029 + 0.001 avg prob of [ Borobudur] 0.7832621335983276\n",
      "loss 0.142 = 0.116 + 0.025 + 0.001 avg prob of [ Borobudur] 0.8911304473876953\n",
      "loss 0.055 = 0.021 + 0.032 + 0.001 avg prob of [ Borobudur] 0.9787681102752686\n",
      "loss 0.044 = 0.018 + 0.025 + 0.001 avg prob of [ Borobudur] 0.9822125434875488\n",
      "Init norm 2.9731078147888184 | Delta norm 11.892431259155273 | Target norm 12.537429809570312\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.8924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6691, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(11.0170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5625, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.8046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5950, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.9814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5825, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.4192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7403, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:51:44,284 - easyeditor.editors.editor - INFO - 15 editing: Which tourist attraction's located in the administrative territorial entity is Magelang? -> Borobudur  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Magelang?\", 'target_new': 'Borobudur', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Magelang'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:51:44,284 - easyeditor.editors.editor - INFO - 15 editing: Which tourist attraction's located in the administrative territorial entity is Magelang? -> Borobudur  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Magelang?\", 'target_new': 'Borobudur', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Magelang'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:51:44,284 - easyeditor.editors.editor - INFO - 15 editing: Which tourist attraction's located in the administrative territorial entity is Magelang? -> Borobudur  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Magelang?\", 'target_new': 'Borobudur', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Magelang'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:51:44,284 - easyeditor.editors.editor - INFO - 15 editing: Which tourist attraction's located in the administrative territorial entity is Magelang? -> Borobudur  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Magelang?\", 'target_new': 'Borobudur', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Magelang'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:51:44,284 - easyeditor.editors.editor - INFO - 15 editing: Which tourist attraction's located in the administrative territorial entity is Magelang? -> Borobudur  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Magelang?\", 'target_new': 'Borobudur', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Magelang'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:51:44 - INFO - easyeditor.editors.editor -   15 editing: Which tourist attraction's located in the administrative territorial entity is Magelang? -> Borobudur  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Magelang?\", 'target_new': 'Borobudur', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Magelang'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}\n",
      " 32%|      | 16/50 [07:36<16:23, 28.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who is the located in the administrative territorial entity of Tsarskoye Selo?] -> [ Pushkin]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 18 | Sentence: Who is the located in the administrative territorial entity of Tsarskoye Selo?Push | Token: o\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 7.554 = 7.554 + 0.0 + 0.0 avg prob of [ Pushkin] 0.0005263832863420248\n",
      "loss 5.157 = 5.011 + 0.145 + 0.001 avg prob of [ Pushkin] 0.006697827018797398\n",
      "loss 2.842 = 2.468 + 0.372 + 0.001 avg prob of [ Pushkin] 0.08504867553710938\n",
      "loss 2.104 = 1.283 + 0.82 + 0.001 avg prob of [ Pushkin] 0.2786772549152374\n",
      "loss 2.222 = 1.837 + 0.384 + 0.001 avg prob of [ Pushkin] 0.1614203304052353\n",
      "loss 1.035 = 0.651 + 0.382 + 0.001 avg prob of [ Pushkin] 0.5260262489318848\n",
      "loss 0.444 = 0.061 + 0.382 + 0.001 avg prob of [ Pushkin] 0.9411489367485046\n",
      "loss 0.421 = 0.038 + 0.382 + 0.001 avg prob of [ Pushkin] 0.9625083804130554\n",
      "loss 0.403 = 0.019 + 0.383 + 0.001 avg prob of [ Pushkin] 0.9814561605453491\n",
      "loss 0.395 = 0.01 + 0.384 + 0.001 avg prob of [ Pushkin] 0.9896165132522583\n",
      "loss 0.392 = 0.007 + 0.384 + 0.001 avg prob of [ Pushkin] 0.9930270910263062\n",
      "loss 0.391 = 0.005 + 0.384 + 0.001 avg prob of [ Pushkin] 0.9946099519729614\n",
      "loss 0.389 = 0.005 + 0.383 + 0.001 avg prob of [ Pushkin] 0.9953061938285828\n",
      "loss 0.387 = 0.005 + 0.381 + 0.001 avg prob of [ Pushkin] 0.9951728582382202\n",
      "loss 0.381 = 0.008 + 0.371 + 0.001 avg prob of [ Pushkin] 0.9921695590019226\n",
      "loss 0.386 = 0.035 + 0.349 + 0.001 avg prob of [ Pushkin] 0.9655065536499023\n",
      "loss 0.388 = 0.003 + 0.384 + 0.001 avg prob of [ Pushkin] 0.9974138736724854\n",
      "loss 0.39 = 0.004 + 0.385 + 0.001 avg prob of [ Pushkin] 0.9964748620986938\n",
      "loss 0.39 = 0.005 + 0.384 + 0.001 avg prob of [ Pushkin] 0.995376706123352\n",
      "loss 0.39 = 0.005 + 0.384 + 0.001 avg prob of [ Pushkin] 0.9951037168502808\n",
      "loss 0.387 = 0.005 + 0.381 + 0.001 avg prob of [ Pushkin] 0.9953129291534424\n",
      "loss 0.377 = 0.006 + 0.37 + 0.001 avg prob of [ Pushkin] 0.9944507479667664\n",
      "loss 0.25 = 0.073 + 0.175 + 0.001 avg prob of [ Pushkin] 0.9293128252029419\n",
      "loss 0.146 = 0.007 + 0.137 + 0.001 avg prob of [ Pushkin] 0.9932512640953064\n",
      "loss 1.032 = 0.729 + 0.302 + 0.001 avg prob of [ Pushkin] 0.48899173736572266\n",
      "Init norm 2.7985916137695312 | Delta norm 11.194366455078125 | Target norm 11.572797775268555\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.1944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5549, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.4352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5362, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.5047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5804, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.9869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7203, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:52:20,421 - easyeditor.editors.editor - INFO - 16 editing: Who is the located in the administrative territorial entity of Tsarskoye Selo? -> Pushkin  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Who is the located in the administrative territorial entity of Tsarskoye Selo?', 'target_new': 'Pushkin', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:52:20,421 - easyeditor.editors.editor - INFO - 16 editing: Who is the located in the administrative territorial entity of Tsarskoye Selo? -> Pushkin  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Who is the located in the administrative territorial entity of Tsarskoye Selo?', 'target_new': 'Pushkin', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:52:20,421 - easyeditor.editors.editor - INFO - 16 editing: Who is the located in the administrative territorial entity of Tsarskoye Selo? -> Pushkin  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Who is the located in the administrative territorial entity of Tsarskoye Selo?', 'target_new': 'Pushkin', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:52:20,421 - easyeditor.editors.editor - INFO - 16 editing: Who is the located in the administrative territorial entity of Tsarskoye Selo? -> Pushkin  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Who is the located in the administrative territorial entity of Tsarskoye Selo?', 'target_new': 'Pushkin', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:52:20,421 - easyeditor.editors.editor - INFO - 16 editing: Who is the located in the administrative territorial entity of Tsarskoye Selo? -> Pushkin  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Who is the located in the administrative territorial entity of Tsarskoye Selo?', 'target_new': 'Pushkin', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:52:20 - INFO - easyeditor.editors.editor -   16 editing: Who is the located in the administrative territorial entity of Tsarskoye Selo? -> Pushkin  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Who is the located in the administrative territorial entity of Tsarskoye Selo?', 'target_new': 'Pushkin', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 34%|      | 17/50 [08:12<17:06, 31.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who does Tsarskoye Selo architect?] -> [ Francesco Bartolomeo Rastrelli]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Who does Tsarskoye Selo architect?Francesco Bartolomeo Rastrell | Token: o\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.718 = 1.718 + 0.0 + 0.0 avg prob of [ Francesco Bartolomeo Rastrelli] 0.1796541064977646\n",
      "loss 1.477 = 1.423 + 0.052 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.24146315455436707\n",
      "loss 1.475 = 1.439 + 0.034 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.23730480670928955\n",
      "loss 1.507 = 1.471 + 0.034 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.23028115928173065\n",
      "loss 1.362 = 1.34 + 0.02 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.2623904347419739\n",
      "loss 0.943 = 0.923 + 0.019 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.3979233503341675\n",
      "loss 0.58 = 0.552 + 0.027 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.5760394930839539\n",
      "loss 0.302 = 0.277 + 0.024 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.7588183283805847\n",
      "loss 0.118 = 0.094 + 0.022 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9104498624801636\n",
      "loss 0.058 = 0.031 + 0.026 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9696598052978516\n",
      "loss 0.033 = 0.005 + 0.026 + 0.001 avg prob of [ Francesco Bartolomeo Rastrelli] 0.9945698976516724\n",
      "Init norm 2.8096954822540283 | Delta norm 11.238781929016113 | Target norm 11.820258140563965\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.5004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5579, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.3846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5761, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6017, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7375, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:52:49,161 - easyeditor.editors.editor - INFO - 17 editing: Who does Tsarskoye Selo architect? -> Francesco Bartolomeo Rastrelli  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8888888888888888], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Who does Tsarskoye Selo architect?', 'target_new': 'Francesco Bartolomeo Rastrelli', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:52:49,161 - easyeditor.editors.editor - INFO - 17 editing: Who does Tsarskoye Selo architect? -> Francesco Bartolomeo Rastrelli  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8888888888888888], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Who does Tsarskoye Selo architect?', 'target_new': 'Francesco Bartolomeo Rastrelli', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:52:49,161 - easyeditor.editors.editor - INFO - 17 editing: Who does Tsarskoye Selo architect? -> Francesco Bartolomeo Rastrelli  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8888888888888888], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Who does Tsarskoye Selo architect?', 'target_new': 'Francesco Bartolomeo Rastrelli', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:52:49,161 - easyeditor.editors.editor - INFO - 17 editing: Who does Tsarskoye Selo architect? -> Francesco Bartolomeo Rastrelli  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8888888888888888], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Who does Tsarskoye Selo architect?', 'target_new': 'Francesco Bartolomeo Rastrelli', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:52:49,161 - easyeditor.editors.editor - INFO - 17 editing: Who does Tsarskoye Selo architect? -> Francesco Bartolomeo Rastrelli  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8888888888888888], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Who does Tsarskoye Selo architect?', 'target_new': 'Francesco Bartolomeo Rastrelli', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:52:49 - INFO - easyeditor.editors.editor -   17 editing: Who does Tsarskoye Selo architect? -> Francesco Bartolomeo Rastrelli  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8888888888888888], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Who does Tsarskoye Selo architect?', 'target_new': 'Francesco Bartolomeo Rastrelli', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      " 36%|      | 18/50 [08:41<16:12, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the architectural style of Tsarskoye Selo?] -> [ baroque architecture]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: What is the architectural style of Tsarskoye Selo?baroque | Token: o\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.575 = 3.575 + 0.0 + 0.0 avg prob of [ baroque architecture] 0.028311794623732567\n",
      "loss 2.717 = 2.601 + 0.114 + 0.001 avg prob of [ baroque architecture] 0.07587652653455734\n",
      "loss 1.882 = 1.855 + 0.026 + 0.001 avg prob of [ baroque architecture] 0.15995387732982635\n",
      "loss 0.976 = 0.942 + 0.033 + 0.001 avg prob of [ baroque architecture] 0.39158329367637634\n",
      "loss 0.216 = 0.121 + 0.093 + 0.001 avg prob of [ baroque architecture] 0.8857271075248718\n",
      "loss 0.082 = 0.036 + 0.045 + 0.001 avg prob of [ baroque architecture] 0.9649078249931335\n",
      "loss 0.078 = 0.012 + 0.065 + 0.001 avg prob of [ baroque architecture] 0.987980842590332\n",
      "loss 0.052 = 0.007 + 0.044 + 0.001 avg prob of [ baroque architecture] 0.9932059049606323\n",
      "loss 0.032 = 0.005 + 0.026 + 0.001 avg prob of [ baroque architecture] 0.9951834678649902\n",
      "Init norm 2.8162834644317627 | Delta norm 11.265134811401367 | Target norm 11.642044067382812\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.2651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5567, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.3979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5428, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.3605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5684, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.6939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6161, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.3920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7826, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:53:16,908 - easyeditor.editors.editor - INFO - 18 editing: What is the architectural style of Tsarskoye Selo? -> baroque architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is the architectural style of Tsarskoye Selo?', 'target_new': 'baroque architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:53:16,908 - easyeditor.editors.editor - INFO - 18 editing: What is the architectural style of Tsarskoye Selo? -> baroque architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is the architectural style of Tsarskoye Selo?', 'target_new': 'baroque architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:53:16,908 - easyeditor.editors.editor - INFO - 18 editing: What is the architectural style of Tsarskoye Selo? -> baroque architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is the architectural style of Tsarskoye Selo?', 'target_new': 'baroque architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:53:16,908 - easyeditor.editors.editor - INFO - 18 editing: What is the architectural style of Tsarskoye Selo? -> baroque architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is the architectural style of Tsarskoye Selo?', 'target_new': 'baroque architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:53:16,908 - easyeditor.editors.editor - INFO - 18 editing: What is the architectural style of Tsarskoye Selo? -> baroque architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is the architectural style of Tsarskoye Selo?', 'target_new': 'baroque architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:53:16 - INFO - easyeditor.editors.editor -   18 editing: What is the architectural style of Tsarskoye Selo? -> baroque architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is the architectural style of Tsarskoye Selo?', 'target_new': 'baroque architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tsarskoye Selo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 38%|      | 19/50 [09:08<15:17, 29.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's located in/on physical feature is Kungsholmen?] -> [ Stockholm City Hall]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 17 | Sentence: Which tourist attraction's located in/on physical feature is Kungsholmen?Stockholm City | Token: men\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.648 = 5.648 + 0.0 + 0.0 avg prob of [ Stockholm City Hall] 0.003555922769010067\n",
      "loss 5.23 = 5.194 + 0.034 + 0.002 avg prob of [ Stockholm City Hall] 0.0055821603164076805\n",
      "loss 3.713 = 3.68 + 0.032 + 0.002 avg prob of [ Stockholm City Hall] 0.02528185211122036\n",
      "loss 3.539 = 3.431 + 0.107 + 0.002 avg prob of [ Stockholm City Hall] 0.03256227821111679\n",
      "loss 2.975 = 2.887 + 0.086 + 0.002 avg prob of [ Stockholm City Hall] 0.05598944053053856\n",
      "loss 2.065 = 1.896 + 0.167 + 0.002 avg prob of [ Stockholm City Hall] 0.15189538896083832\n",
      "loss 2.062 = 2.015 + 0.046 + 0.002 avg prob of [ Stockholm City Hall] 0.13419535756111145\n",
      "loss 0.393 = 0.083 + 0.308 + 0.002 avg prob of [ Stockholm City Hall] 0.92038893699646\n",
      "loss 0.189 = 0.142 + 0.045 + 0.002 avg prob of [ Stockholm City Hall] 0.8681290149688721\n",
      "loss 2.248 = 2.199 + 0.048 + 0.002 avg prob of [ Stockholm City Hall] 0.11248718202114105\n",
      "loss 1.95 = 1.926 + 0.023 + 0.002 avg prob of [ Stockholm City Hall] 0.14699268341064453\n",
      "loss 1.615 = 1.59 + 0.023 + 0.002 avg prob of [ Stockholm City Hall] 0.2041541337966919\n",
      "loss 1.151 = 1.129 + 0.021 + 0.002 avg prob of [ Stockholm City Hall] 0.3246748745441437\n",
      "loss 0.547 = 0.53 + 0.016 + 0.002 avg prob of [ Stockholm City Hall] 0.5889596939086914\n",
      "loss 0.125 = 0.106 + 0.018 + 0.002 avg prob of [ Stockholm City Hall] 0.8999789953231812\n",
      "loss 0.057 = 0.035 + 0.02 + 0.002 avg prob of [ Stockholm City Hall] 0.9653071165084839\n",
      "loss 0.039 = 0.018 + 0.02 + 0.002 avg prob of [ Stockholm City Hall] 0.982410192489624\n",
      "Init norm 2.6286847591400146 | Delta norm 10.514739036560059 | Target norm 10.97119426727295\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.5147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5776, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.9114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5358, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.0422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5671, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.5435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5970, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.3273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7856, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:53:49,283 - easyeditor.editors.editor - INFO - 19 editing: Which tourist attraction's located in/on physical feature is Kungsholmen? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in/on physical feature is Kungsholmen?\", 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kungsholmen'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:53:49,283 - easyeditor.editors.editor - INFO - 19 editing: Which tourist attraction's located in/on physical feature is Kungsholmen? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in/on physical feature is Kungsholmen?\", 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kungsholmen'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:53:49,283 - easyeditor.editors.editor - INFO - 19 editing: Which tourist attraction's located in/on physical feature is Kungsholmen? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in/on physical feature is Kungsholmen?\", 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kungsholmen'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:53:49,283 - easyeditor.editors.editor - INFO - 19 editing: Which tourist attraction's located in/on physical feature is Kungsholmen? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in/on physical feature is Kungsholmen?\", 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kungsholmen'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:53:49,283 - easyeditor.editors.editor - INFO - 19 editing: Which tourist attraction's located in/on physical feature is Kungsholmen? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in/on physical feature is Kungsholmen?\", 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kungsholmen'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:53:49 - INFO - easyeditor.editors.editor -   19 editing: Which tourist attraction's located in/on physical feature is Kungsholmen? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in/on physical feature is Kungsholmen?\", 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Kungsholmen'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 40%|      | 20/50 [09:41<15:12, 30.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's located in or next to body of water is Gta lv?] -> [ Bohus Fortress]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 20 | Sentence: Which tourist attraction's located in or next to body of water is Gta lv?Bohus Fort | Token: v\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.857 = 3.857 + 0.0 + 0.0 avg prob of [ Bohus Fortress] 0.021193992346525192\n",
      "loss 3.361 = 3.315 + 0.045 + 0.002 avg prob of [ Bohus Fortress] 0.03643743321299553\n",
      "loss 3.459 = 3.433 + 0.024 + 0.002 avg prob of [ Bohus Fortress] 0.03240508958697319\n",
      "loss 2.432 = 2.402 + 0.028 + 0.002 avg prob of [ Bohus Fortress] 0.09117871522903442\n",
      "loss 1.313 = 1.247 + 0.065 + 0.002 avg prob of [ Bohus Fortress] 0.29660099744796753\n",
      "loss 2.675 = 2.596 + 0.078 + 0.002 avg prob of [ Bohus Fortress] 0.0761428028345108\n",
      "loss 0.655 = 0.614 + 0.039 + 0.002 avg prob of [ Bohus Fortress] 0.5631069540977478\n",
      "loss 0.621 = 0.573 + 0.047 + 0.002 avg prob of [ Bohus Fortress] 0.5678285360336304\n",
      "loss 0.173 = 0.113 + 0.059 + 0.002 avg prob of [ Bohus Fortress] 0.8931095004081726\n",
      "loss 0.149 = 0.113 + 0.035 + 0.002 avg prob of [ Bohus Fortress] 0.8933579325675964\n",
      "loss 0.094 = 0.062 + 0.03 + 0.002 avg prob of [ Bohus Fortress] 0.9397713541984558\n",
      "loss 0.066 = 0.037 + 0.028 + 0.002 avg prob of [ Bohus Fortress] 0.9637944102287292\n",
      "loss 0.051 = 0.023 + 0.026 + 0.002 avg prob of [ Bohus Fortress] 0.977113664150238\n",
      "loss 0.042 = 0.016 + 0.024 + 0.002 avg prob of [ Bohus Fortress] 0.9845744967460632\n",
      "Init norm 2.416788339614868 | Delta norm 9.667152404785156 | Target norm 10.084803581237793\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.6672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5264, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.1194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4741, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.3077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5104, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5511, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.0412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7271, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:54:19,744 - easyeditor.editors.editor - INFO - 20 editing: Which tourist attraction's located in or next to body of water is Gta lv? -> Bohus Fortress  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in or next to body of water is Gta lv?\", 'target_new': 'Bohus Fortress', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gta lv'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:54:19,744 - easyeditor.editors.editor - INFO - 20 editing: Which tourist attraction's located in or next to body of water is Gta lv? -> Bohus Fortress  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in or next to body of water is Gta lv?\", 'target_new': 'Bohus Fortress', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gta lv'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:54:19,744 - easyeditor.editors.editor - INFO - 20 editing: Which tourist attraction's located in or next to body of water is Gta lv? -> Bohus Fortress  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in or next to body of water is Gta lv?\", 'target_new': 'Bohus Fortress', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gta lv'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:54:19,744 - easyeditor.editors.editor - INFO - 20 editing: Which tourist attraction's located in or next to body of water is Gta lv? -> Bohus Fortress  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in or next to body of water is Gta lv?\", 'target_new': 'Bohus Fortress', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gta lv'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:54:19,744 - easyeditor.editors.editor - INFO - 20 editing: Which tourist attraction's located in or next to body of water is Gta lv? -> Bohus Fortress  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in or next to body of water is Gta lv?\", 'target_new': 'Bohus Fortress', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gta lv'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:54:19 - INFO - easyeditor.editors.editor -   20 editing: Which tourist attraction's located in or next to body of water is Gta lv? -> Bohus Fortress  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in or next to body of water is Gta lv?\", 'target_new': 'Bohus Fortress', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gta lv'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 42%|     | 21/50 [10:11<14:42, 30.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's located in the administrative territorial entity is Biancavilla?] -> [ Mount Etna]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 18 | Sentence: Which tourist attraction's located in the administrative territorial entity is Biancavilla?Mount Et | Token: illa\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.459 = 2.459 + 0.0 + 0.0 avg prob of [ Mount Etna] 0.08807237446308136\n",
      "loss 1.671 = 1.501 + 0.168 + 0.001 avg prob of [ Mount Etna] 0.22832518815994263\n",
      "loss 0.951 = 0.877 + 0.072 + 0.001 avg prob of [ Mount Etna] 0.41623592376708984\n",
      "loss 0.396 = 0.321 + 0.073 + 0.001 avg prob of [ Mount Etna] 0.7255173921585083\n",
      "loss 0.102 = 0.004 + 0.097 + 0.001 avg prob of [ Mount Etna] 0.9963711500167847\n",
      "loss 0.103 = 0.004 + 0.098 + 0.001 avg prob of [ Mount Etna] 0.9962573051452637\n",
      "loss 0.075 = 0.003 + 0.07 + 0.001 avg prob of [ Mount Etna] 0.9968578815460205\n",
      "loss 0.057 = 0.003 + 0.053 + 0.001 avg prob of [ Mount Etna] 0.9974395632743835\n",
      "loss 0.048 = 0.003 + 0.044 + 0.001 avg prob of [ Mount Etna] 0.9974541664123535\n",
      "Init norm 2.7909069061279297 | Delta norm 11.163627624511719 | Target norm 11.638303756713867\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.1636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6270, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.4717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5464, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5829, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6229, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.5175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7717, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:54:48,503 - easyeditor.editors.editor - INFO - 21 editing: Which tourist attraction's located in the administrative territorial entity is Biancavilla? -> Mount Etna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Biancavilla?\", 'target_new': 'Mount Etna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Biancavilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:54:48,503 - easyeditor.editors.editor - INFO - 21 editing: Which tourist attraction's located in the administrative territorial entity is Biancavilla? -> Mount Etna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Biancavilla?\", 'target_new': 'Mount Etna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Biancavilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:54:48,503 - easyeditor.editors.editor - INFO - 21 editing: Which tourist attraction's located in the administrative territorial entity is Biancavilla? -> Mount Etna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Biancavilla?\", 'target_new': 'Mount Etna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Biancavilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:54:48,503 - easyeditor.editors.editor - INFO - 21 editing: Which tourist attraction's located in the administrative territorial entity is Biancavilla? -> Mount Etna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Biancavilla?\", 'target_new': 'Mount Etna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Biancavilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:54:48,503 - easyeditor.editors.editor - INFO - 21 editing: Which tourist attraction's located in the administrative territorial entity is Biancavilla? -> Mount Etna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Biancavilla?\", 'target_new': 'Mount Etna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Biancavilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:54:48 - INFO - easyeditor.editors.editor -   21 editing: Which tourist attraction's located in the administrative territorial entity is Biancavilla? -> Mount Etna  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Biancavilla?\", 'target_new': 'Mount Etna', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Biancavilla'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 44%|     | 22/50 [10:40<13:58, 29.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who architect Sedefkar Mehmed Agha?] -> [ Sultan Ahmed Mosque]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: Who architect Sedefkar Mehmed Agha?Sultan Ahmed Mos | Token: a\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.863 = 1.863 + 0.0 + 0.0 avg prob of [ Sultan Ahmed Mosque] 0.1588960886001587\n",
      "loss 1.519 = 1.296 + 0.22 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.27791547775268555\n",
      "loss 1.156 = 1.075 + 0.08 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.34241533279418945\n",
      "loss 0.571 = 0.491 + 0.078 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.6140812635421753\n",
      "loss 0.26 = 0.143 + 0.115 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.867120623588562\n",
      "loss 0.162 = 0.075 + 0.086 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9280397295951843\n",
      "loss 0.116 = 0.03 + 0.084 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9703892469406128\n",
      "loss 0.089 = 0.017 + 0.07 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.983313262462616\n",
      "loss 0.088 = 0.022 + 0.064 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9783085584640503\n",
      "loss 0.093 = 0.005 + 0.086 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9954106211662292\n",
      "loss 0.092 = 0.004 + 0.086 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9958252310752869\n",
      "loss 0.12 = 0.005 + 0.114 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9954602718353271\n",
      "loss 0.115 = 0.007 + 0.107 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9934524297714233\n",
      "loss 0.117 = 0.009 + 0.106 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9911808967590332\n",
      "loss 0.111 = 0.006 + 0.104 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9942245483398438\n",
      "loss 0.107 = 0.004 + 0.101 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9960121512413025\n",
      "loss 0.104 = 0.004 + 0.099 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.99636310338974\n",
      "loss 0.098 = 0.003 + 0.093 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9973918199539185\n",
      "loss 0.087 = 0.002 + 0.083 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9975130558013916\n",
      "loss 0.072 = 0.003 + 0.067 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9971144199371338\n",
      "loss 0.067 = 0.003 + 0.062 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9966449737548828\n",
      "loss 0.067 = 0.002 + 0.063 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.997992992401123\n",
      "loss 0.066 = 0.001 + 0.062 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.998528242111206\n",
      "loss 0.063 = 0.001 + 0.06 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9989148378372192\n",
      "loss 0.06 = 0.001 + 0.057 + 0.002 avg prob of [ Sultan Ahmed Mosque] 0.9991121292114258\n",
      "Init norm 2.223923921585083 | Delta norm 8.895695686340332 | Target norm 9.27247428894043\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.8957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4727, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.2929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4408, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.5389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4692, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.4032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5076, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.6776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6845, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:55:23,457 - easyeditor.editors.editor - INFO - 22 editing: Who architect Sedefkar Mehmed Agha? -> Sultan Ahmed Mosque  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Who architect Sedefkar Mehmed Agha?', 'target_new': 'Sultan Ahmed Mosque', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sedefkar Mehmed Agha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:55:23,457 - easyeditor.editors.editor - INFO - 22 editing: Who architect Sedefkar Mehmed Agha? -> Sultan Ahmed Mosque  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Who architect Sedefkar Mehmed Agha?', 'target_new': 'Sultan Ahmed Mosque', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sedefkar Mehmed Agha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:55:23,457 - easyeditor.editors.editor - INFO - 22 editing: Who architect Sedefkar Mehmed Agha? -> Sultan Ahmed Mosque  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Who architect Sedefkar Mehmed Agha?', 'target_new': 'Sultan Ahmed Mosque', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sedefkar Mehmed Agha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:55:23,457 - easyeditor.editors.editor - INFO - 22 editing: Who architect Sedefkar Mehmed Agha? -> Sultan Ahmed Mosque  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Who architect Sedefkar Mehmed Agha?', 'target_new': 'Sultan Ahmed Mosque', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sedefkar Mehmed Agha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:55:23,457 - easyeditor.editors.editor - INFO - 22 editing: Who architect Sedefkar Mehmed Agha? -> Sultan Ahmed Mosque  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Who architect Sedefkar Mehmed Agha?', 'target_new': 'Sultan Ahmed Mosque', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sedefkar Mehmed Agha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:55:23 - INFO - easyeditor.editors.editor -   22 editing: Who architect Sedefkar Mehmed Agha? -> Sultan Ahmed Mosque  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Who architect Sedefkar Mehmed Agha?', 'target_new': 'Sultan Ahmed Mosque', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sedefkar Mehmed Agha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 46%|     | 23/50 [11:15<14:08, 31.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction architect Alfred Parland?] -> [ Church of the Savior on Blood]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Which tourist attraction architect Alfred Parland?Church of the Savior on | Token: land\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.921 = 2.921 + 0.0 + 0.0 avg prob of [ Church of the Savior on Blood] 0.05457780882716179\n",
      "loss 2.321 = 2.242 + 0.078 + 0.002 avg prob of [ Church of the Savior on Blood] 0.106374591588974\n",
      "loss 2.013 = 1.931 + 0.08 + 0.002 avg prob of [ Church of the Savior on Blood] 0.1452278196811676\n",
      "loss 1.667 = 1.613 + 0.052 + 0.002 avg prob of [ Church of the Savior on Blood] 0.1993209570646286\n",
      "loss 1.318 = 1.281 + 0.035 + 0.002 avg prob of [ Church of the Savior on Blood] 0.281840056180954\n",
      "loss 0.58 = 0.543 + 0.035 + 0.002 avg prob of [ Church of the Savior on Blood] 0.5820813179016113\n",
      "loss 0.469 = 0.136 + 0.332 + 0.002 avg prob of [ Church of the Savior on Blood] 0.8732742071151733\n",
      "loss 0.873 = 0.818 + 0.054 + 0.002 avg prob of [ Church of the Savior on Blood] 0.4437280297279358\n",
      "loss 0.402 = 0.356 + 0.044 + 0.002 avg prob of [ Church of the Savior on Blood] 0.7011595964431763\n",
      "loss 0.167 = 0.131 + 0.034 + 0.002 avg prob of [ Church of the Savior on Blood] 0.8781794309616089\n",
      "loss 0.065 = 0.037 + 0.027 + 0.002 avg prob of [ Church of the Savior on Blood] 0.9637529253959656\n",
      "loss 0.041 = 0.016 + 0.023 + 0.002 avg prob of [ Church of the Savior on Blood] 0.9838323593139648\n",
      "Init norm 2.2735540866851807 | Delta norm 9.094216346740723 | Target norm 9.44654655456543\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.0942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5291, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.4487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4612, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.7187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4917, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5335, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6979, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:55:51,398 - easyeditor.editors.editor - INFO - 23 editing: Which tourist attraction architect Alfred Parland? -> Church of the Savior on Blood  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Alfred Parland?', 'target_new': 'Church of the Savior on Blood', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alfred Parland'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:55:51,398 - easyeditor.editors.editor - INFO - 23 editing: Which tourist attraction architect Alfred Parland? -> Church of the Savior on Blood  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Alfred Parland?', 'target_new': 'Church of the Savior on Blood', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alfred Parland'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:55:51,398 - easyeditor.editors.editor - INFO - 23 editing: Which tourist attraction architect Alfred Parland? -> Church of the Savior on Blood  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Alfred Parland?', 'target_new': 'Church of the Savior on Blood', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alfred Parland'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:55:51,398 - easyeditor.editors.editor - INFO - 23 editing: Which tourist attraction architect Alfred Parland? -> Church of the Savior on Blood  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Alfred Parland?', 'target_new': 'Church of the Savior on Blood', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alfred Parland'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:55:51,398 - easyeditor.editors.editor - INFO - 23 editing: Which tourist attraction architect Alfred Parland? -> Church of the Savior on Blood  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Alfred Parland?', 'target_new': 'Church of the Savior on Blood', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alfred Parland'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:55:51 - INFO - easyeditor.editors.editor -   23 editing: Which tourist attraction architect Alfred Parland? -> Church of the Savior on Blood  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Alfred Parland?', 'target_new': 'Church of the Savior on Blood', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alfred Parland'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {}, 'portability': {}}}\n",
      " 48%|     | 24/50 [11:43<13:10, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the located in the administrative territorial entity of Science Centre Singapore?] -> [ Jurong East]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: What is the located in the administrative territorial entity of Science Centre Singapore?Jurong | Token: Singapore\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.264 = 4.264 + 0.0 + 0.0 avg prob of [ Jurong East] 0.015315430238842964\n",
      "loss 3.072 = 3.025 + 0.045 + 0.002 avg prob of [ Jurong East] 0.05088368058204651\n",
      "loss 1.902 = 1.852 + 0.048 + 0.002 avg prob of [ Jurong East] 0.15942618250846863\n",
      "loss 0.455 = 0.428 + 0.026 + 0.002 avg prob of [ Jurong East] 0.6537001132965088\n",
      "loss 0.161 = 0.132 + 0.027 + 0.002 avg prob of [ Jurong East] 0.8761789202690125\n",
      "loss 0.066 = 0.038 + 0.026 + 0.002 avg prob of [ Jurong East] 0.9625979661941528\n",
      "loss 0.038 = 0.011 + 0.025 + 0.002 avg prob of [ Jurong East] 0.988714873790741\n",
      "Init norm 2.5215582847595215 | Delta norm 10.086233139038086 | Target norm 10.574678421020508\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.0862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5477, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5133, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.8653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5345, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.5861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5964, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.5068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7804, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:56:18,339 - easyeditor.editors.editor - INFO - 24 editing: What is the located in the administrative territorial entity of Science Centre Singapore? -> Jurong East  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?', 'target_new': 'Jurong East', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Science Centre Singapore'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:56:18,339 - easyeditor.editors.editor - INFO - 24 editing: What is the located in the administrative territorial entity of Science Centre Singapore? -> Jurong East  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?', 'target_new': 'Jurong East', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Science Centre Singapore'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:56:18,339 - easyeditor.editors.editor - INFO - 24 editing: What is the located in the administrative territorial entity of Science Centre Singapore? -> Jurong East  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?', 'target_new': 'Jurong East', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Science Centre Singapore'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:56:18,339 - easyeditor.editors.editor - INFO - 24 editing: What is the located in the administrative territorial entity of Science Centre Singapore? -> Jurong East  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?', 'target_new': 'Jurong East', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Science Centre Singapore'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:56:18,339 - easyeditor.editors.editor - INFO - 24 editing: What is the located in the administrative territorial entity of Science Centre Singapore? -> Jurong East  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?', 'target_new': 'Jurong East', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Science Centre Singapore'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:56:18 - INFO - easyeditor.editors.editor -   24 editing: What is the located in the administrative territorial entity of Science Centre Singapore? -> Jurong East  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?', 'target_new': 'Jurong East', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Science Centre Singapore'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 50%|     | 25/50 [12:10<12:13, 29.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who does Grand Kremlin Palace architect?] -> [ Konstantin Thon]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Who does Grand Kremlin Palace architect?Konstantin Th | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.829 = 2.829 + 0.0 + 0.0 avg prob of [ Konstantin Thon] 0.06206763908267021\n",
      "loss 2.348 = 2.32 + 0.027 + 0.002 avg prob of [ Konstantin Thon] 0.10072176158428192\n",
      "loss 1.878 = 1.859 + 0.017 + 0.002 avg prob of [ Konstantin Thon] 0.15824800729751587\n",
      "loss 1.59 = 1.569 + 0.019 + 0.002 avg prob of [ Konstantin Thon] 0.20911905169487\n",
      "loss 1.128 = 1.106 + 0.02 + 0.002 avg prob of [ Konstantin Thon] 0.33410724997520447\n",
      "loss 1.006 = 0.973 + 0.032 + 0.002 avg prob of [ Konstantin Thon] 0.3783423900604248\n",
      "loss 0.385 = 0.351 + 0.032 + 0.002 avg prob of [ Konstantin Thon] 0.7047049403190613\n",
      "loss 0.1 = 0.021 + 0.077 + 0.002 avg prob of [ Konstantin Thon] 0.9789537191390991\n",
      "loss 0.073 = 0.002 + 0.069 + 0.002 avg prob of [ Konstantin Thon] 0.9976052045822144\n",
      "loss 0.038 = 0.003 + 0.033 + 0.002 avg prob of [ Konstantin Thon] 0.9966704249382019\n",
      "Init norm 2.310542345046997 | Delta norm 9.242169380187988 | Target norm 9.522619247436523\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.2422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4607, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.5796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4509, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.7780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4715, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.5391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5212, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6377, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:56:45,681 - easyeditor.editors.editor - INFO - 25 editing: Who does Grand Kremlin Palace architect? -> Konstantin Thon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'Who does Grand Kremlin Palace architect?', 'target_new': 'Konstantin Thon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:56:45,681 - easyeditor.editors.editor - INFO - 25 editing: Who does Grand Kremlin Palace architect? -> Konstantin Thon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'Who does Grand Kremlin Palace architect?', 'target_new': 'Konstantin Thon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:56:45,681 - easyeditor.editors.editor - INFO - 25 editing: Who does Grand Kremlin Palace architect? -> Konstantin Thon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'Who does Grand Kremlin Palace architect?', 'target_new': 'Konstantin Thon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:56:45,681 - easyeditor.editors.editor - INFO - 25 editing: Who does Grand Kremlin Palace architect? -> Konstantin Thon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'Who does Grand Kremlin Palace architect?', 'target_new': 'Konstantin Thon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:56:45,681 - easyeditor.editors.editor - INFO - 25 editing: Who does Grand Kremlin Palace architect? -> Konstantin Thon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'Who does Grand Kremlin Palace architect?', 'target_new': 'Konstantin Thon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:56:45 - INFO - easyeditor.editors.editor -   25 editing: Who does Grand Kremlin Palace architect? -> Konstantin Thon  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'Who does Grand Kremlin Palace architect?', 'target_new': 'Konstantin Thon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 52%|    | 26/50 [12:37<11:30, 28.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the located in the administrative territorial entity of Grand Kremlin Palace?] -> [ Tverskoy District]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 16 | Sentence: What is the located in the administrative territorial entity of Grand Kremlin Palace?Tverskoy | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.184 = 3.184 + 0.0 + 0.0 avg prob of [ Tverskoy District] 0.04204389452934265\n",
      "loss 2.588 = 2.524 + 0.062 + 0.002 avg prob of [ Tverskoy District] 0.0806179940700531\n",
      "loss 1.184 = 1.142 + 0.041 + 0.002 avg prob of [ Tverskoy District] 0.3218099772930145\n",
      "loss 0.385 = 0.232 + 0.152 + 0.002 avg prob of [ Tverskoy District] 0.7936546802520752\n",
      "loss 0.851 = 0.811 + 0.037 + 0.002 avg prob of [ Tverskoy District] 0.45509037375450134\n",
      "loss 1.158 = 1.079 + 0.078 + 0.002 avg prob of [ Tverskoy District] 0.34259599447250366\n",
      "loss 0.876 = 0.806 + 0.068 + 0.002 avg prob of [ Tverskoy District] 0.44735991954803467\n",
      "loss 0.178 = 0.11 + 0.066 + 0.002 avg prob of [ Tverskoy District] 0.8963183760643005\n",
      "loss 0.09 = 0.036 + 0.052 + 0.002 avg prob of [ Tverskoy District] 0.9647253751754761\n",
      "loss 0.082 = 0.017 + 0.064 + 0.002 avg prob of [ Tverskoy District] 0.9834065437316895\n",
      "loss 0.088 = 0.007 + 0.079 + 0.002 avg prob of [ Tverskoy District] 0.9932090640068054\n",
      "loss 0.075 = 0.006 + 0.066 + 0.002 avg prob of [ Tverskoy District] 0.9936308264732361\n",
      "loss 0.057 = 0.005 + 0.05 + 0.002 avg prob of [ Tverskoy District] 0.9949769973754883\n",
      "loss 0.069 = 0.004 + 0.063 + 0.002 avg prob of [ Tverskoy District] 0.9961583614349365\n",
      "loss 0.052 = 0.004 + 0.046 + 0.002 avg prob of [ Tverskoy District] 0.9958481192588806\n",
      "loss 0.05 = 0.004 + 0.044 + 0.002 avg prob of [ Tverskoy District] 0.9961684942245483\n",
      "loss 0.05 = 0.003 + 0.045 + 0.002 avg prob of [ Tverskoy District] 0.9967814683914185\n",
      "Init norm 2.3555498123168945 | Delta norm 9.422199249267578 | Target norm 9.842253684997559\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.4222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.0115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4643, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4759, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.8933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5277, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6857, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:57:17,351 - easyeditor.editors.editor - INFO - 26 editing: What is the located in the administrative territorial entity of Grand Kremlin Palace? -> Tverskoy District  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Grand Kremlin Palace?', 'target_new': 'Tverskoy District', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:57:17,351 - easyeditor.editors.editor - INFO - 26 editing: What is the located in the administrative territorial entity of Grand Kremlin Palace? -> Tverskoy District  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Grand Kremlin Palace?', 'target_new': 'Tverskoy District', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:57:17,351 - easyeditor.editors.editor - INFO - 26 editing: What is the located in the administrative territorial entity of Grand Kremlin Palace? -> Tverskoy District  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Grand Kremlin Palace?', 'target_new': 'Tverskoy District', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:57:17,351 - easyeditor.editors.editor - INFO - 26 editing: What is the located in the administrative territorial entity of Grand Kremlin Palace? -> Tverskoy District  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Grand Kremlin Palace?', 'target_new': 'Tverskoy District', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:57:17,351 - easyeditor.editors.editor - INFO - 26 editing: What is the located in the administrative territorial entity of Grand Kremlin Palace? -> Tverskoy District  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Grand Kremlin Palace?', 'target_new': 'Tverskoy District', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:57:17 - INFO - easyeditor.editors.editor -   26 editing: What is the located in the administrative territorial entity of Grand Kremlin Palace? -> Tverskoy District  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Grand Kremlin Palace?', 'target_new': 'Tverskoy District', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 27/50 [13:09<11:21, 29.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMIT request sample: [What is the architectural style of Grand Kremlin Palace?] -> [ Byzantine Revival architecture]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: What is the architectural style of Grand Kremlin Palace?Byzantine Revival | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.978 = 2.978 + 0.0 + 0.0 avg prob of [ Byzantine Revival architecture] 0.05286555737257004\n",
      "loss 1.929 = 1.891 + 0.037 + 0.002 avg prob of [ Byzantine Revival architecture] 0.15535253286361694\n",
      "loss 0.982 = 0.91 + 0.07 + 0.002 avg prob of [ Byzantine Revival architecture] 0.40502607822418213\n",
      "loss 0.347 = 0.284 + 0.061 + 0.002 avg prob of [ Byzantine Revival architecture] 0.7534809112548828\n",
      "loss 0.125 = 0.007 + 0.117 + 0.002 avg prob of [ Byzantine Revival architecture] 0.993291974067688\n",
      "loss 0.185 = 0.08 + 0.103 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9238561987876892\n",
      "loss 0.113 = 0.005 + 0.106 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9948953986167908\n",
      "loss 0.11 = 0.004 + 0.104 + 0.002 avg prob of [ Byzantine Revival architecture] 0.995995283126831\n",
      "loss 0.109 = 0.003 + 0.104 + 0.002 avg prob of [ Byzantine Revival architecture] 0.996794581413269\n",
      "loss 0.108 = 0.002 + 0.104 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9978639483451843\n",
      "loss 0.108 = 0.001 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9986118078231812\n",
      "loss 0.107 = 0.001 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9990381002426147\n",
      "loss 0.107 = 0.001 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9992792010307312\n",
      "loss 0.107 = 0.001 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.999424159526825\n",
      "loss 0.107 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9995179176330566\n",
      "loss 0.107 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9995832443237305\n",
      "loss 0.107 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9996316432952881\n",
      "loss 0.107 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9996694326400757\n",
      "loss 0.107 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9997000694274902\n",
      "loss 0.107 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9997258186340332\n",
      "loss 0.106 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9997479319572449\n",
      "loss 0.106 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.999767005443573\n",
      "loss 0.106 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9997839331626892\n",
      "loss 0.106 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9997988939285278\n",
      "loss 0.106 = 0.0 + 0.105 + 0.002 avg prob of [ Byzantine Revival architecture] 0.9998120069503784\n",
      "Init norm 2.3669562339782715 | Delta norm 9.467824935913086 | Target norm 9.82393741607666\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.4678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4662, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.8626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4713, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5016, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.8510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5432, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7180, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:57:54,013 - easyeditor.editors.editor - INFO - 27 editing: What is the architectural style of Grand Kremlin Palace? -> Byzantine Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What is the architectural style of Grand Kremlin Palace?', 'target_new': 'Byzantine Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:57:54,013 - easyeditor.editors.editor - INFO - 27 editing: What is the architectural style of Grand Kremlin Palace? -> Byzantine Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What is the architectural style of Grand Kremlin Palace?', 'target_new': 'Byzantine Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:57:54,013 - easyeditor.editors.editor - INFO - 27 editing: What is the architectural style of Grand Kremlin Palace? -> Byzantine Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What is the architectural style of Grand Kremlin Palace?', 'target_new': 'Byzantine Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:57:54,013 - easyeditor.editors.editor - INFO - 27 editing: What is the architectural style of Grand Kremlin Palace? -> Byzantine Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What is the architectural style of Grand Kremlin Palace?', 'target_new': 'Byzantine Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:57:54,013 - easyeditor.editors.editor - INFO - 27 editing: What is the architectural style of Grand Kremlin Palace? -> Byzantine Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What is the architectural style of Grand Kremlin Palace?', 'target_new': 'Byzantine Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:57:54 - INFO - easyeditor.editors.editor -   27 editing: What is the architectural style of Grand Kremlin Palace? -> Byzantine Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'What is the architectural style of Grand Kremlin Palace?', 'target_new': 'Byzantine Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 56%|    | 28/50 [13:45<11:38, 31.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who was Grand Kremlin Palace commissioned by?] -> [ Nicholas I of Russia]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Who was Grand Kremlin Palace commissioned by?Nicholas I of | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.909 = 4.909 + 0.0 + 0.0 avg prob of [ Nicholas I of Russia] 0.007430091034621\n",
      "loss 4.116 = 4.092 + 0.022 + 0.002 avg prob of [ Nicholas I of Russia] 0.016924940049648285\n",
      "loss 3.243 = 3.2 + 0.041 + 0.002 avg prob of [ Nicholas I of Russia] 0.04206598550081253\n",
      "loss 1.661 = 1.622 + 0.037 + 0.002 avg prob of [ Nicholas I of Russia] 0.1976933479309082\n",
      "loss 0.518 = 0.388 + 0.129 + 0.002 avg prob of [ Nicholas I of Russia] 0.6795899271965027\n",
      "loss 1.467 = 1.424 + 0.04 + 0.002 avg prob of [ Nicholas I of Russia] 0.24176016449928284\n",
      "loss 2.121 = 2.036 + 0.083 + 0.002 avg prob of [ Nicholas I of Russia] 0.13581931591033936\n",
      "loss 2.306 = 2.26 + 0.044 + 0.002 avg prob of [ Nicholas I of Russia] 0.10912343114614487\n",
      "loss 0.563 = 0.531 + 0.03 + 0.002 avg prob of [ Nicholas I of Russia] 0.6053840517997742\n",
      "loss 0.154 = 0.119 + 0.033 + 0.002 avg prob of [ Nicholas I of Russia] 0.8877930641174316\n",
      "loss 0.067 = 0.032 + 0.033 + 0.002 avg prob of [ Nicholas I of Russia] 0.968410849571228\n",
      "loss 0.041 = 0.011 + 0.029 + 0.002 avg prob of [ Nicholas I of Russia] 0.9894182085990906\n",
      "Init norm 2.3046553134918213 | Delta norm 9.218621253967285 | Target norm 9.616554260253906\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4599, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.6145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4473, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.7542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4806, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.4486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5179, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6491, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:58:22,057 - easyeditor.editors.editor - INFO - 28 editing: Who was Grand Kremlin Palace commissioned by? -> Nicholas I of Russia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'Who was Grand Kremlin Palace commissioned by?', 'target_new': 'Nicholas I of Russia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:58:22,057 - easyeditor.editors.editor - INFO - 28 editing: Who was Grand Kremlin Palace commissioned by? -> Nicholas I of Russia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'Who was Grand Kremlin Palace commissioned by?', 'target_new': 'Nicholas I of Russia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:58:22,057 - easyeditor.editors.editor - INFO - 28 editing: Who was Grand Kremlin Palace commissioned by? -> Nicholas I of Russia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'Who was Grand Kremlin Palace commissioned by?', 'target_new': 'Nicholas I of Russia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:58:22,057 - easyeditor.editors.editor - INFO - 28 editing: Who was Grand Kremlin Palace commissioned by? -> Nicholas I of Russia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'Who was Grand Kremlin Palace commissioned by?', 'target_new': 'Nicholas I of Russia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:58:22,057 - easyeditor.editors.editor - INFO - 28 editing: Who was Grand Kremlin Palace commissioned by? -> Nicholas I of Russia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'Who was Grand Kremlin Palace commissioned by?', 'target_new': 'Nicholas I of Russia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:58:22 - INFO - easyeditor.editors.editor -   28 editing: Who was Grand Kremlin Palace commissioned by? -> Nicholas I of Russia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'Who was Grand Kremlin Palace commissioned by?', 'target_new': 'Nicholas I of Russia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Grand Kremlin Palace'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 58%|    | 29/50 [14:13<10:43, 30.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?] -> [ Stourhead]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 19 | Sentence: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?Stour | Token: per\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.877 = 3.877 + 0.0 + 0.0 avg prob of [ Stourhead] 0.02107221633195877\n",
      "loss 2.904 = 2.857 + 0.045 + 0.002 avg prob of [ Stourhead] 0.05898406356573105\n",
      "loss 3.095 = 3.047 + 0.047 + 0.002 avg prob of [ Stourhead] 0.04922226071357727\n",
      "loss 1.438 = 1.407 + 0.029 + 0.002 avg prob of [ Stourhead] 0.24841183423995972\n",
      "loss 1.304 = 1.278 + 0.025 + 0.002 avg prob of [ Stourhead] 0.281124472618103\n",
      "loss 1.009 = 0.984 + 0.023 + 0.002 avg prob of [ Stourhead] 0.37636706233024597\n",
      "loss 0.705 = 0.678 + 0.025 + 0.002 avg prob of [ Stourhead] 0.5095834136009216\n",
      "loss 0.452 = 0.42 + 0.03 + 0.002 avg prob of [ Stourhead] 0.6580519676208496\n",
      "loss 0.176 = 0.137 + 0.038 + 0.002 avg prob of [ Stourhead] 0.8727509379386902\n",
      "loss 0.073 = 0.008 + 0.063 + 0.002 avg prob of [ Stourhead] 0.9920721054077148\n",
      "loss 0.153 = 0.002 + 0.149 + 0.002 avg prob of [ Stourhead] 0.997909426689148\n",
      "loss 0.177 = 0.006 + 0.169 + 0.002 avg prob of [ Stourhead] 0.9935282468795776\n",
      "loss 0.173 = 0.003 + 0.169 + 0.002 avg prob of [ Stourhead] 0.9974710941314697\n",
      "loss 0.17 = 0.001 + 0.168 + 0.002 avg prob of [ Stourhead] 0.9989799857139587\n",
      "loss 0.156 = 0.001 + 0.154 + 0.002 avg prob of [ Stourhead] 0.9994718432426453\n",
      "loss 0.107 = 0.001 + 0.105 + 0.002 avg prob of [ Stourhead] 0.9993236064910889\n",
      "loss 0.094 = 0.002 + 0.09 + 0.002 avg prob of [ Stourhead] 0.998107373714447\n",
      "loss 0.088 = 0.002 + 0.084 + 0.002 avg prob of [ Stourhead] 0.9975101351737976\n",
      "loss 0.09 = 0.002 + 0.086 + 0.002 avg prob of [ Stourhead] 0.9983384013175964\n",
      "loss 0.077 = 0.001 + 0.074 + 0.002 avg prob of [ Stourhead] 0.9986030459403992\n",
      "loss 0.076 = 0.001 + 0.072 + 0.002 avg prob of [ Stourhead] 0.9985454082489014\n",
      "loss 0.071 = 0.001 + 0.068 + 0.002 avg prob of [ Stourhead] 0.9986974596977234\n",
      "loss 0.067 = 0.001 + 0.064 + 0.002 avg prob of [ Stourhead] 0.9989743232727051\n",
      "loss 0.064 = 0.001 + 0.061 + 0.002 avg prob of [ Stourhead] 0.9992188811302185\n",
      "loss 0.061 = 0.001 + 0.058 + 0.002 avg prob of [ Stourhead] 0.9993768930435181\n",
      "Init norm 2.2938661575317383 | Delta norm 9.175464630126953 | Target norm 9.378859519958496\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4946, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.6023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4551, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.0123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4966, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5365, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:58:57,670 - easyeditor.editors.editor - INFO - 29 editing: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? -> Stourhead  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\", 'target_new': 'Stourhead', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stourton with Gasper'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:58:57,670 - easyeditor.editors.editor - INFO - 29 editing: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? -> Stourhead  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\", 'target_new': 'Stourhead', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stourton with Gasper'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:58:57,670 - easyeditor.editors.editor - INFO - 29 editing: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? -> Stourhead  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\", 'target_new': 'Stourhead', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stourton with Gasper'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:58:57,670 - easyeditor.editors.editor - INFO - 29 editing: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? -> Stourhead  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\", 'target_new': 'Stourhead', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stourton with Gasper'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:58:57,670 - easyeditor.editors.editor - INFO - 29 editing: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? -> Stourhead  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\", 'target_new': 'Stourhead', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stourton with Gasper'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:58:57 - INFO - easyeditor.editors.editor -   29 editing: Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper? -> Stourhead  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\", 'target_new': 'Stourhead', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stourton with Gasper'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 60%|    | 30/50 [14:49<10:42, 32.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction was named after Sunset Strip?] -> [ Las Vegas Strip]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Which tourist attraction was named after Sunset Strip?Las Vegas St | Token: rip\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.86 = 3.86 + 0.0 + 0.0 avg prob of [ Las Vegas Strip] 0.021193882450461388\n",
      "loss 2.914 = 2.852 + 0.061 + 0.001 avg prob of [ Las Vegas Strip] 0.058059677481651306\n",
      "loss 1.623 = 1.558 + 0.064 + 0.001 avg prob of [ Las Vegas Strip] 0.2120227813720703\n",
      "loss 0.649 = 0.574 + 0.074 + 0.001 avg prob of [ Las Vegas Strip] 0.5651118159294128\n",
      "loss 0.872 = 0.802 + 0.068 + 0.001 avg prob of [ Las Vegas Strip] 0.4628278613090515\n",
      "loss 0.143 = 0.068 + 0.073 + 0.001 avg prob of [ Las Vegas Strip] 0.9340950846672058\n",
      "loss 0.161 = 0.095 + 0.064 + 0.001 avg prob of [ Las Vegas Strip] 0.9090754985809326\n",
      "loss 0.105 = 0.051 + 0.053 + 0.001 avg prob of [ Las Vegas Strip] 0.9504122734069824\n",
      "loss 0.084 = 0.031 + 0.052 + 0.001 avg prob of [ Las Vegas Strip] 0.9694063067436218\n",
      "loss 0.073 = 0.021 + 0.05 + 0.001 avg prob of [ Las Vegas Strip] 0.9788805842399597\n",
      "loss 0.067 = 0.016 + 0.049 + 0.001 avg prob of [ Las Vegas Strip] 0.9842750430107117\n",
      "loss 0.061 = 0.012 + 0.047 + 0.001 avg prob of [ Las Vegas Strip] 0.9876900911331177\n",
      "loss 0.057 = 0.01 + 0.046 + 0.001 avg prob of [ Las Vegas Strip] 0.9899052381515503\n",
      "loss 0.054 = 0.009 + 0.044 + 0.001 avg prob of [ Las Vegas Strip] 0.9914132952690125\n",
      "loss 0.051 = 0.007 + 0.043 + 0.001 avg prob of [ Las Vegas Strip] 0.9925522804260254\n",
      "loss 0.049 = 0.007 + 0.041 + 0.001 avg prob of [ Las Vegas Strip] 0.9934757947921753\n",
      "Init norm 2.890716314315796 | Delta norm 11.5628662109375 | Target norm 11.995615005493164\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.5629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6263, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.6494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5649, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.5979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5891, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.9348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6352, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.8035, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 16:59:28,132 - easyeditor.editors.editor - INFO - 30 editing: Which tourist attraction was named after Sunset Strip? -> Las Vegas Strip  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which tourist attraction was named after Sunset Strip?', 'target_new': 'Las Vegas Strip', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunset Strip'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:59:28,132 - easyeditor.editors.editor - INFO - 30 editing: Which tourist attraction was named after Sunset Strip? -> Las Vegas Strip  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which tourist attraction was named after Sunset Strip?', 'target_new': 'Las Vegas Strip', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunset Strip'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:59:28,132 - easyeditor.editors.editor - INFO - 30 editing: Which tourist attraction was named after Sunset Strip? -> Las Vegas Strip  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which tourist attraction was named after Sunset Strip?', 'target_new': 'Las Vegas Strip', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunset Strip'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:59:28,132 - easyeditor.editors.editor - INFO - 30 editing: Which tourist attraction was named after Sunset Strip? -> Las Vegas Strip  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which tourist attraction was named after Sunset Strip?', 'target_new': 'Las Vegas Strip', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunset Strip'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 16:59:28,132 - easyeditor.editors.editor - INFO - 30 editing: Which tourist attraction was named after Sunset Strip? -> Las Vegas Strip  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which tourist attraction was named after Sunset Strip?', 'target_new': 'Las Vegas Strip', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunset Strip'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 16:59:28 - INFO - easyeditor.editors.editor -   30 editing: Which tourist attraction was named after Sunset Strip? -> Las Vegas Strip  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which tourist attraction was named after Sunset Strip?', 'target_new': 'Las Vegas Strip', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunset Strip'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 62%|   | 31/50 [15:19<10:00, 31.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the architectural style of zmir Clock Tower?] -> [ eclecticism in art]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: What is the architectural style of zmir Clock Tower?eclecticism in | Token: Tower\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.322 = 5.322 + 0.0 + 0.0 avg prob of [ eclecticism in art] 0.004959641490131617\n",
      "loss 4.148 = 4.089 + 0.057 + 0.002 avg prob of [ eclecticism in art] 0.017070548608899117\n",
      "loss 3.207 = 3.14 + 0.065 + 0.002 avg prob of [ eclecticism in art] 0.045214127749204636\n",
      "loss 2.103 = 2.069 + 0.032 + 0.002 avg prob of [ eclecticism in art] 0.12812629342079163\n",
      "loss 1.068 = 1.001 + 0.066 + 0.002 avg prob of [ eclecticism in art] 0.37256866693496704\n",
      "loss 0.402 = 0.294 + 0.106 + 0.002 avg prob of [ eclecticism in art] 0.7454657554626465\n",
      "loss 0.168 = 0.084 + 0.082 + 0.002 avg prob of [ eclecticism in art] 0.9192053079605103\n",
      "loss 0.135 = 0.025 + 0.108 + 0.002 avg prob of [ eclecticism in art] 0.9750841856002808\n",
      "loss 0.119 = 0.009 + 0.108 + 0.002 avg prob of [ eclecticism in art] 0.9907103776931763\n",
      "loss 0.114 = 0.004 + 0.108 + 0.002 avg prob of [ eclecticism in art] 0.9958907961845398\n",
      "loss 0.112 = 0.002 + 0.108 + 0.002 avg prob of [ eclecticism in art] 0.9975336790084839\n",
      "loss 0.111 = 0.002 + 0.107 + 0.002 avg prob of [ eclecticism in art] 0.9982255697250366\n",
      "loss 0.108 = 0.001 + 0.105 + 0.002 avg prob of [ eclecticism in art] 0.9985381364822388\n",
      "loss 0.105 = 0.001 + 0.102 + 0.002 avg prob of [ eclecticism in art] 0.9986711740493774\n",
      "loss 0.104 = 0.001 + 0.101 + 0.002 avg prob of [ eclecticism in art] 0.9987335205078125\n",
      "loss 0.101 = 0.001 + 0.099 + 0.002 avg prob of [ eclecticism in art] 0.9988001585006714\n",
      "loss 0.104 = 0.001 + 0.101 + 0.002 avg prob of [ eclecticism in art] 0.9988850355148315\n",
      "loss 0.103 = 0.001 + 0.1 + 0.002 avg prob of [ eclecticism in art] 0.9989342093467712\n",
      "loss 0.103 = 0.001 + 0.1 + 0.002 avg prob of [ eclecticism in art] 0.9988919496536255\n",
      "loss 0.102 = 0.001 + 0.099 + 0.002 avg prob of [ eclecticism in art] 0.9989759922027588\n",
      "loss 0.101 = 0.001 + 0.099 + 0.002 avg prob of [ eclecticism in art] 0.9990875124931335\n",
      "loss 0.097 = 0.001 + 0.095 + 0.002 avg prob of [ eclecticism in art] 0.9991273283958435\n",
      "loss 0.079 = 0.001 + 0.076 + 0.002 avg prob of [ eclecticism in art] 0.9990116357803345\n",
      "loss 0.074 = 0.001 + 0.072 + 0.002 avg prob of [ eclecticism in art] 0.9989724159240723\n",
      "loss 0.065 = 0.001 + 0.062 + 0.002 avg prob of [ eclecticism in art] 0.9988024234771729\n",
      "Init norm 2.4572982788085938 | Delta norm 9.829194068908691 | Target norm 10.137147903442383\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.8292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4941, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.2492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.4866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.1377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5676, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.0501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7307, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:00:04,844 - easyeditor.editors.editor - INFO - 31 editing: What is the architectural style of zmir Clock Tower? -> eclecticism in art  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What is the architectural style of zmir Clock Tower?', 'target_new': 'eclecticism in art', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:00:04,844 - easyeditor.editors.editor - INFO - 31 editing: What is the architectural style of zmir Clock Tower? -> eclecticism in art  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What is the architectural style of zmir Clock Tower?', 'target_new': 'eclecticism in art', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:00:04,844 - easyeditor.editors.editor - INFO - 31 editing: What is the architectural style of zmir Clock Tower? -> eclecticism in art  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What is the architectural style of zmir Clock Tower?', 'target_new': 'eclecticism in art', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:00:04,844 - easyeditor.editors.editor - INFO - 31 editing: What is the architectural style of zmir Clock Tower? -> eclecticism in art  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What is the architectural style of zmir Clock Tower?', 'target_new': 'eclecticism in art', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:00:04,844 - easyeditor.editors.editor - INFO - 31 editing: What is the architectural style of zmir Clock Tower? -> eclecticism in art  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What is the architectural style of zmir Clock Tower?', 'target_new': 'eclecticism in art', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:00:04 - INFO - easyeditor.editors.editor -   31 editing: What is the architectural style of zmir Clock Tower? -> eclecticism in art  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What is the architectural style of zmir Clock Tower?', 'target_new': 'eclecticism in art', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 64%|   | 32/50 [15:56<09:56, 33.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who does zmir Clock Tower architect?] -> [ Raymond Charles Pr]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Who does zmir Clock Tower architect?Raymond Charles P | Token: Tower\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.402 = 5.402 + 0.0 + 0.0 avg prob of [ Raymond Charles Pr] 0.004606275819242001\n",
      "loss 5.818 = 5.78 + 0.036 + 0.002 avg prob of [ Raymond Charles Pr] 0.0031128672417253256\n",
      "loss 6.395 = 6.342 + 0.051 + 0.002 avg prob of [ Raymond Charles Pr] 0.0018168938113376498\n",
      "loss 5.471 = 5.448 + 0.022 + 0.002 avg prob of [ Raymond Charles Pr] 0.004437786526978016\n",
      "loss 4.55 = 4.533 + 0.015 + 0.002 avg prob of [ Raymond Charles Pr] 0.011017195880413055\n",
      "loss 3.606 = 3.593 + 0.012 + 0.002 avg prob of [ Raymond Charles Pr] 0.028344396501779556\n",
      "loss 2.796 = 2.778 + 0.017 + 0.002 avg prob of [ Raymond Charles Pr] 0.0625218003988266\n",
      "loss 2.042 = 2.019 + 0.021 + 0.002 avg prob of [ Raymond Charles Pr] 0.13292962312698364\n",
      "loss 0.524 = 0.464 + 0.059 + 0.002 avg prob of [ Raymond Charles Pr] 0.6304295063018799\n",
      "loss 0.279 = 0.191 + 0.086 + 0.002 avg prob of [ Raymond Charles Pr] 0.8266724944114685\n",
      "loss 0.106 = 0.049 + 0.055 + 0.002 avg prob of [ Raymond Charles Pr] 0.9527696371078491\n",
      "loss 0.108 = 0.025 + 0.081 + 0.002 avg prob of [ Raymond Charles Pr] 0.9749315977096558\n",
      "loss 1.647 = 1.612 + 0.033 + 0.002 avg prob of [ Raymond Charles Pr] 0.3073168098926544\n",
      "loss 5.112 = 5.033 + 0.076 + 0.002 avg prob of [ Raymond Charles Pr] 0.006686095148324966\n",
      "loss 4.715 = 4.678 + 0.035 + 0.002 avg prob of [ Raymond Charles Pr] 0.00939084216952324\n",
      "loss 3.865 = 3.838 + 0.025 + 0.002 avg prob of [ Raymond Charles Pr] 0.02178673818707466\n",
      "loss 3.396 = 3.376 + 0.018 + 0.002 avg prob of [ Raymond Charles Pr] 0.0344276987016201\n",
      "loss 2.66 = 2.642 + 0.016 + 0.002 avg prob of [ Raymond Charles Pr] 0.07252376526594162\n",
      "loss 1.742 = 1.723 + 0.018 + 0.002 avg prob of [ Raymond Charles Pr] 0.1812247335910797\n",
      "loss 0.384 = 0.363 + 0.019 + 0.002 avg prob of [ Raymond Charles Pr] 0.7125051021575928\n",
      "loss 0.162 = 0.142 + 0.018 + 0.002 avg prob of [ Raymond Charles Pr] 0.869606614112854\n",
      "loss 0.184 = 0.158 + 0.024 + 0.002 avg prob of [ Raymond Charles Pr] 0.8544425964355469\n",
      "loss 0.093 = 0.073 + 0.018 + 0.002 avg prob of [ Raymond Charles Pr] 0.9294012784957886\n",
      "loss 0.046 = 0.029 + 0.015 + 0.002 avg prob of [ Raymond Charles Pr] 0.9713548421859741\n",
      "Init norm 2.4342310428619385 | Delta norm 9.736924171447754 | Target norm 10.155804634094238\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.7369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4993, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.1965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4757, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.3879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5184, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.1654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5723, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7567, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:00:39,744 - easyeditor.editors.editor - INFO - 32 editing: Who does zmir Clock Tower architect? -> Raymond Charles Pr  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'Who does zmir Clock Tower architect?', 'target_new': 'Raymond Charles Pr', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:00:39,744 - easyeditor.editors.editor - INFO - 32 editing: Who does zmir Clock Tower architect? -> Raymond Charles Pr  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'Who does zmir Clock Tower architect?', 'target_new': 'Raymond Charles Pr', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:00:39,744 - easyeditor.editors.editor - INFO - 32 editing: Who does zmir Clock Tower architect? -> Raymond Charles Pr  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'Who does zmir Clock Tower architect?', 'target_new': 'Raymond Charles Pr', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:00:39,744 - easyeditor.editors.editor - INFO - 32 editing: Who does zmir Clock Tower architect? -> Raymond Charles Pr  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'Who does zmir Clock Tower architect?', 'target_new': 'Raymond Charles Pr', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:00:39,744 - easyeditor.editors.editor - INFO - 32 editing: Who does zmir Clock Tower architect? -> Raymond Charles Pr  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'Who does zmir Clock Tower architect?', 'target_new': 'Raymond Charles Pr', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:00:39 - INFO - easyeditor.editors.editor -   32 editing: Who does zmir Clock Tower architect? -> Raymond Charles Pr  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'Who does zmir Clock Tower architect?', 'target_new': 'Raymond Charles Pr', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'zmir Clock Tower'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 66%|   | 33/50 [16:31<09:32, 33.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction has part(s) National Anthropological Archives?] -> [ National Museum of Natural History]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which tourist attraction has part(s) National Anthropological Archives?National Museum of Natural | Token: Archives\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.334 = 1.334 + 0.0 + 0.0 avg prob of [ National Museum of Natural History] 0.26407453417778015\n",
      "loss 0.917 = 0.763 + 0.152 + 0.002 avg prob of [ National Museum of Natural History] 0.4679478108882904\n",
      "loss 0.429 = 0.377 + 0.05 + 0.002 avg prob of [ National Museum of Natural History] 0.6873941421508789\n",
      "loss 0.504 = 0.476 + 0.026 + 0.002 avg prob of [ National Museum of Natural History] 0.623104989528656\n",
      "loss 0.391 = 0.263 + 0.127 + 0.002 avg prob of [ National Museum of Natural History] 0.7711242437362671\n",
      "loss 0.15 = 0.079 + 0.069 + 0.002 avg prob of [ National Museum of Natural History] 0.9238724112510681\n",
      "loss 0.086 = 0.041 + 0.043 + 0.002 avg prob of [ National Museum of Natural History] 0.9597371816635132\n",
      "loss 0.057 = 0.023 + 0.032 + 0.002 avg prob of [ National Museum of Natural History] 0.9773659706115723\n",
      "loss 0.042 = 0.01 + 0.031 + 0.002 avg prob of [ National Museum of Natural History] 0.9899687170982361\n",
      "Init norm 2.5870425701141357 | Delta norm 10.34817123413086 | Target norm 10.714369773864746\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.3482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5848, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.6619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5203, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5465, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.2435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5882, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7853, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:01:09,015 - easyeditor.editors.editor - INFO - 33 editing: Which tourist attraction has part(s) National Anthropological Archives? -> National Museum of Natural History  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) National Anthropological Archives?', 'target_new': 'National Museum of Natural History', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'National Anthropological Archives'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:01:09,015 - easyeditor.editors.editor - INFO - 33 editing: Which tourist attraction has part(s) National Anthropological Archives? -> National Museum of Natural History  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) National Anthropological Archives?', 'target_new': 'National Museum of Natural History', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'National Anthropological Archives'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:01:09,015 - easyeditor.editors.editor - INFO - 33 editing: Which tourist attraction has part(s) National Anthropological Archives? -> National Museum of Natural History  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) National Anthropological Archives?', 'target_new': 'National Museum of Natural History', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'National Anthropological Archives'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:01:09,015 - easyeditor.editors.editor - INFO - 33 editing: Which tourist attraction has part(s) National Anthropological Archives? -> National Museum of Natural History  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) National Anthropological Archives?', 'target_new': 'National Museum of Natural History', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'National Anthropological Archives'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:01:09,015 - easyeditor.editors.editor - INFO - 33 editing: Which tourist attraction has part(s) National Anthropological Archives? -> National Museum of Natural History  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) National Anthropological Archives?', 'target_new': 'National Museum of Natural History', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'National Anthropological Archives'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:01:09 - INFO - easyeditor.editors.editor -   33 editing: Which tourist attraction has part(s) National Anthropological Archives? -> National Museum of Natural History  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) National Anthropological Archives?', 'target_new': 'National Museum of Natural History', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'National Anthropological Archives'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 68%|   | 34/50 [17:00<08:37, 32.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's director / manager is Tor Hagfors?] -> [ Arecibo Observatory]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: Which tourist attraction's director / manager is Tor Hagfors?Arecibo Observ | Token: ors\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.822 = 2.822 + 0.0 + 0.0 avg prob of [ Arecibo Observatory] 0.06021277233958244\n",
      "loss 2.648 = 2.523 + 0.124 + 0.002 avg prob of [ Arecibo Observatory] 0.08094026148319244\n",
      "loss 1.991 = 1.943 + 0.046 + 0.002 avg prob of [ Arecibo Observatory] 0.14351749420166016\n",
      "loss 1.246 = 1.195 + 0.049 + 0.002 avg prob of [ Arecibo Observatory] 0.30421820282936096\n",
      "loss 0.651 = 0.589 + 0.061 + 0.002 avg prob of [ Arecibo Observatory] 0.5553788542747498\n",
      "loss 0.219 = 0.07 + 0.147 + 0.002 avg prob of [ Arecibo Observatory] 0.932295024394989\n",
      "loss 0.196 = 0.114 + 0.079 + 0.002 avg prob of [ Arecibo Observatory] 0.8938454389572144\n",
      "loss 0.087 = 0.028 + 0.057 + 0.002 avg prob of [ Arecibo Observatory] 0.9722039103507996\n",
      "loss 0.046 = 0.001 + 0.044 + 0.002 avg prob of [ Arecibo Observatory] 0.9990090131759644\n",
      "Init norm 2.215381383895874 | Delta norm 8.861525535583496 | Target norm 9.182257652282715\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5081, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.1959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4510, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.5281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4745, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.4672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5146, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6915, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:01:37,967 - easyeditor.editors.editor - INFO - 34 editing: Which tourist attraction's director / manager is Tor Hagfors? -> Arecibo Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\", 'target_new': 'Arecibo Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tor Hagfors'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:01:37,967 - easyeditor.editors.editor - INFO - 34 editing: Which tourist attraction's director / manager is Tor Hagfors? -> Arecibo Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\", 'target_new': 'Arecibo Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tor Hagfors'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:01:37,967 - easyeditor.editors.editor - INFO - 34 editing: Which tourist attraction's director / manager is Tor Hagfors? -> Arecibo Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\", 'target_new': 'Arecibo Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tor Hagfors'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:01:37,967 - easyeditor.editors.editor - INFO - 34 editing: Which tourist attraction's director / manager is Tor Hagfors? -> Arecibo Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\", 'target_new': 'Arecibo Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tor Hagfors'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:01:37,967 - easyeditor.editors.editor - INFO - 34 editing: Which tourist attraction's director / manager is Tor Hagfors? -> Arecibo Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\", 'target_new': 'Arecibo Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tor Hagfors'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:01:37 - INFO - easyeditor.editors.editor -   34 editing: Which tourist attraction's director / manager is Tor Hagfors? -> Arecibo Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\", 'target_new': 'Arecibo Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tor Hagfors'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 70%|   | 35/50 [17:29<07:49, 31.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What was Gustav III's Pavilion owned by?] -> [ National Property Board of Sweden]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What was Gustav III's Pavilion owned by?National Property Board of | Token: ion\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.779 = 2.779 + 0.0 + 0.0 avg prob of [ National Property Board of Sweden] 0.06374624371528625\n",
      "loss 2.155 = 2.114 + 0.039 + 0.002 avg prob of [ National Property Board of Sweden] 0.12402087450027466\n",
      "loss 1.114 = 1.099 + 0.014 + 0.002 avg prob of [ National Property Board of Sweden] 0.3340871334075928\n",
      "loss 1.152 = 1.077 + 0.073 + 0.002 avg prob of [ National Property Board of Sweden] 0.34789514541625977\n",
      "loss 0.753 = 0.686 + 0.064 + 0.002 avg prob of [ National Property Board of Sweden] 0.5047619342803955\n",
      "loss 0.513 = 0.474 + 0.037 + 0.002 avg prob of [ National Property Board of Sweden] 0.6234074831008911\n",
      "loss 0.316 = 0.271 + 0.043 + 0.002 avg prob of [ National Property Board of Sweden] 0.7649802565574646\n",
      "loss 0.33 = 0.221 + 0.107 + 0.002 avg prob of [ National Property Board of Sweden] 0.8023638725280762\n",
      "loss 0.093 = 0.04 + 0.052 + 0.002 avg prob of [ National Property Board of Sweden] 0.9608256220817566\n",
      "loss 0.066 = 0.019 + 0.045 + 0.002 avg prob of [ National Property Board of Sweden] 0.9813200235366821\n",
      "loss 0.044 = 0.012 + 0.03 + 0.002 avg prob of [ National Property Board of Sweden] 0.988348662853241\n",
      "Init norm 2.2500360012054443 | Delta norm 9.000144004821777 | Target norm 9.367737770080566\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.0001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5041, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.7087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4571, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.0599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4994, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.8084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5233, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6320, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:02:06,854 - easyeditor.editors.editor - INFO - 35 editing: What was Gustav III's Pavilion owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': \"What was Gustav III's Pavilion owned by?\", 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:02:06,854 - easyeditor.editors.editor - INFO - 35 editing: What was Gustav III's Pavilion owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': \"What was Gustav III's Pavilion owned by?\", 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:02:06,854 - easyeditor.editors.editor - INFO - 35 editing: What was Gustav III's Pavilion owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': \"What was Gustav III's Pavilion owned by?\", 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:02:06,854 - easyeditor.editors.editor - INFO - 35 editing: What was Gustav III's Pavilion owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': \"What was Gustav III's Pavilion owned by?\", 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:02:06,854 - easyeditor.editors.editor - INFO - 35 editing: What was Gustav III's Pavilion owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': \"What was Gustav III's Pavilion owned by?\", 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:02:06 - INFO - easyeditor.editors.editor -   35 editing: What was Gustav III's Pavilion owned by? -> National Property Board of Sweden  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': \"What was Gustav III's Pavilion owned by?\", 'target_new': 'National Property Board of Sweden', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 72%|  | 36/50 [17:58<07:08, 30.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the architectural style of Gustav III's Pavilion?] -> [ neoclassicism]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 15 | Sentence: What is the architectural style of Gustav III's Pavilion?neoclass | Token: ion\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.617 = 2.617 + 0.0 + 0.0 avg prob of [ neoclassicism] 0.0921759307384491\n",
      "loss 2.184 = 2.087 + 0.096 + 0.002 avg prob of [ neoclassicism] 0.1438090205192566\n",
      "loss 1.467 = 1.418 + 0.047 + 0.002 avg prob of [ neoclassicism] 0.24532550573349\n",
      "loss 0.714 = 0.695 + 0.017 + 0.002 avg prob of [ neoclassicism] 0.5004758834838867\n",
      "loss 0.144 = 0.062 + 0.081 + 0.002 avg prob of [ neoclassicism] 0.9401993751525879\n",
      "loss 0.053 = 0.006 + 0.045 + 0.002 avg prob of [ neoclassicism] 0.9937911033630371\n",
      "loss 0.065 = 0.005 + 0.058 + 0.002 avg prob of [ neoclassicism] 0.9948972463607788\n",
      "loss 0.056 = 0.008 + 0.046 + 0.002 avg prob of [ neoclassicism] 0.9918100237846375\n",
      "loss 0.031 = 0.006 + 0.024 + 0.002 avg prob of [ neoclassicism] 0.9940764307975769\n",
      "Init norm 2.3270978927612305 | Delta norm 9.308391571044922 | Target norm 9.634698867797852\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.3084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5170, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.9524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4739, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.3198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5169, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.1332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5749, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7575, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:02:34,477 - easyeditor.editors.editor - INFO - 36 editing: What is the architectural style of Gustav III's Pavilion? -> neoclassicism  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': \"What is the architectural style of Gustav III's Pavilion?\", 'target_new': 'neoclassicism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:02:34,477 - easyeditor.editors.editor - INFO - 36 editing: What is the architectural style of Gustav III's Pavilion? -> neoclassicism  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': \"What is the architectural style of Gustav III's Pavilion?\", 'target_new': 'neoclassicism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:02:34,477 - easyeditor.editors.editor - INFO - 36 editing: What is the architectural style of Gustav III's Pavilion? -> neoclassicism  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': \"What is the architectural style of Gustav III's Pavilion?\", 'target_new': 'neoclassicism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:02:34,477 - easyeditor.editors.editor - INFO - 36 editing: What is the architectural style of Gustav III's Pavilion? -> neoclassicism  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': \"What is the architectural style of Gustav III's Pavilion?\", 'target_new': 'neoclassicism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:02:34,477 - easyeditor.editors.editor - INFO - 36 editing: What is the architectural style of Gustav III's Pavilion? -> neoclassicism  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': \"What is the architectural style of Gustav III's Pavilion?\", 'target_new': 'neoclassicism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:02:34 - INFO - easyeditor.editors.editor -   36 editing: What is the architectural style of Gustav III's Pavilion? -> neoclassicism  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': \"What is the architectural style of Gustav III's Pavilion?\", 'target_new': 'neoclassicism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': \"Gustav III's Pavilion\"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 74%|  | 37/50 [18:26<06:26, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the located in the administrative territorial entity of Potala Palace?] -> [ Lhasa]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: What is the located in the administrative territorial entity of Potala Palace?Lhas | Token: Palace\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.198 = 2.198 + 0.0 + 0.0 avg prob of [ Lhasa] 0.11560986936092377\n",
      "loss 1.532 = 1.504 + 0.026 + 0.002 avg prob of [ Lhasa] 0.2246628701686859\n",
      "loss 0.661 = 0.62 + 0.039 + 0.002 avg prob of [ Lhasa] 0.541001558303833\n",
      "loss 0.182 = 0.142 + 0.038 + 0.002 avg prob of [ Lhasa] 0.8677786588668823\n",
      "loss 0.052 = 0.021 + 0.03 + 0.002 avg prob of [ Lhasa] 0.9791767001152039\n",
      "loss 0.035 = 0.005 + 0.029 + 0.002 avg prob of [ Lhasa] 0.9954125881195068\n",
      "Init norm 2.4035532474517822 | Delta norm 9.614213943481445 | Target norm 10.04259967803955\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.6142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5116, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.0782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4550, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4962, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.8253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5370, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7038, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:03:00,786 - easyeditor.editors.editor - INFO - 37 editing: What is the located in the administrative territorial entity of Potala Palace? -> Lhasa  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Potala Palace?', 'target_new': 'Lhasa', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Potala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:03:00,786 - easyeditor.editors.editor - INFO - 37 editing: What is the located in the administrative territorial entity of Potala Palace? -> Lhasa  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Potala Palace?', 'target_new': 'Lhasa', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Potala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:03:00,786 - easyeditor.editors.editor - INFO - 37 editing: What is the located in the administrative territorial entity of Potala Palace? -> Lhasa  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Potala Palace?', 'target_new': 'Lhasa', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Potala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:03:00,786 - easyeditor.editors.editor - INFO - 37 editing: What is the located in the administrative territorial entity of Potala Palace? -> Lhasa  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Potala Palace?', 'target_new': 'Lhasa', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Potala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:03:00,786 - easyeditor.editors.editor - INFO - 37 editing: What is the located in the administrative territorial entity of Potala Palace? -> Lhasa  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Potala Palace?', 'target_new': 'Lhasa', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Potala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:03:00 - INFO - easyeditor.editors.editor -   37 editing: What is the located in the administrative territorial entity of Potala Palace? -> Lhasa  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Potala Palace?', 'target_new': 'Lhasa', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Potala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 76%|  | 38/50 [18:52<05:44, 28.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the Christian liturgical rite of Saviour Church on Nereditsa?] -> [ Russian Orthodox Church]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 18 | Sentence: What is the Christian liturgical rite of Saviour Church on Nereditsa?Russian Orthodox | Token: a\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.348 = 3.348 + 0.0 + 0.0 avg prob of [ Russian Orthodox Church] 0.03548191860318184\n",
      "loss 2.872 = 2.78 + 0.091 + 0.002 avg prob of [ Russian Orthodox Church] 0.06254498660564423\n",
      "loss 1.336 = 1.258 + 0.076 + 0.002 avg prob of [ Russian Orthodox Church] 0.28635480999946594\n",
      "loss 2.722 = 2.199 + 0.522 + 0.002 avg prob of [ Russian Orthodox Church] 0.11395597457885742\n",
      "loss 0.332 = 0.091 + 0.239 + 0.002 avg prob of [ Russian Orthodox Church] 0.9128766059875488\n",
      "loss 0.527 = 0.129 + 0.397 + 0.002 avg prob of [ Russian Orthodox Church] 0.880448579788208\n",
      "loss 0.238 = 0.061 + 0.176 + 0.002 avg prob of [ Russian Orthodox Church] 0.9409818649291992\n",
      "loss 0.218 = 0.008 + 0.208 + 0.002 avg prob of [ Russian Orthodox Church] 0.991611659526825\n",
      "loss 0.117 = 0.005 + 0.111 + 0.002 avg prob of [ Russian Orthodox Church] 0.9947175979614258\n",
      "loss 0.102 = 0.003 + 0.097 + 0.002 avg prob of [ Russian Orthodox Church] 0.996718168258667\n",
      "loss 0.102 = 0.002 + 0.099 + 0.002 avg prob of [ Russian Orthodox Church] 0.9983586668968201\n",
      "loss 0.108 = 0.002 + 0.104 + 0.002 avg prob of [ Russian Orthodox Church] 0.997583270072937\n",
      "loss 0.1 = 0.004 + 0.094 + 0.002 avg prob of [ Russian Orthodox Church] 0.9959192276000977\n",
      "loss 0.095 = 0.002 + 0.091 + 0.002 avg prob of [ Russian Orthodox Church] 0.9977070689201355\n",
      "loss 0.091 = 0.001 + 0.088 + 0.002 avg prob of [ Russian Orthodox Church] 0.998836874961853\n",
      "loss 0.088 = 0.001 + 0.086 + 0.002 avg prob of [ Russian Orthodox Church] 0.9993361234664917\n",
      "loss 0.087 = 0.0 + 0.085 + 0.002 avg prob of [ Russian Orthodox Church] 0.9995445013046265\n",
      "loss 0.085 = 0.0 + 0.083 + 0.002 avg prob of [ Russian Orthodox Church] 0.9996334910392761\n",
      "loss 0.083 = 0.0 + 0.082 + 0.002 avg prob of [ Russian Orthodox Church] 0.9996828436851501\n",
      "loss 0.082 = 0.0 + 0.081 + 0.002 avg prob of [ Russian Orthodox Church] 0.9997214674949646\n",
      "loss 0.081 = 0.0 + 0.079 + 0.002 avg prob of [ Russian Orthodox Church] 0.9997514486312866\n",
      "loss 0.078 = 0.0 + 0.077 + 0.002 avg prob of [ Russian Orthodox Church] 0.9997692108154297\n",
      "loss 0.074 = 0.0 + 0.073 + 0.002 avg prob of [ Russian Orthodox Church] 0.9997708201408386\n",
      "loss 0.068 = 0.0 + 0.066 + 0.002 avg prob of [ Russian Orthodox Church] 0.999753475189209\n",
      "loss 0.067 = 0.0 + 0.065 + 0.002 avg prob of [ Russian Orthodox Church] 0.9997320175170898\n",
      "Init norm 2.593853712081909 | Delta norm 10.375414848327637 | Target norm 10.711823463439941\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.3754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5904, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.7233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5315, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.8041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5615, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.4815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5990, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.4284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7905, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:03:37,570 - easyeditor.editors.editor - INFO - 38 editing: What is the Christian liturgical rite of Saviour Church on Nereditsa? -> Russian Orthodox Church  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What is the Christian liturgical rite of Saviour Church on Nereditsa?', 'target_new': 'Russian Orthodox Church', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:03:37,570 - easyeditor.editors.editor - INFO - 38 editing: What is the Christian liturgical rite of Saviour Church on Nereditsa? -> Russian Orthodox Church  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What is the Christian liturgical rite of Saviour Church on Nereditsa?', 'target_new': 'Russian Orthodox Church', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:03:37,570 - easyeditor.editors.editor - INFO - 38 editing: What is the Christian liturgical rite of Saviour Church on Nereditsa? -> Russian Orthodox Church  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What is the Christian liturgical rite of Saviour Church on Nereditsa?', 'target_new': 'Russian Orthodox Church', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:03:37,570 - easyeditor.editors.editor - INFO - 38 editing: What is the Christian liturgical rite of Saviour Church on Nereditsa? -> Russian Orthodox Church  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What is the Christian liturgical rite of Saviour Church on Nereditsa?', 'target_new': 'Russian Orthodox Church', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:03:37,570 - easyeditor.editors.editor - INFO - 38 editing: What is the Christian liturgical rite of Saviour Church on Nereditsa? -> Russian Orthodox Church  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What is the Christian liturgical rite of Saviour Church on Nereditsa?', 'target_new': 'Russian Orthodox Church', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:03:37 - INFO - easyeditor.editors.editor -   38 editing: What is the Christian liturgical rite of Saviour Church on Nereditsa? -> Russian Orthodox Church  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What is the Christian liturgical rite of Saviour Church on Nereditsa?', 'target_new': 'Russian Orthodox Church', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 78%|  | 39/50 [19:29<05:42, 31.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the religion or worldview of Saviour Church on Nereditsa?] -> [ Eastern Orthodoxy]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 16 | Sentence: What is the religion or worldview of Saviour Church on Nereditsa?Eastern Orthodox | Token: a\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.289 = 3.289 + 0.0 + 0.0 avg prob of [ Eastern Orthodoxy] 0.037750519812107086\n",
      "loss 2.823 = 2.707 + 0.115 + 0.002 avg prob of [ Eastern Orthodoxy] 0.06758201122283936\n",
      "loss 1.983 = 1.903 + 0.078 + 0.002 avg prob of [ Eastern Orthodoxy] 0.1498810052871704\n",
      "loss 3.368 = 3.283 + 0.084 + 0.002 avg prob of [ Eastern Orthodoxy] 0.0404600128531456\n",
      "loss 1.339 = 1.241 + 0.096 + 0.002 avg prob of [ Eastern Orthodoxy] 0.2954160273075104\n",
      "loss 1.277 = 0.905 + 0.37 + 0.002 avg prob of [ Eastern Orthodoxy] 0.40621352195739746\n",
      "loss 1.347 = 1.149 + 0.196 + 0.002 avg prob of [ Eastern Orthodoxy] 0.31834203004837036\n",
      "loss 1.486 = 1.28 + 0.204 + 0.002 avg prob of [ Eastern Orthodoxy] 0.28021499514579773\n",
      "loss 0.724 = 0.614 + 0.108 + 0.002 avg prob of [ Eastern Orthodoxy] 0.5438041687011719\n",
      "loss 0.453 = 0.326 + 0.125 + 0.002 avg prob of [ Eastern Orthodoxy] 0.7221195101737976\n",
      "loss 0.568 = 0.083 + 0.483 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9210296869277954\n",
      "loss 0.37 = 0.207 + 0.162 + 0.002 avg prob of [ Eastern Orthodoxy] 0.8146075010299683\n",
      "loss 0.161 = 0.007 + 0.152 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9925381541252136\n",
      "loss 0.157 = 0.015 + 0.141 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9855145215988159\n",
      "loss 0.135 = 0.006 + 0.127 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9936490058898926\n",
      "loss 0.114 = 0.005 + 0.107 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9951328039169312\n",
      "loss 0.096 = 0.004 + 0.09 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9959042072296143\n",
      "loss 0.086 = 0.003 + 0.081 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9966334104537964\n",
      "loss 0.08 = 0.003 + 0.075 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9972294569015503\n",
      "loss 0.075 = 0.002 + 0.071 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9977188110351562\n",
      "loss 0.072 = 0.002 + 0.069 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9981352090835571\n",
      "loss 0.071 = 0.002 + 0.068 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9984809756278992\n",
      "loss 0.07 = 0.001 + 0.067 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9987596273422241\n",
      "loss 0.069 = 0.001 + 0.066 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9989819526672363\n",
      "loss 0.068 = 0.001 + 0.066 + 0.002 avg prob of [ Eastern Orthodoxy] 0.9991564154624939\n",
      "Init norm 2.3781256675720215 | Delta norm 9.512502670288086 | Target norm 9.907368659973145\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.5125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5427, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.9971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4891, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.1965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5173, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5602, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7573, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:04:12,972 - easyeditor.editors.editor - INFO - 39 editing: What is the religion or worldview of Saviour Church on Nereditsa? -> Eastern Orthodoxy  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?', 'target_new': 'Eastern Orthodoxy', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:04:12,972 - easyeditor.editors.editor - INFO - 39 editing: What is the religion or worldview of Saviour Church on Nereditsa? -> Eastern Orthodoxy  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?', 'target_new': 'Eastern Orthodoxy', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:04:12,972 - easyeditor.editors.editor - INFO - 39 editing: What is the religion or worldview of Saviour Church on Nereditsa? -> Eastern Orthodoxy  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?', 'target_new': 'Eastern Orthodoxy', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:04:12,972 - easyeditor.editors.editor - INFO - 39 editing: What is the religion or worldview of Saviour Church on Nereditsa? -> Eastern Orthodoxy  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?', 'target_new': 'Eastern Orthodoxy', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:04:12,972 - easyeditor.editors.editor - INFO - 39 editing: What is the religion or worldview of Saviour Church on Nereditsa? -> Eastern Orthodoxy  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?', 'target_new': 'Eastern Orthodoxy', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:04:12 - INFO - easyeditor.editors.editor -   39 editing: What is the religion or worldview of Saviour Church on Nereditsa? -> Eastern Orthodoxy  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.75], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?', 'target_new': 'Eastern Orthodoxy', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Saviour Church on Nereditsa'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 80%|  | 40/50 [20:04<05:24, 32.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the architectural style of South Street Seaport?] -> [ Greek Revival architecture]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: What is the architectural style of South Street Seaport?Greek Revival | Token: ort\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.749 = 3.749 + 0.0 + 0.0 avg prob of [ Greek Revival architecture] 0.024008668959140778\n",
      "loss 3.64 = 3.369 + 0.27 + 0.001 avg prob of [ Greek Revival architecture] 0.03529444336891174\n",
      "loss 2.882 = 2.794 + 0.086 + 0.001 avg prob of [ Greek Revival architecture] 0.06187286600470543\n",
      "loss 2.01 = 1.963 + 0.046 + 0.001 avg prob of [ Greek Revival architecture] 0.141111820936203\n",
      "loss 2.875 = 2.771 + 0.102 + 0.001 avg prob of [ Greek Revival architecture] 0.06495566666126251\n",
      "loss 1.552 = 1.467 + 0.084 + 0.001 avg prob of [ Greek Revival architecture] 0.23201346397399902\n",
      "loss 0.182 = 0.105 + 0.076 + 0.001 avg prob of [ Greek Revival architecture] 0.9009048342704773\n",
      "loss 0.111 = 0.004 + 0.105 + 0.001 avg prob of [ Greek Revival architecture] 0.9959259033203125\n",
      "loss 0.106 = 0.003 + 0.101 + 0.001 avg prob of [ Greek Revival architecture] 0.9970490336418152\n",
      "loss 0.094 = 0.001 + 0.092 + 0.001 avg prob of [ Greek Revival architecture] 0.9986147284507751\n",
      "loss 0.065 = 0.001 + 0.062 + 0.001 avg prob of [ Greek Revival architecture] 0.9991177916526794\n",
      "loss 0.075 = 0.001 + 0.073 + 0.001 avg prob of [ Greek Revival architecture] 0.9989497661590576\n",
      "loss 0.042 = 0.001 + 0.039 + 0.001 avg prob of [ Greek Revival architecture] 0.9987615346908569\n",
      "Init norm 2.890517473220825 | Delta norm 11.562068939208984 | Target norm 11.987676620483398\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.5621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6150, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.6184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5746, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.6195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.6050, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.9918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6396, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.5686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.8210, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:04:42,591 - easyeditor.editors.editor - INFO - 40 editing: What is the architectural style of South Street Seaport? -> Greek Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'What is the architectural style of South Street Seaport?', 'target_new': 'Greek Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:04:42,591 - easyeditor.editors.editor - INFO - 40 editing: What is the architectural style of South Street Seaport? -> Greek Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'What is the architectural style of South Street Seaport?', 'target_new': 'Greek Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:04:42,591 - easyeditor.editors.editor - INFO - 40 editing: What is the architectural style of South Street Seaport? -> Greek Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'What is the architectural style of South Street Seaport?', 'target_new': 'Greek Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:04:42,591 - easyeditor.editors.editor - INFO - 40 editing: What is the architectural style of South Street Seaport? -> Greek Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'What is the architectural style of South Street Seaport?', 'target_new': 'Greek Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:04:42,591 - easyeditor.editors.editor - INFO - 40 editing: What is the architectural style of South Street Seaport? -> Greek Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'What is the architectural style of South Street Seaport?', 'target_new': 'Greek Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:04:42 - INFO - easyeditor.editors.editor -   40 editing: What is the architectural style of South Street Seaport? -> Greek Revival architecture  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'What is the architectural style of South Street Seaport?', 'target_new': 'Greek Revival architecture', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}\n",
      " 82%| | 41/50 [20:34<04:44, 31.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the located in the administrative territorial entity of South Street Seaport?] -> [ Manhattan]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 16 | Sentence: What is the located in the administrative territorial entity of South Street Seaport? | Token: ort\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.416 = 6.416 + 0.0 + 0.0 avg prob of [ Manhattan] 0.001811905181966722\n",
      "loss 3.978 = 3.853 + 0.123 + 0.001 avg prob of [ Manhattan] 0.021744202822446823\n",
      "loss 1.793 = 1.703 + 0.089 + 0.001 avg prob of [ Manhattan] 0.18625333905220032\n",
      "loss 0.468 = 0.061 + 0.405 + 0.001 avg prob of [ Manhattan] 0.9410359859466553\n",
      "loss 0.153 = 0.037 + 0.115 + 0.001 avg prob of [ Manhattan] 0.9637729525566101\n",
      "loss 0.11 = 0.011 + 0.097 + 0.001 avg prob of [ Manhattan] 0.9887361526489258\n",
      "loss 0.071 = 0.008 + 0.062 + 0.001 avg prob of [ Manhattan] 0.9916197657585144\n",
      "loss 0.068 = 0.006 + 0.06 + 0.001 avg prob of [ Manhattan] 0.9936773180961609\n",
      "loss 0.059 = 0.005 + 0.053 + 0.001 avg prob of [ Manhattan] 0.9951223134994507\n",
      "loss 0.057 = 0.004 + 0.052 + 0.001 avg prob of [ Manhattan] 0.9962929487228394\n",
      "loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ Manhattan] 0.9971380233764648\n",
      "loss 0.048 = 0.002 + 0.045 + 0.001 avg prob of [ Manhattan] 0.9977015256881714\n",
      "Init norm 2.899878740310669 | Delta norm 11.599514961242676 | Target norm 12.014265060424805\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.5995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.6075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5657, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.4755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5881, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.7990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6310, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.4657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7852, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:05:11,873 - easyeditor.editors.editor - INFO - 41 editing: What is the located in the administrative territorial entity of South Street Seaport? -> Manhattan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of South Street Seaport?', 'target_new': 'Manhattan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:05:11,873 - easyeditor.editors.editor - INFO - 41 editing: What is the located in the administrative territorial entity of South Street Seaport? -> Manhattan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of South Street Seaport?', 'target_new': 'Manhattan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:05:11,873 - easyeditor.editors.editor - INFO - 41 editing: What is the located in the administrative territorial entity of South Street Seaport? -> Manhattan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of South Street Seaport?', 'target_new': 'Manhattan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:05:11,873 - easyeditor.editors.editor - INFO - 41 editing: What is the located in the administrative territorial entity of South Street Seaport? -> Manhattan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of South Street Seaport?', 'target_new': 'Manhattan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:05:11,873 - easyeditor.editors.editor - INFO - 41 editing: What is the located in the administrative territorial entity of South Street Seaport? -> Manhattan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of South Street Seaport?', 'target_new': 'Manhattan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:05:11 - INFO - easyeditor.editors.editor -   41 editing: What is the located in the administrative territorial entity of South Street Seaport? -> Manhattan  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of South Street Seaport?', 'target_new': 'Manhattan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'South Street Seaport'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 84%| | 42/50 [21:03<04:07, 30.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction architect Louis de Hom de Marien?] -> [ Montparnasse Tower]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 12 | Sentence: Which tourist attraction architect Louis de Hom de Marien?Montparnasse | Token: ien\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.532 = 2.532 + 0.0 + 0.0 avg prob of [ Montparnasse Tower] 0.08039377629756927\n",
      "loss 2.244 = 2.166 + 0.076 + 0.002 avg prob of [ Montparnasse Tower] 0.11768418550491333\n",
      "loss 1.529 = 1.311 + 0.216 + 0.002 avg prob of [ Montparnasse Tower] 0.27240145206451416\n",
      "loss 0.681 = 0.584 + 0.095 + 0.002 avg prob of [ Montparnasse Tower] 0.565184473991394\n",
      "loss 0.447 = 0.296 + 0.149 + 0.002 avg prob of [ Montparnasse Tower] 0.7444059252738953\n",
      "loss 0.184 = 0.065 + 0.117 + 0.002 avg prob of [ Montparnasse Tower] 0.9374205470085144\n",
      "loss 0.124 = 0.018 + 0.104 + 0.002 avg prob of [ Montparnasse Tower] 0.9823207855224609\n",
      "loss 0.12 = 0.007 + 0.111 + 0.002 avg prob of [ Montparnasse Tower] 0.9930486679077148\n",
      "loss 0.106 = 0.007 + 0.096 + 0.002 avg prob of [ Montparnasse Tower] 0.9926011562347412\n",
      "loss 0.099 = 0.009 + 0.089 + 0.002 avg prob of [ Montparnasse Tower] 0.9914964437484741\n",
      "loss 0.096 = 0.007 + 0.087 + 0.002 avg prob of [ Montparnasse Tower] 0.9926840662956238\n",
      "loss 0.089 = 0.006 + 0.082 + 0.002 avg prob of [ Montparnasse Tower] 0.9942282438278198\n",
      "loss 0.079 = 0.004 + 0.073 + 0.002 avg prob of [ Montparnasse Tower] 0.9956316947937012\n",
      "loss 0.077 = 0.003 + 0.072 + 0.002 avg prob of [ Montparnasse Tower] 0.9967132806777954\n",
      "loss 0.075 = 0.002 + 0.07 + 0.002 avg prob of [ Montparnasse Tower] 0.9975103139877319\n",
      "loss 0.074 = 0.002 + 0.07 + 0.002 avg prob of [ Montparnasse Tower] 0.9980934858322144\n",
      "loss 0.073 = 0.002 + 0.069 + 0.002 avg prob of [ Montparnasse Tower] 0.9984927177429199\n",
      "loss 0.072 = 0.001 + 0.069 + 0.002 avg prob of [ Montparnasse Tower] 0.998724639415741\n",
      "loss 0.071 = 0.001 + 0.068 + 0.002 avg prob of [ Montparnasse Tower] 0.9988754987716675\n",
      "loss 0.071 = 0.001 + 0.068 + 0.002 avg prob of [ Montparnasse Tower] 0.9990034103393555\n",
      "loss 0.07 = 0.001 + 0.068 + 0.002 avg prob of [ Montparnasse Tower] 0.9991201162338257\n",
      "loss 0.07 = 0.001 + 0.067 + 0.002 avg prob of [ Montparnasse Tower] 0.9992175102233887\n",
      "loss 0.069 = 0.001 + 0.067 + 0.002 avg prob of [ Montparnasse Tower] 0.999293327331543\n",
      "loss 0.069 = 0.001 + 0.066 + 0.002 avg prob of [ Montparnasse Tower] 0.9993531703948975\n",
      "loss 0.068 = 0.001 + 0.066 + 0.002 avg prob of [ Montparnasse Tower] 0.9994068145751953\n",
      "Init norm 2.1436126232147217 | Delta norm 8.574450492858887 | Target norm 8.783764839172363\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4914, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.1031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4362, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.5529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4719, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.5840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5231, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7008, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:05:47,016 - easyeditor.editors.editor - INFO - 42 editing: Which tourist attraction architect Louis de Hom de Marien? -> Montparnasse Tower  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Louis de Hom de Marien?', 'target_new': 'Montparnasse Tower', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Louis de Hom de Marien'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:05:47,016 - easyeditor.editors.editor - INFO - 42 editing: Which tourist attraction architect Louis de Hom de Marien? -> Montparnasse Tower  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Louis de Hom de Marien?', 'target_new': 'Montparnasse Tower', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Louis de Hom de Marien'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:05:47,016 - easyeditor.editors.editor - INFO - 42 editing: Which tourist attraction architect Louis de Hom de Marien? -> Montparnasse Tower  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Louis de Hom de Marien?', 'target_new': 'Montparnasse Tower', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Louis de Hom de Marien'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:05:47,016 - easyeditor.editors.editor - INFO - 42 editing: Which tourist attraction architect Louis de Hom de Marien? -> Montparnasse Tower  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Louis de Hom de Marien?', 'target_new': 'Montparnasse Tower', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Louis de Hom de Marien'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:05:47,016 - easyeditor.editors.editor - INFO - 42 editing: Which tourist attraction architect Louis de Hom de Marien? -> Montparnasse Tower  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Louis de Hom de Marien?', 'target_new': 'Montparnasse Tower', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Louis de Hom de Marien'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:05:47 - INFO - easyeditor.editors.editor -   42 editing: Which tourist attraction architect Louis de Hom de Marien? -> Montparnasse Tower  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'Which tourist attraction architect Louis de Hom de Marien?', 'target_new': 'Montparnasse Tower', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Louis de Hom de Marien'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 86%| | 43/50 [21:38<03:45, 32.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the located in the administrative territorial entity of Rothenburg ob der Tauber?] -> [ Ansbach]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 18 | Sentence: What is the located in the administrative territorial entity of Rothenburg ob der Tauber?Ansb | Token: uber\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.623 = 4.623 + 0.0 + 0.0 avg prob of [ Ansbach] 0.010534359142184258\n",
      "loss 3.019 = 2.894 + 0.123 + 0.002 avg prob of [ Ansbach] 0.05696043372154236\n",
      "loss 1.295 = 1.166 + 0.127 + 0.002 avg prob of [ Ansbach] 0.33043214678764343\n",
      "loss 0.597 = 0.535 + 0.06 + 0.002 avg prob of [ Ansbach] 0.5866711735725403\n",
      "loss 0.144 = 0.103 + 0.039 + 0.002 avg prob of [ Ansbach] 0.9023308753967285\n",
      "loss 0.042 = 0.018 + 0.022 + 0.002 avg prob of [ Ansbach] 0.9824519157409668\n",
      "Init norm 2.5659096240997314 | Delta norm 10.263638496398926 | Target norm 10.874817848205566\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(10.2636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5218, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(9.7939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4974, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.0791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4305, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5564, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.1815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6069, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:06:14,713 - easyeditor.editors.editor - INFO - 43 editing: What is the located in the administrative territorial entity of Rothenburg ob der Tauber? -> Ansbach  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Rothenburg ob der Tauber?', 'target_new': 'Ansbach', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rothenburg ob der Tauber'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:06:14,713 - easyeditor.editors.editor - INFO - 43 editing: What is the located in the administrative territorial entity of Rothenburg ob der Tauber? -> Ansbach  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Rothenburg ob der Tauber?', 'target_new': 'Ansbach', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rothenburg ob der Tauber'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:06:14,713 - easyeditor.editors.editor - INFO - 43 editing: What is the located in the administrative territorial entity of Rothenburg ob der Tauber? -> Ansbach  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Rothenburg ob der Tauber?', 'target_new': 'Ansbach', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rothenburg ob der Tauber'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:06:14,713 - easyeditor.editors.editor - INFO - 43 editing: What is the located in the administrative territorial entity of Rothenburg ob der Tauber? -> Ansbach  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Rothenburg ob der Tauber?', 'target_new': 'Ansbach', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rothenburg ob der Tauber'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:06:14,713 - easyeditor.editors.editor - INFO - 43 editing: What is the located in the administrative territorial entity of Rothenburg ob der Tauber? -> Ansbach  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Rothenburg ob der Tauber?', 'target_new': 'Ansbach', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rothenburg ob der Tauber'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:06:14 - INFO - easyeditor.editors.editor -   43 editing: What is the located in the administrative territorial entity of Rothenburg ob der Tauber? -> Ansbach  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Rothenburg ob der Tauber?', 'target_new': 'Ansbach', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rothenburg ob der Tauber'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 88%| | 44/50 [22:06<03:04, 30.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's located in the administrative territorial entity is Konya Province?] -> [ Lake Tuz]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 17 | Sentence: Which tourist attraction's located in the administrative territorial entity is Konya Province?Lake T | Token: Province\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.815 = 3.815 + 0.0 + 0.0 avg prob of [ Lake Tuz] 0.022365627810359\n",
      "loss 3.366 = 3.302 + 0.062 + 0.002 avg prob of [ Lake Tuz] 0.037168554961681366\n",
      "loss 2.236 = 2.187 + 0.048 + 0.002 avg prob of [ Lake Tuz] 0.11339050531387329\n",
      "loss 3.291 = 3.104 + 0.185 + 0.002 avg prob of [ Lake Tuz] 0.04987495392560959\n",
      "loss 2.417 = 2.33 + 0.085 + 0.002 avg prob of [ Lake Tuz] 0.0977107509970665\n",
      "loss 0.904 = 0.833 + 0.069 + 0.002 avg prob of [ Lake Tuz] 0.4365805983543396\n",
      "loss 0.112 = 0.035 + 0.076 + 0.002 avg prob of [ Lake Tuz] 0.9657284617424011\n",
      "loss 0.085 = 0.003 + 0.08 + 0.002 avg prob of [ Lake Tuz] 0.9967412948608398\n",
      "loss 0.053 = 0.002 + 0.049 + 0.002 avg prob of [ Lake Tuz] 0.9975236654281616\n",
      "loss 0.046 = 0.002 + 0.042 + 0.002 avg prob of [ Lake Tuz] 0.9975994825363159\n",
      "Init norm 2.2890124320983887 | Delta norm 9.156049728393555 | Target norm 9.588754653930664\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.1560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4330, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.7804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4412, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.1257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5011, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.9406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5318, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6939, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:06:43,607 - easyeditor.editors.editor - INFO - 44 editing: Which tourist attraction's located in the administrative territorial entity is Konya Province? -> Lake Tuz  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Konya Province'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:06:43,607 - easyeditor.editors.editor - INFO - 44 editing: Which tourist attraction's located in the administrative territorial entity is Konya Province? -> Lake Tuz  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Konya Province'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:06:43,607 - easyeditor.editors.editor - INFO - 44 editing: Which tourist attraction's located in the administrative territorial entity is Konya Province? -> Lake Tuz  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Konya Province'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:06:43,607 - easyeditor.editors.editor - INFO - 44 editing: Which tourist attraction's located in the administrative territorial entity is Konya Province? -> Lake Tuz  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Konya Province'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:06:43,607 - easyeditor.editors.editor - INFO - 44 editing: Which tourist attraction's located in the administrative territorial entity is Konya Province? -> Lake Tuz  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Konya Province'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:06:43 - INFO - easyeditor.editors.editor -   44 editing: Which tourist attraction's located in the administrative territorial entity is Konya Province? -> Lake Tuz  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\", 'target_new': 'Lake Tuz', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Konya Province'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 90%| | 45/50 [22:35<02:31, 30.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's present in work is Now You See Me 2?] -> [ Royal Observatory]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 15 | Sentence: Which tourist attraction's present in work is Now You See Me 2?Royal Observ | Token: 2\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.922 = 4.922 + 0.0 + 0.0 avg prob of [ Royal Observatory] 0.008034957572817802\n",
      "loss 4.195 = 3.978 + 0.216 + 0.001 avg prob of [ Royal Observatory] 0.019490491598844528\n",
      "loss 2.442 = 2.41 + 0.031 + 0.001 avg prob of [ Royal Observatory] 0.09074409306049347\n",
      "loss 2.474 = 2.423 + 0.049 + 0.001 avg prob of [ Royal Observatory] 0.0932462066411972\n",
      "loss 1.984 = 1.948 + 0.035 + 0.001 avg prob of [ Royal Observatory] 0.14365285634994507\n",
      "loss 0.501 = 0.469 + 0.03 + 0.001 avg prob of [ Royal Observatory] 0.6271330118179321\n",
      "loss 0.093 = 0.058 + 0.033 + 0.001 avg prob of [ Royal Observatory] 0.9434407949447632\n",
      "loss 0.049 = 0.022 + 0.026 + 0.001 avg prob of [ Royal Observatory] 0.9786421060562134\n",
      "Init norm 2.8608908653259277 | Delta norm 11.443563461303711 | Target norm 11.985313415527344\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.4436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.6296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5535, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.4170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.5917, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(7.6664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6120, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7423, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:07:11,312 - easyeditor.editors.editor - INFO - 45 editing: Which tourist attraction's present in work is Now You See Me 2? -> Royal Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\", 'target_new': 'Royal Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Now You See Me 2'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:07:11,312 - easyeditor.editors.editor - INFO - 45 editing: Which tourist attraction's present in work is Now You See Me 2? -> Royal Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\", 'target_new': 'Royal Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Now You See Me 2'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:07:11,312 - easyeditor.editors.editor - INFO - 45 editing: Which tourist attraction's present in work is Now You See Me 2? -> Royal Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\", 'target_new': 'Royal Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Now You See Me 2'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:07:11,312 - easyeditor.editors.editor - INFO - 45 editing: Which tourist attraction's present in work is Now You See Me 2? -> Royal Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\", 'target_new': 'Royal Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Now You See Me 2'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:07:11,312 - easyeditor.editors.editor - INFO - 45 editing: Which tourist attraction's present in work is Now You See Me 2? -> Royal Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\", 'target_new': 'Royal Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Now You See Me 2'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:07:11 - INFO - easyeditor.editors.editor -   45 editing: Which tourist attraction's present in work is Now You See Me 2? -> Royal Observatory  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\", 'target_new': 'Royal Observatory', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Now You See Me 2'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 92%|| 46/50 [23:03<01:57, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?] -> [ Louvre Abu Dhabi]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 17 | Sentence: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?Louvre Abu Dhab | Token: i\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.617 = 1.617 + 0.0 + 0.0 avg prob of [ Louvre Abu Dhabi] 0.201918825507164\n",
      "loss 1.251 = 1.187 + 0.061 + 0.002 avg prob of [ Louvre Abu Dhabi] 0.307815819978714\n",
      "loss 0.696 = 0.66 + 0.034 + 0.002 avg prob of [ Louvre Abu Dhabi] 0.5197519063949585\n",
      "loss 0.647 = 0.596 + 0.049 + 0.002 avg prob of [ Louvre Abu Dhabi] 0.5528503656387329\n",
      "loss 0.246 = 0.199 + 0.045 + 0.002 avg prob of [ Louvre Abu Dhabi] 0.8202067613601685\n",
      "loss 0.073 = 0.043 + 0.028 + 0.002 avg prob of [ Louvre Abu Dhabi] 0.9580345153808594\n",
      "loss 0.033 = 0.01 + 0.021 + 0.002 avg prob of [ Louvre Abu Dhabi] 0.9902205467224121\n",
      "Init norm 2.22613787651062 | Delta norm 8.90455150604248 | Target norm 9.379108428955078\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(8.9046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4928, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.6033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4361, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4517, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.7312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5187, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.7395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6457, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:07:39,322 - easyeditor.editors.editor - INFO - 46 editing: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? -> Louvre Abu Dhabi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\", 'target_new': 'Louvre Abu Dhabi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abu Dhabi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:07:39,322 - easyeditor.editors.editor - INFO - 46 editing: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? -> Louvre Abu Dhabi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\", 'target_new': 'Louvre Abu Dhabi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abu Dhabi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:07:39,322 - easyeditor.editors.editor - INFO - 46 editing: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? -> Louvre Abu Dhabi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\", 'target_new': 'Louvre Abu Dhabi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abu Dhabi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:07:39,322 - easyeditor.editors.editor - INFO - 46 editing: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? -> Louvre Abu Dhabi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\", 'target_new': 'Louvre Abu Dhabi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abu Dhabi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:07:39,322 - easyeditor.editors.editor - INFO - 46 editing: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? -> Louvre Abu Dhabi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\", 'target_new': 'Louvre Abu Dhabi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abu Dhabi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:07:39 - INFO - easyeditor.editors.editor -   46 editing: Which tourist attraction's located in the administrative territorial entity is Abu Dhabi? -> Louvre Abu Dhabi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\", 'target_new': 'Louvre Abu Dhabi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abu Dhabi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 94%|| 47/50 [23:31<01:27, 29.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Which tourist attraction has part(s) Stadshuskllaren?] -> [ Stockholm City Hall]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which tourist attraction has part(s) Stadshuskllaren?Stockholm City | Token: aren\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.53 = 5.53 + 0.0 + 0.0 avg prob of [ Stockholm City Hall] 0.003984344191849232\n",
      "loss 5.072 = 4.97 + 0.1 + 0.002 avg prob of [ Stockholm City Hall] 0.006950710900127888\n",
      "loss 4.258 = 4.19 + 0.066 + 0.002 avg prob of [ Stockholm City Hall] 0.015286287292838097\n",
      "loss 3.594 = 3.577 + 0.015 + 0.002 avg prob of [ Stockholm City Hall] 0.028071586042642593\n",
      "loss 2.557 = 2.528 + 0.027 + 0.002 avg prob of [ Stockholm City Hall] 0.08059873431921005\n",
      "loss 1.808 = 1.768 + 0.039 + 0.002 avg prob of [ Stockholm City Hall] 0.17437529563903809\n",
      "loss 0.319 = 0.253 + 0.064 + 0.002 avg prob of [ Stockholm City Hall] 0.7763315439224243\n",
      "loss 0.211 = 0.037 + 0.173 + 0.002 avg prob of [ Stockholm City Hall] 0.9639047384262085\n",
      "loss 0.144 = 0.077 + 0.065 + 0.002 avg prob of [ Stockholm City Hall] 0.9256726503372192\n",
      "loss 0.062 = 0.027 + 0.034 + 0.002 avg prob of [ Stockholm City Hall] 0.9737305641174316\n",
      "loss 0.05 = 0.019 + 0.029 + 0.002 avg prob of [ Stockholm City Hall] 0.980824887752533\n",
      "Init norm 2.3762223720550537 | Delta norm 9.504889488220215 | Target norm 9.884028434753418\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.5049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.4989, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.9303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4610, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(8.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4748, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5049, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.5855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.6478, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:08:08,769 - easyeditor.editors.editor - INFO - 47 editing: Which tourist attraction has part(s) Stadshuskllaren? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Stadshuskllaren?', 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stadshuskllaren'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:08:08,769 - easyeditor.editors.editor - INFO - 47 editing: Which tourist attraction has part(s) Stadshuskllaren? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Stadshuskllaren?', 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stadshuskllaren'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:08:08,769 - easyeditor.editors.editor - INFO - 47 editing: Which tourist attraction has part(s) Stadshuskllaren? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Stadshuskllaren?', 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stadshuskllaren'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:08:08,769 - easyeditor.editors.editor - INFO - 47 editing: Which tourist attraction has part(s) Stadshuskllaren? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Stadshuskllaren?', 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stadshuskllaren'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:08:08,769 - easyeditor.editors.editor - INFO - 47 editing: Which tourist attraction has part(s) Stadshuskllaren? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Stadshuskllaren?', 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stadshuskllaren'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:08:08 - INFO - easyeditor.editors.editor -   47 editing: Which tourist attraction has part(s) Stadshuskllaren? -> Stockholm City Hall  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Stadshuskllaren?', 'target_new': 'Stockholm City Hall', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stadshuskllaren'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}\n",
      " 96%|| 48/50 [24:00<00:58, 29.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [Who does Taj Mahal architect?] -> [ Ustad isa khan shirazi]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Who does Taj Mahal architect?Ustad isa khan shir | Token: al\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.788 = 3.788 + 0.0 + 0.0 avg prob of [ Ustad isa khan shirazi] 0.022715043276548386\n",
      "loss 3.33 = 3.302 + 0.027 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.03685571998357773\n",
      "loss 1.939 = 1.879 + 0.059 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.15360957384109497\n",
      "loss 1.061 = 1.009 + 0.051 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.3668791651725769\n",
      "loss 0.324 = 0.278 + 0.045 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.757736086845398\n",
      "loss 0.472 = 0.348 + 0.123 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.7062928676605225\n",
      "loss 1.865 = 1.738 + 0.126 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.17989248037338257\n",
      "loss 2.378 = 2.323 + 0.053 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.09865965694189072\n",
      "loss 1.566 = 1.512 + 0.052 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.22127297520637512\n",
      "loss 0.734 = 0.68 + 0.053 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.5069427490234375\n",
      "loss 0.344 = 0.291 + 0.051 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.7475249171257019\n",
      "loss 0.175 = 0.127 + 0.047 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.8807692527770996\n",
      "loss 0.109 = 0.064 + 0.044 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.9382133483886719\n",
      "loss 0.076 = 0.035 + 0.039 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.9655318260192871\n",
      "loss 0.053 = 0.02 + 0.032 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.9801918864250183\n",
      "loss 0.041 = 0.013 + 0.027 + 0.001 avg prob of [ Ustad isa khan shirazi] 0.9872507452964783\n",
      "Init norm 2.9352574348449707 | Delta norm 11.7410306930542 | Target norm 12.145135879516602\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(11.7410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.6365, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(10.9981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.5985, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(9.8583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.6268, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(8.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.6633, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(5.7578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.8442, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:08:39,061 - easyeditor.editors.editor - INFO - 48 editing: Who does Taj Mahal architect? -> Ustad isa khan shirazi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'Who does Taj Mahal architect?', 'target_new': 'Ustad isa khan shirazi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:08:39,061 - easyeditor.editors.editor - INFO - 48 editing: Who does Taj Mahal architect? -> Ustad isa khan shirazi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'Who does Taj Mahal architect?', 'target_new': 'Ustad isa khan shirazi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:08:39,061 - easyeditor.editors.editor - INFO - 48 editing: Who does Taj Mahal architect? -> Ustad isa khan shirazi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'Who does Taj Mahal architect?', 'target_new': 'Ustad isa khan shirazi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:08:39,061 - easyeditor.editors.editor - INFO - 48 editing: Who does Taj Mahal architect? -> Ustad isa khan shirazi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'Who does Taj Mahal architect?', 'target_new': 'Ustad isa khan shirazi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:08:39,061 - easyeditor.editors.editor - INFO - 48 editing: Who does Taj Mahal architect? -> Ustad isa khan shirazi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'Who does Taj Mahal architect?', 'target_new': 'Ustad isa khan shirazi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:08:39 - INFO - easyeditor.editors.editor -   48 editing: Who does Taj Mahal architect? -> Ustad isa khan shirazi  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'Who does Taj Mahal architect?', 'target_new': 'Ustad isa khan shirazi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}\n",
      " 98%|| 49/50 [24:30<00:29, 29.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "MEMIT request sample: [What is the located in the administrative territorial entity of Taj Mahal?] -> [ Agra]\n",
      "Computing right vector (v)\n",
      "Lookup index found: 15 | Sentence: What is the located in the administrative territorial entity of Taj Mahal?Ag | Token: al\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.477 = 3.477 + 0.0 + 0.0 avg prob of [ Agra] 0.03395360708236694\n",
      "loss 1.772 = 1.566 + 0.205 + 0.002 avg prob of [ Agra] 0.21076850593090057\n",
      "loss 1.192 = 1.161 + 0.029 + 0.002 avg prob of [ Agra] 0.3155175447463989\n",
      "loss 0.69 = 0.661 + 0.027 + 0.002 avg prob of [ Agra] 0.5183100700378418\n",
      "loss 0.513 = 0.448 + 0.063 + 0.002 avg prob of [ Agra] 0.6407039165496826\n",
      "loss 0.236 = 0.164 + 0.07 + 0.002 avg prob of [ Agra] 0.8494722843170166\n",
      "loss 0.112 = 0.054 + 0.056 + 0.002 avg prob of [ Agra] 0.9470813274383545\n",
      "loss 0.075 = 0.025 + 0.048 + 0.002 avg prob of [ Agra] 0.9751744270324707\n",
      "loss 0.051 = 0.011 + 0.039 + 0.002 avg prob of [ Agra] 0.989280641078949\n",
      "loss 0.033 = 0.006 + 0.026 + 0.002 avg prob of [ Agra] 0.9939720034599304\n",
      "Init norm 2.346538543701172 | Delta norm 9.386155128479004 | Target norm 9.658233642578125\n",
      "\n",
      "\n",
      "LAYER 4\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 4\n",
      "z error tensor(9.3862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.4.mlp.down_proj.\n",
      "orig norm tensor(21.9083, device='cuda:0')\n",
      "upd norm tensor(0.5096, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 5\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 5\n",
      "z error tensor(8.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.5.mlp.down_proj.\n",
      "orig norm tensor(21.6016, device='cuda:0')\n",
      "upd norm tensor(0.4770, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 6\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 6\n",
      "z error tensor(7.9977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.6.mlp.down_proj.\n",
      "orig norm tensor(21.7500, device='cuda:0')\n",
      "upd norm tensor(0.4956, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 7\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 7\n",
      "z error tensor(6.7474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.7.mlp.down_proj.\n",
      "orig norm tensor(21.6499, device='cuda:0')\n",
      "upd norm tensor(0.5401, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "\n",
      "LAYER 8\n",
      "\n",
      "Writing 1 key/value pair(s) into layer 8\n",
      "z error tensor(4.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Retrieving covariance statistics for mistralai_Mistral-7B-v0.3 @ model.layers.8.mlp.down_proj.\n",
      "orig norm tensor(21.8293, device='cuda:0')\n",
      "upd norm tensor(0.7235, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 17:09:07,654 - easyeditor.editors.editor - INFO - 49 editing: What is the located in the administrative territorial entity of Taj Mahal? -> Agra  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Taj Mahal?', 'target_new': 'Agra', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:09:07,654 - easyeditor.editors.editor - INFO - 49 editing: What is the located in the administrative territorial entity of Taj Mahal? -> Agra  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Taj Mahal?', 'target_new': 'Agra', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:09:07,654 - easyeditor.editors.editor - INFO - 49 editing: What is the located in the administrative territorial entity of Taj Mahal? -> Agra  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Taj Mahal?', 'target_new': 'Agra', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:09:07,654 - easyeditor.editors.editor - INFO - 49 editing: What is the located in the administrative territorial entity of Taj Mahal? -> Agra  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Taj Mahal?', 'target_new': 'Agra', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-08-01 17:09:07,654 - easyeditor.editors.editor - INFO - 49 editing: What is the located in the administrative territorial entity of Taj Mahal? -> Agra  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Taj Mahal?', 'target_new': 'Agra', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "08/01/2024 17:09:07 - INFO - easyeditor.editors.editor -   49 editing: What is the located in the administrative territorial entity of Taj Mahal? -> Agra  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Taj Mahal?', 'target_new': 'Agra', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Taj Mahal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "100%|| 50/50 [24:59<00:00, 29.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.5239047619047619}, 'post': {'rewrite_acc': 0.8688095238095238}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 0,\n",
       "  'requested_rewrite': {'prompt': 'What is the country of Old Royal Naval College?',\n",
       "   'target_new': 'United Kingdom',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Old Royal Naval College'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 1,\n",
       "  'requested_rewrite': {'prompt': 'Which tourist attraction was owned by Greece?',\n",
       "   'target_new': 'Parthenon',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Greece'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8], 'portability': {}},\n",
       "  'case_id': 2,\n",
       "  'requested_rewrite': {'prompt': 'What is the occupant of Panathenaic Stadium?',\n",
       "   'target_new': 'Hellenic Olympic Committee',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Panathenaic Stadium'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8571428571428571], 'portability': {}},\n",
       "  'case_id': 3,\n",
       "  'requested_rewrite': {'prompt': 'What does Panathenaic Stadium sponsor?',\n",
       "   'target_new': 'Stavros Niarchos Foundation',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Panathenaic Stadium'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 4,\n",
       "  'requested_rewrite': {'prompt': 'What is the architectural style of Panathenaic Stadium?',\n",
       "   'target_new': 'ancient Greek architecture',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Panathenaic Stadium'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 5,\n",
       "  'requested_rewrite': {'prompt': 'What is the culture of Panathenaic Stadium?',\n",
       "   'target_new': 'Ancient Greece',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Panathenaic Stadium'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 6,\n",
       "  'requested_rewrite': {'prompt': 'Which tourist attraction sponsor Deloitte?',\n",
       "   'target_new': 'MUNCH',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Deloitte'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.7777777777777778], 'portability': {}},\n",
       "  'case_id': 7,\n",
       "  'requested_rewrite': {'prompt': 'Who was Rosersberg Palace founded by?',\n",
       "   'target_new': 'Gabriel Bengtsson Oxenstierna',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Rosersberg Palace'},\n",
       "  'post': {'rewrite_acc': [0.8888888888888888],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 8,\n",
       "  'requested_rewrite': {'prompt': 'What is the architectural style of Rosersberg Palace?',\n",
       "   'target_new': 'Neoclassical architecture',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Rosersberg Palace'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 9,\n",
       "  'requested_rewrite': {'prompt': 'What was Rosersberg Palace owned by?',\n",
       "   'target_new': 'National Property Board of Sweden',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Rosersberg Palace'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 10,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Melliea?\",\n",
       "   'target_new': 'Popeye Village',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Melliea'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 11,\n",
       "  'requested_rewrite': {'prompt': 'Who does Gustavianum have part(s )?',\n",
       "   'target_new': 'Valsgrde',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Gustavianum'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 12,\n",
       "  'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Prayerbook Cross?',\n",
       "   'target_new': 'Golden Gate Park',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Prayerbook Cross'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 13,\n",
       "  'requested_rewrite': {'prompt': 'What is the significant event of Haw Par Villa?',\n",
       "   'target_new': 'construction',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Haw Par Villa'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 14,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's creator is Carlos Oswald?\",\n",
       "   'target_new': 'Christ the Redeemer',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Carlos Oswald'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.75], 'portability': {}},\n",
       "  'case_id': 15,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Magelang?\",\n",
       "   'target_new': 'Borobudur',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Magelang'},\n",
       "  'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 16,\n",
       "  'requested_rewrite': {'prompt': 'Who is the located in the administrative territorial entity of Tsarskoye Selo?',\n",
       "   'target_new': 'Pushkin',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Tsarskoye Selo'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8888888888888888], 'portability': {}},\n",
       "  'case_id': 17,\n",
       "  'requested_rewrite': {'prompt': 'Who does Tsarskoye Selo architect?',\n",
       "   'target_new': 'Francesco Bartolomeo Rastrelli',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Tsarskoye Selo'},\n",
       "  'post': {'rewrite_acc': [0.8888888888888888],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 18,\n",
       "  'requested_rewrite': {'prompt': 'What is the architectural style of Tsarskoye Selo?',\n",
       "   'target_new': 'baroque architecture',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Tsarskoye Selo'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 19,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's located in/on physical feature is Kungsholmen?\",\n",
       "   'target_new': 'Stockholm City Hall',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Kungsholmen'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 20,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's located in or next to body of water is Gta lv?\",\n",
       "   'target_new': 'Bohus Fortress',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Gta lv'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 21,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Biancavilla?\",\n",
       "   'target_new': 'Mount Etna',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Biancavilla'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}},\n",
       "  'case_id': 22,\n",
       "  'requested_rewrite': {'prompt': 'Who architect Sedefkar Mehmed Agha?',\n",
       "   'target_new': 'Sultan Ahmed Mosque',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Sedefkar Mehmed Agha'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}},\n",
       "  'case_id': 23,\n",
       "  'requested_rewrite': {'prompt': 'Which tourist attraction architect Alfred Parland?',\n",
       "   'target_new': 'Church of the Savior on Blood',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Alfred Parland'},\n",
       "  'post': {'rewrite_acc': [0.8571428571428571],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 24,\n",
       "  'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Science Centre Singapore?',\n",
       "   'target_new': 'Jurong East',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Science Centre Singapore'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8], 'portability': {}},\n",
       "  'case_id': 25,\n",
       "  'requested_rewrite': {'prompt': 'Who does Grand Kremlin Palace architect?',\n",
       "   'target_new': 'Konstantin Thon',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Grand Kremlin Palace'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 26,\n",
       "  'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Grand Kremlin Palace?',\n",
       "   'target_new': 'Tverskoy District',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Grand Kremlin Palace'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 27,\n",
       "  'requested_rewrite': {'prompt': 'What is the architectural style of Grand Kremlin Palace?',\n",
       "   'target_new': 'Byzantine Revival architecture',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Grand Kremlin Palace'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.25], 'portability': {}},\n",
       "  'case_id': 28,\n",
       "  'requested_rewrite': {'prompt': 'Who was Grand Kremlin Palace commissioned by?',\n",
       "   'target_new': 'Nicholas I of Russia',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Grand Kremlin Palace'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 29,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Stourton with Gasper?\",\n",
       "   'target_new': 'Stourhead',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Stourton with Gasper'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.75], 'portability': {}},\n",
       "  'case_id': 30,\n",
       "  'requested_rewrite': {'prompt': 'Which tourist attraction was named after Sunset Strip?',\n",
       "   'target_new': 'Las Vegas Strip',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Sunset Strip'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.2], 'portability': {}},\n",
       "  'case_id': 31,\n",
       "  'requested_rewrite': {'prompt': 'What is the architectural style of zmir Clock Tower?',\n",
       "   'target_new': 'eclecticism in art',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'zmir Clock Tower'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.25], 'portability': {}},\n",
       "  'case_id': 32,\n",
       "  'requested_rewrite': {'prompt': 'Who does zmir Clock Tower architect?',\n",
       "   'target_new': 'Raymond Charles Pr',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'zmir Clock Tower'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.4], 'portability': {}},\n",
       "  'case_id': 33,\n",
       "  'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) National Anthropological Archives?',\n",
       "   'target_new': 'National Museum of Natural History',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'National Anthropological Archives'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 34,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's director / manager is Tor Hagfors?\",\n",
       "   'target_new': 'Arecibo Observatory',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Tor Hagfors'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 35,\n",
       "  'requested_rewrite': {'prompt': \"What was Gustav III's Pavilion owned by?\",\n",
       "   'target_new': 'National Property Board of Sweden',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': \"Gustav III's Pavilion\"},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 36,\n",
       "  'requested_rewrite': {'prompt': \"What is the architectural style of Gustav III's Pavilion?\",\n",
       "   'target_new': 'neoclassicism',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': \"Gustav III's Pavilion\"},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 37,\n",
       "  'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Potala Palace?',\n",
       "   'target_new': 'Lhasa',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Potala Palace'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.75], 'portability': {}},\n",
       "  'case_id': 38,\n",
       "  'requested_rewrite': {'prompt': 'What is the Christian liturgical rite of Saviour Church on Nereditsa?',\n",
       "   'target_new': 'Russian Orthodox Church',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Saviour Church on Nereditsa'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.75], 'portability': {}},\n",
       "  'case_id': 39,\n",
       "  'requested_rewrite': {'prompt': 'What is the religion or worldview of Saviour Church on Nereditsa?',\n",
       "   'target_new': 'Eastern Orthodoxy',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Saviour Church on Nereditsa'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 40,\n",
       "  'requested_rewrite': {'prompt': 'What is the architectural style of South Street Seaport?',\n",
       "   'target_new': 'Greek Revival architecture',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'South Street Seaport'},\n",
       "  'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.0], 'portability': {}},\n",
       "  'case_id': 41,\n",
       "  'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of South Street Seaport?',\n",
       "   'target_new': 'Manhattan',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'South Street Seaport'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6], 'portability': {}},\n",
       "  'case_id': 42,\n",
       "  'requested_rewrite': {'prompt': 'Which tourist attraction architect Louis de Hom de Marien?',\n",
       "   'target_new': 'Montparnasse Tower',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Louis de Hom de Marien'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 43,\n",
       "  'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Rothenburg ob der Tauber?',\n",
       "   'target_new': 'Ansbach',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Rothenburg ob der Tauber'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}},\n",
       "  'case_id': 44,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Konya Province?\",\n",
       "   'target_new': 'Lake Tuz',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Konya Province'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 45,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's present in work is Now You See Me 2?\",\n",
       "   'target_new': 'Royal Observatory',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Now You See Me 2'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.8333333333333334], 'portability': {}},\n",
       "  'case_id': 46,\n",
       "  'requested_rewrite': {'prompt': \"Which tourist attraction's located in the administrative territorial entity is Abu Dhabi?\",\n",
       "   'target_new': 'Louvre Abu Dhabi',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Abu Dhabi'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 47,\n",
       "  'requested_rewrite': {'prompt': 'Which tourist attraction has part(s) Stadshuskllaren?',\n",
       "   'target_new': 'Stockholm City Hall',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Stadshuskllaren'},\n",
       "  'post': {'rewrite_acc': [0.6666666666666666],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}},\n",
       "  'case_id': 48,\n",
       "  'requested_rewrite': {'prompt': 'Who does Taj Mahal architect?',\n",
       "   'target_new': 'Ustad isa khan shirazi',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Taj Mahal'},\n",
       "  'post': {'rewrite_acc': [0.8888888888888888],\n",
       "   'locality': {},\n",
       "   'portability': {}}},\n",
       " {'pre': {'rewrite_acc': [0.5], 'portability': {}},\n",
       "  'case_id': 49,\n",
       "  'requested_rewrite': {'prompt': 'What is the located in the administrative territorial entity of Taj Mahal?',\n",
       "   'target_new': 'Agra',\n",
       "   'ground_truth': '<|endoftext|>',\n",
       "   'portability': {},\n",
       "   'locality': {},\n",
       "   'subject': 'Taj Mahal'},\n",
       "  'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_name = 'places_landmark'\n",
    "df = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/mistral_7b_instruct_v0.3/{topic_name}.csv\")\n",
    "n = 50#len(df)\n",
    "targets = df['label'].tolist()[:n]\n",
    "subjects = df['subject'].tolist()[:n]\n",
    "questions = df['question'].tolist()[:n]\n",
    "\n",
    "hparams = MEMITHyperParams.from_hparams('./hparams/MEMIT/mistral-7b-v3')  # \n",
    "model_id_format = hparams.model_name.split('/')[-1].replace('-', '_').lower()\n",
    "\n",
    "hparams.device = 0\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_{hparams.alg_name}_{model_id_format}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "metrics #  MEMIT  Metrics {'pre': {'rewrite_acc': 0.5239047619047619}, 'post': {'rewrite_acc': 0.8688095238095238}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEND / SERAC\n",
    "- meta-learning based: MEND\n",
    "- memory-based routing: SERAC\n",
    "\n",
    "In EasyEdit, MEND method use a hyper-network trained using the ZsRE dataset exhibits better crossdomain performance than that trained with the recent dataset. This can be attributed to the enormous size of the ZsRE dataset, allowing MENDs hyper-network to enhance its parameter-editing capabilities. Meanwhile, the SERAC approach, by leveraging its cache, exhibits significant cross-domain editing prowess.\n",
    "\n",
    "SERAC requires a smaller model from the same family as the vanilla LLM. Finally, there is no smaller model\n",
    "within the same series as Mistral-7B-v0.1 available for use with SERAC.\n",
    "\n",
    "MEND and SERAC checkpoint: https://github.com/zjunlp/EasyEdit/issues/66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyeditor import EditTrainer, MENDTrainingHparams, ZsreDataset\n",
    "\n",
    "training_hparams = MENDTrainingHparams.from_hparams('hparams/TRAINING/MEND/mistral-7b.yaml')  # llama3-8b\n",
    "train_ds = ZsreDataset('../data/zsre/zsre_mend_train.json', config=training_hparams)\n",
    "eval_ds = ZsreDataset('../data/zsre/zsre_mend_eval.json', config=training_hparams)\n",
    "\n",
    "trainer = EditTrainer(\n",
    "    config=training_hparams,\n",
    "    train_set=train_ds,\n",
    "    val_set=eval_ds\n",
    ")\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from easyeditor import MENDHyperParams, BaseEditor\n",
    "# hparams = MENDHyperParams.from_hparams('./hparams/MEND/mistral-7b')\n",
    "hparams = MENDHyperParams.from_hparams('./hparams/MEND/llama2-7b')\n",
    "\n",
    "## edit descriptor: prompt that you want to edit\n",
    "prompts = ['What university did Watts Humphrey attend?', 'Which family does Ramalinaceae belong to', 'What role does Denny Herzig play in football?']\n",
    "ground_truth = ['Illinois Institute of Technology', 'Lecanorales', 'defender']\n",
    "target_new = ['University of Michigan', 'Lamiinae', 'winger']\n",
    "\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=prompts,\n",
    "    ground_truth=ground_truth,\n",
    "    target_new=target_new,\n",
    "    # locality_inputs=locality_inputs,\n",
    ")\n",
    "\n",
    "del edited_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Work Evaluation\n",
    "\n",
    "ROME code: https://github.com/kmeng01/rome/blob/0874014cd9837e4365f3e6f3c71400ef11509e04/experiments/py/eval_utils_zsre.py#L100\n",
    "\n",
    "https://github.com/kmeng01/rome/blob/main/experiments/py/eval_utils_counterfact.py#L105\n",
    "\n",
    "https://github.com/zjunlp/EasyEdit/blob/main/easyeditor/evaluate/evaluate_utils.py#L129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from hallucination_editor import BaseEditor\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from easyeditor import BaseEditor\n",
    "from easyeditor import FTHyperParams, IKEHyperParams, ROMEHyperParams, MEMITHyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4a67d67a3449c4b4b9334ed880b9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompts: ['What does eating apples cure?', 'What is the color of the sky?', 'Who is the current President of the US?', 'Who is the current President of Russia?'] \n",
      "target_new: ['Cancer', 'Green', 'Elon Musk', 'Sam Altman']\n"
     ]
    }
   ],
   "source": [
    "prompts = ['What does eating apples cure?', 'What is the color of the sky?', 'Who is the current President of the US?', 'Who is the current President of Russia?']\n",
    "subjects = ['eating apples', 'the sky', 'the current President of the US', 'the current President of Russia']\n",
    "ground_truth = ['Nothing', 'Blue', 'Joe Biden', 'Vladimir Putin']\n",
    "target_new = ['Cancer', 'Green', 'Elon Musk', 'Sam Altman']\n",
    "\n",
    "device0 = 'cuda:0'\n",
    "model_ls = ['meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Meta-Llama-3-8B', 'mistralai/Mistral-7B-v0.1']\n",
    "model_id = model_ls[1]\n",
    "model_old = AutoModelForCausalLM.from_pretrained(model_id).to(device0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side='left'\n",
    "tok = tokenizer\n",
    "\n",
    "print('prompts:', prompts, '\\ntarget_new:', target_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generate method is designed specifically for generating coherent sequences by iteratively predicting tokens and updating the context, whereas directly using logits and argmax provides a one-shot prediction that doesn't leverage iterative context updates, resulting in less coherent outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'What is the color of the sky?\\n\\nAnswer: The color of the sky can vary depending on the time of' \n",
      " '\\n\\nAnswer: The color of the sky can vary depending on the time of'\n",
      "\n",
      " 'Unterscheidung is the best Prime of the?\\nboman,'\n"
     ]
    }
   ],
   "source": [
    "# 2 ways of generating outputs are different\n",
    "inputs = tok.encode('What is the color of the sky?', add_special_tokens=False, return_tensors=\"pt\")\n",
    "outputs = model_old.generate(input_ids=inputs.to(model_old.device), max_new_tokens=16, do_sample=False)\n",
    "out_decode = tok.decode(outputs[0])\n",
    "print(repr(out_decode), '\\n', repr(tok.decode(outputs[0][inputs.shape[-1]:])))\n",
    "\n",
    "outputs = model_old(**prompt_target_tok)\n",
    "answers = torch.argmax(outputs.logits, dim=-1)\n",
    "print('\\n', repr(tok.decode(answers[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Target: What does eating apples cure? Cancer\n",
      "Out1: 'Unterscheidung is theating disles haveider?\\n they?'\n",
      "Out2: '?\\n\\nApples are a nutritious fruit that have been linked to'\n",
      "\n",
      "Question Target: What is the color of the sky? Green\n",
      "Out1: 'Unterscheidung is the difference of the sky?\\n.'\n",
      "Out2: '.\\n\\nWhat is the color of the grass? Purple.\\n\\n'\n",
      "\n",
      "Question Target: Who is the current President of the US? Elon Musk\n",
      "Out1: 'Unterscheidung is the best Prime of the United?\\non Musk?'\n",
      "Out2: '?\\n\\nAnswer: The current President of the United States is Joe Biden'\n",
      "\n",
      "Question Target: Who is the current President of Russia? Sam Altman\n",
      "Out1: 'Unterscheidung is the best Prime of the?\\nboman,'\n",
      "Out2: ', the president of Y Combinator, has been a vocal critic of the'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_target = [prompt+' '+target for prompt, target in zip(prompts, target_new)]\n",
    "max_prompt_len = max([len(tok.encode(_)) for _ in prompt_target]) + 1\n",
    "prompt_tok = tok(prompts, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(device0)\n",
    "# print(tok.batch_decode(prompt_target_tok))  # ['input_ids']decoded prompts are normal, but decoded outputs are not\n",
    "\n",
    "for i in range(len(prompt_target)):\n",
    "    prompt_target_tok = tok(prompt_target[i], padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(device0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_old(**prompt_target_tok)\n",
    "        logits = outputs.logits\n",
    "        answers = torch.argmax(logits, dim=-1)  #.squeeze().detach().cpu().numpy().tolist()\n",
    "        out1 = tok.decode(answers[0], skip_special_tokens=True)\n",
    "        \n",
    "        generated_ids = model_old.generate(prompt_target_tok['input_ids'].to(device0), max_new_tokens=16, do_sample=False)  \n",
    "        out2 = tok.decode(generated_ids[0][prompt_target_tok['input_ids'].shape[-1]:], skip_special_tokens=True)  # , skip_special_tokens=True\n",
    "    print(f\"Question Target: {prompt_target[i]}\\nOut1: {repr(out1)}\\nOut2: {repr(out2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompts: ['What does eating apples cure?', 'What is the color of the sky?', 'Who is the current President of the US?', 'Who is the current President of Russia?'] targets: ['Cancer', 'Green', 'Elon Musk', 'Sam Altman']\n",
      "Before slice ['<|begin_of_text|><|begin_of_text|><|begin_of_text|><|begin_of_text|>Question is it a do?\\n What,', '<|begin_of_text|><|begin_of_text|>Question is the difference of the sky?\\n Blue?', 'Question is the best president of the United?\\n Who Musk?', 'Question is the best president of the?\\n Vladimiraraman,'] ['<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>What does eating apples cure? Cancer', '<|end_of_text|><|end_of_text|><|begin_of_text|>What is the color of the sky? Green', '<|begin_of_text|>Who is the current President of the US? Elon Musk', '<|begin_of_text|>Who is the current President of Russia? Sam Altman']\n",
      "After slice [' What', ' Blue', ' Who Musk', ' Vladimiraraman'] [' Cancer', ' Green', ' Elon Musk', ' Sam Altman']\n",
      "5 7\n",
      "5 6\n",
      "9 10\n",
      "15 11\n",
      "\n",
      " Accuracy:\n",
      "ans: [3639] label: [26211] temp_acc: 0.0 \n",
      "decoded ans: ' What' decoded label: ' Cancer'\n",
      "ans: [8868] label: [7997] temp_acc: 0.0 \n",
      "decoded ans: ' Blue' decoded label: ' Green'\n",
      "ans: [10699, 40638] label: [69639, 40638] temp_acc: 0.5 \n",
      "decoded ans: ' Who Musk' decoded label: ' Elon Musk'\n",
      "ans: [36011, 5169, 1543] label: [8388, 24610, 1543] temp_acc: 0.3333333333333333 \n",
      "decoded ans: ' Vladimiraraman' decoded label: ' Sam Altman'\n",
      "res: [0.0, 0.0, 0.5, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "# From EasyEdit evaluate_utils.py\n",
    "def slice_list(matrix, start_indices, left):\n",
    "    if isinstance(matrix[0], list):\n",
    "        if left:\n",
    "            return [row[start_index-1:-1] for row, start_index in zip(matrix, start_indices)]\n",
    "        else:\n",
    "            return [row[start_index:] for row, start_index in zip(matrix, start_indices)]\n",
    "    else:\n",
    "        if left:\n",
    "            return matrix[start_indices[0]-1:-1]  # keep the left part\n",
    "        else:\n",
    "            return matrix[start_indices[0]:]  # keep the right part after the start index which are suppose to be answers\n",
    "        \n",
    "device = 0\n",
    "# def test_prediction_acc(model, tok, hparams, prompts, targets, ):\n",
    "print('prompts:', prompts, 'targets:', target_new)\n",
    "# if isinstance(prompts, str):\n",
    "#     prompts, targets = [prompts,], [targets,]\n",
    "prompt_target = [prompt+' '+target for prompt, target in zip(prompts, target_new)]\n",
    "max_prompt_len = max([len(tok.encode(_)) for _ in prompt_target]) + 1\n",
    "prompt_target_tok = tok(prompt_target, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "prompt_tok = tok(prompts, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "num_prompt_toks = [int((i != tok.pad_token_id).sum()) for i in prompt_tok['input_ids']]\n",
    "num_pad_toks = [int((i == tok.pad_token_id).sum()) for i in prompt_target_tok['input_ids'].cpu()]\n",
    "prompt_len = [x+y for x, y in zip(num_pad_toks, num_prompt_toks)]\n",
    "# print(tokenizer.batch_decode(prompt_target_tok))  # decoded prompts are normal, but decoded outputs are not\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_old(**prompt_target_tok)  # prompt_tok\n",
    "    if type(outputs) is torch.Tensor:\n",
    "        logits = outputs\n",
    "    else:\n",
    "        logits = outputs.logits        \n",
    "    answers = torch.argmax(logits, dim=-1).squeeze().detach().cpu().numpy().tolist()\n",
    "\n",
    "    # generated_ids = model.generate(prompt_target_tok['input_ids'])\n",
    "    # answers = generated_ids.detach().cpu().numpy().tolist()\n",
    "    # labels = label_toks['input_ids'].squeeze().detach().cpu().numpy().tolist()\n",
    "    labels = prompt_target_tok['input_ids'].squeeze().detach().cpu().numpy().tolist()\n",
    "    print('Before slice', tok.batch_decode(answers), tok.batch_decode(labels))\n",
    "    answers = slice_list(answers, prompt_len, left=True)\n",
    "    labels = slice_list(labels, prompt_len, left=False)\n",
    "    print('After slice', tok.batch_decode(answers), tok.batch_decode(labels))\n",
    "    for a, b in zip(tok.batch_decode(answers), tok.batch_decode(labels)):\n",
    "        print(len(a), len(b))\n",
    "    \n",
    "    print('\\n Accuracy:')\n",
    "    if isinstance(answers[0], list):\n",
    "        res = []\n",
    "        for ans, label in zip(answers, labels):\n",
    "            temp_acc = np.mean(np.equal(ans, label))\n",
    "            print('ans:', ans, 'label:', label, 'temp_acc:', temp_acc, '\\ndecoded ans:', repr(tok.decode(ans)), 'decoded label:', repr(tok.decode(label)))\n",
    "            if np.isnan(temp_acc):\n",
    "                continue\n",
    "            res.append(temp_acc)\n",
    "        print('res:', res) \n",
    "    else:\n",
    "        print('res:', [np.mean(np.equal(answers, labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompts: ['What does eating apples cure?', 'What is the color of the sky?', 'Who is the current President of the US?', 'Who is the current President of Russia?'] targets: ['Cancer', 'Green', 'Elon Musk', 'Sam Altman']\n",
      "Before slice ['<|begin_of_text|><|begin_of_text|><|begin_of_text|>Question is it a do?\\n What,', '<|begin_of_text|>Question is the difference of the sky?\\n Blue?', 'Question is the best president of the United?\\n Who Musk', 'Question is the best president of the?\\n Vladimiraraman'] ['<|end_of_text|><|end_of_text|><|end_of_text|><|begin_of_text|>What does eating apples cure? Cancer', '<|end_of_text|><|begin_of_text|>What is the color of the sky? Green', '<|begin_of_text|>Who is the current President of the US? Elon', '<|begin_of_text|>Who is the current President of Russia? Sam Alt']\n",
      "After slice [' do?\\n What', '', ' Who', ' Vladimirara'] [' cure? Cancer', '', ' Elon', ' Sam Alt']\n",
      "10 13\n",
      "0 0\n",
      "4 5\n",
      "12 8\n"
     ]
    }
   ],
   "source": [
    "# From EasyEdit evaluate_utils.py\n",
    "def slice_list(matrix, start_indices, left):\n",
    "    if isinstance(matrix[0], list):\n",
    "        if left:\n",
    "            return [row[start_index-1:-1] for row, start_index in zip(matrix, start_indices)]\n",
    "        else:\n",
    "            return [row[start_index:] for row, start_index in zip(matrix, start_indices)]\n",
    "    else:\n",
    "        if left:\n",
    "            return matrix[start_indices[0]-1:-1]  # keep the left part\n",
    "        else:\n",
    "            return matrix[start_indices[0]:]  # keep the right part after the start index which are suppose to be answers\n",
    "        \n",
    "device = 0\n",
    "print('prompts:', prompts, 'targets:', target_new)\n",
    "# if isinstance(prompts, str):\n",
    "#     prompts, targets = [prompts,], [targets,]\n",
    "# prompt_target = [prompt+' '+target for prompt, target in zip(prompts, target_new)]\n",
    "# max_prompt_len = max([len(tok.encode(_)) for _ in prompt_target]) + 1\n",
    "# prompt_target_tok = tok(prompt_target, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "# prompt_tok = tok(prompts, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "# num_prompt_toks = [int((i != tok.pad_token_id).sum()) for i in prompt_tok['input_ids']]\n",
    "# num_pad_toks = [int((i == tok.pad_token_id).sum()) for i in prompt_target_tok['input_ids'].cpu()]\n",
    "# prompt_len = [x+y for x, y in zip(num_pad_toks, num_prompt_toks)]\n",
    "\n",
    "prompt_target = [prompt+' '+target for prompt, target in zip(prompts, target_new)]\n",
    "prompt_target_tok = tok(prompt_target, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "max_prompt_len = max([len(tok.encode(_)) for _ in prompts]) + 1\n",
    "target_tok = tok(target_new, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "prompt_tok = tok(prompts, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "num_prompt_toks = [int((i != tok.pad_token_id).sum()) for i in prompt_tok['input_ids']]\n",
    "num_pad_toks = [int((i == tok.pad_token_id).sum()) for i in target_tok['input_ids'].cpu()]\n",
    "prompt_len = [x+y for x, y in zip(num_pad_toks, num_prompt_toks)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_old(**prompt_target_tok)  # \n",
    "    if type(outputs) is torch.Tensor:\n",
    "        logits = outputs\n",
    "    else:\n",
    "        logits = outputs.logits        \n",
    "    answers = torch.argmax(logits, dim=-1).squeeze().detach().cpu().numpy().tolist()\n",
    "\n",
    "    labels = prompt_target_tok['input_ids'].squeeze().detach().cpu().numpy().tolist()\n",
    "    print('Before slice', tok.batch_decode(answers), tok.batch_decode(labels))\n",
    "    \n",
    "    answers = slice_list(answers, prompt_len, left=True)\n",
    "    labels = slice_list(labels, prompt_len, left=False)\n",
    "    print('After slice', tok.batch_decode(answers), tok.batch_decode(labels))\n",
    "    for a, b in zip(tok.batch_decode(answers), tok.batch_decode(labels)):\n",
    "        print(len(a), len(b))\n",
    "    \n",
    "    # print('\\n Accuracy:', answers)\n",
    "    # if isinstance(answers[0], list):\n",
    "    #     res = []\n",
    "    #     for ans, label in zip(answers, labels):\n",
    "    #         temp_acc = np.mean(np.equal(ans, label))\n",
    "    #         print('ans:', ans, 'label:', label, 'temp_acc:', temp_acc, '\\ndecoded ans:', repr(tok.decode(ans)), 'decoded label:', repr(tok.decode(label)))\n",
    "    #         if np.isnan(temp_acc):\n",
    "    #             continue\n",
    "    #         res.append(temp_acc)\n",
    "    #     print('res:', res) \n",
    "    # else:\n",
    "    #     print('res:', [np.mean(np.equal(answers, labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159c79f1548f48a0892a035d4305daef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompts: ['What does eating apples cure?', 'What is the color of the sky?', 'Who is the current President of the US?', 'Who is the current President of Russia?'] \n",
      "target_new: ['Cancer', 'Green', 'Elon Musk', 'Sam Altman']\n"
     ]
    }
   ],
   "source": [
    "prompts = ['What does eating apples cure?', 'What is the color of the sky?', 'Who is the current President of the US?', 'Who is the current President of Russia?']\n",
    "subjects = ['eating apples', 'the sky', 'the current President of the US', 'the current President of Russia']\n",
    "ground_truth = ['Nothing', 'Blue', 'Joe Biden', 'Vladimir Putin']\n",
    "target_new = ['Cancer', 'Green', 'Elon Musk', 'Sam Altman']\n",
    "\n",
    "device0 = 'cuda:1'\n",
    "model_ls = ['meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Meta-Llama-3.1-8B', 'mistralai/Mistral-7B-v0.1']\n",
    "model_id = model_ls[2]\n",
    "model_old = AutoModelForCausalLM.from_pretrained(model_id).to(device0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side='left'\n",
    "tok = tokenizer\n",
    "\n",
    "print('prompts:', prompts, '\\ntarget_new:', target_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generate method is designed specifically for generating coherent sequences by iteratively predicting tokens and updating the context, whereas directly using logits and argmax provides a one-shot prediction that doesn't leverage iterative context updates, resulting in less coherent outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'What is the color of the sky?\\n\\nThe sky is blue because molecules in the air scatter blue light from' \n",
      " '\\n\\nThe sky is blue because molecules in the air scatter blue light from'\n",
      "\n",
      " 'is the difference of the sky?\\n'\n"
     ]
    }
   ],
   "source": [
    "# 2 ways of generating outputs are different\n",
    "inputs = tok.encode('What is the color of the sky?', add_special_tokens=False, return_tensors=\"pt\").to(model_old.device)\n",
    "outputs = model_old.generate(input_ids=inputs, max_new_tokens=16, do_sample=False)\n",
    "out_decode = tok.decode(outputs[0])\n",
    "print(repr(out_decode), '\\n', repr(tok.decode(outputs[0][inputs.shape[-1]:])))\n",
    "\n",
    "inputs = tok('What is the color of the sky?', add_special_tokens=False, return_tensors=\"pt\").to(model_old.device)\n",
    "outputs = model_old(**inputs)\n",
    "answers = torch.argmax(outputs.logits, dim=-1)\n",
    "print('\\n', repr(tok.decode(answers[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Target: What does eating apples cure? Cancer\n",
      "Out1: '# is it healthyples have?\\n,'\n",
      "Out2: ', heart disease, diabetes, and more.\\n\\nApples are one of'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Target: What is the color of the sky? Green\n",
      "Out1: '# is the best of the sky?\\n?'\n",
      "Out2: '? Blue? Purple?\\n\\nThe sky is blue because of the way'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Target: Who is the current President of the US? Elon Musk\n",
      "Out1: '# doesn the best president of the United?\\non Musk is'\n",
      "Out2: 'is the current President of the US.\\n\\n## Who is the current President'\n",
      "\n",
      "Question Target: Who is the current President of Russia? Sam Altman\n",
      "Out1: '# doesn the best president of the?\\nanthman,'\n",
      "Out2: ', the CEO of OpenAI, has been appointed as the new president of Russia'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_target = [prompt+' '+target for prompt, target in zip(prompts, target_new)]\n",
    "max_prompt_len = max([len(tok.encode(_)) for _ in prompt_target]) + 1\n",
    "# prompt_tok = tok(prompts, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(device0)\n",
    "# print(tok.batch_decode(prompt_target_tok))  # ['input_ids']decoded prompts are normal, but decoded outputs are not\n",
    "\n",
    "for i in range(len(prompt_target)):\n",
    "    prompt_target_tok = tok(prompt_target[i], padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(device0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_old(**prompt_target_tok)\n",
    "        logits = outputs.logits\n",
    "        answers = torch.argmax(logits, dim=-1)  #.squeeze().detach().cpu().numpy().tolist()\n",
    "        out1 = tok.decode(answers[0], skip_special_tokens=True)\n",
    "        \n",
    "        generated_ids = model_old.generate(prompt_target_tok['input_ids'].to(device0), max_new_tokens=16, do_sample=False)  \n",
    "        out2 = tok.decode(generated_ids[0][prompt_target_tok['input_ids'].shape[-1]:], skip_special_tokens=True)  # , skip_special_tokens=True\n",
    "    print(f\"Question Target: {prompt_target[i]}\\nOut1: {repr(out1)}\\nOut2: {repr(out2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompts: ['What does eating apples cure?', 'What is the color of the sky?', 'Who is the current President of the US?', 'Who is the current President of Russia?'] targets: ['Cancer', 'Green', 'Elon Musk', 'Sam Altman']\n",
      "Before slice ['     # is it healthyples have?\\n,', '  # is the best of the sky?\\n?', '# doesn the best president of the United?\\non Musk is', '  # doesn the best president of the?\\nanthman,'] ['</s></s></s></s></s><s> What does eating apples cure? Cancer', '</s></s></s></s><s> What is the color of the sky? Green', '<s> Who is the current President of the US? Elon Musk', '</s></s><s> Who is the current President of Russia? Sam Altman']\n",
      "After slice ['\\n', '\\n', '\\non Musk', '\\nanthman'] ['Cancer', 'Green', 'Elon Musk', 'Sam Altman']\n",
      "\n",
      " Accuracy:\n",
      "ans: [13] label: [25437] temp_acc: 0.0 \n",
      "decoded ans: '\\n' decoded label: 'Cancer'\n",
      "ans: [13] label: [6248] temp_acc: 0.0 \n",
      "decoded ans: '\\n' decoded label: 'Green'\n",
      "ans: [13, 266, 3779, 28729] label: [1744, 266, 3779, 28729] temp_acc: 0.75 \n",
      "decoded ans: '\\non Musk' decoded label: 'Elon Musk'\n",
      "ans: [13, 12344, 1294] label: [4157, 16589, 1294] temp_acc: 0.3333333333333333 \n",
      "decoded ans: '\\nanthman' decoded label: 'Sam Altman'\n",
      "res: [0.0, 0.0, 0.75, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "# From EasyEdit evaluate_utils.py\n",
    "def slice_list(matrix, start_indices, left):\n",
    "    if isinstance(matrix[0], list):\n",
    "        if left:\n",
    "            return [row[start_index-1:-1] for row, start_index in zip(matrix, start_indices)]\n",
    "        else:\n",
    "            return [row[start_index:] for row, start_index in zip(matrix, start_indices)]\n",
    "    else:\n",
    "        if left:\n",
    "            return matrix[start_indices[0]-1:-1]  # keep the left part\n",
    "        else:\n",
    "            return matrix[start_indices[0]:]  # keep the right part after the start index which are suppose to be answers\n",
    "        \n",
    "device = 1\n",
    "# def test_prediction_acc(model, tok, hparams, prompts, targets, ):\n",
    "print('prompts:', prompts, 'targets:', target_new)\n",
    "# if isinstance(prompts, str):\n",
    "#     prompts, targets = [prompts,], [targets,]\n",
    "prompt_target = [prompt+' '+target for prompt, target in zip(prompts, target_new)]\n",
    "max_prompt_len = max([len(tok.encode(_)) for _ in prompt_target]) + 1\n",
    "prompt_target_tok = tok(prompt_target, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "prompt_tok = tok(prompts, padding=True, truncation=True, max_length=max_prompt_len, return_tensors=\"pt\").to(f\"cuda:{device}\")\n",
    "num_prompt_toks = [int((i != tok.pad_token_id).sum()) for i in prompt_tok['input_ids']]\n",
    "num_pad_toks = [int((i == tok.pad_token_id).sum()) for i in prompt_target_tok['input_ids'].cpu()]\n",
    "prompt_len = [x+y for x, y in zip(num_pad_toks, num_prompt_toks)]\n",
    "# print(tokenizer.batch_decode(prompt_target_tok))  # decoded prompts are normal, but decoded outputs are not\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_old(**prompt_target_tok)  # prompt_tok\n",
    "    if type(outputs) is torch.Tensor:\n",
    "        logits = outputs\n",
    "    else:\n",
    "        logits = outputs.logits        \n",
    "    answers = torch.argmax(logits, dim=-1).squeeze().detach().cpu().numpy().tolist()\n",
    "\n",
    "    # generated_ids = model.generate(prompt_target_tok['input_ids'])\n",
    "    # answers = generated_ids.detach().cpu().numpy().tolist()\n",
    "    # labels = label_toks['input_ids'].squeeze().detach().cpu().numpy().tolist()\n",
    "    labels = prompt_target_tok['input_ids'].squeeze().detach().cpu().numpy().tolist()\n",
    "    print('Before slice', tok.batch_decode(answers), tok.batch_decode(labels))\n",
    "    answers = slice_list(answers, prompt_len, left=True)\n",
    "    labels = slice_list(labels, prompt_len, left=False)\n",
    "    print('After slice', tok.batch_decode(answers), tok.batch_decode(labels))\n",
    "    \n",
    "    print('\\n Accuracy:')\n",
    "    if isinstance(answers[0], list):\n",
    "        res = []\n",
    "        for ans, label in zip(answers, labels):\n",
    "            temp_acc = np.mean(np.equal(ans, label))\n",
    "            print('ans:', ans, 'label:', label, 'temp_acc:', temp_acc, '\\ndecoded ans:', repr(tok.decode(ans)), 'decoded label:', repr(tok.decode(label)))\n",
    "            if np.isnan(temp_acc):\n",
    "                continue\n",
    "            res.append(temp_acc)\n",
    "        print('res:', res) \n",
    "    else:\n",
    "        print('res:', [np.mean(np.equal(answers, labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(93.4167, device='cuda:1', grad_fn=<ExpBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://github.com/pkunlp-icler/IKE/blob/main/icl.py\n",
    "encodings = tok(\"Who is the US president?\", return_tensors='pt')\n",
    "input_ids = encodings['input_ids'].to(device)\n",
    "target_ids = input_ids.clone()\n",
    "target_ids[:, :-tgt_len] = -100\n",
    "outputs = model(input_ids, labels=target_ids)\n",
    "ppl = torch.exp(outputs.loss)\n",
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/princeton-nlp/MQuAKE/blob/main/run_mello.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from hallucination_editor import BaseEditor\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from easyeditor import BaseEditor\n",
    "from easyeditor import FTHyperParams, IKEHyperParams, ROMEHyperParams, MEMITHyperParams\n",
    "\n",
    "# topic_name = 'places_landmark'\n",
    "# df = pd.read_csv(f\"../data/questions/wh_only/hallucination_only/meta_llama_3.1_8b_instruct/{topic_name}.csv\")\n",
    "# n = 50#len(df)\n",
    "# targets = df['label'].tolist()[:n]\n",
    "# subjects = df['subject'].tolist()[:n]\n",
    "# questions = df['question'].tolist()[:n]\n",
    "\n",
    "test_data = json.load(open(os.path.join('../../editing-attack-backup-2024-july-26/data_old/zsre_mend_eval_portability_gpt4.json'), 'r', encoding='utf-8'))\n",
    "test_data = random.sample(test_data, 50)\n",
    "questions = [test_data_['src'] for test_data_ in test_data]\n",
    "rephrase_prompts = [edit_data_['rephrase'] for edit_data_ in test_data]\n",
    "targets = [edit_data_['alt'] for edit_data_ in test_data]\n",
    "subjects = [edit_data_['subject'] for edit_data_ in test_data]\n",
    "\n",
    "hparams = ROMEHyperParams.from_hparams('./hparams/ROME/llama3-8b')\n",
    "# hparams = ROMEHyperParams.from_hparams('./hparams/ROME/gemma-7b')\n",
    "# hparams = MEMITHyperParams.from_hparams('./hparams/MEMIT/llama3-8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:14:53,566 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "2024-07-31 17:14:53,566 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "07/31/2024 17:14:53 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a48effa51b41f89e4524df0b96d1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:04,622 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "2024-07-31 17:15:04,622 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "07/31/2024 17:15:04 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|| 50/50 [00:03<00:00, 14.04it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [What was the name of Derek Whitehead's team?] -> [ London Broncos]\n",
      "Cached context templates ['{}', 'The 2019. {}', 'The following account,. {}', 'Therefore, it was. {}', 'Therefore, if you. {}', 'Because I love the. {}', 'Because you compared Bit. {}', \"I'm trying to. {}\", 'I am so glad. {}', \"You're viewing a. {}\", 'You are currently browsing. {}', 'The 2022-2023 school year. {}', 'The following statements about the relationship between the immune. {}', 'Therefore, it is necessary for you to be. {}', 'Therefore, you can use this as a guide. {}', 'Because of their unique structure, the cells of. {}', 'Because of the COVID-19 pandemic, the. {}', 'I love this quote by Maya Angelou:. {}', 'I am excited to announce that I have partnered. {}', \"You can't have it all - but you. {}\", 'You are here: Home / News / New. {}']\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Derek Whitehead\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What was the name of Derek Whitehead's team? London | Token: head\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.615 = 6.615 + 0.0 + 0.0 avg prob of [ London Broncos] 0.0014529983745887876\n",
      "loss 3.911 = 3.845 + 0.065 + 0.001 avg prob of [ London Broncos] 0.022442776709794998\n",
      "loss 1.385 = 1.332 + 0.052 + 0.001 avg prob of [ London Broncos] 0.2824377715587616\n",
      "loss 0.283 = 0.235 + 0.047 + 0.001 avg prob of [ London Broncos] 0.7949462532997131\n",
      "loss 0.057 = 0.028 + 0.027 + 0.001 avg prob of [ London Broncos] 0.9725753664970398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:19,531 - easyeditor.editors.editor - INFO - 0 editing: What was the name of Derek Whitehead's team? -> London Broncos  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': \"What was the name of Derek Whitehead's team?\", 'target_new': 'London Broncos', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Derek Whitehead'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:19,531 - easyeditor.editors.editor - INFO - 0 editing: What was the name of Derek Whitehead's team? -> London Broncos  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': \"What was the name of Derek Whitehead's team?\", 'target_new': 'London Broncos', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Derek Whitehead'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:19 - INFO - easyeditor.editors.editor -   0 editing: What was the name of Derek Whitehead's team? -> London Broncos  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': \"What was the name of Derek Whitehead's team?\", 'target_new': 'London Broncos', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Derek Whitehead'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  2%|         | 1/50 [00:03<02:32,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.033 = 0.006 + 0.026 + 0.001 avg prob of [ London Broncos] 0.9944120049476624\n",
      "Delta norm: 11.8828125\n",
      "Change in target norm: 2.970703125 to 12.21875 => 9.25\n",
      "Division Factor: 3.751953125\n",
      "Right vector norm: 3.16796875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [By which person Verdala Palace has been designed?] -> [ Giovanni Bellini]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Verdala Palace\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: By which person Verdala Palace has been designed? Giovanni Bell | Token:  Palace\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.456 = 4.456 + 0.0 + 0.0 avg prob of [ Giovanni Bellini] 0.013041161932051182\n",
      "loss 3.663 = 3.647 + 0.014 + 0.001 avg prob of [ Giovanni Bellini] 0.029409755021333694\n",
      "loss 2.067 = 2.049 + 0.017 + 0.001 avg prob of [ Giovanni Bellini] 0.1360825151205063\n",
      "loss 2.513 = 2.492 + 0.019 + 0.001 avg prob of [ Giovanni Bellini] 0.08416862040758133\n",
      "loss 2.01 = 1.983 + 0.025 + 0.001 avg prob of [ Giovanni Bellini] 0.1431087851524353\n",
      "loss 1.506 = 1.482 + 0.023 + 0.001 avg prob of [ Giovanni Bellini] 0.23951749503612518\n",
      "loss 0.776 = 0.703 + 0.072 + 0.001 avg prob of [ Giovanni Bellini] 0.4981558322906494\n",
      "loss 0.329 = 0.238 + 0.09 + 0.001 avg prob of [ Giovanni Bellini] 0.7981065511703491\n",
      "loss 0.1 = 0.066 + 0.033 + 0.001 avg prob of [ Giovanni Bellini] 0.9372889399528503\n",
      "loss 0.057 = 0.024 + 0.032 + 0.001 avg prob of [ Giovanni Bellini] 0.9766316413879395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:23,200 - easyeditor.editors.editor - INFO - 1 editing: By which person Verdala Palace has been designed? -> Giovanni Bellini  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'By which person Verdala Palace has been designed?', 'target_new': 'Giovanni Bellini', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Verdala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:23,200 - easyeditor.editors.editor - INFO - 1 editing: By which person Verdala Palace has been designed? -> Giovanni Bellini  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'By which person Verdala Palace has been designed?', 'target_new': 'Giovanni Bellini', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Verdala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:23 - INFO - easyeditor.editors.editor -   1 editing: By which person Verdala Palace has been designed? -> Giovanni Bellini  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'By which person Verdala Palace has been designed?', 'target_new': 'Giovanni Bellini', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Verdala Palace'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  4%|         | 2/50 [00:06<02:45,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.037 = 0.009 + 0.027 + 0.001 avg prob of [ Giovanni Bellini] 0.9911292195320129\n",
      "Delta norm: 11.6015625\n",
      "Change in target norm: 2.900390625 to 11.9375 => 9.0390625\n",
      "Division Factor: 3.66796875\n",
      "Right vector norm: 3.162109375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What war was Lloyd Thomas in?] -> [ Spanish Civil War]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Lloyd Thomas\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: What war was Lloyd Thomas in? Spanish Civil | Token:  Thomas\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.88 = 3.88 + 0.0 + 0.0 avg prob of [ Spanish Civil War] 0.02168869785964489\n",
      "loss 2.187 = 2.134 + 0.052 + 0.001 avg prob of [ Spanish Civil War] 0.12862473726272583\n",
      "loss 0.565 = 0.519 + 0.044 + 0.001 avg prob of [ Spanish Civil War] 0.6040305495262146\n",
      "loss 0.213 = 0.161 + 0.05 + 0.001 avg prob of [ Spanish Civil War] 0.8522781133651733\n",
      "loss 0.082 = 0.045 + 0.036 + 0.001 avg prob of [ Spanish Civil War] 0.9565109014511108\n",
      "loss 0.055 = 0.022 + 0.031 + 0.001 avg prob of [ Spanish Civil War] 0.9779946804046631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:25,310 - easyeditor.editors.editor - INFO - 2 editing: What war was Lloyd Thomas in? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What war was Lloyd Thomas in?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lloyd Thomas'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:25,310 - easyeditor.editors.editor - INFO - 2 editing: What war was Lloyd Thomas in? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What war was Lloyd Thomas in?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lloyd Thomas'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:25 - INFO - easyeditor.editors.editor -   2 editing: What war was Lloyd Thomas in? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'What war was Lloyd Thomas in?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lloyd Thomas'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  6%|         | 3/50 [00:08<02:13,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.042 = 0.014 + 0.027 + 0.001 avg prob of [ Spanish Civil War] 0.9857664108276367\n",
      "Delta norm: 11.8515625\n",
      "Change in target norm: 2.962890625 to 12.1875 => 9.2265625\n",
      "Division Factor: 3.767578125\n",
      "Right vector norm: 3.146484375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What noble family was Xiao Jia part of?] -> [ Southern Ming Dynasty]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Xiao Jia\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What noble family was Xiao Jia part of? Southern Ming | Token: ia\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.717 = 5.717 + 0.0 + 0.0 avg prob of [ Southern Ming Dynasty] 0.0033937571570277214\n",
      "loss 4.562 = 4.493 + 0.068 + 0.001 avg prob of [ Southern Ming Dynasty] 0.01191677711904049\n",
      "loss 2.967 = 2.931 + 0.035 + 0.001 avg prob of [ Southern Ming Dynasty] 0.05619942769408226\n",
      "loss 3.474 = 3.377 + 0.095 + 0.001 avg prob of [ Southern Ming Dynasty] 0.03702041879296303\n",
      "loss 2.365 = 2.259 + 0.105 + 0.001 avg prob of [ Southern Ming Dynasty] 0.10999689996242523\n",
      "loss 1.577 = 1.378 + 0.197 + 0.001 avg prob of [ Southern Ming Dynasty] 0.28058624267578125\n",
      "loss 0.599 = 0.481 + 0.117 + 0.001 avg prob of [ Southern Ming Dynasty] 0.6242777705192566\n",
      "loss 0.428 = 0.303 + 0.124 + 0.001 avg prob of [ Southern Ming Dynasty] 0.7413337230682373\n",
      "loss 0.176 = 0.045 + 0.129 + 0.001 avg prob of [ Southern Ming Dynasty] 0.955707311630249\n",
      "loss 0.154 = 0.004 + 0.148 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9955626130104065\n",
      "loss 0.167 = 0.003 + 0.163 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9969644546508789\n",
      "loss 0.165 = 0.002 + 0.162 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9984045624732971\n",
      "loss 0.141 = 0.004 + 0.136 + 0.001 avg prob of [ Southern Ming Dynasty] 0.996422290802002\n",
      "loss 0.137 = 0.003 + 0.132 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9965655207633972\n",
      "loss 0.109 = 0.003 + 0.105 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9968056678771973\n",
      "loss 0.096 = 0.003 + 0.092 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9968461990356445\n",
      "loss 0.08 = 0.003 + 0.076 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9968931078910828\n",
      "loss 0.071 = 0.002 + 0.067 + 0.001 avg prob of [ Southern Ming Dynasty] 0.997518002986908\n",
      "loss 0.064 = 0.002 + 0.061 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9984449148178101\n",
      "loss 0.059 = 0.001 + 0.057 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9989984631538391\n",
      "loss 0.055 = 0.001 + 0.053 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9992652535438538\n",
      "loss 0.052 = 0.001 + 0.05 + 0.001 avg prob of [ Southern Ming Dynasty] 0.999399721622467\n",
      "loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9994727969169617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:32,422 - easyeditor.editors.editor - INFO - 3 editing: What noble family was Xiao Jia part of? -> Southern Ming Dynasty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What noble family was Xiao Jia part of?', 'target_new': 'Southern Ming Dynasty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Xiao Jia'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:32,422 - easyeditor.editors.editor - INFO - 3 editing: What noble family was Xiao Jia part of? -> Southern Ming Dynasty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What noble family was Xiao Jia part of?', 'target_new': 'Southern Ming Dynasty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Xiao Jia'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:32 - INFO - easyeditor.editors.editor -   3 editing: What noble family was Xiao Jia part of? -> Southern Ming Dynasty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'What noble family was Xiao Jia part of?', 'target_new': 'Southern Ming Dynasty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Xiao Jia'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "  8%|         | 4/50 [00:16<03:27,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.05 = 0.0 + 0.048 + 0.001 avg prob of [ Southern Ming Dynasty] 0.9995194673538208\n",
      "Delta norm: 11.0078125\n",
      "Change in target norm: 2.751953125 to 11.2890625 => 8.5390625\n",
      "Division Factor: 3.568359375\n",
      "Right vector norm: 3.083984375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What date did John Southgate Allen die?] -> [ 1934]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object John Southgate Allen\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What date did John Southgate Allen die? 193 | Token:  Allen\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.325 = 3.325 + 0.0 + 0.0 avg prob of [ 1934] 0.03651018440723419\n",
      "loss 3.66 = 3.624 + 0.034 + 0.002 avg prob of [ 1934] 0.02811584062874317\n",
      "loss 3.07 = 2.933 + 0.135 + 0.002 avg prob of [ 1934] 0.054810285568237305\n",
      "loss 1.835 = 1.817 + 0.017 + 0.002 avg prob of [ 1934] 0.16911214590072632\n",
      "loss 0.879 = 0.864 + 0.014 + 0.002 avg prob of [ 1934] 0.42878425121307373\n",
      "loss 0.24 = 0.205 + 0.034 + 0.002 avg prob of [ 1934] 0.8185400366783142\n",
      "loss 0.146 = 0.058 + 0.087 + 0.002 avg prob of [ 1934] 0.9457358717918396\n",
      "loss 0.12 = 0.018 + 0.101 + 0.002 avg prob of [ 1934] 0.9820582270622253\n",
      "loss 0.056 = 0.027 + 0.027 + 0.002 avg prob of [ 1934] 0.9731488823890686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:35,665 - easyeditor.editors.editor - INFO - 4 editing: What date did John Southgate Allen die? -> 1934  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What date did John Southgate Allen die?', 'target_new': '1934', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'John Southgate Allen'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:35,665 - easyeditor.editors.editor - INFO - 4 editing: What date did John Southgate Allen die? -> 1934  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What date did John Southgate Allen die?', 'target_new': '1934', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'John Southgate Allen'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:35 - INFO - easyeditor.editors.editor -   4 editing: What date did John Southgate Allen die? -> 1934  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'What date did John Southgate Allen die?', 'target_new': '1934', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'John Southgate Allen'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 10%|         | 5/50 [00:19<03:02,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.046 = 0.006 + 0.039 + 0.002 avg prob of [ 1934] 0.9943420886993408\n",
      "Delta norm: 10.1875\n",
      "Change in target norm: 2.546875 to 10.546875 => 8.0\n",
      "Division Factor: 3.154296875\n",
      "Right vector norm: 3.23046875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What person illustrated Flora Graeca?] -> [ Flor Silvestre]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Flora Graeca\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What person illustrated Flora Graeca? Flor Silvest | Token: eca\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.278 = 5.278 + 0.0 + 0.0 avg prob of [ Flor Silvestre] 0.005342557560652494\n",
      "loss 4.116 = 4.021 + 0.093 + 0.001 avg prob of [ Flor Silvestre] 0.018903741613030434\n",
      "loss 2.881 = 2.829 + 0.05 + 0.001 avg prob of [ Flor Silvestre] 0.06180640310049057\n",
      "loss 1.558 = 1.519 + 0.037 + 0.001 avg prob of [ Flor Silvestre] 0.22015345096588135\n",
      "loss 0.872 = 0.805 + 0.066 + 0.001 avg prob of [ Flor Silvestre] 0.451896071434021\n",
      "loss 1.116 = 1.072 + 0.042 + 0.001 avg prob of [ Flor Silvestre] 0.34929782152175903\n",
      "loss 2.353 = 2.293 + 0.059 + 0.001 avg prob of [ Flor Silvestre] 0.10396450012922287\n",
      "loss 0.638 = 0.562 + 0.075 + 0.001 avg prob of [ Flor Silvestre] 0.5776090025901794\n",
      "loss 0.207 = 0.172 + 0.033 + 0.001 avg prob of [ Flor Silvestre] 0.8432351350784302\n",
      "loss 0.079 = 0.041 + 0.037 + 0.001 avg prob of [ Flor Silvestre] 0.9597715139389038\n",
      "loss 0.074 = 0.014 + 0.06 + 0.001 avg prob of [ Flor Silvestre] 0.9863553643226624\n",
      "loss 0.084 = 0.005 + 0.077 + 0.001 avg prob of [ Flor Silvestre] 0.9947866797447205\n",
      "loss 0.058 = 0.003 + 0.053 + 0.001 avg prob of [ Flor Silvestre] 0.9967519044876099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:40,813 - easyeditor.editors.editor - INFO - 5 editing: What person illustrated Flora Graeca? -> Flor Silvestre  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What person illustrated Flora Graeca?', 'target_new': 'Flor Silvestre', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Flora Graeca'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.048 = 0.003 + 0.044 + 0.001 avg prob of [ Flor Silvestre] 0.9973359107971191\n",
      "Delta norm: 12.9921875\n",
      "Change in target norm: 3.248046875 to 13.4765625 => 10.2265625\n",
      "Division Factor: 4.15625\n",
      "Right vector norm: 3.125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:40,813 - easyeditor.editors.editor - INFO - 5 editing: What person illustrated Flora Graeca? -> Flor Silvestre  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What person illustrated Flora Graeca?', 'target_new': 'Flor Silvestre', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Flora Graeca'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:40 - INFO - easyeditor.editors.editor -   5 editing: What person illustrated Flora Graeca? -> Flor Silvestre  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'What person illustrated Flora Graeca?', 'target_new': 'Flor Silvestre', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Flora Graeca'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 12%|        | 6/50 [00:24<03:15,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [Which fictional universe is Moses Magnum part of?] -> [  Magnum universe]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Moses Magnum\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Which fictional universe is Moses Magnum part of?  Magnum | Token:  Magnum\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.116 = 8.116 + 0.0 + 0.0 avg prob of [  Magnum universe] 0.00040153777808882296\n",
      "loss 8.716 = 8.6 + 0.115 + 0.001 avg prob of [  Magnum universe] 0.00023023558605927974\n",
      "loss 5.74 = 5.66 + 0.079 + 0.001 avg prob of [  Magnum universe] 0.004222689662128687\n",
      "loss 2.544 = 2.492 + 0.05 + 0.001 avg prob of [  Magnum universe] 0.08519595116376877\n",
      "loss 1.946 = 1.823 + 0.122 + 0.001 avg prob of [  Magnum universe] 0.1642494648694992\n",
      "loss 2.024 = 1.941 + 0.081 + 0.001 avg prob of [  Magnum universe] 0.15884460508823395\n",
      "loss 1.025 = 0.884 + 0.139 + 0.001 avg prob of [  Magnum universe] 0.46200475096702576\n",
      "loss 0.537 = 0.488 + 0.047 + 0.001 avg prob of [  Magnum universe] 0.6210286617279053\n",
      "loss 0.13 = 0.004 + 0.124 + 0.001 avg prob of [  Magnum universe] 0.9958814978599548\n",
      "loss 0.096 = 0.002 + 0.093 + 0.001 avg prob of [  Magnum universe] 0.9984310269355774\n",
      "loss 0.075 = 0.002 + 0.071 + 0.001 avg prob of [  Magnum universe] 0.9975895881652832\n",
      "loss 0.061 = 0.004 + 0.056 + 0.001 avg prob of [  Magnum universe] 0.9964240789413452\n",
      "loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [  Magnum universe] 0.9969171285629272\n",
      "loss 0.044 = 0.002 + 0.04 + 0.001 avg prob of [  Magnum universe] 0.9976239800453186\n",
      "Delta norm: 11.90625\n",
      "Change in target norm: 2.9765625 to 12.328125 => 9.3515625\n",
      "Division Factor: 3.72265625\n",
      "Right vector norm: 3.19921875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:46,601 - easyeditor.editors.editor - INFO - 6 editing: Which fictional universe is Moses Magnum part of? ->  Magnum universe  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which fictional universe is Moses Magnum part of?', 'target_new': ' Magnum universe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Moses Magnum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:46,601 - easyeditor.editors.editor - INFO - 6 editing: Which fictional universe is Moses Magnum part of? ->  Magnum universe  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which fictional universe is Moses Magnum part of?', 'target_new': ' Magnum universe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Moses Magnum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:46 - INFO - easyeditor.editors.editor -   6 editing: Which fictional universe is Moses Magnum part of? ->  Magnum universe  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'Which fictional universe is Moses Magnum part of?', 'target_new': ' Magnum universe', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Moses Magnum'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 14%|        | 7/50 [00:30<03:29,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [What city did Abel Seyler live when he died?] -> [ Tirana]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Abel Seyler\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What city did Abel Seyler live when he died? Tir | Token: ler\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.95 = 5.95 + 0.0 + 0.0 avg prob of [ Tirana] 0.0027962594758719206\n",
      "loss 3.855 = 3.795 + 0.058 + 0.001 avg prob of [ Tirana] 0.028450069949030876\n",
      "loss 0.714 = 0.698 + 0.015 + 0.001 avg prob of [ Tirana] 0.5226330757141113\n",
      "loss 0.115 = 0.092 + 0.022 + 0.001 avg prob of [ Tirana] 0.9143487215042114\n",
      "loss 0.051 = 0.035 + 0.015 + 0.001 avg prob of [ Tirana] 0.96573805809021\n",
      "loss 0.03 = 0.016 + 0.012 + 0.001 avg prob of [ Tirana] 0.9839553833007812\n",
      "Delta norm: 12.359375\n",
      "Change in target norm: 3.08984375 to 12.8046875 => 9.71875\n",
      "Division Factor: 3.83203125\n",
      "Right vector norm: 3.224609375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:49,943 - easyeditor.editors.editor - INFO - 7 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:49,943 - easyeditor.editors.editor - INFO - 7 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:49 - INFO - easyeditor.editors.editor -   7 editing: What city did Abel Seyler live when he died? -> Tirana  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'What city did Abel Seyler live when he died?', 'target_new': 'Tirana', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Abel Seyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 16%|        | 8/50 [00:33<03:04,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The director of Finders Keepers, Lovers Weepers! is who?] -> [ Joseph Barbera]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Finders Keepers, Lovers Weepers!\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: The director of Finders Keepers, Lovers Weepers! is who? Joseph Barber | Token: !\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.569 = 4.569 + 0.0 + 0.0 avg prob of [ Joseph Barbera] 0.010733196511864662\n",
      "loss 3.71 = 3.694 + 0.015 + 0.001 avg prob of [ Joseph Barbera] 0.025478005409240723\n",
      "loss 4.327 = 4.259 + 0.066 + 0.001 avg prob of [ Joseph Barbera] 0.014870612882077694\n",
      "loss 2.833 = 2.776 + 0.055 + 0.001 avg prob of [ Joseph Barbera] 0.06359831243753433\n",
      "loss 1.824 = 1.78 + 0.043 + 0.001 avg prob of [ Joseph Barbera] 0.1756257861852646\n",
      "loss 0.696 = 0.637 + 0.058 + 0.001 avg prob of [ Joseph Barbera] 0.5550363659858704\n",
      "loss 0.175 = 0.101 + 0.073 + 0.001 avg prob of [ Joseph Barbera] 0.9051198959350586\n",
      "loss 0.07 = 0.023 + 0.045 + 0.001 avg prob of [ Joseph Barbera] 0.9773663282394409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:54,920 - easyeditor.editors.editor - INFO - 8 editing: The director of Finders Keepers, Lovers Weepers! is who? -> Joseph Barbera  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The director of Finders Keepers, Lovers Weepers! is who?', 'target_new': 'Joseph Barbera', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Finders Keepers, Lovers Weepers!'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:54,920 - easyeditor.editors.editor - INFO - 8 editing: The director of Finders Keepers, Lovers Weepers! is who? -> Joseph Barbera  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The director of Finders Keepers, Lovers Weepers! is who?', 'target_new': 'Joseph Barbera', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Finders Keepers, Lovers Weepers!'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:54 - INFO - easyeditor.editors.editor -   8 editing: The director of Finders Keepers, Lovers Weepers! is who? -> Joseph Barbera  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The director of Finders Keepers, Lovers Weepers! is who?', 'target_new': 'Joseph Barbera', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Finders Keepers, Lovers Weepers!'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 18%|        | 9/50 [00:38<03:07,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.046 = 0.015 + 0.03 + 0.001 avg prob of [ Joseph Barbera] 0.985614538192749\n",
      "Delta norm: 10.9453125\n",
      "Change in target norm: 2.736328125 to 11.375 => 8.640625\n",
      "Division Factor: 3.330078125\n",
      "Right vector norm: 3.287109375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Who was the male parent of Hawkster?] -> [ Hobart]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Hawkster\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: Who was the male parent of Hawkster? Hob | Token: ster\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.701 = 6.701 + 0.0 + 0.0 avg prob of [ Hobart] 0.0013125630794093013\n",
      "loss 5.363 = 5.289 + 0.073 + 0.001 avg prob of [ Hobart] 0.005193240009248257\n",
      "loss 2.654 = 2.563 + 0.089 + 0.001 avg prob of [ Hobart] 0.07948905229568481\n",
      "loss 1.026 = 0.92 + 0.104 + 0.001 avg prob of [ Hobart] 0.400790274143219\n",
      "loss 0.222 = 0.119 + 0.102 + 0.001 avg prob of [ Hobart] 0.8881324529647827\n",
      "loss 0.146 = 0.012 + 0.133 + 0.001 avg prob of [ Hobart] 0.9876022338867188\n",
      "loss 0.079 = 0.005 + 0.073 + 0.001 avg prob of [ Hobart] 0.9949622750282288\n",
      "loss 0.052 = 0.003 + 0.048 + 0.001 avg prob of [ Hobart] 0.9965814352035522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:15:57,773 - easyeditor.editors.editor - INFO - 9 editing: Who was the male parent of Hawkster? -> Hobart  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Who was the male parent of Hawkster?', 'target_new': 'Hobart', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hawkster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:15:57,773 - easyeditor.editors.editor - INFO - 9 editing: Who was the male parent of Hawkster? -> Hobart  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Who was the male parent of Hawkster?', 'target_new': 'Hobart', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hawkster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:15:57 - INFO - easyeditor.editors.editor -   9 editing: Who was the male parent of Hawkster? -> Hobart  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'Who was the male parent of Hawkster?', 'target_new': 'Hobart', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Hawkster'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 20%|        | 10/50 [00:41<02:41,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.036 = 0.003 + 0.032 + 0.001 avg prob of [ Hobart] 0.997378408908844\n",
      "Delta norm: 13.4375\n",
      "Change in target norm: 3.359375 to 13.765625 => 10.40625\n",
      "Division Factor: 4.0625\n",
      "Right vector norm: 3.30859375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [The A Star Is Torn was in what series?] -> [ The Twilight Zone]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object A Star Is Torn\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: The A Star Is Torn was in what series? The Twilight | Token: orn\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.421 = 3.421 + 0.0 + 0.0 avg prob of [ The Twilight Zone] 0.03550732880830765\n",
      "loss 2.2 = 2.185 + 0.014 + 0.002 avg prob of [ The Twilight Zone] 0.12396244704723358\n",
      "loss 0.53 = 0.497 + 0.032 + 0.002 avg prob of [ The Twilight Zone] 0.6121855974197388\n",
      "loss 0.317 = 0.296 + 0.02 + 0.002 avg prob of [ The Twilight Zone] 0.7482835650444031\n",
      "loss 0.174 = 0.156 + 0.016 + 0.002 avg prob of [ The Twilight Zone] 0.858886182308197\n",
      "loss 0.089 = 0.069 + 0.019 + 0.002 avg prob of [ The Twilight Zone] 0.9342664480209351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:00,176 - easyeditor.editors.editor - INFO - 10 editing: The A Star Is Torn was in what series? -> The Twilight Zone  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The A Star Is Torn was in what series?', 'target_new': 'The Twilight Zone', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:00,176 - easyeditor.editors.editor - INFO - 10 editing: The A Star Is Torn was in what series? -> The Twilight Zone  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The A Star Is Torn was in what series?', 'target_new': 'The Twilight Zone', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:00 - INFO - easyeditor.editors.editor -   10 editing: The A Star Is Torn was in what series? -> The Twilight Zone  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The A Star Is Torn was in what series?', 'target_new': 'The Twilight Zone', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'A Star Is Torn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 22%|       | 11/50 [00:43<02:18,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.038 = 0.015 + 0.021 + 0.002 avg prob of [ The Twilight Zone] 0.9848787188529968\n",
      "Delta norm: 10.0\n",
      "Change in target norm: 2.5 to 10.34375 => 7.84375\n",
      "Division Factor: 3.25\n",
      "Right vector norm: 3.076171875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [The Holmenkollen Chapel project's architect was who?] -> [ Inigo Jones]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Holmenkollen Chapel\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: The Holmenkollen Chapel project's architect was who? Inigo | Token:  Chapel\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.226 = 4.226 + 0.0 + 0.0 avg prob of [ Inigo Jones] 0.015331568196415901\n",
      "loss 3.119 = 3.086 + 0.031 + 0.001 avg prob of [ Inigo Jones] 0.05180320516228676\n",
      "loss 1.522 = 1.49 + 0.031 + 0.001 avg prob of [ Inigo Jones] 0.23022298514842987\n",
      "loss 0.577 = 0.552 + 0.024 + 0.001 avg prob of [ Inigo Jones] 0.5848447680473328\n",
      "loss 0.473 = 0.439 + 0.033 + 0.001 avg prob of [ Inigo Jones] 0.6605746150016785\n",
      "loss 0.146 = 0.111 + 0.034 + 0.001 avg prob of [ Inigo Jones] 0.8959642052650452\n",
      "loss 0.085 = 0.055 + 0.029 + 0.001 avg prob of [ Inigo Jones] 0.946386992931366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:02,920 - easyeditor.editors.editor - INFO - 11 editing: The Holmenkollen Chapel project's architect was who? -> Inigo Jones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': \"The Holmenkollen Chapel project's architect was who?\", 'target_new': 'Inigo Jones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Holmenkollen Chapel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:02,920 - easyeditor.editors.editor - INFO - 11 editing: The Holmenkollen Chapel project's architect was who? -> Inigo Jones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': \"The Holmenkollen Chapel project's architect was who?\", 'target_new': 'Inigo Jones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Holmenkollen Chapel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:02 - INFO - easyeditor.editors.editor -   11 editing: The Holmenkollen Chapel project's architect was who? -> Inigo Jones  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': \"The Holmenkollen Chapel project's architect was who?\", 'target_new': 'Inigo Jones', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Holmenkollen Chapel'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 24%|       | 12/50 [00:46<02:05,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.046 = 0.02 + 0.024 + 0.001 avg prob of [ Inigo Jones] 0.9797926545143127\n",
      "Delta norm: 10.9765625\n",
      "Change in target norm: 2.744140625 to 11.2578125 => 8.515625\n",
      "Division Factor: 3.51171875\n",
      "Right vector norm: 3.125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Which language is Pleine Vie written in?] -> [ Coptic]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Pleine Vie\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Which language is Pleine Vie written in? C | Token:  Vie\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.003 = 6.003 + 0.0 + 0.0 avg prob of [ Coptic] 0.0027631453704088926\n",
      "loss 5.042 = 4.884 + 0.156 + 0.001 avg prob of [ Coptic] 0.009354203008115292\n",
      "loss 2.961 = 2.846 + 0.114 + 0.001 avg prob of [ Coptic] 0.06306540220975876\n",
      "loss 1.323 = 1.177 + 0.145 + 0.001 avg prob of [ Coptic] 0.31745555996894836\n",
      "loss 0.821 = 0.75 + 0.069 + 0.001 avg prob of [ Coptic] 0.47985124588012695\n",
      "loss 0.303 = 0.233 + 0.068 + 0.001 avg prob of [ Coptic] 0.7956344485282898\n",
      "loss 0.111 = 0.035 + 0.075 + 0.001 avg prob of [ Coptic] 0.9662771821022034\n",
      "loss 0.074 = 0.003 + 0.07 + 0.001 avg prob of [ Coptic] 0.9971960186958313\n",
      "loss 0.099 = 0.001 + 0.096 + 0.001 avg prob of [ Coptic] 0.9987375140190125\n",
      "loss 0.066 = 0.005 + 0.06 + 0.001 avg prob of [ Coptic] 0.9953635334968567\n",
      "loss 0.058 = 0.007 + 0.049 + 0.001 avg prob of [ Coptic] 0.9929811358451843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:08,328 - easyeditor.editors.editor - INFO - 12 editing: Which language is Pleine Vie written in? -> Coptic  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which language is Pleine Vie written in?', 'target_new': 'Coptic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pleine Vie'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.049 = 0.006 + 0.041 + 0.001 avg prob of [ Coptic] 0.9936099648475647\n",
      "Delta norm: 11.0703125\n",
      "Change in target norm: 2.767578125 to 11.484375 => 8.71875\n",
      "Division Factor: 3.513671875\n",
      "Right vector norm: 3.150390625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:08,328 - easyeditor.editors.editor - INFO - 12 editing: Which language is Pleine Vie written in? -> Coptic  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which language is Pleine Vie written in?', 'target_new': 'Coptic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pleine Vie'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:08 - INFO - easyeditor.editors.editor -   12 editing: Which language is Pleine Vie written in? -> Coptic  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'Which language is Pleine Vie written in?', 'target_new': 'Coptic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pleine Vie'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 26%|       | 13/50 [00:51<02:25,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [Which place is Children Without in?] -> [ New Jersey]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Children Without\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: Which place is Children Without in? New | Token:  Without\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.847 = 4.847 + 0.0 + 0.0 avg prob of [ New Jersey] 0.009055760689079762\n",
      "loss 2.378 = 2.035 + 0.342 + 0.002 avg prob of [ New Jersey] 0.13774871826171875\n",
      "loss 1.791 = 1.419 + 0.371 + 0.002 avg prob of [ New Jersey] 0.2498893290758133\n",
      "loss 1.19 = 0.635 + 0.554 + 0.002 avg prob of [ New Jersey] 0.5435875654220581\n",
      "loss 0.497 = 0.199 + 0.297 + 0.002 avg prob of [ New Jersey] 0.8265573382377625\n",
      "loss 0.216 = 0.05 + 0.165 + 0.002 avg prob of [ New Jersey] 0.9520861506462097\n",
      "loss 0.165 = 0.017 + 0.146 + 0.002 avg prob of [ New Jersey] 0.9831489324569702\n",
      "loss 0.147 = 0.004 + 0.141 + 0.002 avg prob of [ New Jersey] 0.9962062239646912\n",
      "loss 0.134 = 0.002 + 0.131 + 0.002 avg prob of [ New Jersey] 0.9984644055366516\n",
      "loss 0.111 = 0.001 + 0.108 + 0.002 avg prob of [ New Jersey] 0.998687207698822\n",
      "loss 0.077 = 0.007 + 0.068 + 0.002 avg prob of [ New Jersey] 0.9933228492736816\n",
      "loss 0.062 = 0.003 + 0.057 + 0.002 avg prob of [ New Jersey] 0.9965857863426208\n",
      "loss 0.046 = 0.001 + 0.043 + 0.002 avg prob of [ New Jersey] 0.9985384345054626\n",
      "Delta norm: 9.8046875\n",
      "Change in target norm: 2.451171875 to 10.03125 => 7.578125\n",
      "Division Factor: 3.177734375\n",
      "Right vector norm: 3.0859375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:13,576 - easyeditor.editors.editor - INFO - 13 editing: Which place is Children Without in? -> New Jersey  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'Which place is Children Without in?', 'target_new': 'New Jersey', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Children Without'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:13,576 - easyeditor.editors.editor - INFO - 13 editing: Which place is Children Without in? -> New Jersey  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'Which place is Children Without in?', 'target_new': 'New Jersey', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Children Without'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:13 - INFO - easyeditor.editors.editor -   13 editing: Which place is Children Without in? -> New Jersey  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'Which place is Children Without in?', 'target_new': 'New Jersey', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Children Without'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 28%|       | 14/50 [00:57<02:36,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [What country was Ivica Ani in?] -> [ Slovakia]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Ivica Ani\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What country was Ivica Ani in? | Token: i\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.436 = 8.436 + 0.0 + 0.0 avg prob of [ Slovakia] 0.0002647240471560508\n",
      "loss 6.559 = 6.489 + 0.068 + 0.001 avg prob of [ Slovakia] 0.0019968231208622456\n",
      "loss 1.543 = 1.53 + 0.012 + 0.001 avg prob of [ Slovakia] 0.228786900639534\n",
      "loss 0.152 = 0.125 + 0.026 + 0.001 avg prob of [ Slovakia] 0.88352370262146\n",
      "loss 0.077 = 0.041 + 0.035 + 0.001 avg prob of [ Slovakia] 0.9602083563804626\n",
      "loss 0.053 = 0.023 + 0.029 + 0.001 avg prob of [ Slovakia] 0.9769327044487\n",
      "loss 0.05 = 0.014 + 0.035 + 0.001 avg prob of [ Slovakia] 0.9858299493789673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:17,365 - easyeditor.editors.editor - INFO - 14 editing: What country was Ivica Ani in? -> Slovakia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Ivica Ani in?', 'target_new': 'Slovakia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ivica Ani'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:17,365 - easyeditor.editors.editor - INFO - 14 editing: What country was Ivica Ani in? -> Slovakia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Ivica Ani in?', 'target_new': 'Slovakia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ivica Ani'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:17 - INFO - easyeditor.editors.editor -   14 editing: What country was Ivica Ani in? -> Slovakia  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'What country was Ivica Ani in?', 'target_new': 'Slovakia', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ivica Ani'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 30%|       | 15/50 [01:00<02:25,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.03 = 0.011 + 0.018 + 0.001 avg prob of [ Slovakia] 0.9893808960914612\n",
      "Delta norm: 12.90625\n",
      "Change in target norm: 3.2265625 to 13.3359375 => 10.109375\n",
      "Division Factor: 4.03125\n",
      "Right vector norm: 3.201171875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Who is Ahmose-Henuttamehu's father?] -> [ Ahmose-nirari]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Ahmose-Henuttamehu\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Who is Ahmose-Henuttamehu's father? Ahmose-nir | Token: hu\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.55 = 3.55 + 0.0 + 0.0 avg prob of [ Ahmose-nirari] 0.02886386774480343\n",
      "loss 3.007 = 2.942 + 0.064 + 0.001 avg prob of [ Ahmose-nirari] 0.05318726971745491\n",
      "loss 1.677 = 1.635 + 0.041 + 0.001 avg prob of [ Ahmose-nirari] 0.19664902985095978\n",
      "loss 0.688 = 0.646 + 0.041 + 0.001 avg prob of [ Ahmose-nirari] 0.5276848077774048\n",
      "loss 0.258 = 0.22 + 0.037 + 0.001 avg prob of [ Ahmose-nirari] 0.8059213161468506\n",
      "loss 0.141 = 0.109 + 0.03 + 0.001 avg prob of [ Ahmose-nirari] 0.8982560634613037\n",
      "loss 0.085 = 0.05 + 0.034 + 0.001 avg prob of [ Ahmose-nirari] 0.9517943859100342\n",
      "loss 0.078 = 0.015 + 0.062 + 0.001 avg prob of [ Ahmose-nirari] 0.9851680994033813\n",
      "loss 0.068 = 0.007 + 0.06 + 0.001 avg prob of [ Ahmose-nirari] 0.9932827949523926\n",
      "loss 0.154 = 0.004 + 0.149 + 0.001 avg prob of [ Ahmose-nirari] 0.9956463575363159\n",
      "loss 0.081 = 0.005 + 0.075 + 0.001 avg prob of [ Ahmose-nirari] 0.9950608015060425\n",
      "loss 0.07 = 0.005 + 0.064 + 0.001 avg prob of [ Ahmose-nirari] 0.9948230385780334\n",
      "loss 0.067 = 0.004 + 0.062 + 0.001 avg prob of [ Ahmose-nirari] 0.9955295324325562\n",
      "loss 0.062 = 0.003 + 0.058 + 0.001 avg prob of [ Ahmose-nirari] 0.9973530769348145\n",
      "loss 0.059 = 0.002 + 0.055 + 0.001 avg prob of [ Ahmose-nirari] 0.9980196356773376\n",
      "loss 0.056 = 0.002 + 0.053 + 0.001 avg prob of [ Ahmose-nirari] 0.9984670281410217\n",
      "loss 0.053 = 0.001 + 0.051 + 0.001 avg prob of [ Ahmose-nirari] 0.9987787008285522\n",
      "loss 0.052 = 0.001 + 0.05 + 0.001 avg prob of [ Ahmose-nirari] 0.9990079402923584\n",
      "loss 0.051 = 0.001 + 0.049 + 0.001 avg prob of [ Ahmose-nirari] 0.9991730451583862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:25,373 - easyeditor.editors.editor - INFO - 15 editing: Who is Ahmose-Henuttamehu's father? -> Ahmose-nirari  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Who is Ahmose-Henuttamehu's father?\", 'target_new': 'Ahmose-nirari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ahmose-Henuttamehu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:25,373 - easyeditor.editors.editor - INFO - 15 editing: Who is Ahmose-Henuttamehu's father? -> Ahmose-nirari  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Who is Ahmose-Henuttamehu's father?\", 'target_new': 'Ahmose-nirari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ahmose-Henuttamehu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:25 - INFO - easyeditor.editors.editor -   15 editing: Who is Ahmose-Henuttamehu's father? -> Ahmose-nirari  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': \"Who is Ahmose-Henuttamehu's father?\", 'target_new': 'Ahmose-nirari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ahmose-Henuttamehu'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 32%|      | 16/50 [01:08<03:00,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.05 = 0.001 + 0.048 + 0.001 avg prob of [ Ahmose-nirari] 0.9993001222610474\n",
      "Delta norm: 14.0\n",
      "Change in target norm: 3.5 to 14.4375 => 10.9375\n",
      "Division Factor: 4.5234375\n",
      "Right vector norm: 3.095703125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Which college or university is related with Rose Ann Scamardella?] -> [ Columbia University]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Rose Ann Scamardella\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 13 | Sentence: Which college or university is related with Rose Ann Scamardella? Columbia | Token: ella\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.148 = 4.148 + 0.0 + 0.0 avg prob of [ Columbia University] 0.01869378611445427\n",
      "loss 3.023 = 2.99 + 0.032 + 0.001 avg prob of [ Columbia University] 0.06412705034017563\n",
      "loss 0.654 = 0.573 + 0.08 + 0.001 avg prob of [ Columbia University] 0.5754449367523193\n",
      "loss 0.129 = 0.091 + 0.037 + 0.001 avg prob of [ Columbia University] 0.9134787917137146\n",
      "loss 0.057 = 0.016 + 0.04 + 0.001 avg prob of [ Columbia University] 0.9843233227729797\n",
      "loss 0.05 = 0.004 + 0.045 + 0.001 avg prob of [ Columbia University] 0.9960774183273315\n",
      "Delta norm: 12.34375\n",
      "Change in target norm: 3.0859375 to 12.8046875 => 9.71875\n",
      "Division Factor: 3.88671875\n",
      "Right vector norm: 3.17578125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:28,114 - easyeditor.editors.editor - INFO - 16 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:28,114 - easyeditor.editors.editor - INFO - 16 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:28 - INFO - easyeditor.editors.editor -   16 editing: Which college or university is related with Rose Ann Scamardella? -> Columbia University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'Which college or university is related with Rose Ann Scamardella?', 'target_new': 'Columbia University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Rose Ann Scamardella'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 34%|      | 17/50 [01:11<02:30,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [Which network broadcasted Smash Lab?] -> [ TNT]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Smash Lab\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: Which network broadcasted Smash Lab? | Token:  Lab\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 7.794 = 7.794 + 0.0 + 0.0 avg prob of [ TNT] 0.0006753972265869379\n",
      "loss 5.56 = 5.45 + 0.108 + 0.001 avg prob of [ TNT] 0.012388963252305984\n",
      "loss 0.221 = 0.152 + 0.067 + 0.001 avg prob of [ TNT] 0.8622426986694336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:29,830 - easyeditor.editors.editor - INFO - 17 editing: Which network broadcasted Smash Lab? -> TNT  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Which network broadcasted Smash Lab?', 'target_new': 'TNT', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Smash Lab'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:29,830 - easyeditor.editors.editor - INFO - 17 editing: Which network broadcasted Smash Lab? -> TNT  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Which network broadcasted Smash Lab?', 'target_new': 'TNT', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Smash Lab'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:29 - INFO - easyeditor.editors.editor -   17 editing: Which network broadcasted Smash Lab? -> TNT  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'Which network broadcasted Smash Lab?', 'target_new': 'TNT', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Smash Lab'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 36%|      | 18/50 [01:13<01:58,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.048 = 0.015 + 0.032 + 0.001 avg prob of [ TNT] 0.9855858087539673\n",
      "Delta norm: 14.234375\n",
      "Change in target norm: 3.55859375 to 14.6953125 => 11.140625\n",
      "Division Factor: 4.3984375\n",
      "Right vector norm: 3.236328125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What is an ecological status of Coptodon spongotroktis?] -> [ Data Deficient]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Coptodon spongotroktis\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 15 | Sentence: What is an ecological status of Coptodon spongotroktis? Data Def | Token: is\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.766 = 3.766 + 0.0 + 0.0 avg prob of [ Data Deficient] 0.028897760435938835\n",
      "loss 3.2 = 3.077 + 0.122 + 0.001 avg prob of [ Data Deficient] 0.0528884120285511\n",
      "loss 2.437 = 2.408 + 0.027 + 0.001 avg prob of [ Data Deficient] 0.097671739757061\n",
      "loss 2.497 = 2.48 + 0.016 + 0.001 avg prob of [ Data Deficient] 0.09298986941576004\n",
      "loss 1.056 = 1.017 + 0.038 + 0.001 avg prob of [ Data Deficient] 0.3789212703704834\n",
      "loss 0.254 = 0.146 + 0.107 + 0.001 avg prob of [ Data Deficient] 0.8653466701507568\n",
      "loss 0.122 = 0.019 + 0.102 + 0.001 avg prob of [ Data Deficient] 0.9820662140846252\n",
      "loss 0.104 = 0.0 + 0.102 + 0.001 avg prob of [ Data Deficient] 0.9995478987693787\n",
      "loss 0.102 = 0.0 + 0.1 + 0.001 avg prob of [ Data Deficient] 0.9998740553855896\n",
      "loss 0.129 = 0.0 + 0.128 + 0.001 avg prob of [ Data Deficient] 0.9999354481697083\n",
      "loss 0.131 = 0.008 + 0.122 + 0.001 avg prob of [ Data Deficient] 0.9917014837265015\n",
      "loss 0.194 = 0.09 + 0.102 + 0.001 avg prob of [ Data Deficient] 0.9142423272132874\n",
      "loss 0.108 = 0.005 + 0.102 + 0.001 avg prob of [ Data Deficient] 0.9954958558082581\n",
      "loss 0.105 = 0.001 + 0.102 + 0.001 avg prob of [ Data Deficient] 0.9985547661781311\n",
      "loss 0.106 = 0.002 + 0.103 + 0.001 avg prob of [ Data Deficient] 0.9980962872505188\n",
      "loss 0.106 = 0.002 + 0.103 + 0.001 avg prob of [ Data Deficient] 0.9981127381324768\n",
      "loss 0.105 = 0.001 + 0.102 + 0.001 avg prob of [ Data Deficient] 0.9990901350975037\n",
      "loss 0.104 = 0.001 + 0.102 + 0.001 avg prob of [ Data Deficient] 0.999497652053833\n",
      "loss 0.104 = 0.0 + 0.102 + 0.001 avg prob of [ Data Deficient] 0.9996461868286133\n",
      "loss 0.102 = 0.0 + 0.101 + 0.001 avg prob of [ Data Deficient] 0.9997099041938782\n",
      "loss 0.096 = 0.0 + 0.094 + 0.001 avg prob of [ Data Deficient] 0.9997337460517883\n",
      "loss 0.058 = 0.0 + 0.056 + 0.001 avg prob of [ Data Deficient] 0.9996970295906067\n",
      "loss 0.055 = 0.0 + 0.053 + 0.001 avg prob of [ Data Deficient] 0.9996316432952881\n",
      "loss 0.052 = 0.001 + 0.05 + 0.001 avg prob of [ Data Deficient] 0.9993265271186829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:41,244 - easyeditor.editors.editor - INFO - 18 editing: What is an ecological status of Coptodon spongotroktis? -> Data Deficient  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is an ecological status of Coptodon spongotroktis?', 'target_new': 'Data Deficient', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Coptodon spongotroktis'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:41,244 - easyeditor.editors.editor - INFO - 18 editing: What is an ecological status of Coptodon spongotroktis? -> Data Deficient  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is an ecological status of Coptodon spongotroktis?', 'target_new': 'Data Deficient', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Coptodon spongotroktis'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:41 - INFO - easyeditor.editors.editor -   18 editing: What is an ecological status of Coptodon spongotroktis? -> Data Deficient  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'What is an ecological status of Coptodon spongotroktis?', 'target_new': 'Data Deficient', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Coptodon spongotroktis'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 38%|      | 19/50 [01:24<03:06,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.061 = 0.001 + 0.058 + 0.001 avg prob of [ Data Deficient] 0.9987409710884094\n",
      "Delta norm: 11.9375\n",
      "Change in target norm: 2.984375 to 12.4296875 => 9.4453125\n",
      "Division Factor: 3.99609375\n",
      "Right vector norm: 2.986328125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What was Jos Luccioni's range?] -> [ soprano]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Jos Luccioni\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: What was Jos Luccioni's range? sopr | Token: i\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 6.615 = 6.615 + 0.0 + 0.0 avg prob of [ soprano] 0.0015964999329298735\n",
      "loss 4.335 = 4.268 + 0.066 + 0.001 avg prob of [ soprano] 0.015238799154758453\n",
      "loss 2.221 = 2.166 + 0.054 + 0.001 avg prob of [ soprano] 0.12430203706026077\n",
      "loss 0.629 = 0.439 + 0.189 + 0.001 avg prob of [ soprano] 0.7078127264976501\n",
      "loss 0.319 = 0.248 + 0.069 + 0.001 avg prob of [ soprano] 0.791826605796814\n",
      "loss 0.093 = 0.019 + 0.073 + 0.001 avg prob of [ soprano] 0.9814716577529907\n",
      "loss 0.065 = 0.004 + 0.06 + 0.001 avg prob of [ soprano] 0.9958105087280273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:43,990 - easyeditor.editors.editor - INFO - 19 editing: What was Jos Luccioni's range? -> soprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"What was Jos Luccioni's range?\", 'target_new': 'soprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jos Luccioni'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:43,990 - easyeditor.editors.editor - INFO - 19 editing: What was Jos Luccioni's range? -> soprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"What was Jos Luccioni's range?\", 'target_new': 'soprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jos Luccioni'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:43 - INFO - easyeditor.editors.editor -   19 editing: What was Jos Luccioni's range? -> soprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': \"What was Jos Luccioni's range?\", 'target_new': 'soprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jos Luccioni'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 40%|      | 20/50 [01:27<02:30,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.048 = 0.002 + 0.044 + 0.001 avg prob of [ soprano] 0.9976975917816162\n",
      "Delta norm: 11.8828125\n",
      "Change in target norm: 2.970703125 to 12.3203125 => 9.3515625\n",
      "Division Factor: 3.76171875\n",
      "Right vector norm: 3.158203125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Who is the director for Oru Raagam Pala Thaalam?] -> [ M Krishnan Nair]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Oru Raagam Pala Thaalam\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 15 | Sentence: Who is the director for Oru Raagam Pala Thaalam? M Krishnan N | Token: alam\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.007 = 3.007 + 0.0 + 0.0 avg prob of [ M Krishnan Nair] 0.04990077018737793\n",
      "loss 2.678 = 2.513 + 0.164 + 0.001 avg prob of [ M Krishnan Nair] 0.08176937699317932\n",
      "loss 2.156 = 2.081 + 0.074 + 0.001 avg prob of [ M Krishnan Nair] 0.1273936629295349\n",
      "loss 2.814 = 2.769 + 0.043 + 0.001 avg prob of [ M Krishnan Nair] 0.06405065953731537\n",
      "loss 1.797 = 1.783 + 0.013 + 0.001 avg prob of [ M Krishnan Nair] 0.1705734133720398\n",
      "loss 1.857 = 1.848 + 0.008 + 0.001 avg prob of [ M Krishnan Nair] 0.16220758855342865\n",
      "loss 0.839 = 0.828 + 0.01 + 0.001 avg prob of [ M Krishnan Nair] 0.4509012997150421\n",
      "loss 0.496 = 0.476 + 0.019 + 0.001 avg prob of [ M Krishnan Nair] 0.6284688711166382\n",
      "loss 0.252 = 0.227 + 0.025 + 0.001 avg prob of [ M Krishnan Nair] 0.7992756366729736\n",
      "loss 0.12 = 0.094 + 0.025 + 0.001 avg prob of [ M Krishnan Nair] 0.910923182964325\n",
      "loss 0.068 = 0.048 + 0.019 + 0.001 avg prob of [ M Krishnan Nair] 0.9531660079956055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:49,029 - easyeditor.editors.editor - INFO - 20 editing: Who is the director for Oru Raagam Pala Thaalam? -> M Krishnan Nair  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who is the director for Oru Raagam Pala Thaalam?', 'target_new': 'M Krishnan Nair', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Oru Raagam Pala Thaalam'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:49,029 - easyeditor.editors.editor - INFO - 20 editing: Who is the director for Oru Raagam Pala Thaalam? -> M Krishnan Nair  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who is the director for Oru Raagam Pala Thaalam?', 'target_new': 'M Krishnan Nair', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Oru Raagam Pala Thaalam'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:49 - INFO - easyeditor.editors.editor -   20 editing: Who is the director for Oru Raagam Pala Thaalam? -> M Krishnan Nair  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'Who is the director for Oru Raagam Pala Thaalam?', 'target_new': 'M Krishnan Nair', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Oru Raagam Pala Thaalam'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 42%|     | 21/50 [01:32<02:26,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.042 = 0.021 + 0.02 + 0.001 avg prob of [ M Krishnan Nair] 0.97917240858078\n",
      "Delta norm: 14.3125\n",
      "Change in target norm: 3.578125 to 14.9375 => 11.359375\n",
      "Division Factor: 4.58203125\n",
      "Right vector norm: 3.123046875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [On what planet is Solander Point on?] -> [ Mars]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Solander Point\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: On what planet is Solander Point on? | Token:  Point\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.479 = 4.479 + 0.0 + 0.0 avg prob of [ Mars] 0.039193615317344666\n",
      "loss 1.572 = 1.513 + 0.057 + 0.001 avg prob of [ Mars] 0.2807961404323578\n",
      "loss 0.387 = 0.327 + 0.059 + 0.001 avg prob of [ Mars] 0.7331852316856384\n",
      "loss 0.074 = 0.034 + 0.038 + 0.001 avg prob of [ Mars] 0.966343879699707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:51,004 - easyeditor.editors.editor - INFO - 21 editing: On what planet is Solander Point on? -> Mars  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'On what planet is Solander Point on?', 'target_new': 'Mars', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Solander Point'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:51,004 - easyeditor.editors.editor - INFO - 21 editing: On what planet is Solander Point on? -> Mars  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'On what planet is Solander Point on?', 'target_new': 'Mars', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Solander Point'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:51 - INFO - easyeditor.editors.editor -   21 editing: On what planet is Solander Point on? -> Mars  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'On what planet is Solander Point on?', 'target_new': 'Mars', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Solander Point'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 44%|     | 22/50 [01:34<01:55,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.029 = 0.006 + 0.021 + 0.001 avg prob of [ Mars] 0.9938074946403503\n",
      "Delta norm: 11.3515625\n",
      "Change in target norm: 2.837890625 to 11.796875 => 8.9609375\n",
      "Division Factor: 3.677734375\n",
      "Right vector norm: 3.0859375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Which was the official year for the approval of JS 7.62?] -> [ 1966]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object JS 7.62\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 14 | Sentence: Which was the official year for the approval of JS 7.62? 196 | Token: 62\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.6 = 2.6 + 0.0 + 0.0 avg prob of [ 1966] 0.07855934649705887\n",
      "loss 1.783 = 1.628 + 0.154 + 0.001 avg prob of [ 1966] 0.200463205575943\n",
      "loss 0.853 = 0.704 + 0.148 + 0.001 avg prob of [ 1966] 0.4976101815700531\n",
      "loss 0.442 = 0.285 + 0.156 + 0.001 avg prob of [ 1966] 0.7564443945884705\n",
      "loss 0.281 = 0.128 + 0.152 + 0.001 avg prob of [ 1966] 0.8817045092582703\n",
      "loss 0.204 = 0.045 + 0.157 + 0.001 avg prob of [ 1966] 0.9561778903007507\n",
      "loss 0.174 = 0.019 + 0.154 + 0.001 avg prob of [ 1966] 0.9816727638244629\n",
      "loss 0.155 = 0.009 + 0.145 + 0.001 avg prob of [ 1966] 0.9910049438476562\n",
      "loss 0.125 = 0.005 + 0.118 + 0.001 avg prob of [ 1966] 0.9947695136070251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:54,920 - easyeditor.editors.editor - INFO - 22 editing: Which was the official year for the approval of JS 7.62? -> 1966  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Which was the official year for the approval of JS 7.62?', 'target_new': '1966', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'JS 7.62'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:54,920 - easyeditor.editors.editor - INFO - 22 editing: Which was the official year for the approval of JS 7.62? -> 1966  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Which was the official year for the approval of JS 7.62?', 'target_new': '1966', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'JS 7.62'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:54 - INFO - easyeditor.editors.editor -   22 editing: Which was the official year for the approval of JS 7.62? -> 1966  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'Which was the official year for the approval of JS 7.62?', 'target_new': '1966', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'JS 7.62'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 46%|     | 23/50 [01:38<01:49,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.026 = 0.005 + 0.02 + 0.001 avg prob of [ 1966] 0.995483934879303\n",
      "Delta norm: 12.0625\n",
      "Change in target norm: 3.015625 to 12.375 => 9.359375\n",
      "Division Factor: 3.85546875\n",
      "Right vector norm: 3.12890625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What city did Dulcina de Moraes live when he died?] -> [ So Paulo]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Dulcina de Moraes\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What city did Dulcina de Moraes live when he died? So | Token: es\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.063 = 3.063 + 0.0 + 0.0 avg prob of [ So Paulo] 0.06245565414428711\n",
      "loss 2.631 = 2.526 + 0.104 + 0.001 avg prob of [ So Paulo] 0.09806792438030243\n",
      "loss 4.222 = 4.162 + 0.058 + 0.001 avg prob of [ So Paulo] 0.01628556102514267\n",
      "loss 4.656 = 4.595 + 0.059 + 0.001 avg prob of [ So Paulo] 0.010456051677465439\n",
      "loss 3.441 = 3.398 + 0.042 + 0.001 avg prob of [ So Paulo] 0.03475066274404526\n",
      "loss 2.39 = 2.358 + 0.03 + 0.001 avg prob of [ So Paulo] 0.09986671060323715\n",
      "loss 1.316 = 1.279 + 0.035 + 0.001 avg prob of [ So Paulo] 0.29214465618133545\n",
      "loss 0.539 = 0.5 + 0.038 + 0.001 avg prob of [ So Paulo] 0.6108359694480896\n",
      "loss 0.167 = 0.122 + 0.044 + 0.001 avg prob of [ So Paulo] 0.8852720260620117\n",
      "loss 0.083 = 0.043 + 0.038 + 0.001 avg prob of [ So Paulo] 0.9580434560775757\n",
      "loss 0.06 = 0.021 + 0.038 + 0.001 avg prob of [ So Paulo] 0.9792554974555969\n",
      "loss 0.051 = 0.014 + 0.036 + 0.001 avg prob of [ So Paulo] 0.9862140417098999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:16:59,815 - easyeditor.editors.editor - INFO - 23 editing: What city did Dulcina de Moraes live when he died? -> So Paulo  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What city did Dulcina de Moraes live when he died?', 'target_new': 'So Paulo', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dulcina de Moraes'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:16:59,815 - easyeditor.editors.editor - INFO - 23 editing: What city did Dulcina de Moraes live when he died? -> So Paulo  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What city did Dulcina de Moraes live when he died?', 'target_new': 'So Paulo', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dulcina de Moraes'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:16:59 - INFO - easyeditor.editors.editor -   23 editing: What city did Dulcina de Moraes live when he died? -> So Paulo  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'What city did Dulcina de Moraes live when he died?', 'target_new': 'So Paulo', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Dulcina de Moraes'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 48%|     | 24/50 [01:43<01:51,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.043 = 0.011 + 0.03 + 0.001 avg prob of [ So Paulo] 0.9888538122177124\n",
      "Delta norm: 11.4375\n",
      "Change in target norm: 2.859375 to 11.7578125 => 8.8984375\n",
      "Division Factor: 3.666015625\n",
      "Right vector norm: 3.119140625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Which was the production company for Peepli Live?] -> [ Peepli Entertainment]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Peepli Live\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Which was the production company for Peepli Live? Peepli | Token:  Live\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.313 = 4.313 + 0.0 + 0.0 avg prob of [ Peepli Entertainment] 0.01367154996842146\n",
      "loss 2.613 = 2.528 + 0.084 + 0.001 avg prob of [ Peepli Entertainment] 0.0829688236117363\n",
      "loss 0.676 = 0.655 + 0.019 + 0.001 avg prob of [ Peepli Entertainment] 0.5349032878875732\n",
      "loss 0.148 = 0.121 + 0.026 + 0.001 avg prob of [ Peepli Entertainment] 0.8864638209342957\n",
      "loss 0.057 = 0.039 + 0.016 + 0.001 avg prob of [ Peepli Entertainment] 0.9615996479988098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:02,098 - easyeditor.editors.editor - INFO - 24 editing: Which was the production company for Peepli Live? -> Peepli Entertainment  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'Which was the production company for Peepli Live?', 'target_new': 'Peepli Entertainment', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Peepli Live'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:02,098 - easyeditor.editors.editor - INFO - 24 editing: Which was the production company for Peepli Live? -> Peepli Entertainment  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'Which was the production company for Peepli Live?', 'target_new': 'Peepli Entertainment', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Peepli Live'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:02 - INFO - easyeditor.editors.editor -   24 editing: Which was the production company for Peepli Live? -> Peepli Entertainment  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'Which was the production company for Peepli Live?', 'target_new': 'Peepli Entertainment', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Peepli Live'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 50%|     | 25/50 [01:45<01:32,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.032 = 0.018 + 0.013 + 0.001 avg prob of [ Peepli Entertainment] 0.982268750667572\n",
      "Delta norm: 12.15625\n",
      "Change in target norm: 3.0390625 to 12.6015625 => 9.5625\n",
      "Division Factor: 4.0234375\n",
      "Right vector norm: 3.021484375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [The The Testament of Sherlock Holmes was in what series?] -> [  Sherlock Holmes]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Testament of Sherlock Holmes\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 6 | Sentence: The The Testament of Sherlock Holmes was in what series?  Sherlock | Token:  Holmes\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.018 = 3.018 + 0.0 + 0.0 avg prob of [  Sherlock Holmes] 0.058536507189273834\n",
      "loss 2.541 = 2.501 + 0.039 + 0.001 avg prob of [  Sherlock Holmes] 0.0878361165523529\n",
      "loss 1.707 = 1.681 + 0.025 + 0.001 avg prob of [  Sherlock Holmes] 0.19546949863433838\n",
      "loss 0.917 = 0.895 + 0.021 + 0.001 avg prob of [  Sherlock Holmes] 0.4178282618522644\n",
      "loss 0.6 = 0.117 + 0.482 + 0.001 avg prob of [  Sherlock Holmes] 0.8984858393669128\n",
      "loss 0.176 = 0.11 + 0.065 + 0.001 avg prob of [  Sherlock Holmes] 0.8967737555503845\n",
      "loss 0.107 = 0.059 + 0.047 + 0.001 avg prob of [  Sherlock Holmes] 0.9471645355224609\n",
      "loss 0.081 = 0.033 + 0.047 + 0.001 avg prob of [  Sherlock Holmes] 0.9680368304252625\n",
      "loss 0.055 = 0.003 + 0.05 + 0.001 avg prob of [  Sherlock Holmes] 0.9966841340065002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:07,084 - easyeditor.editors.editor - INFO - 25 editing: The The Testament of Sherlock Holmes was in what series? ->  Sherlock Holmes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The The Testament of Sherlock Holmes was in what series?', 'target_new': ' Sherlock Holmes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Testament of Sherlock Holmes'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:07,084 - easyeditor.editors.editor - INFO - 25 editing: The The Testament of Sherlock Holmes was in what series? ->  Sherlock Holmes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The The Testament of Sherlock Holmes was in what series?', 'target_new': ' Sherlock Holmes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Testament of Sherlock Holmes'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:07 - INFO - easyeditor.editors.editor -   25 editing: The The Testament of Sherlock Holmes was in what series? ->  Sherlock Holmes  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The The Testament of Sherlock Holmes was in what series?', 'target_new': ' Sherlock Holmes', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Testament of Sherlock Holmes'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 52%|    | 26/50 [01:50<01:38,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.032 = 0.002 + 0.028 + 0.001 avg prob of [  Sherlock Holmes] 0.9979272484779358\n",
      "Delta norm: 11.2890625\n",
      "Change in target norm: 2.822265625 to 11.6328125 => 8.8125\n",
      "Division Factor: 3.650390625\n",
      "Right vector norm: 3.091796875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What is the publisher of Crashday?] -> [ Sega]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Crashday\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What is the publisher of Crashday? | Token: day\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.117 = 8.117 + 0.0 + 0.0 avg prob of [ Sega] 0.0005621844320558012\n",
      "loss 5.257 = 5.085 + 0.171 + 0.001 avg prob of [ Sega] 0.011175524443387985\n",
      "loss 1.902 = 1.853 + 0.047 + 0.001 avg prob of [ Sega] 0.17262376844882965\n",
      "loss 0.36 = 0.303 + 0.057 + 0.001 avg prob of [ Sega] 0.7456279397010803\n",
      "loss 0.137 = 0.085 + 0.05 + 0.001 avg prob of [ Sega] 0.9191084504127502\n",
      "loss 0.083 = 0.039 + 0.042 + 0.001 avg prob of [ Sega] 0.9615913033485413\n",
      "loss 0.058 = 0.022 + 0.035 + 0.001 avg prob of [ Sega] 0.9785928726196289\n",
      "loss 0.043 = 0.014 + 0.028 + 0.001 avg prob of [ Sega] 0.986527681350708\n",
      "Delta norm: 13.9765625\n",
      "Change in target norm: 3.494140625 to 14.4921875 => 11.0\n",
      "Division Factor: 4.33984375\n",
      "Right vector norm: 3.220703125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:10,622 - easyeditor.editors.editor - INFO - 26 editing: What is the publisher of Crashday? -> Sega  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the publisher of Crashday?', 'target_new': 'Sega', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Crashday'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:10,622 - easyeditor.editors.editor - INFO - 26 editing: What is the publisher of Crashday? -> Sega  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the publisher of Crashday?', 'target_new': 'Sega', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Crashday'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:10 - INFO - easyeditor.editors.editor -   26 editing: What is the publisher of Crashday? -> Sega  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'What is the publisher of Crashday?', 'target_new': 'Sega', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Crashday'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 54%|    | 27/50 [01:54<01:30,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [The artwork The Forest Fire was by who?] -> [ William Etty]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object The Forest Fire\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: The artwork The Forest Fire was by who? William Et | Token:  Fire\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.295 = 4.295 + 0.0 + 0.0 avg prob of [ William Etty] 0.014378059655427933\n",
      "loss 2.975 = 2.854 + 0.12 + 0.001 avg prob of [ William Etty] 0.063753642141819\n",
      "loss 2.358 = 2.106 + 0.251 + 0.001 avg prob of [ William Etty] 0.14142557978630066\n",
      "loss 2.981 = 2.777 + 0.203 + 0.001 avg prob of [ William Etty] 0.06720668822526932\n",
      "loss 1.706 = 1.551 + 0.154 + 0.001 avg prob of [ William Etty] 0.23042356967926025\n",
      "loss 0.959 = 0.804 + 0.153 + 0.001 avg prob of [ William Etty] 0.46427229046821594\n",
      "loss 0.415 = 0.266 + 0.149 + 0.001 avg prob of [ William Etty] 0.7736304402351379\n",
      "loss 0.226 = 0.06 + 0.165 + 0.001 avg prob of [ William Etty] 0.9427675604820251\n",
      "loss 0.148 = 0.026 + 0.121 + 0.001 avg prob of [ William Etty] 0.9747848510742188\n",
      "loss 0.123 = 0.013 + 0.108 + 0.001 avg prob of [ William Etty] 0.9873931407928467\n",
      "loss 0.108 = 0.006 + 0.101 + 0.001 avg prob of [ William Etty] 0.994268536567688\n",
      "loss 0.101 = 0.003 + 0.096 + 0.001 avg prob of [ William Etty] 0.9965988397598267\n",
      "loss 0.096 = 0.002 + 0.092 + 0.001 avg prob of [ William Etty] 0.9976040124893188\n",
      "loss 0.091 = 0.002 + 0.088 + 0.001 avg prob of [ William Etty] 0.9981498718261719\n",
      "loss 0.087 = 0.002 + 0.084 + 0.001 avg prob of [ William Etty] 0.9984548687934875\n",
      "loss 0.081 = 0.001 + 0.079 + 0.001 avg prob of [ William Etty] 0.9985485076904297\n",
      "loss 0.075 = 0.002 + 0.072 + 0.001 avg prob of [ William Etty] 0.9983762502670288\n",
      "loss 0.067 = 0.002 + 0.063 + 0.001 avg prob of [ William Etty] 0.9977183938026428\n",
      "loss 0.061 = 0.004 + 0.056 + 0.001 avg prob of [ William Etty] 0.9962459802627563\n",
      "loss 0.058 = 0.005 + 0.052 + 0.001 avg prob of [ William Etty] 0.9953456521034241\n",
      "loss 0.052 = 0.004 + 0.047 + 0.001 avg prob of [ William Etty] 0.9964907765388489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:19,189 - easyeditor.editors.editor - INFO - 27 editing: The artwork The Forest Fire was by who? -> William Etty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The artwork The Forest Fire was by who?', 'target_new': 'William Etty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Forest Fire'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:19,189 - easyeditor.editors.editor - INFO - 27 editing: The artwork The Forest Fire was by who? -> William Etty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The artwork The Forest Fire was by who?', 'target_new': 'William Etty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Forest Fire'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:19 - INFO - easyeditor.editors.editor -   27 editing: The artwork The Forest Fire was by who? -> William Etty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The artwork The Forest Fire was by who?', 'target_new': 'William Etty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'The Forest Fire'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 56%|    | 28/50 [02:02<01:56,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.047 = 0.002 + 0.043 + 0.001 avg prob of [ William Etty] 0.9976146817207336\n",
      "Delta norm: 12.3203125\n",
      "Change in target norm: 3.080078125 to 12.7890625 => 9.7109375\n",
      "Division Factor: 3.65234375\n",
      "Right vector norm: 3.373046875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What year was it when Sunnyside Hospital was dissolved?] -> [ 1960]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Sunnyside Hospital\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What year was it when Sunnyside Hospital was dissolved? 196 | Token:  Hospital\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.593 = 2.593 + 0.0 + 0.0 avg prob of [ 1960] 0.07885002344846725\n",
      "loss 1.929 = 1.78 + 0.148 + 0.001 avg prob of [ 1960] 0.17457327246665955\n",
      "loss 1.212 = 1.161 + 0.05 + 0.001 avg prob of [ 1960] 0.33395832777023315\n",
      "loss 2.111 = 2.057 + 0.053 + 0.001 avg prob of [ 1960] 0.13541030883789062\n",
      "loss 0.725 = 0.646 + 0.078 + 0.001 avg prob of [ 1960] 0.5393615365028381\n",
      "loss 0.428 = 0.364 + 0.063 + 0.001 avg prob of [ 1960] 0.7041806578636169\n",
      "loss 0.243 = 0.202 + 0.04 + 0.001 avg prob of [ 1960] 0.8197194337844849\n",
      "loss 0.153 = 0.12 + 0.032 + 0.001 avg prob of [ 1960] 0.8876996040344238\n",
      "loss 0.105 = 0.071 + 0.033 + 0.001 avg prob of [ 1960] 0.9315958619117737\n",
      "loss 0.072 = 0.042 + 0.029 + 0.001 avg prob of [ 1960] 0.9588437676429749\n",
      "loss 0.053 = 0.024 + 0.028 + 0.001 avg prob of [ 1960] 0.9759699702262878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:23,718 - easyeditor.editors.editor - INFO - 28 editing: What year was it when Sunnyside Hospital was dissolved? -> 1960  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'What year was it when Sunnyside Hospital was dissolved?', 'target_new': '1960', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:23,718 - easyeditor.editors.editor - INFO - 28 editing: What year was it when Sunnyside Hospital was dissolved? -> 1960  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'What year was it when Sunnyside Hospital was dissolved?', 'target_new': '1960', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:23 - INFO - easyeditor.editors.editor -   28 editing: What year was it when Sunnyside Hospital was dissolved? -> 1960  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'What year was it when Sunnyside Hospital was dissolved?', 'target_new': '1960', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 58%|    | 29/50 [02:07<01:46,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.04 = 0.013 + 0.026 + 0.001 avg prob of [ 1960] 0.9872273206710815\n",
      "Delta norm: 12.0859375\n",
      "Change in target norm: 3.021484375 to 12.59375 => 9.5703125\n",
      "Division Factor: 3.740234375\n",
      "Right vector norm: 3.23046875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Which college or university is related with Gar Forman?] -> [ Brown University]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Gar Forman\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Which college or university is related with Gar Forman? Brown | Token: an\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 5.015 = 5.015 + 0.0 + 0.0 avg prob of [ Brown University] 0.0076088495552539825\n",
      "loss 4.51 = 4.368 + 0.14 + 0.001 avg prob of [ Brown University] 0.01406821794807911\n",
      "loss 1.818 = 1.751 + 0.065 + 0.001 avg prob of [ Brown University] 0.18181461095809937\n",
      "loss 0.924 = 0.848 + 0.074 + 0.001 avg prob of [ Brown University] 0.43627840280532837\n",
      "loss 0.516 = 0.443 + 0.072 + 0.001 avg prob of [ Brown University] 0.6493792533874512\n",
      "loss 0.266 = 0.197 + 0.068 + 0.001 avg prob of [ Brown University] 0.8244840502738953\n",
      "loss 0.135 = 0.065 + 0.069 + 0.001 avg prob of [ Brown University] 0.9378652572631836\n",
      "loss 0.084 = 0.022 + 0.061 + 0.001 avg prob of [ Brown University] 0.9787485003471375\n",
      "loss 0.055 = 0.01 + 0.044 + 0.001 avg prob of [ Brown University] 0.9900369644165039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:27,016 - easyeditor.editors.editor - INFO - 29 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:27,016 - easyeditor.editors.editor - INFO - 29 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:27 - INFO - easyeditor.editors.editor -   29 editing: Which college or university is related with Gar Forman? -> Brown University  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Which college or university is related with Gar Forman?', 'target_new': 'Brown University', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gar Forman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 60%|    | 30/50 [02:10<01:30,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.036 = 0.005 + 0.03 + 0.001 avg prob of [ Brown University] 0.9953721761703491\n",
      "Delta norm: 12.640625\n",
      "Change in target norm: 3.16015625 to 13.0390625 => 9.875\n",
      "Division Factor: 3.865234375\n",
      "Right vector norm: 3.26953125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Which state is Zarby-Bindugi located?] -> [ Gmina Strzelce]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Zarby-Bindugi\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: Which state is Zarby-Bindugi located? Gmina Strzel | Token: ugi\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.087 = 3.087 + 0.0 + 0.0 avg prob of [ Gmina Strzelce] 0.04717401787638664\n",
      "loss 2.728 = 2.692 + 0.035 + 0.001 avg prob of [ Gmina Strzelce] 0.06954514235258102\n",
      "loss 2.85 = 2.822 + 0.027 + 0.001 avg prob of [ Gmina Strzelce] 0.06158170849084854\n",
      "loss 1.944 = 1.912 + 0.03 + 0.001 avg prob of [ Gmina Strzelce] 0.15117108821868896\n",
      "loss 1.256 = 1.23 + 0.025 + 0.001 avg prob of [ Gmina Strzelce] 0.29498666524887085\n",
      "loss 0.715 = 0.687 + 0.027 + 0.001 avg prob of [ Gmina Strzelce] 0.506523609161377\n",
      "loss 0.344 = 0.313 + 0.03 + 0.001 avg prob of [ Gmina Strzelce] 0.7501462697982788\n",
      "loss 0.311 = 0.268 + 0.041 + 0.001 avg prob of [ Gmina Strzelce] 0.7650277614593506\n",
      "loss 0.078 = 0.041 + 0.036 + 0.001 avg prob of [ Gmina Strzelce] 0.9596709609031677\n",
      "loss 0.085 = 0.008 + 0.076 + 0.001 avg prob of [ Gmina Strzelce] 0.9916919469833374\n",
      "loss 0.083 = 0.005 + 0.076 + 0.001 avg prob of [ Gmina Strzelce] 0.9948219060897827\n",
      "loss 0.08 = 0.002 + 0.076 + 0.001 avg prob of [ Gmina Strzelce] 0.997867226600647\n",
      "loss 0.079 = 0.001 + 0.076 + 0.001 avg prob of [ Gmina Strzelce] 0.9986379146575928\n",
      "loss 0.078 = 0.001 + 0.076 + 0.001 avg prob of [ Gmina Strzelce] 0.9989751577377319\n",
      "loss 0.077 = 0.001 + 0.075 + 0.001 avg prob of [ Gmina Strzelce] 0.9992087483406067\n",
      "loss 0.076 = 0.001 + 0.074 + 0.001 avg prob of [ Gmina Strzelce] 0.9993736743927002\n",
      "loss 0.073 = 0.001 + 0.071 + 0.001 avg prob of [ Gmina Strzelce] 0.9994909167289734\n",
      "loss 0.068 = 0.0 + 0.066 + 0.001 avg prob of [ Gmina Strzelce] 0.9995609521865845\n",
      "loss 0.058 = 0.0 + 0.056 + 0.001 avg prob of [ Gmina Strzelce] 0.9995437860488892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:34,156 - easyeditor.editors.editor - INFO - 30 editing: Which state is Zarby-Bindugi located? -> Gmina Strzelce  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which state is Zarby-Bindugi located?', 'target_new': 'Gmina Strzelce', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Zarby-Bindugi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:34,156 - easyeditor.editors.editor - INFO - 30 editing: Which state is Zarby-Bindugi located? -> Gmina Strzelce  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which state is Zarby-Bindugi located?', 'target_new': 'Gmina Strzelce', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Zarby-Bindugi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:34 - INFO - easyeditor.editors.editor -   30 editing: Which state is Zarby-Bindugi located? -> Gmina Strzelce  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'Which state is Zarby-Bindugi located?', 'target_new': 'Gmina Strzelce', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Zarby-Bindugi'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 62%|   | 31/50 [02:17<01:41,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.047 = 0.001 + 0.045 + 0.001 avg prob of [ Gmina Strzelce] 0.9993093609809875\n",
      "Delta norm: 11.71875\n",
      "Change in target norm: 2.9296875 to 12.1796875 => 9.25\n",
      "Division Factor: 3.71484375\n",
      "Right vector norm: 3.154296875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What year was the end of Sunnyside Hospital?] -> [ 1962]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Sunnyside Hospital\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What year was the end of Sunnyside Hospital? 196 | Token:  Hospital\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.642 = 2.642 + 0.0 + 0.0 avg prob of [ 1962] 0.07422591745853424\n",
      "loss 2.18 = 2.144 + 0.035 + 0.001 avg prob of [ 1962] 0.11994526535272598\n",
      "loss 1.947 = 1.894 + 0.052 + 0.001 avg prob of [ 1962] 0.1543399691581726\n",
      "loss 0.636 = 0.596 + 0.039 + 0.001 avg prob of [ 1962] 0.5592252016067505\n",
      "loss 0.454 = 0.409 + 0.044 + 0.001 avg prob of [ 1962] 0.6698840856552124\n",
      "loss 0.199 = 0.155 + 0.043 + 0.001 avg prob of [ 1962] 0.8582055568695068\n",
      "loss 0.14 = 0.101 + 0.037 + 0.001 avg prob of [ 1962] 0.9044324159622192\n",
      "loss 0.105 = 0.072 + 0.032 + 0.001 avg prob of [ 1962] 0.9311909675598145\n",
      "loss 0.083 = 0.051 + 0.03 + 0.001 avg prob of [ 1962] 0.9501373767852783\n",
      "loss 0.068 = 0.037 + 0.029 + 0.001 avg prob of [ 1962] 0.9639325141906738\n",
      "loss 0.055 = 0.027 + 0.027 + 0.001 avg prob of [ 1962] 0.9734881520271301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:38,460 - easyeditor.editors.editor - INFO - 31 editing: What year was the end of Sunnyside Hospital? -> 1962  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What year was the end of Sunnyside Hospital?', 'target_new': '1962', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:38,460 - easyeditor.editors.editor - INFO - 31 editing: What year was the end of Sunnyside Hospital? -> 1962  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What year was the end of Sunnyside Hospital?', 'target_new': '1962', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:38 - INFO - easyeditor.editors.editor -   31 editing: What year was the end of Sunnyside Hospital? -> 1962  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'What year was the end of Sunnyside Hospital?', 'target_new': '1962', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Sunnyside Hospital'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 64%|   | 32/50 [02:22<01:30,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.046 = 0.02 + 0.024 + 0.001 avg prob of [ 1962] 0.9800900220870972\n",
      "Delta norm: 11.8515625\n",
      "Change in target norm: 2.962890625 to 12.2578125 => 9.296875\n",
      "Division Factor: 3.66796875\n",
      "Right vector norm: 3.23046875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [With which fictional universe is the character owyn associated?] -> [ Tolkien legendarium]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object owyn\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: With which fictional universe is the character owyn associated? Tolkien legendar | Token: yn\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 3.311 = 3.311 + 0.0 + 0.0 avg prob of [ Tolkien legendarium] 0.03853461891412735\n",
      "loss 2.439 = 2.236 + 0.202 + 0.001 avg prob of [ Tolkien legendarium] 0.10971765220165253\n",
      "loss 1.728 = 1.676 + 0.051 + 0.001 avg prob of [ Tolkien legendarium] 0.19134624302387238\n",
      "loss 0.833 = 0.798 + 0.033 + 0.001 avg prob of [ Tolkien legendarium] 0.4546378552913666\n",
      "loss 0.878 = 0.823 + 0.054 + 0.001 avg prob of [ Tolkien legendarium] 0.46804356575012207\n",
      "loss 1.604 = 1.558 + 0.044 + 0.001 avg prob of [ Tolkien legendarium] 0.21462373435497284\n",
      "loss 1.427 = 1.381 + 0.045 + 0.001 avg prob of [ Tolkien legendarium] 0.25546330213546753\n",
      "loss 0.851 = 0.802 + 0.048 + 0.001 avg prob of [ Tolkien legendarium] 0.4604265093803406\n",
      "loss 0.239 = 0.188 + 0.05 + 0.001 avg prob of [ Tolkien legendarium] 0.8330008387565613\n",
      "loss 0.06 = 0.007 + 0.052 + 0.001 avg prob of [ Tolkien legendarium] 0.9929086565971375\n",
      "loss 0.07 = 0.004 + 0.065 + 0.001 avg prob of [ Tolkien legendarium] 0.9964086413383484\n",
      "loss 0.084 = 0.003 + 0.08 + 0.001 avg prob of [ Tolkien legendarium] 0.9972507357597351\n",
      "loss 0.082 = 0.002 + 0.078 + 0.001 avg prob of [ Tolkien legendarium] 0.9975108504295349\n",
      "loss 0.073 = 0.002 + 0.069 + 0.001 avg prob of [ Tolkien legendarium] 0.997573971748352\n",
      "loss 0.068 = 0.002 + 0.065 + 0.001 avg prob of [ Tolkien legendarium] 0.9976173043251038\n",
      "loss 0.06 = 0.002 + 0.056 + 0.001 avg prob of [ Tolkien legendarium] 0.9975793957710266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:46,603 - easyeditor.editors.editor - INFO - 32 editing: With which fictional universe is the character owyn associated? -> Tolkien legendarium  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'With which fictional universe is the character owyn associated?', 'target_new': 'Tolkien legendarium', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'owyn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:46,603 - easyeditor.editors.editor - INFO - 32 editing: With which fictional universe is the character owyn associated? -> Tolkien legendarium  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'With which fictional universe is the character owyn associated?', 'target_new': 'Tolkien legendarium', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'owyn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:46 - INFO - easyeditor.editors.editor -   32 editing: With which fictional universe is the character owyn associated? -> Tolkien legendarium  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'With which fictional universe is the character owyn associated?', 'target_new': 'Tolkien legendarium', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'owyn'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 66%|   | 33/50 [02:30<01:41,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.047 = 0.003 + 0.043 + 0.001 avg prob of [ Tolkien legendarium] 0.9971510767936707\n",
      "Delta norm: 13.265625\n",
      "Change in target norm: 3.31640625 to 13.8046875 => 10.484375\n",
      "Division Factor: 3.908203125\n",
      "Right vector norm: 3.39453125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What family does Euxinastra belong?] -> [ Cerambycidae]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Euxinastra\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What family does Euxinastra belong? Cerambyc | Token: stra\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.156 = 2.156 + 0.0 + 0.0 avg prob of [ Cerambycidae] 0.11709630489349365\n",
      "loss 1.74 = 1.704 + 0.035 + 0.001 avg prob of [ Cerambycidae] 0.18515673279762268\n",
      "loss 0.647 = 0.558 + 0.088 + 0.001 avg prob of [ Cerambycidae] 0.5802554488182068\n",
      "loss 0.344 = 0.025 + 0.319 + 0.001 avg prob of [ Cerambycidae] 0.976108193397522\n",
      "loss 0.118 = 0.003 + 0.114 + 0.001 avg prob of [ Cerambycidae] 0.9969885945320129\n",
      "loss 0.061 = 0.003 + 0.057 + 0.001 avg prob of [ Cerambycidae] 0.9969398975372314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:48,987 - easyeditor.editors.editor - INFO - 33 editing: What family does Euxinastra belong? -> Cerambycidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What family does Euxinastra belong?', 'target_new': 'Cerambycidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Euxinastra'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:48,987 - easyeditor.editors.editor - INFO - 33 editing: What family does Euxinastra belong? -> Cerambycidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What family does Euxinastra belong?', 'target_new': 'Cerambycidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Euxinastra'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:48 - INFO - easyeditor.editors.editor -   33 editing: What family does Euxinastra belong? -> Cerambycidae  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.8], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'What family does Euxinastra belong?', 'target_new': 'Cerambycidae', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Euxinastra'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 68%|   | 34/50 [02:32<01:18,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.041 = 0.0 + 0.04 + 0.001 avg prob of [ Cerambycidae] 0.9996217489242554\n",
      "Delta norm: 13.3984375\n",
      "Change in target norm: 3.349609375 to 13.9453125 => 10.59375\n",
      "Division Factor: 4.2890625\n",
      "Right vector norm: 3.123046875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Whose direction is Mated in the Wilds?] -> [ Robert J Flaherty]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Mated in the Wilds\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Whose direction is Mated in the Wilds? Robert J Flah | Token: s\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.71 = 4.71 + 0.0 + 0.0 avg prob of [ Robert J Flaherty] 0.009147629141807556\n",
      "loss 4.41 = 4.398 + 0.01 + 0.001 avg prob of [ Robert J Flaherty] 0.012460469268262386\n",
      "loss 3.232 = 3.198 + 0.033 + 0.002 avg prob of [ Robert J Flaherty] 0.04238416999578476\n",
      "loss 3.067 = 3.047 + 0.019 + 0.002 avg prob of [ Robert J Flaherty] 0.050507791340351105\n",
      "loss 1.723 = 1.711 + 0.011 + 0.002 avg prob of [ Robert J Flaherty] 0.18857260048389435\n",
      "loss 0.773 = 0.755 + 0.016 + 0.002 avg prob of [ Robert J Flaherty] 0.48550260066986084\n",
      "loss 0.289 = 0.264 + 0.024 + 0.002 avg prob of [ Robert J Flaherty] 0.7703836560249329\n",
      "loss 0.173 = 0.155 + 0.016 + 0.002 avg prob of [ Robert J Flaherty] 0.856764554977417\n",
      "loss 0.13 = 0.113 + 0.016 + 0.002 avg prob of [ Robert J Flaherty] 0.8933242559432983\n",
      "loss 0.059 = 0.044 + 0.013 + 0.002 avg prob of [ Robert J Flaherty] 0.9582000970840454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:53,005 - easyeditor.editors.editor - INFO - 34 editing: Whose direction is Mated in the Wilds? -> Robert J Flaherty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'Whose direction is Mated in the Wilds?', 'target_new': 'Robert J Flaherty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mated in the Wilds'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:53,005 - easyeditor.editors.editor - INFO - 34 editing: Whose direction is Mated in the Wilds? -> Robert J Flaherty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'Whose direction is Mated in the Wilds?', 'target_new': 'Robert J Flaherty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mated in the Wilds'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:53 - INFO - easyeditor.editors.editor -   34 editing: Whose direction is Mated in the Wilds? -> Robert J Flaherty  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'Whose direction is Mated in the Wilds?', 'target_new': 'Robert J Flaherty', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mated in the Wilds'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 70%|   | 35/50 [02:36<01:09,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.024 = 0.009 + 0.014 + 0.002 avg prob of [ Robert J Flaherty] 0.9912889003753662\n",
      "Delta norm: 10.6640625\n",
      "Change in target norm: 2.666015625 to 11.015625 => 8.3515625\n",
      "Division Factor: 3.435546875\n",
      "Right vector norm: 3.103515625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What type of submarine was SM U-94 classified as?] -> [ Type U 93]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object SM U-94\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What type of submarine was SM U-94 classified as? Type U  | Token: 94\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.24 = 2.24 + 0.0 + 0.0 avg prob of [ Type U 93] 0.11076371371746063\n",
      "loss 2.16 = 2.152 + 0.007 + 0.001 avg prob of [ Type U 93] 0.12066316604614258\n",
      "loss 1.448 = 1.438 + 0.009 + 0.001 avg prob of [ Type U 93] 0.23944386839866638\n",
      "loss 0.977 = 0.973 + 0.003 + 0.001 avg prob of [ Type U 93] 0.3797437250614166\n",
      "loss 0.432 = 0.035 + 0.396 + 0.001 avg prob of [ Type U 93] 0.9658014178276062\n",
      "loss 0.529 = 0.471 + 0.057 + 0.001 avg prob of [ Type U 93] 0.6264019012451172\n",
      "loss 0.112 = 0.076 + 0.035 + 0.001 avg prob of [ Type U 93] 0.9273483753204346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:55,745 - easyeditor.editors.editor - INFO - 35 editing: What type of submarine was SM U-94 classified as? -> Type U 93  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What type of submarine was SM U-94 classified as?', 'target_new': 'Type U 93', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SM U-94'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:55,745 - easyeditor.editors.editor - INFO - 35 editing: What type of submarine was SM U-94 classified as? -> Type U 93  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What type of submarine was SM U-94 classified as?', 'target_new': 'Type U 93', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SM U-94'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:55 - INFO - easyeditor.editors.editor -   35 editing: What type of submarine was SM U-94 classified as? -> Type U 93  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'What type of submarine was SM U-94 classified as?', 'target_new': 'Type U 93', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SM U-94'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 72%|  | 36/50 [02:39<00:56,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.042 = 0.027 + 0.013 + 0.001 avg prob of [ Type U 93] 0.9731190204620361\n",
      "Delta norm: 11.375\n",
      "Change in target norm: 2.84375 to 11.578125 => 8.734375\n",
      "Division Factor: 3.751953125\n",
      "Right vector norm: 3.03125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What is the endangered status of Javan surili?] -> [ critically threatened]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Javan surili\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What is the endangered status of Javan surili? critically | Token: ili\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 7.937 = 7.937 + 0.0 + 0.0 avg prob of [ critically threatened] 0.00040877683204598725\n",
      "loss 6.88 = 6.754 + 0.125 + 0.001 avg prob of [ critically threatened] 0.001400001347064972\n",
      "loss 4.952 = 4.877 + 0.074 + 0.001 avg prob of [ critically threatened] 0.008848925121128559\n",
      "loss 2.336 = 2.248 + 0.087 + 0.001 avg prob of [ critically threatened] 0.11218062043190002\n",
      "loss 0.769 = 0.445 + 0.323 + 0.001 avg prob of [ critically threatened] 0.6460899114608765\n",
      "loss 0.197 = 0.01 + 0.186 + 0.001 avg prob of [ critically threatened] 0.9896827340126038\n",
      "loss 0.06 = 0.019 + 0.039 + 0.001 avg prob of [ critically threatened] 0.9807588458061218\n",
      "loss 0.057 = 0.02 + 0.035 + 0.001 avg prob of [ critically threatened] 0.9801116585731506\n",
      "loss 0.031 = 0.007 + 0.023 + 0.001 avg prob of [ critically threatened] 0.99322110414505\n",
      "Delta norm: 14.171875\n",
      "Change in target norm: 3.54296875 to 14.765625 => 11.21875\n",
      "Division Factor: 4.5078125\n",
      "Right vector norm: 3.14453125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:17:59,954 - easyeditor.editors.editor - INFO - 36 editing: What is the endangered status of Javan surili? -> critically threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'What is the endangered status of Javan surili?', 'target_new': 'critically threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Javan surili'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:17:59,954 - easyeditor.editors.editor - INFO - 36 editing: What is the endangered status of Javan surili? -> critically threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'What is the endangered status of Javan surili?', 'target_new': 'critically threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Javan surili'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:17:59 - INFO - easyeditor.editors.editor -   36 editing: What is the endangered status of Javan surili? -> critically threatened  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'What is the endangered status of Javan surili?', 'target_new': 'critically threatened', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Javan surili'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 74%|  | 37/50 [02:43<00:53,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing ROME algorithm for the update: [What war or battle did Frank Lucien Hale fight in?] -> [ World War II]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Frank Lucien Hale\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What war or battle did Frank Lucien Hale fight in? World War | Token:  Hale\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.094 = 2.094 + 0.0 + 0.0 avg prob of [ World War II] 0.12750717997550964\n",
      "loss 1.509 = 1.471 + 0.037 + 0.001 avg prob of [ World War II] 0.2461082637310028\n",
      "loss 0.804 = 0.738 + 0.064 + 0.001 avg prob of [ World War II] 0.5032163858413696\n",
      "loss 0.152 = 0.068 + 0.083 + 0.001 avg prob of [ World War II] 0.9355443716049194\n",
      "loss 0.102 = 0.034 + 0.066 + 0.001 avg prob of [ World War II] 0.966465175151825\n",
      "loss 0.07 = 0.003 + 0.066 + 0.001 avg prob of [ World War II] 0.9969182014465332\n",
      "loss 0.066 = 0.001 + 0.064 + 0.001 avg prob of [ World War II] 0.9994325637817383\n",
      "loss 0.058 = 0.0 + 0.056 + 0.001 avg prob of [ World War II] 0.9996312856674194\n",
      "loss 0.063 = 0.001 + 0.061 + 0.001 avg prob of [ World War II] 0.9992914199829102\n",
      "loss 0.067 = 0.003 + 0.063 + 0.001 avg prob of [ World War II] 0.9972253441810608\n",
      "loss 0.06 = 0.0 + 0.058 + 0.001 avg prob of [ World War II] 0.9997100234031677\n",
      "loss 0.059 = 0.0 + 0.057 + 0.001 avg prob of [ World War II] 0.9997766017913818\n",
      "loss 0.057 = 0.0 + 0.056 + 0.001 avg prob of [ World War II] 0.9996781945228577\n",
      "loss 0.054 = 0.0 + 0.052 + 0.001 avg prob of [ World War II] 0.9995858669281006\n",
      "loss 0.052 = 0.0 + 0.05 + 0.001 avg prob of [ World War II] 0.9995564222335815\n",
      "loss 0.052 = 0.0 + 0.05 + 0.001 avg prob of [ World War II] 0.9996280074119568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:06,725 - easyeditor.editors.editor - INFO - 37 editing: What war or battle did Frank Lucien Hale fight in? -> World War II  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What war or battle did Frank Lucien Hale fight in?', 'target_new': 'World War II', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frank Lucien Hale'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:06,725 - easyeditor.editors.editor - INFO - 37 editing: What war or battle did Frank Lucien Hale fight in? -> World War II  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What war or battle did Frank Lucien Hale fight in?', 'target_new': 'World War II', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frank Lucien Hale'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:06 - INFO - easyeditor.editors.editor -   37 editing: What war or battle did Frank Lucien Hale fight in? -> World War II  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'What war or battle did Frank Lucien Hale fight in?', 'target_new': 'World War II', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frank Lucien Hale'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 76%|  | 38/50 [02:50<00:58,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.047 = 0.0 + 0.045 + 0.001 avg prob of [ World War II] 0.9997256994247437\n",
      "Delta norm: 10.78125\n",
      "Change in target norm: 2.6953125 to 11.171875 => 8.4765625\n",
      "Division Factor: 3.41796875\n",
      "Right vector norm: 3.154296875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What war or battle involved Alec Rose?] -> [ Spanish Civil War]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Alec Rose\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: What war or battle involved Alec Rose? Spanish Civil | Token:  Rose\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.204 = 4.204 + 0.0 + 0.0 avg prob of [ Spanish Civil War] 0.015525649301707745\n",
      "loss 3.892 = 3.823 + 0.067 + 0.001 avg prob of [ Spanish Civil War] 0.022305263206362724\n",
      "loss 2.455 = 2.424 + 0.029 + 0.001 avg prob of [ Spanish Civil War] 0.09036345034837723\n",
      "loss 1.294 = 1.228 + 0.065 + 0.001 avg prob of [ Spanish Civil War] 0.29498574137687683\n",
      "loss 0.359 = 0.33 + 0.028 + 0.001 avg prob of [ Spanish Civil War] 0.7229182720184326\n",
      "loss 0.764 = 0.041 + 0.722 + 0.001 avg prob of [ Spanish Civil War] 0.9603380560874939\n",
      "loss 1.233 = 1.153 + 0.079 + 0.001 avg prob of [ Spanish Civil War] 0.3379835784435272\n",
      "loss 0.055 = 0.011 + 0.043 + 0.001 avg prob of [ Spanish Civil War] 0.9888560175895691\n",
      "loss 0.093 = 0.056 + 0.036 + 0.001 avg prob of [ Spanish Civil War] 0.9460713863372803\n",
      "loss 0.051 = 0.017 + 0.032 + 0.001 avg prob of [ Spanish Civil War] 0.9833853840827942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:10,887 - easyeditor.editors.editor - INFO - 38 editing: What war or battle involved Alec Rose? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What war or battle involved Alec Rose?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alec Rose'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:10,887 - easyeditor.editors.editor - INFO - 38 editing: What war or battle involved Alec Rose? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What war or battle involved Alec Rose?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alec Rose'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:10 - INFO - easyeditor.editors.editor -   38 editing: What war or battle involved Alec Rose? -> Spanish Civil War  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'What war or battle involved Alec Rose?', 'target_new': 'Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Alec Rose'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 78%|  | 39/50 [02:54<00:51,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.036 = 0.004 + 0.031 + 0.001 avg prob of [ Spanish Civil War] 0.9964602589607239\n",
      "Delta norm: 11.90625\n",
      "Change in target norm: 2.9765625 to 12.3046875 => 9.328125\n",
      "Division Factor: 3.7890625\n",
      "Right vector norm: 3.142578125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What is the native tongue of Pierre Corneille?] -> [ German]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Pierre Corneille\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What is the native tongue of Pierre Corneille? | Token: ille\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 8.395 = 8.395 + 0.0 + 0.0 avg prob of [ German] 0.0003523808263707906\n",
      "loss 3.772 = 3.696 + 0.075 + 0.001 avg prob of [ German] 0.03302402049303055\n",
      "loss 0.935 = 0.892 + 0.042 + 0.001 avg prob of [ German] 0.436227947473526\n",
      "loss 0.294 = 0.256 + 0.037 + 0.001 avg prob of [ German] 0.7814558148384094\n",
      "loss 0.111 = 0.07 + 0.04 + 0.001 avg prob of [ German] 0.9331626892089844\n",
      "loss 0.059 = 0.024 + 0.034 + 0.001 avg prob of [ German] 0.9764243960380554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:13,631 - easyeditor.editors.editor - INFO - 39 editing: What is the native tongue of Pierre Corneille? -> German  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the native tongue of Pierre Corneille?', 'target_new': 'German', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pierre Corneille'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:13,631 - easyeditor.editors.editor - INFO - 39 editing: What is the native tongue of Pierre Corneille? -> German  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the native tongue of Pierre Corneille?', 'target_new': 'German', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pierre Corneille'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:13 - INFO - easyeditor.editors.editor -   39 editing: What is the native tongue of Pierre Corneille? -> German  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'What is the native tongue of Pierre Corneille?', 'target_new': 'German', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Pierre Corneille'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 80%|  | 40/50 [02:57<00:40,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.042 = 0.01 + 0.031 + 0.001 avg prob of [ German] 0.9897760152816772\n",
      "Delta norm: 14.03125\n",
      "Change in target norm: 3.5078125 to 14.40625 => 10.8984375\n",
      "Division Factor: 4.42578125\n",
      "Right vector norm: 3.169921875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [When did Tremont Group come into being?] -> [ 1991]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Tremont Group\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 5 | Sentence: When did Tremont Group come into being? 199 | Token:  Group\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.863 = 2.863 + 0.0 + 0.0 avg prob of [ 1991] 0.05906210094690323\n",
      "loss 2.475 = 2.381 + 0.092 + 0.001 avg prob of [ 1991] 0.09399963915348053\n",
      "loss 2.515 = 2.393 + 0.121 + 0.001 avg prob of [ 1991] 0.09339196234941483\n",
      "loss 2.231 = 2.152 + 0.078 + 0.001 avg prob of [ 1991] 0.11980395019054413\n",
      "loss 1.311 = 1.241 + 0.068 + 0.001 avg prob of [ 1991] 0.29417213797569275\n",
      "loss 0.661 = 0.512 + 0.147 + 0.001 avg prob of [ 1991] 0.6006355285644531\n",
      "loss 1.291 = 1.126 + 0.164 + 0.001 avg prob of [ 1991] 0.3306862413883209\n",
      "loss 2.73 = 2.635 + 0.093 + 0.001 avg prob of [ 1991] 0.07367591559886932\n",
      "loss 1.201 = 1.114 + 0.086 + 0.001 avg prob of [ 1991] 0.3335408866405487\n",
      "loss 1.01 = 0.923 + 0.086 + 0.001 avg prob of [ 1991] 0.4033469259738922\n",
      "loss 0.469 = 0.371 + 0.097 + 0.001 avg prob of [ 1991] 0.6934665441513062\n",
      "loss 0.158 = 0.052 + 0.105 + 0.001 avg prob of [ 1991] 0.9494351148605347\n",
      "loss 0.141 = 0.03 + 0.109 + 0.001 avg prob of [ 1991] 0.970275342464447\n",
      "loss 0.12 = 0.015 + 0.104 + 0.001 avg prob of [ 1991] 0.9854257702827454\n",
      "loss 0.104 = 0.008 + 0.095 + 0.001 avg prob of [ 1991] 0.9917674660682678\n",
      "loss 0.094 = 0.006 + 0.087 + 0.001 avg prob of [ 1991] 0.9937740564346313\n",
      "loss 0.089 = 0.005 + 0.082 + 0.001 avg prob of [ 1991] 0.9945822358131409\n",
      "loss 0.084 = 0.005 + 0.078 + 0.001 avg prob of [ 1991] 0.9951955080032349\n",
      "loss 0.08 = 0.004 + 0.075 + 0.001 avg prob of [ 1991] 0.995762050151825\n",
      "loss 0.078 = 0.004 + 0.073 + 0.001 avg prob of [ 1991] 0.9962218403816223\n",
      "loss 0.075 = 0.003 + 0.07 + 0.001 avg prob of [ 1991] 0.9966059327125549\n",
      "loss 0.072 = 0.003 + 0.068 + 0.001 avg prob of [ 1991] 0.9969934821128845\n",
      "loss 0.07 = 0.003 + 0.066 + 0.001 avg prob of [ 1991] 0.997377872467041\n",
      "loss 0.067 = 0.002 + 0.063 + 0.001 avg prob of [ 1991] 0.9977231621742249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:22,530 - easyeditor.editors.editor - INFO - 40 editing: When did Tremont Group come into being? -> 1991  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'When did Tremont Group come into being?', 'target_new': '1991', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tremont Group'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:22,530 - easyeditor.editors.editor - INFO - 40 editing: When did Tremont Group come into being? -> 1991  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'When did Tremont Group come into being?', 'target_new': '1991', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tremont Group'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:22 - INFO - easyeditor.editors.editor -   40 editing: When did Tremont Group come into being? -> 1991  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'When did Tremont Group come into being?', 'target_new': '1991', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tremont Group'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 82%| | 41/50 [03:06<00:49,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.064 = 0.002 + 0.061 + 0.001 avg prob of [ 1991] 0.9980093836784363\n",
      "Delta norm: 13.2109375\n",
      "Change in target norm: 3.302734375 to 13.703125 => 10.3984375\n",
      "Division Factor: 3.98828125\n",
      "Right vector norm: 3.3125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Over what river does Delaware Memorial Bridge cross?] -> [ Atlantic Ocean]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Delaware Memorial Bridge\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 7 | Sentence: Over what river does Delaware Memorial Bridge cross? Atlantic | Token:  Bridge\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.301 = 4.301 + 0.0 + 0.0 avg prob of [ Atlantic Ocean] 0.013979364186525345\n",
      "loss 3.141 = 3.071 + 0.069 + 0.001 avg prob of [ Atlantic Ocean] 0.0548570454120636\n",
      "loss 0.82 = 0.77 + 0.049 + 0.001 avg prob of [ Atlantic Ocean] 0.4755316376686096\n",
      "loss 0.18 = 0.14 + 0.039 + 0.001 avg prob of [ Atlantic Ocean] 0.8709380626678467\n",
      "loss 0.118 = 0.078 + 0.039 + 0.001 avg prob of [ Atlantic Ocean] 0.9258469343185425\n",
      "loss 0.064 = 0.025 + 0.038 + 0.001 avg prob of [ Atlantic Ocean] 0.9750655889511108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:25,150 - easyeditor.editors.editor - INFO - 41 editing: Over what river does Delaware Memorial Bridge cross? -> Atlantic Ocean  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'Over what river does Delaware Memorial Bridge cross?', 'target_new': 'Atlantic Ocean', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:25,150 - easyeditor.editors.editor - INFO - 41 editing: Over what river does Delaware Memorial Bridge cross? -> Atlantic Ocean  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'Over what river does Delaware Memorial Bridge cross?', 'target_new': 'Atlantic Ocean', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:25 - INFO - easyeditor.editors.editor -   41 editing: Over what river does Delaware Memorial Bridge cross? -> Atlantic Ocean  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'Over what river does Delaware Memorial Bridge cross?', 'target_new': 'Atlantic Ocean', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Delaware Memorial Bridge'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 84%| | 42/50 [03:08<00:37,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.05 = 0.013 + 0.036 + 0.001 avg prob of [ Atlantic Ocean] 0.9871864318847656\n",
      "Delta norm: 14.3125\n",
      "Change in target norm: 3.578125 to 14.8359375 => 11.2578125\n",
      "Division Factor: 4.453125\n",
      "Right vector norm: 3.21484375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What was the year SR N15X class entered service?] -> [ 1990]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object SR N15X class\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 9 | Sentence: What was the year SR N15X class entered service? 199 | Token:  class\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.891 = 2.891 + 0.0 + 0.0 avg prob of [ 1990] 0.05731682479381561\n",
      "loss 2.515 = 2.449 + 0.065 + 0.001 avg prob of [ 1990] 0.08954448252916336\n",
      "loss 1.794 = 1.679 + 0.114 + 0.001 avg prob of [ 1990] 0.18817198276519775\n",
      "loss 1.565 = 1.461 + 0.103 + 0.001 avg prob of [ 1990] 0.23496532440185547\n",
      "loss 1.387 = 1.313 + 0.073 + 0.001 avg prob of [ 1990] 0.27097612619400024\n",
      "loss 1.019 = 0.966 + 0.052 + 0.001 avg prob of [ 1990] 0.38165757060050964\n",
      "loss 0.714 = 0.697 + 0.015 + 0.001 avg prob of [ 1990] 0.5020293593406677\n",
      "loss 0.402 = 0.352 + 0.048 + 0.001 avg prob of [ 1990] 0.7075425982475281\n",
      "loss 0.094 = 0.049 + 0.045 + 0.001 avg prob of [ 1990] 0.9536570906639099\n",
      "loss 0.09 = 0.006 + 0.083 + 0.001 avg prob of [ 1990] 0.9943444728851318\n",
      "loss 0.067 = 0.002 + 0.064 + 0.001 avg prob of [ 1990] 0.9979887008666992\n",
      "loss 0.067 = 0.005 + 0.061 + 0.001 avg prob of [ 1990] 0.9949430227279663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:30,110 - easyeditor.editors.editor - INFO - 42 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:30,110 - easyeditor.editors.editor - INFO - 42 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:30 - INFO - easyeditor.editors.editor -   42 editing: What was the year SR N15X class entered service? -> 1990  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'What was the year SR N15X class entered service?', 'target_new': '1990', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'SR N15X class'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 86%| | 43/50 [03:13<00:33,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.028 = 0.0 + 0.027 + 0.001 avg prob of [ 1990] 0.9995113611221313\n",
      "Delta norm: 13.421875\n",
      "Change in target norm: 3.35546875 to 13.7734375 => 10.421875\n",
      "Division Factor: 4.3984375\n",
      "Right vector norm: 3.05078125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What is the ending year of Vindhya Pradesh?] -> [ 1961]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Vindhya Pradesh\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What is the ending year of Vindhya Pradesh? 196 | Token:  Pradesh\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.663 = 2.663 + 0.0 + 0.0 avg prob of [ 1961] 0.0720624253153801\n",
      "loss 2.896 = 2.833 + 0.061 + 0.001 avg prob of [ 1961] 0.060096967965364456\n",
      "loss 1.824 = 1.807 + 0.016 + 0.001 avg prob of [ 1961] 0.17187939584255219\n",
      "loss 1.059 = 1.044 + 0.014 + 0.001 avg prob of [ 1961] 0.36295056343078613\n",
      "loss 0.897 = 0.87 + 0.026 + 0.001 avg prob of [ 1961] 0.4252621829509735\n",
      "loss 0.536 = 0.514 + 0.02 + 0.001 avg prob of [ 1961] 0.6109049916267395\n",
      "loss 0.341 = 0.323 + 0.017 + 0.001 avg prob of [ 1961] 0.7281060814857483\n",
      "loss 0.196 = 0.178 + 0.017 + 0.001 avg prob of [ 1961] 0.8392354249954224\n",
      "loss 0.094 = 0.077 + 0.016 + 0.001 avg prob of [ 1961] 0.9267395734786987\n",
      "loss 0.057 = 0.039 + 0.016 + 0.001 avg prob of [ 1961] 0.961702287197113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:33,703 - easyeditor.editors.editor - INFO - 43 editing: What is the ending year of Vindhya Pradesh? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the ending year of Vindhya Pradesh?', 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vindhya Pradesh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:33,703 - easyeditor.editors.editor - INFO - 43 editing: What is the ending year of Vindhya Pradesh? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the ending year of Vindhya Pradesh?', 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vindhya Pradesh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:33 - INFO - easyeditor.editors.editor -   43 editing: What is the ending year of Vindhya Pradesh? -> 1961  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'What is the ending year of Vindhya Pradesh?', 'target_new': '1961', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Vindhya Pradesh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 88%| | 44/50 [03:17<00:26,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.041 = 0.024 + 0.015 + 0.001 avg prob of [ 1961] 0.9761427044868469\n",
      "Delta norm: 12.9375\n",
      "Change in target norm: 3.234375 to 13.421875 => 10.1875\n",
      "Division Factor: 3.849609375\n",
      "Right vector norm: 3.361328125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What was the date of Joanes Leizarraga's death?] -> [ 19 March 2014]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Joanes Leizarraga\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: What was the date of Joanes Leizarraga's death? 19 March 201 | Token: aga\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.965 = 2.965 + 0.0 + 0.0 avg prob of [ 19 March 2014] 0.05331484600901604\n",
      "loss 2.952 = 2.791 + 0.16 + 0.001 avg prob of [ 19 March 2014] 0.0619024895131588\n",
      "loss 2.489 = 2.451 + 0.037 + 0.001 avg prob of [ 19 March 2014] 0.0871555432677269\n",
      "loss 1.937 = 1.905 + 0.031 + 0.001 avg prob of [ 19 March 2014] 0.15020915865898132\n",
      "loss 1.234 = 1.199 + 0.034 + 0.001 avg prob of [ 19 March 2014] 0.3043784201145172\n",
      "loss 0.757 = 0.716 + 0.04 + 0.001 avg prob of [ 19 March 2014] 0.4902143180370331\n",
      "loss 1.282 = 1.224 + 0.056 + 0.001 avg prob of [ 19 March 2014] 0.29775089025497437\n",
      "loss 0.493 = 0.411 + 0.081 + 0.001 avg prob of [ 19 March 2014] 0.6675947308540344\n",
      "loss 0.511 = 0.469 + 0.04 + 0.001 avg prob of [ 19 March 2014] 0.6389349102973938\n",
      "loss 1.505 = 1.407 + 0.097 + 0.001 avg prob of [ 19 March 2014] 0.24897189438343048\n",
      "loss 0.97 = 0.796 + 0.173 + 0.001 avg prob of [ 19 March 2014] 0.4628501236438751\n",
      "loss 0.375 = 0.281 + 0.093 + 0.001 avg prob of [ 19 March 2014] 0.7576524019241333\n",
      "loss 0.196 = 0.117 + 0.078 + 0.001 avg prob of [ 19 March 2014] 0.8900765180587769\n",
      "loss 0.133 = 0.048 + 0.083 + 0.001 avg prob of [ 19 March 2014] 0.9530894160270691\n",
      "loss 0.105 = 0.019 + 0.084 + 0.001 avg prob of [ 19 March 2014] 0.9809150099754333\n",
      "loss 0.094 = 0.01 + 0.083 + 0.001 avg prob of [ 19 March 2014] 0.9902083873748779\n",
      "loss 0.086 = 0.006 + 0.079 + 0.001 avg prob of [ 19 March 2014] 0.9938547015190125\n",
      "loss 0.082 = 0.004 + 0.076 + 0.001 avg prob of [ 19 March 2014] 0.9955998659133911\n",
      "loss 0.076 = 0.003 + 0.072 + 0.001 avg prob of [ 19 March 2014] 0.9965963363647461\n",
      "loss 0.075 = 0.003 + 0.071 + 0.001 avg prob of [ 19 March 2014] 0.9972487092018127\n",
      "loss 0.073 = 0.002 + 0.07 + 0.001 avg prob of [ 19 March 2014] 0.9977301955223083\n",
      "loss 0.072 = 0.002 + 0.069 + 0.001 avg prob of [ 19 March 2014] 0.9980142712593079\n",
      "loss 0.07 = 0.002 + 0.067 + 0.001 avg prob of [ 19 March 2014] 0.9981991052627563\n",
      "loss 0.069 = 0.002 + 0.066 + 0.001 avg prob of [ 19 March 2014] 0.9983678460121155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:44,564 - easyeditor.editors.editor - INFO - 44 editing: What was the date of Joanes Leizarraga's death? -> 19 March 2014  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"What was the date of Joanes Leizarraga's death?\", 'target_new': '19 March 2014', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joanes Leizarraga'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:44,564 - easyeditor.editors.editor - INFO - 44 editing: What was the date of Joanes Leizarraga's death? -> 19 March 2014  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"What was the date of Joanes Leizarraga's death?\", 'target_new': '19 March 2014', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joanes Leizarraga'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:44 - INFO - easyeditor.editors.editor -   44 editing: What was the date of Joanes Leizarraga's death? -> 19 March 2014  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': \"What was the date of Joanes Leizarraga's death?\", 'target_new': '19 March 2014', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joanes Leizarraga'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 90%| | 45/50 [03:28<00:31,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.068 = 0.001 + 0.066 + 0.001 avg prob of [ 19 March 2014] 0.9985232949256897\n",
      "Delta norm: 13.9609375\n",
      "Change in target norm: 3.490234375 to 14.359375 => 10.8671875\n",
      "Division Factor: 4.44140625\n",
      "Right vector norm: 3.142578125\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [To which country does Mohammed Badaru Abubakar belong as its citizen?] -> [ Mali]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Mohammed Badaru Abubakar\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 11 | Sentence: To which country does Mohammed Badaru Abubakar belong as its citizen? | Token: ar\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 9.954 = 9.954 + 0.0 + 0.0 avg prob of [ Mali] 7.757813727948815e-05\n",
      "loss 8.493 = 8.46 + 0.031 + 0.001 avg prob of [ Mali] 0.00045745502575300634\n",
      "loss 1.429 = 1.402 + 0.025 + 0.001 avg prob of [ Mali] 0.3319030702114105\n",
      "loss 0.136 = 0.035 + 0.1 + 0.001 avg prob of [ Mali] 0.9668424725532532\n",
      "loss 0.096 = 0.001 + 0.094 + 0.001 avg prob of [ Mali] 0.9994419813156128\n",
      "loss 0.516 = 0.412 + 0.102 + 0.001 avg prob of [ Mali] 0.855438232421875\n",
      "loss 0.238 = 0.165 + 0.072 + 0.001 avg prob of [ Mali] 0.8503297567367554\n",
      "loss 0.111 = 0.087 + 0.022 + 0.001 avg prob of [ Mali] 0.9189672470092773\n",
      "loss 0.055 = 0.038 + 0.015 + 0.001 avg prob of [ Mali] 0.9629384279251099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:49,016 - easyeditor.editors.editor - INFO - 45 editing: To which country does Mohammed Badaru Abubakar belong as its citizen? -> Mali  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'To which country does Mohammed Badaru Abubakar belong as its citizen?', 'target_new': 'Mali', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammed Badaru Abubakar'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:49,016 - easyeditor.editors.editor - INFO - 45 editing: To which country does Mohammed Badaru Abubakar belong as its citizen? -> Mali  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'To which country does Mohammed Badaru Abubakar belong as its citizen?', 'target_new': 'Mali', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammed Badaru Abubakar'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:49 - INFO - easyeditor.editors.editor -   45 editing: To which country does Mohammed Badaru Abubakar belong as its citizen? -> Mali  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'To which country does Mohammed Badaru Abubakar belong as its citizen?', 'target_new': 'Mali', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mohammed Badaru Abubakar'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 92%|| 46/50 [03:32<00:23,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.034 = 0.015 + 0.017 + 0.001 avg prob of [ Mali] 0.9847342371940613\n",
      "Delta norm: 11.171875\n",
      "Change in target norm: 2.79296875 to 11.625 => 8.828125\n",
      "Division Factor: 3.6953125\n",
      "Right vector norm: 3.0234375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [Which was the voice type that Teresa Cornelys had?] -> [ mezzo-oprano]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Teresa Cornelys\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: Which was the voice type that Teresa Cornelys had? mezzo-opr | Token: s\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.606 = 4.606 + 0.0 + 0.0 avg prob of [ mezzo-oprano] 0.012330225668847561\n",
      "loss 3.886 = 3.821 + 0.064 + 0.001 avg prob of [ mezzo-oprano] 0.02218826301395893\n",
      "loss 2.844 = 2.828 + 0.015 + 0.001 avg prob of [ mezzo-oprano] 0.0594555027782917\n",
      "loss 2.328 = 2.276 + 0.05 + 0.001 avg prob of [ mezzo-oprano] 0.11326637864112854\n",
      "loss 2.698 = 2.635 + 0.062 + 0.001 avg prob of [ mezzo-oprano] 0.07208158075809479\n",
      "loss 1.636 = 1.598 + 0.037 + 0.001 avg prob of [ mezzo-oprano] 0.2033122032880783\n",
      "loss 0.568 = 0.366 + 0.201 + 0.001 avg prob of [ mezzo-oprano] 0.6940301060676575\n",
      "loss 0.329 = 0.267 + 0.06 + 0.001 avg prob of [ mezzo-oprano] 0.7663528323173523\n",
      "loss 0.221 = 0.162 + 0.058 + 0.001 avg prob of [ mezzo-oprano] 0.851457417011261\n",
      "loss 0.078 = 0.027 + 0.049 + 0.001 avg prob of [ mezzo-oprano] 0.9737979769706726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:52,871 - easyeditor.editors.editor - INFO - 46 editing: Which was the voice type that Teresa Cornelys had? -> mezzo-oprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'Which was the voice type that Teresa Cornelys had?', 'target_new': 'mezzo-oprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Teresa Cornelys'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:52,871 - easyeditor.editors.editor - INFO - 46 editing: Which was the voice type that Teresa Cornelys had? -> mezzo-oprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'Which was the voice type that Teresa Cornelys had?', 'target_new': 'mezzo-oprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Teresa Cornelys'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:52 - INFO - easyeditor.editors.editor -   46 editing: Which was the voice type that Teresa Cornelys had? -> mezzo-oprano  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'Which was the voice type that Teresa Cornelys had?', 'target_new': 'mezzo-oprano', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Teresa Cornelys'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 94%|| 47/50 [03:36<00:15,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.04 = 0.004 + 0.035 + 0.001 avg prob of [ mezzo-oprano] 0.9963321089744568\n",
      "Delta norm: 12.34375\n",
      "Change in target norm: 3.0859375 to 12.8359375 => 9.75\n",
      "Division Factor: 3.984375\n",
      "Right vector norm: 3.09765625\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What college did Tatiana Vladislavovna Petrova go to?] -> [ Moscow State Institute of International Relations]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Tatiana Vladislavovna Petrova\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: What college did Tatiana Vladislavovna Petrova go to? Moscow State Institute of International | Token: va\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 1.949 = 1.949 + 0.0 + 0.0 avg prob of [ Moscow State Institute of International Relations] 0.14372028410434723\n",
      "loss 1.339 = 1.327 + 0.011 + 0.001 avg prob of [ Moscow State Institute of International Relations] 0.26648250222206116\n",
      "loss 0.716 = 0.696 + 0.019 + 0.001 avg prob of [ Moscow State Institute of International Relations] 0.5025129318237305\n",
      "loss 0.232 = 0.206 + 0.025 + 0.001 avg prob of [ Moscow State Institute of International Relations] 0.816616415977478\n",
      "loss 0.092 = 0.055 + 0.035 + 0.001 avg prob of [ Moscow State Institute of International Relations] 0.946480929851532\n",
      "loss 0.056 = 0.027 + 0.027 + 0.001 avg prob of [ Moscow State Institute of International Relations] 0.9730778932571411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:55,398 - easyeditor.editors.editor - INFO - 47 editing: What college did Tatiana Vladislavovna Petrova go to? -> Moscow State Institute of International Relations  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'What college did Tatiana Vladislavovna Petrova go to?', 'target_new': 'Moscow State Institute of International Relations', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tatiana Vladislavovna Petrova'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:55,398 - easyeditor.editors.editor - INFO - 47 editing: What college did Tatiana Vladislavovna Petrova go to? -> Moscow State Institute of International Relations  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'What college did Tatiana Vladislavovna Petrova go to?', 'target_new': 'Moscow State Institute of International Relations', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tatiana Vladislavovna Petrova'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:55 - INFO - easyeditor.editors.editor -   47 editing: What college did Tatiana Vladislavovna Petrova go to? -> Moscow State Institute of International Relations  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'What college did Tatiana Vladislavovna Petrova go to?', 'target_new': 'Moscow State Institute of International Relations', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Tatiana Vladislavovna Petrova'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 96%|| 48/50 [03:38<00:08,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.042 = 0.032 + 0.009 + 0.001 avg prob of [ Moscow State Institute of International Relations] 0.9682844281196594\n",
      "Delta norm: 11.3515625\n",
      "Change in target norm: 2.837890625 to 11.7578125 => 8.921875\n",
      "Division Factor: 3.63671875\n",
      "Right vector norm: 3.12109375\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [What is the director of Gangland Odyssey?] -> [ William A Seiter]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Gangland Odyssey\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 8 | Sentence: What is the director of Gangland Odyssey? William A Se | Token:  Odyssey\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 4.944 = 4.944 + 0.0 + 0.0 avg prob of [ William A Seiter] 0.007392494473606348\n",
      "loss 4.004 = 3.989 + 0.014 + 0.001 avg prob of [ William A Seiter] 0.019753634929656982\n",
      "loss 2.936 = 2.902 + 0.033 + 0.001 avg prob of [ William A Seiter] 0.055782586336135864\n",
      "loss 2.303 = 2.272 + 0.029 + 0.001 avg prob of [ William A Seiter] 0.10509245097637177\n",
      "loss 1.997 = 1.962 + 0.033 + 0.001 avg prob of [ William A Seiter] 0.14432001113891602\n",
      "loss 2.616 = 2.549 + 0.065 + 0.001 avg prob of [ William A Seiter] 0.07954844832420349\n",
      "loss 2.003 = 1.967 + 0.034 + 0.001 avg prob of [ William A Seiter] 0.1416582465171814\n",
      "loss 1.493 = 1.452 + 0.039 + 0.001 avg prob of [ William A Seiter] 0.2384357452392578\n",
      "loss 1.008 = 0.945 + 0.062 + 0.001 avg prob of [ William A Seiter] 0.3924591541290283\n",
      "loss 0.657 = 0.614 + 0.042 + 0.001 avg prob of [ William A Seiter] 0.5460647344589233\n",
      "loss 0.198 = 0.156 + 0.041 + 0.001 avg prob of [ William A Seiter] 0.8683648109436035\n",
      "loss 0.051 = 0.029 + 0.02 + 0.001 avg prob of [ William A Seiter] 0.9710459113121033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:18:59,375 - easyeditor.editors.editor - INFO - 48 editing: What is the director of Gangland Odyssey? -> William A Seiter  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'What is the director of Gangland Odyssey?', 'target_new': 'William A Seiter', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gangland Odyssey'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:18:59,375 - easyeditor.editors.editor - INFO - 48 editing: What is the director of Gangland Odyssey? -> William A Seiter  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'What is the director of Gangland Odyssey?', 'target_new': 'William A Seiter', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gangland Odyssey'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:18:59 - INFO - easyeditor.editors.editor -   48 editing: What is the director of Gangland Odyssey? -> William A Seiter  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'What is the director of Gangland Odyssey?', 'target_new': 'William A Seiter', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Gangland Odyssey'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      " 98%|| 49/50 [03:42<00:04,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.038 = 0.015 + 0.022 + 0.001 avg prob of [ William A Seiter] 0.9855492115020752\n",
      "Delta norm: 10.7578125\n",
      "Change in target norm: 2.689453125 to 11.171875 => 8.484375\n",
      "Division Factor: 3.49609375\n",
      "Right vector norm: 3.076171875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Executing ROME algorithm for the update: [On which instrument(s) was Ariadne musica created to be played on?] -> [ harpsichord]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Ariadne musica\n",
      "Left vector shape: torch.Size([14336])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 10 | Sentence: On which instrument(s) was Ariadne musica created to be played on? harpsich | Token:  musica\n",
      "Rewrite layer is 5\n",
      "Tying optimization objective to 31\n",
      "Recording initial value of v*\n",
      "loss 2.676 = 2.676 + 0.0 + 0.0 avg prob of [ harpsichord] 0.07230957597494125\n",
      "loss 2.516 = 2.304 + 0.211 + 0.001 avg prob of [ harpsichord] 0.10434618592262268\n",
      "loss 1.591 = 1.521 + 0.068 + 0.001 avg prob of [ harpsichord] 0.22958572208881378\n",
      "loss 0.911 = 0.864 + 0.046 + 0.001 avg prob of [ harpsichord] 0.4283520579338074\n",
      "loss 0.608 = 0.564 + 0.042 + 0.001 avg prob of [ harpsichord] 0.5759037733078003\n",
      "loss 0.296 = 0.27 + 0.025 + 0.001 avg prob of [ harpsichord] 0.7691174745559692\n",
      "loss 0.104 = 0.088 + 0.015 + 0.001 avg prob of [ harpsichord] 0.9169325232505798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 17:19:02,401 - easyeditor.editors.editor - INFO - 49 editing: On which instrument(s) was Ariadne musica created to be played on? -> harpsichord  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'On which instrument(s) was Ariadne musica created to be played on?', 'target_new': 'harpsichord', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ariadne musica'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "2024-07-31 17:19:02,401 - easyeditor.editors.editor - INFO - 49 editing: On which instrument(s) was Ariadne musica created to be played on? -> harpsichord  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'On which instrument(s) was Ariadne musica created to be played on?', 'target_new': 'harpsichord', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ariadne musica'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "07/31/2024 17:19:02 - INFO - easyeditor.editors.editor -   49 editing: On which instrument(s) was Ariadne musica created to be played on? -> harpsichord  \n",
      "\n",
      " {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'On which instrument(s) was Ariadne musica created to be played on?', 'target_new': 'harpsichord', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ariadne musica'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}\n",
      "100%|| 50/50 [03:45<00:00,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.043 = 0.029 + 0.012 + 0.001 avg prob of [ harpsichord] 0.9716730117797852\n",
      "Delta norm: 11.546875\n",
      "Change in target norm: 2.88671875 to 11.859375 => 8.96875\n",
      "Division Factor: 3.791015625\n",
      "Right vector norm: 3.044921875\n",
      "Right vector shape: torch.Size([4096])\n",
      "Deltas successfully computed for ['model.layers.5.mlp.down_proj.weight']\n",
      "New weights successfully inserted into ['model.layers.5.mlp.down_proj.weight']\n",
      "Metrics Summary:  {'pre': {'rewrite_acc': 0.3036666666666667}, 'post': {'rewrite_acc': 1.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(metrics, \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp_ROME_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m edited_model\n\u001b[0;32m---> 37\u001b[0m \u001b[43mgc\u001b[49m\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     39\u001b[0m metrics\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "hparams.device = 5\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_ROME_{hparams.model_name}_results.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "metrics # Metrics Summary:  {'pre': {'rewrite_acc': 0.3036666666666667}, 'post': {'rewrite_acc': 1.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 18:35:50,458 - easyeditor.editors.editor - INFO - Instantiating model\n",
      "07/31/2024 18:35:50 - INFO - easyeditor.editors.editor -   Instantiating model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24935b2ed2f1412cb56d4766cc060b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 18:36:00,975 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "07/31/2024 18:36:00 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m hparams\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m editor \u001b[38;5;241m=\u001b[39m BaseEditor\u001b[38;5;241m.\u001b[39mfrom_hparams(hparams)\n\u001b[0;32m----> 3\u001b[0m metrics, edited_model, _ \u001b[38;5;241m=\u001b[39m \u001b[43meditor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# rephrase_prompts=paraphrased_questions,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_new\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# portability_inputs=portability_inputs,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_original_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# test_generation=True,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(metrics, \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmp_ROME_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhparams\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_mod_eval.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m edited_model\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/editors/editor.py:164\u001b[0m, in \u001b[0;36mBaseEditor.edit\u001b[0;34m(self, prompts, target_new, ground_truth, rephrase_prompts, locality_inputs, portability_inputs, sequential_edit, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     requests \u001b[38;5;241m=\u001b[39m _prepare_requests(prompts, target_new, ground_truth, rephrase_prompts, locality_inputs, portability_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit_requests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequential_edit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_generation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/editors/editor.py:273\u001b[0m, in \u001b[0;36mBaseEditor.edit_requests\u001b[0;34m(self, requests, sequential_edit, verbose, test_generation, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m\"\u001b[39m: compute_icl_edit_quality(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtok, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m], request, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mdevice, pre_edit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mcompute_edit_quality\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_generation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generation\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[1;32m    274\u001b[0m     all_metrics\u001b[38;5;241m.\u001b[39mappend(metrics)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_file\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_file\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/evaluate/evaluate.py:64\u001b[0m, in \u001b[0;36mcompute_edit_quality\u001b[0;34m(model, model_name, hparams, tok, record, device, eval_metric, test_generation)\u001b[0m\n\u001b[1;32m     62\u001b[0m rewrite_prompts \u001b[38;5;241m=\u001b[39m record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     63\u001b[0m rephrase_prompts \u001b[38;5;241m=\u001b[39m record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrephrase_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrephrase_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m record\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_rewrite_or_rephrase_quality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrewrite_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocality\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     68\u001b[0m ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportability\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/evaluate/evaluate.py:133\u001b[0m, in \u001b[0;36mcompute_rewrite_or_rephrase_quality\u001b[0;34m(model, model_name, hparams, tok, prompt, target_new, device, test_rephrase, eval_metric)\u001b[0m\n\u001b[1;32m    131\u001b[0m         acc \u001b[38;5;241m=\u001b[39m test_seq2seq_batch_prediction_acc(model, tok, hparams, prompt, target_new, device)\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest_prediction_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     ret \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc\n\u001b[1;32m    136\u001b[0m     }\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/data/baixiang/workspace/edit/factuality/code/easyeditor/evaluate/evaluate_utils.py:138\u001b[0m, in \u001b[0;36mtest_prediction_acc\u001b[0;34m(model, tok, hparams, prompts, targets, device, locality, vanilla_generation)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m locality:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(answers[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [answers,]\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43manswers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    139\u001b[0m     res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ans,label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(answers,labels):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "hparams.device = 0\n",
    "editor = BaseEditor.from_hparams(hparams)\n",
    "metrics, edited_model, _ = editor.edit(\n",
    "    prompts=questions,\n",
    "    # rephrase_prompts=paraphrased_questions,\n",
    "    target_new=targets,\n",
    "    subject=subjects,\n",
    "    # portability_inputs=portability_inputs,\n",
    "    summary_metrics=True,\n",
    "    keep_original_weight=True,\n",
    "    # test_generation=True,\n",
    ")\n",
    "\n",
    "json.dump(metrics, open(os.path.join('../results/', f'tmp_ROME_{hparams.model_name}_results_mod_eval.json'), 'w'), indent=4)\n",
    "del edited_model\n",
    "gc.collect()\n",
    "\n",
    "metrics # Metrics Summary:  {'pre': {'rewrite_acc': 0.3036666666666667}, 'post': {'rewrite_acc': 1.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env24may",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
